{
  "hash": "3029394c92d45139a12d4b484387ebe7",
  "result": {
    "markdown": "---\ntitle: \"Applied Machine Learning Using mlr3 in R\"\ndate: \"2023-08-16\"\ndate-modified: \"2023-08-25\"\nimage: \"logo.png\"\ncategories: \n  - Machine Learning\n  - R\n  - mlr3\n---\n\n\n\n\n::: {.callout-note title='Progress'}\nLearning Progress: 14.67%.\n:::\n\n::: {.callout-tip title=\"Learning Source\"}\n- <https://mlr3book.mlr-org.com/>\n- 中文翻译由 ChatGPT 3.5 提供\n:::\n\n# Getting Started {.unnumbered}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\nlibrary(mlr3pipelines)\nlibrary(mlr3benchmark)\nlibrary(ggplot2)\n\ntheme_set(theme_minimal())\n```\n:::\n\n\n# Introduction and Overview\n\n`mlr3` by Example:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\n\ntask = tsk(\"penguins\")\nsplit = partition(task)\nlearner = lrn(\"classif.rpart\")\n\nlearner$train(task, row_ids = split$train)\nlearner$model\n\nprediction = learner$predict(task, row_ids = split$test)\nprediction\n\nprediction$score(msr(\"classif.acc\"))\n```\n:::\n\n\nWe use dictionaries to group large collections of relevant objects so they can be listed and retrieved easily.\nFor example, you can see an overview of available learners (that are in loaded packages) and their properties with `as.data.table(mlr_learners)` or by calling the sugar function without any arguments, e.g. `lrn()`.\n\n> 我们使用字典来分组大量相关对象，以便可以轻松地列出和检索它们。例如，您可以通过 `as.data.table(mlr_learners)` 查看可用学习器（位于加载的包中）及其属性的概述，或者通过调用糖函数而不带任何参数，例如 `lrn()`。\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nas.data.table(mlr_learners)[1:3]\n#>                    key                              label task_type\n#> 1:   classif.cv_glmnet                               <NA>   classif\n#> 2:       classif.debug   Debug Learner for Classification   classif\n#> 3: classif.featureless Featureless Classification Learner   classif\n#>                                           feature_types\n#> 1:                              logical,integer,numeric\n#> 2:     logical,integer,numeric,character,factor,ordered\n#> 3: logical,integer,numeric,character,factor,ordered,...\n#>                    packages\n#> 1: mlr3,mlr3learners,glmnet\n#> 2:                     mlr3\n#> 3:                     mlr3\n#>                                                               properties\n#> 1:                         multiclass,selected_features,twoclass,weights\n#> 2:                         hotstart_forward,missings,multiclass,twoclass\n#> 3: featureless,importance,missings,multiclass,selected_features,twoclass\n#>    predict_types\n#> 1: response,prob\n#> 2: response,prob\n#> 3: response,prob\n```\n:::\n\n\n# Fundamentals {.unnumbered}\n\n# Data and Basic Modeling\n\n## Tasks\n\n### Constructing Tasks\n\n`mlr3` includes a few predefined machine learning tasks in the `mlr_tasks` Dictionary.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmlr_tasks\n#> <DictionaryTask> with 21 stored values\n#> Keys: ames_housing, bike_sharing, boston_housing, breast_cancer,\n#>   german_credit, ilpd, iris, kc_housing, moneyball, mtcars, optdigits,\n#>   penguins, penguins_simple, pima, ruspini, sonar, spam, titanic,\n#>   usarrests, wine, zoo\n# the same as \n# tsk()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntsk_mtcars = tsk(\"mtcars\")\ntsk_mtcars\n#> <TaskRegr:mtcars> (32 x 11): Motor Trends\n#> * Target: mpg\n#> * Properties: -\n#> * Features (10):\n#>   - dbl (10): am, carb, cyl, disp, drat, gear, hp, qsec, vs, wt\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# create my own regression task\ndata(\"mtcars\", package = \"datasets\")\nmtcars_subset = subset(mtcars, select = c(\"mpg\", \"cyl\", \"disp\"))\ntsk_mtcars = as_task_regr(mtcars_subset, target = \"mpg\", id = \"cars\")\ntsk_mtcars\n#> <TaskRegr:cars> (32 x 3)\n#> * Target: mpg\n#> * Properties: -\n#> * Features (2):\n#>   - dbl (2): cyl, disp\n```\n:::\n\n\nThe `id` argument is optional and specifies an identifier for the task that is used in plots and summaries; if omitted the variable name of the data will be used as the `id`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3viz)\nautoplot(tsk_mtcars, type = \"pairs\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n### Retrieving Data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nc(tsk_mtcars$nrow, tsk_mtcars$ncol)\n#> [1] 32  3\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nc(Features = tsk_mtcars$feature_names,\n  Target = tsk_mtcars$target_names)\n#> Features1 Features2    Target \n#>     \"cyl\"    \"disp\"     \"mpg\"\n```\n:::\n\n\nRow IDs are not used as features when training or predicting but are metadata that allow access to individual observations. Note that row IDs are not the same as row numbers.\n\nThis design decision allows tasks and learners to transparently operate on real database management systems, where primary keys are required to be unique, but not necessarily consecutive.\n\n> 行ID在训练或预测时不作为特征使用，而是元数据，用于访问个别观测数据。需要注意的是，行ID与行号不同。\n>\n> 这种设计决策使得任务和学习器能够透明地在真实的数据库管理系统上运行，其中要求主键是唯一的，但不一定连续。\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = as_task_regr(data.frame(x = runif(5), y = runif(5)),\n                    target = \"y\")\ntask$row_ids\n#> [1] 1 2 3 4 5\n\ntask$filter(c(4, 1, 3))\ntask$row_ids\n#> [1] 1 3 4\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntsk_mtcars$data()[1:3]\n#>     mpg cyl disp\n#> 1: 21.0   6  160\n#> 2: 21.0   6  160\n#> 3: 22.8   4  108\ntsk_mtcars$data(rows = c(1, 5, 10), cols = tsk_mtcars$feature_names)\n#>    cyl  disp\n#> 1:   6 160.0\n#> 2:   8 360.0\n#> 3:   6 167.6\n```\n:::\n\n\n### Task Mutators\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntsk_mtcars_small = tsk(\"mtcars\")\ntsk_mtcars_small$select(\"cyl\")\ntsk_mtcars_small$filter(2:3)\ntsk_mtcars_small$data()\n#>     mpg cyl\n#> 1: 21.0   6\n#> 2: 22.8   4\n```\n:::\n\n\nAs `R6` uses reference semantics, you need to use `$clone()` if you want to modify a task while keeping the original object intact.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntsk_mtcars = tsk(\"mtcars\")\ntsk_mtcars_clone = tsk_mtcars$clone()\ntsk_mtcars_clone$filter(1:2)\ntsk_mtcars_clone$head()\n#>    mpg am carb cyl disp drat gear  hp  qsec vs    wt\n#> 1:  21  1    4   6  160  3.9    4 110 16.46  0 2.620\n#> 2:  21  1    4   6  160  3.9    4 110 17.02  0 2.875\n```\n:::\n\n\nTo add extra rows and columns to a task, you can use `$rbind()` and `$cbind()` respectively:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntsk_mtcars_small\n#> <TaskRegr:mtcars> (2 x 2): Motor Trends\n#> * Target: mpg\n#> * Properties: -\n#> * Features (1):\n#>   - dbl (1): cyl\ntsk_mtcars_small$cbind(data.frame(disp = c(150, 160)))\ntsk_mtcars_small$rbind(data.frame(mpg = 23, cyl = 5, disp = 170))\ntsk_mtcars_small$data()\n#>     mpg cyl disp\n#> 1: 21.0   6  150\n#> 2: 22.8   4  160\n#> 3: 23.0   5  170\n```\n:::\n\n\n## Learners\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# all the learners available in mlr3\nmlr_learners\n#> <DictionaryLearner> with 46 stored values\n#> Keys: classif.cv_glmnet, classif.debug, classif.featureless,\n#>   classif.glmnet, classif.kknn, classif.lda, classif.log_reg,\n#>   classif.multinom, classif.naive_bayes, classif.nnet, classif.qda,\n#>   classif.ranger, classif.rpart, classif.svm, classif.xgboost,\n#>   clust.agnes, clust.ap, clust.cmeans, clust.cobweb, clust.dbscan,\n#>   clust.diana, clust.em, clust.fanny, clust.featureless, clust.ff,\n#>   clust.hclust, clust.kkmeans, clust.kmeans, clust.MBatchKMeans,\n#>   clust.mclust, clust.meanshift, clust.pam, clust.SimpleKMeans,\n#>   clust.xmeans, regr.cv_glmnet, regr.debug, regr.featureless,\n#>   regr.glmnet, regr.kknn, regr.km, regr.lm, regr.nnet, regr.ranger,\n#>   regr.rpart, regr.svm, regr.xgboost\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn(\"regr.rpart\")\n#> <LearnerRegrRpart:regr.rpart>: Regression Tree\n#> * Model: -\n#> * Parameters: xval=0\n#> * Packages: mlr3, rpart\n#> * Predict Types:  [response]\n#> * Feature Types: logical, integer, numeric, factor, ordered\n#> * Properties: importance, missings, selected_features, weights\n```\n:::\n\n\nAll `Learner` objects include the following metadata, which can be seen in the output above:\n\n- `$feature_types`: the type of features the learner can handle.\n- `$packages`: the packages required to be installed to use the learner.\n- `$properties`: the properties of the learner. For example, the “missings” properties means a model can handle missing data, and “importance” means it can compute the relative importance of each feature.\n- `$predict_types`: the types of prediction that the model can make.\n- `$param_set`: the set of available hyperparameters.\n\n### Training\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load mtcars task\ntsk_mtcars = tsk(\"mtcars\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load a regression tree\nlrn_rpart = lrn(\"regr.rpart\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# pass the task to the learner via $train()\nlrn_rpart$train(tsk_mtcars)\n```\n:::\n\n\nAfter training, the fitted model is stored in the `$model` field for future inspection and prediction:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn_rpart$model\n#> n= 32 \n#> \n#> node), split, n, deviance, yval\n#>       * denotes terminal node\n#> \n#> 1) root 32 1126.04700 20.09062  \n#>   2) cyl>=5 21  198.47240 16.64762  \n#>     4) hp>=192.5 7   28.82857 13.41429 *\n#>     5) hp< 192.5 14   59.87214 18.26429 *\n#>   3) cyl< 5 11  203.38550 26.66364 *\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsplits = partition(tsk_mtcars)\nsplits\n#> $train\n#>  [1]  1  2  3  4  5 10 25 27 32  6  7 13 14 15 22 23 24 29 19 26 28\n#> \n#> $test\n#>  [1]  8  9 21 30 11 12 16 17 31 18 20\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn_rpart$train(tsk_mtcars, row_ids = splits$train)\n```\n:::\n\n\n### Predicting\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprediction = lrn_rpart$predict(tsk_mtcars, row_ids = splits$test)\nprediction\n#> <PredictionRegr> for 11 observations:\n#>     row_ids truth response\n#>           8  24.4 25.03750\n#>           9  22.8 25.03750\n#>          21  21.5 25.03750\n#> ---                       \n#>          31  15.0 16.43077\n#>          18  32.4 25.03750\n#>          20  33.9 25.03750\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(prediction)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmtcars_new = data.table(cyl = c(5, 6), disp = c(100, 120),\n  hp = c(100, 150), drat = c(4, 3.9), wt = c(3.8, 4.1),\n  qsec = c(18, 19.5), vs = c(1, 0), am = c(1, 1),\n  gear = c(6, 4), carb = c(3, 5))\nprediction = lrn_rpart$predict_newdata(mtcars_new)\nprediction\n#> <PredictionRegr> for 2 observations:\n#>  row_ids truth response\n#>        1    NA  25.0375\n#>        2    NA  25.0375\n```\n:::\n\n\n### Hyperparameters\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn_rpart$param_set\n#> <ParamSet>\n#>                 id    class lower upper nlevels        default value\n#>  1:             cp ParamDbl     0     1     Inf           0.01      \n#>  2:     keep_model ParamLgl    NA    NA       2          FALSE      \n#>  3:     maxcompete ParamInt     0   Inf     Inf              4      \n#>  4:       maxdepth ParamInt     1    30      30             30      \n#>  5:   maxsurrogate ParamInt     0   Inf     Inf              5      \n#>  6:      minbucket ParamInt     1   Inf     Inf <NoDefault[3]>      \n#>  7:       minsplit ParamInt     1   Inf     Inf             20      \n#>  8: surrogatestyle ParamInt     0     1       2              0      \n#>  9:   usesurrogate ParamInt     0     2       3              2      \n#> 10:           xval ParamInt     0   Inf     Inf             10     0\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# change hyperparameter\nlrn_rpart = lrn(\"regr.rpart\", maxdepth = 1)\n\nlrn_rpart$param_set$values\n#> $xval\n#> [1] 0\n#> \n#> $maxdepth\n#> [1] 1\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# learned regression tree\nlrn_rpart$train(tsk(\"mtcars\"))$model\n#> n= 32 \n#> \n#> node), split, n, deviance, yval\n#>       * denotes terminal node\n#> \n#> 1) root 32 1126.0470 20.09062  \n#>   2) cyl>=5 21  198.4724 16.64762 *\n#>   3) cyl< 5 11  203.3855 26.66364 *\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# another way to update hyperparameters\nlrn_rpart$param_set$values$maxdepth = 2\nlrn_rpart$param_set$values\n#> $xval\n#> [1] 0\n#> \n#> $maxdepth\n#> [1] 2\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# now with depth 2\nlrn_rpart$train(tsk(\"mtcars\"))$model\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# or with set_values()\nlrn_rpart$param_set$set_values(xval = 2, cp = .5)\nlrn_rpart$param_set$values\n#> $xval\n#> [1] 2\n#> \n#> $maxdepth\n#> [1] 2\n#> \n#> $cp\n#> [1] 0.5\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.callout-tip title=\"To be continued\"}\n- <https://mlr3book.mlr-org.com/chapters/chapter2/data_and_basic_modeling.html#sec-param-set>\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}