{
  "hash": "a37d5f2cdf801e431193093ef41e13bd",
  "result": {
    "markdown": "---\ntitle: \"Python Data Science Handbook\"\ndate: \"2023-07-03\"\ndate-modified: \"2023-07-11\"\nimage: \"img.png\"\ncategories: \n  - Data Science\n  - Python\nexecute: \n  warning: false\n  message: false\nfig-align: center\n---\n\n::: {.callout-note title='Progress'}\n<!-- `r stfun::progress(50, 66, stop = TRUE)` -->\nLearning Progress: Paused, current progress 75.76%.⏱\n:::\n\n::: {.callout-tip title=\"Learning Source\"}\n- <https://jakevdp.github.io/PythonDataScienceHandbook/>\n:::\n\n# IPython Beyond Normal Python\n\n## Help and Documentation in IPython\n\n- If you play with this much, you'll notice that sometimes the `??` suffix doesn't display any source code: this is generally because the object in question is not implemented in Python, but in C or some other compiled extension language. If this is the case, the `??` suffix gives the same output as the `?` suffix. You'll find this particularly with many of Python's built-in objects and types.\n\n- Though Python has no strictly enforced distinction between public/external attributes and private/internal attributes, by convention a preceding underscore is used to denote the latter. For clarity, these private methods and special methods are omitted from the list by default, but it's possible to list them by explicitly typing the underscore.\n\n## IPython Magic Commands\n\n- As you begin developing more extensive code, you will likely find yourself working in IPython for interactive exploration, as well as a text editor to store code that you want to reuse. Rather than running this code in a new window, it can be convenient to run it within your IPython session. This can be done with the `%run` magic command.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# file: myscript.py\n%run myscript.py\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1 squared is 1\n2 squared is 4\n3 squared is 9\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 672x480 with 0 Axes>\n```\n:::\n:::\n\n\n- Another example of a useful magic function is `%timeit`, which will automatically determine the execution time of the single-line Python statement that follows it. For example, we may want to check the performance of a list comprehension:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n%timeit L = [n ** 2 for n in range(1000)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n59 µs ± 6.87 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n%%timeit\nL = []\nfor n in range(1000):\n    L.append(n ** 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n68.7 µs ± 8.66 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n```\n:::\n:::\n\n\n- Like normal Python functions, IPython magic functions have docstrings, and this useful documentation can be accessed in the standard manner. So, for example, to read the documentation of the `%timeit` magic function, simply type this:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n%timeit?\n```\n:::\n\n\n## Input and Output History\n\nThe standard Python shell contains just one simple shortcut for accessing previous output: the variable `_` (i.e., a single underscore) is kept updated with the previous output. This works in IPython as well. \nBut IPython takes this a bit further—you can use a double underscore to access the second-to-last output, and a triple underscore to access the third-to-last output (skipping any commands with no output). \nIPython stops there: more than three underscores starts to get a bit hard to count, and at that point it's easier to refer to the output by line number.\n\nThere is one more shortcut I should mention, however—a shorthand for `Out[X]` is `_X` (i.e., a single underscore followed by the line number):\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n_2\n```\n:::\n\n\nSometimes you might wish to suppress the output of a statement,\nor maybe the command you're executing produces a result that you'd prefer not to store in your output history,\nperhaps so that it can be deallocated when other references are removed.\nThe easiest way to suppress the output of a command is to add a semicolon to the end of the line:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nimport math\n\nmath.sin(2) + math.cos(2);\n```\n:::\n\n\nThe result is computed silently, and the output is neither displayed on the screen nor stored in the `Out` dictionary:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n14 in Out\n```\n:::\n\n\n# Introduction to NumPy\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nimport numpy as np\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nnp.__version__\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\n'1.24.3'\n```\n:::\n:::\n\n\n## Understanding Data Types in Python\n\n### A Python List Is More Than Just a List\n\n- At the implementation level, the array essentially contains a single pointer to one contiguous block of data. The Python list, on the other hand, contains a pointer to a block of pointers, each of which in turn points to a full Python object like the Python integer we saw earlier. Again, **the advantage of the list is flexibility**: because each list element is a full structure containing both data and type information, the list can be filled with data of any desired type. Fixed-type NumPy-style arrays lack this flexibility, but are much more efficient for storing and manipulating data.\n\n### Creating Arrays from Python Lists\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# Integer array\nnp.array([1, 4, 2, 5, 3])\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\narray([1, 4, 2, 5, 3])\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n# Integer upcast to floating point\nnp.array([3.14, 3, 2, 3])\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\narray([3.14, 3.  , 2.  , 3.  ])\n```\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# Set data type\nnp.array([1, 2, 3, 4], dtype = np.float32)\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\narray([1., 2., 3., 4.], dtype=float32)\n```\n:::\n:::\n\n\nNumPy arrarys can be multidimensional:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# Nested list result in multidismentional arrays\nnp.array([range(i, i + 3) for i in [2, 4, 6]])\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\narray([[2, 3, 4],\n       [4, 5, 6],\n       [6, 7, 8]])\n```\n:::\n:::\n\n\n### Creating Arrays from Scratch\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# Create a length-10 integer array filled with 0s\nnp.zeros(10, dtype = int)\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n```\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Create a 3x5 floating-point array filled with 1s\nnp.ones((3, 5), dtype = float)\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```\narray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n# Create a 3x5 array filled with 3.14\nnp.full((3, 5), 3.14)\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```\narray([[3.14, 3.14, 3.14, 3.14, 3.14],\n       [3.14, 3.14, 3.14, 3.14, 3.14],\n       [3.14, 3.14, 3.14, 3.14, 3.14]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# Create an array filled with a linear sequence\nnp.arange(0, 20, 2)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\narray([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\n```\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# Create an array of five values evenly spaced between 0 and 1\nnp.linspace(0, 1, 5)\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\narray([0.  , 0.25, 0.5 , 0.75, 1.  ])\n```\n:::\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n# Create a 3x3 array of uniformly distributed pseudorandom\n# values between 0 and 1\nnp.random.random((3, 3))\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\narray([[0.65279032, 0.63505887, 0.99529957],\n       [0.58185033, 0.41436859, 0.4746975 ],\n       [0.6235101 , 0.33800761, 0.67475232]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n# Create a 3x3 array of normally distributed pseudorandom\n# values with mean 0 and standard deviation 1\nnp.random.normal(0, 1, (3, 3))\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\narray([[ 1.0657892 , -0.69993739,  0.14407911],\n       [ 0.3985421 ,  0.02686925,  1.05583713],\n       [-0.07318342, -0.66572066, -0.04411241]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n# Create a 3x3 array of pseudorandom integers in the interval [0, 10)\nnp.random.randint(0, 10, (3, 3))\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\narray([[7, 2, 9],\n       [2, 3, 3],\n       [2, 3, 4]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\n# Create a 3x3 identity matrix\nnp.eye(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n# Create an uninitialized array of three integers; the values will be\n# whatever happens to already exist at that memory location\nnp.empty(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\narray([1., 1., 1.])\n```\n:::\n:::\n\n\n## The Basics of NumPy Arrays\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nnp.random.seed(0)\n\nx1 = np.random.randint(10, size = 6)\nx2 = np.random.randint(10, size = (3, 4))\nx3 = np.random.randint(10, size = (3, 4, 5))\n```\n:::\n\n\nEach array has attributes `ndim` (the number of dimensions), `shape` (the size of each dimension), and `size` (the total size of the array):\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nprint(\"x3 ndim: \", x3.ndim)\nprint(\"x3 shape: \", x3.shape)\nprint(\"x3 size: \", x3.size)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nx3 ndim:  3\nx3 shape:  (3, 4, 5)\nx3 size:  60\n```\n:::\n:::\n\n\n# Machine Learning\n\n## What Is Machine Learning?\n\nFundamentally, machine learning involves building mathematical models to help understand data. \"Learning\" enters the fray when we give these models tunable parameters that can be adapted to observed data; in this way the program can be considered to be \"learning\" from the data. Once these models have been fit to previously seen data, they can be used to predict and understand aspects of newly observed data.1\n\n## Introducing Scikit-Learn\n\n### Data Representation in Scikit-Learn\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nimport seaborn as sns\niris = sns.load_dataset('iris')\niris.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n%matplotlib inline\nsns.set()\nsns.pairplot(iris, hue = 'species', size = 1.5)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-28-output-1.png){width=688 height=567 fig-align='center'}\n:::\n:::\n\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nX_iris = iris.drop(\"species\", axis = 1)\nX_iris.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\n(150, 4)\n```\n:::\n:::\n\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\ny_iris = iris[\"species\"]\ny_iris.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=59}\n```\n(150,)\n```\n:::\n:::\n\n\n### Scikit-Learn's Estimator API\n\n#### Supervised learning example: Simple linear regression\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nrng = np.random.RandomState(42)\nx = 10 * rng.rand(50)\ny = 2 * x - 1 + rng.randn(50)\nplt.scatter(x, y)\n```\n\n::: {.cell-output .cell-output-display execution_count=60}\n```\n<matplotlib.collections.PathCollection at 0x1da862f1690>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-31-output-2.png){width=581 height=415 fig-align='center'}\n:::\n:::\n\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nimport sklearn\nfrom sklearn.linear_model import LinearRegression\n```\n:::\n\n\nAn important point is that **a class of model is not the same as an instance of a model**.\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nmodel = LinearRegression(fit_intercept = True)\nmodel\n```\n\n::: {.cell-output .cell-output-display execution_count=62}\n```{=html}\n<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\nKeep in mind that when the model is instantiated, the only action is the storing of these hyperparameter values. In particular, we have not yet applied the model to any data: the Scikit-Learn API makes very clear the distinction between *choice of model* and *application of model to data*.\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\n# Arrange data into a features matrix and target vector\nX = x[:, np.newaxis]\nX.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=63}\n```\n(50, 1)\n```\n:::\n:::\n\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\n# Fit the model to your data\nmodel.fit(X, y)\n```\n\n::: {.cell-output .cell-output-display execution_count=64}\n```{=html}\n<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\nIn Scikit-Learn, by convention all model parameters that were learned during the `fit()` process have trailing underscores; for example in this linear model, we have the following:\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\nmodel.coef_\n```\n\n::: {.cell-output .cell-output-display execution_count=65}\n```\narray([1.9776566])\n```\n:::\n:::\n\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\nmodel.intercept_\n```\n\n::: {.cell-output .cell-output-display execution_count=66}\n```\n-0.903310725531111\n```\n:::\n:::\n\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\n# Predict labels for unknown data\nxfit = np.linspace(-1, 11)\nXfit = xfit[:, np.newaxis]\nyfit = model.predict(Xfit)\n```\n:::\n\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\nplt.scatter(x, y)\nplt.plot(xfit, yfit)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-39-output-1.png){width=569 height=415 fig-align='center'}\n:::\n:::\n\n\n## Hyperparameters and Model Validation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.callout-tip title=\"To be continued\"}\n- <https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html>\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}