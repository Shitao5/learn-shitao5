---
title: "mlr3verse 技术手册"
date: "2023-09-07"
date-modified: "2023-09-08"
image: "cover.jpg"
categories: 
  - Machine Learning
  - R
  - mlr3
---

::: {.callout-note title='Progress'}
`r stfun::progress(57, 137)`
:::

::: {.callout-tip title="Learning Source"}
- 张敬信老师 QQ 群（222427909）文件
- <https://github.com/zhjx19/RConf15/tree/main>
:::

```{r}
#| message: false
library(mlr3verse)
```

# 基础知识

## 任务：封装数据

任务是表格数据的封装，自变量为特征，因变量为目标或结果变量。

```{r}
tsks() # 查看所有自带任务
```

```{r}
# 创建任务
dat = tsk("german_credit")$data() # 提取数据
task = as_task_classif(dat, target = "credit_risk")
task
```

```{r}
# 选择特征
task$select(cols = setdiff(task$feature_names, "telephone"))
task
```

```{r}
# 划分训练集、测试集
set.seed(1)
split = partition(task, ratio = .7)
```

`stratify = TRUE` 默认按目标变量分层，得到训练集和测试集的索引（行号）。

## 学习器：封装算法

```{r}
lrns()  # 查看所有自带学习器名字
```

```{r}
# 选择随机森林分类学习器
learner = lrn("classif.ranger", num.trees = 100, predict_type = "prob")
learner
```

学习器 `$model` 属性为 `NULL`，用 `$train()` 方法在训练集上训练模型，模型结果存入 `$model`，再用 `predict()` 方法在测试集上做预测，得到结果是 `Prediction` 对象。

```{r}
learner$train(task, row_ids = split$train)
learner$model
```

```{r}
#| eval: false
prediction = learner$predict(task, row_ids = split$test)
prediction
```

## 性能评估

```{r}
msrs() # 查看所有支持的性能度量指标
```

用预测对象的 `$score()` 方法，计算该度量指标的得分：

```{r}
#| eval: false
prediction$score(msr("classif.acc"))  # 准确率
```

```{r}
#| eval: false
# 绘制 ROC 曲线
library(precrec)
autoplot(prediction, type = "roc")
```

```{r}
#| eval: false
prediction$score(msr("classif.auc"))  # auc 面积
```

## 重抽样

```{r}
rsmps()  # 查看所有支持的重抽样方法
```

```{r}
cv10 = rsmp("cv", folds = 10)  # 10 折交叉验证
```

### 实例化重抽样对象

```{r}
cv10$instantiate(task)  # 实例化
cv10$iters  # 数据副本数
```

```{r}
#| eval: false
cv10$train_set(1)  # 第 1 个数据副本的训练集索引
cv10$test_set(1)   # 第 1 个数据副本的测试集索引
```

### 使用重抽样

```{r}
#| message: false
rr =  resample(task, learner, cv10, store_models = TRUE)
```

```{r}
rr$aggregate(msr("classif.acc"))  # 所有重抽样的平均准确率
```

```{r}
rr$score(msr("classif.acc"))  # 各个重抽样的平均准确率
```

```{r}
#| eval: false

# 查看第 1 个数据副本（第 1 折）上的结果
rr$resampling$train_set(1)  # 第 1 折的训练集索引
rr$learners[[1]]$model      # 第 1 折学习器的拟合模型
rr$predictions()[[1]]       # 第 1 折的预测结果
```

## 基准测试

基准测试（benchmark）用来比较不同学习器（算法）、在多个任务（数据）和/或不同重抽样策略（多个数据副本）上的平均性能表现。

基准测试时有个关键问题：测试的公平性。即每个算法的每次测试必须在相同的重抽样训练集拟合模型，在相同的重抽样测试集评估性能。这些事情 `beachmark()` 会自动做好。

```{r}
tasks = tsk("sonar")  # 可以多任务
learners = lrns(c("classif.rpart", "classif.kknn", "classif.ranger", "classif.svm"),
                predict_type = "prob")
design = benchmark_grid(tasks, learners, rsmps("cv", folds = 5))
design
```

```{r}
#| results: hide
bmr = benchmark(design)  # 执行基准测试
bmr$aggregate(list(msr("classif.acc"), msr("classif.auc")))  # 汇总基准测试结果
```

```{r}
# 可视化：对比性能
autoplot(bmr, type = "roc")  # ROC 曲线
autoplot(bmr, measure = msr("classif.auc"))  # AUC 箱线图
```

## 可视化

mlr3viz 包定义了 `autoplot()` 函数来用 ggplot2 绘图。通常一个对象有不止一种类型的图，可以通过 `type` 参数来改变绘图。图形使用 viridis 的调色板，外观由 theme 参数控制，默认是 minimal 主题。

### 可视化任务

#### 分类任务

```{r}
task = tsk("penguins")
task$select(c("body_mass", "bill_length"))
```

```{r}
#| warning: false
#| message: false
autoplot(task, type = "target")  # "target" 图：条形图展示目标变量的各类别频数
autoplot(task, type = "duo")     # "duo" 图：箱线图展示多个特征的分布
autoplot(task, type = "pairs")   # "pairs" 图：展示多个特征的成对比较
```

#### 回归任务

```{r}
task = tsk("mtcars")
task$select(c("am", "carb"))
```

```{r}
autoplot(task, type = "target")  # "target" 图：箱线图展示目标变量的分布
autoplot(task, type = "pairs")   # "pairs" 图：展示多个特征与目标变量的成对比较
```

### 可视化学习器

#### glmnet 回归学习器

```{r}
task = tsk("mtcars")
learner = lrn("regr.glmnet")
learner$train(task)
autoplot(learner)
```

#### 决策树学习器

```{r}
# 分类树
task = tsk("penguins")
learner = lrn("classif.rpart", keep_model = TRUE)
learner$train(task)
autoplot(learner)
```

```{r}
# 回归树
task = tsk("mtcars")
learner = lrn("regr.rpart", keep_model = TRUE)
learner$train(task)
autoplot(learner)
```

#### 层次聚类学习器

```{r}
# 层次聚类树
task = tsk("usarrests")
learner = lrn("clust.hclust")
learner$train(task)
autoplot(learner, type = "dend", task = task)
```

```{r}
# 碎石图
autoplot(learner, type = "scree")
```

### 可视化预测对象

#### 分类预测对象

```{r}
# "stacked" 图：堆叠条形图展示预测类别和真实类别频数对比
task = tsk("spam")
learner = lrn("classif.rpart", predict_type = "prob")
pred = learner$train(task)$predict(task)
autoplot(pred, type = "stacked")
```

```{r}
# ROC 曲线：展示不同阈值下的真阳率与假阳率
autoplot(pred, type = "roc")
```

```{r}
# PR 曲线：展示不同阈值下的查准率与召回率
autoplot(pred, type = "prc")
```

```{r}
# “threshold” 图：展示二元分类在不同阈值下的性能
autoplot(pred, type = "threshold")
```

#### 回归预测对象

```{r}
# "xy" 图：散点图展示回归预测的真实值与预测值
task = tsk("boston_housing")
learner = lrn("regr.rpart")
pred = learner$train(task)$predict(task)
autoplot(pred, type = "xy")
```

```{r}
# "residual" 图：绘制响应的残差图
autoplot(pred, type = "residual")
```

```{r}
#| message: false
# "histogram" 图：残差直方图展示残差的分布
autoplot(pred, type = "histogram")
```

#### 聚类预测对象

```{r}
#| warning: false
# "scatter" 图：绘制按聚类预测结果着色的散点图
task = tsk("usarrests")
learner = lrn("clust.kmeans", centers = 3)
pred = learner$train(task)$predict(task)
autoplot(pred, task, type = "scatter")
```

```{r}
# "sil" 图：展示聚类的silhouette 宽度，虚线是平均silhouette 宽度
autoplot(pred, task, type = "sil")
```

```{r}
# "pca" 图：展示数据的前两个主成分，不同聚类用颜色区分
autoplot(pred, task, type = "pca")
```

### 可视化重抽样结果

#### 分类重抽样结果

```{r}
# "boxplot"/"histogram" 图：箱线图展示性能度量的分布
task = tsk("sonar")
learner = lrn("classif.rpart", predict_type = "prob")
resampling = rsmp("cv")
rr = resample(task, learner, resampling)
autoplot(rr, type = "boxplot")
autoplot(rr, type = "histogram")
```

```{r}
# ROC 曲线：展示不同阈值下的真阳率与假阳率
autoplot(rr, type = "roc")
```

```{r}
# PR 曲线：展示不同阈值下的查准率与召回率
autoplot(rr, type = "prc")
```

```{r}
#| warning: false
# "prediction" 图：展示两个特征表示的测试集样本点和以背景色区分的预测类别
task = tsk("pima")
task$filter(seq(100))
task$select(c("age", "glucose"))
learner = lrn("classif.rpart")
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling, store_models = TRUE)
autoplot(rr, type = "prediction")
```

```{r}
#| warning: false
# 若将学习器的预测类型改为"prob"，则用颜色深浅展示概率值
learner = lrn("classif.rpart", predict_type = "prob")
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling, store_models = TRUE)
autoplot(rr, type = "prediction")
```

```{r}
#| warning: false
# 上面是只绘制测试集，也可以加入训练集
learner = lrn("classif.rpart", predict_type = "prob",
              predict_sets = c("train", "test"))
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling, store_models = TRUE)
autoplot(rr, type = "prediction",
         predict_sets = c("train", "test"))
```

```{r}
# "prediction" 图也可以绘制分类特征
task = tsk("german_credit")
task$filter(seq(100))
task$select(c("housing", "employment_duration"))
learner = lrn("classif.rpart")
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling, store_models = TRUE)
autoplot(rr, type = "prediction")
```

#### 回归重抽样结果

```{r}
# "prediction" 图：绘制一个特征与响应的散点图，散点表示测试集中的观测
task = tsk("boston_housing")
task$select("age")
task$filter(seq(100))
learner = lrn("regr.rpart")
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling, store_models = TRUE)
autoplot(rr, type = "prediction")
```

```{r}
# 若将学习器的预测类型改为"se"，还可以加上置信带
learner = lrn("regr.lm", predict_type = "se")
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling, store_models = TRUE)
autoplot(rr, type = "prediction")
```

```{r}
# 上面是只绘制测试集，也可以加入训练集
task$select("age")
learner = lrn("regr.lm", predict_type = "se",
              predict_sets = c("train", "test"))
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling, store_models = TRUE)
autoplot(rr, type = "prediction",
         predict_sets = c("train", "test"))
```

```{r}
# 还可以将预测面添加到背景
task = tsk("boston_housing")
task$select(c("age", "rm"))
task$filter(seq(100))
learner = lrn("regr.rpart")
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling, store_models = TRUE)
autoplot(rr, type = "prediction")
```

### 可视化基准测试结果

```{r}
#| results: hide
# "boxplot" 图：箱线图展示了多个任务的基准测试的性能分布
tasks = tsks(c("pima", "sonar"))
learners = lrns(c("classif.featureless", "classif.rpart", "classif.xgboost"),
                predict_type = "prob")
resampling = rsmps("cv")
bmr = benchmark(benchmark_grid(tasks, learners, resampling))
autoplot(bmr, type = "boxplot")
```

```{r}
#| results: hide
# 绘制一个任务与多个学习器的基准测试
task = tsk("pima")
learners = lrns(c("classif.featureless", "classif.rpart", "classif.xgboost"),
                predict_type = "prob")
resampling = rsmp("cv")
bmr = benchmark(benchmark_grid(task, learners, resampling))
```

```{r}
autoplot(bmr, type = "roc")
autoplot(bmr, type = "prc")
```

### 可视化调参实例

```{r}
#| results: hide
# "performance" 图：散点折线图展示随批次的模型性能变化
instance = tune(
  tuner = tnr("gensa"),
  task = tsk("sonar"),
  learner = lts(lrn("classif.rpart")),
  resampling = rsmp("holdout"),
  measures = msr("classif.ce"),
  term_evals = 100
)
autoplot(instance, type = "performance")
```


```{r}
# "parameter" 图：散点图展示每个超参数取值与模型性能变化
autoplot(instance, type = "parameter", cols_x = c("cp", "minsplit"))
```

```{r}
# "marginal" 图：展示不同超参数值的性能，颜色表示批次
autoplot(instance, type = "marginal", cols_x = "cp")
```

```{r}
# "parallel" 图：可视化超参数之间的关系
autoplot(instance, type = "parallel")
```

```{r}
# "points" 图：散点热力图展示两个超参数的性能对比，用颜色深浅表示模型性能
autoplot(instance, type = "points", cols_x = c("cp", "minsplit"))
```

```{r}
#| message: false
#| results: hide
# "pairs" 图：展示所有超参数成对对比
autoplot(instance, type = "pairs")
```

```{r}
# "surface" 图：绘制两个超参数的模型性能面，该面是用一个学习器插值的
autoplot(instance, type = "surface", cols_x = c("cp", "minsplit"),
         learner = lrn("regr.ranger"))
```

### 可视化特征过滤器

```{r}
# 条形图展示基于过滤器的特征得分
task = tsk("mtcars")
ft = flt("correlation")
ft$calculate(task)
autoplot(ft, n = 5)
```

更多细节在 mlr3viz 包的 reference 页。

# 图学习器

一个管道运算（PipeOp），表示机器学习管道中的一个计算步骤。一系列的 PipeOps  通过边连接（`%>>%`）构成图（Graph），图可以是简单的线性图，也可以是复杂的非线性图。

搭建图学习器：

- 用 `po()` 获取 PipeOp，通过连接符 `%>>%` 连接 Graphs 与 PipeOps

- 通过 `gunion()` 将 Graphs 与 PipeOps 并起来

- 用 `ppl("replicate", graph, n)` 将 Graph 或 PipeOps 复制 n 份并起来

- `Graph$plot()` 绘制图的结构关系

- `as_learner(Graph)` 将图转化为学习器，即可跟普通学习器一样使用

管道、图学习器的主要用处在于：

- 特征工程：缺失值插补、特征提取、特征选择、处理不均衡数据……

- 集成学习：袋装法、堆叠法

- 分支训练、分块训练

## 线形图

```{r}
# 搭建图
graph = po("scale") %>>%
  po("encode") %>>%
  po("imputemedian") %>>%
  lrn("classif.rpart")
```

```{r}
# 可视化图
graph$plot()
```

```{r}
# 转为图学习器
gl = as_learner(graph)
```

```{r}
# 训练任务
task = tsk("iris")
gl$train(task)
```

调试图：

```{r}
# 取出或设置图学习器超参数
graph$pipeops$scale$param_set$values$center = FALSE
```

```{r}
# 获取单独PipeOp 的$state（经过$train() 后）
graph$keep_results = TRUE
graph$train(task)
```

```{r}
graph$pipeops$scale$state$scale
```


```{r}
# 查看图的中间结果：$.result（需提前设置$keep_results = TRUE）
graph$pipeops$scale$.result[[1]]$head()
```

## 非线性图

### 分支

集成学习的袋装法、堆叠法都是非线性图，另一种非线性图是分支：即只执行若干条备选路径中的一条。

```{r}
graph_branch = ppl("branch", list(
  pca = po("pca"),
  ica = po("ica")
)) %>>%
  lrn("classif.kknn")
graph_branch$plot()
```

### 分块训练

在数据太大，无法载入内存的情况下，一个常用的技术是将数据分成几块，然后分别对各块数据进行训练，之后再用 PipeOpClassifAvg 或 PipeOpRegrAvg 将模型按加权平均汇总。

```{r}
graph_chunks = po("chunk", 4) %>>%
  ppl("greplicate", lrn("classif.rpart"), 4) %>>%
  po("classifavg", 4)
graph_chunks$plot()
```

```{r}
# 转化为图学习器，与学习器一样使用
chunks_lrn = as_learner(graph_chunks)
chunks_lrn$train(tsk("iris"))
```

## 集成学习

集成学习，是通过构建多个基学习器，并按一定策略结合成强学习器来完成学习任务，即所谓“博采众长”，最终效果是优于任何一个原学习器。集成学习可用于分类/回归集成、特征选择集成、异常值检测集成等。

这多个基学习器可以是同质的，比如都用决策树或都用神经网络，以 Bagging 和 Boosting 模式为代表；也可以是异质的，即采用不同的算法，以 Stacking 模式为代表。






















































::: {.callout-tip title="To be continued"}
- 集成学习
:::

