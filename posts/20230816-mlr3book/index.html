<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Shitao5">
<meta name="dcterms.date" content="2023-08-16">
<title>Learn-Shitao5 – Applied Machine Learning Using mlr3 in R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>
<!-- htmldependencies:E3FAD763 --><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script>

function getGiscusTheme() {
  const quartoTheme = localStorage.getItem("quarto-color-scheme");
  const giscusTheme = quartoTheme === "alternate" ? "dark" : "light";
  return giscusTheme;
}

function setGiscusTheme() {
  function sendMessage(message) {
    const iframe = document.querySelector('iframe.giscus-frame');
    if (!iframe) return;
    iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
  }
  sendMessage({
    setConfig: {
      theme: getGiscusTheme(),
    },
  });
}

document.addEventListener('DOMContentLoaded', function () {
  const giscusAttributes = {
    "src": "https://giscus.app/client.js",
    "data-repo": "Shitao5/learn-shitao5",
    "data-repo-id": "R_kgDOJwyqzA",
    "data-category": "Announcements",
    "data-category-id": "DIC_kwDOJwyqzM4CXVMv",
    "data-mapping": "pathname",
    "data-strict": "0",
    "data-reactions-enabled": "1",
    "data-emit-metadata": "0",
    "data-input-position": "top",
    "data-theme": getGiscusTheme(),
    "data-lang": "en",
    "crossorigin": "anonymous",
    "async": "",
  };

  // Dynamically create script tag
  const giscusScript = document.createElement("script");
  Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
  document.body.appendChild(giscusScript);

  // Update giscus theme when theme switcher is clicked
  const toggle = document.querySelector('.quarto-color-scheme-toggle');
  if (toggle) {
    toggle.addEventListener('click', setGiscusTheme);
  }
});

</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg navbar-dark "><div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="/index.html">
    <span class="navbar-title">Learn-Shitao5</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item">
    <a class="nav-link" href="/about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="/toread.html" rel="" target="">
 <span class="menu-text">To Read</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://shitao5.org/" rel="" target="">
 <span class="menu-text">Shitao's Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Shitao5/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="/index.xml" rel="" target=""><i class="bi bi-rss-fill" role="img" aria-label="RSS">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
<div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <div id="quarto-toc-target"></div>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title-banner">
    <div class="quarto-title column-body">
      <h1 class="title">Applied Machine Learning Using mlr3 in R</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Machine Learning</div>
                <div class="quarto-category">R</div>
                <div class="quarto-category">mlr3</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Shitao5 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">2023-08-16</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">2023-10-23</p>
      </div>
    </div>
      
    </div>
    
  
  </header><nav id="TOC" role="doc-toc"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li><a href="#getting-started" id="toc-getting-started">Getting Started</a></li>
  <li><a href="#introduction-and-overview" id="toc-introduction-and-overview"><span class="header-section-number">1</span> Introduction and Overview</a></li>
  <li><a href="#fundamentals" id="toc-fundamentals">Fundamentals</a></li>
  <li>
<a href="#data-and-basic-modeling" id="toc-data-and-basic-modeling"><span class="header-section-number">2</span> Data and Basic Modeling</a>
  <ul>
<li>
<a href="#tasks" id="toc-tasks"><span class="header-section-number">2.1</span> Tasks</a>
  <ul>
<li><a href="#constructing-tasks" id="toc-constructing-tasks"><span class="header-section-number">2.1.1</span> Constructing Tasks</a></li>
  <li><a href="#retrieving-data" id="toc-retrieving-data"><span class="header-section-number">2.1.2</span> Retrieving Data</a></li>
  <li><a href="#task-mutators" id="toc-task-mutators"><span class="header-section-number">2.1.3</span> Task Mutators</a></li>
  </ul>
</li>
  <li>
<a href="#learners" id="toc-learners"><span class="header-section-number">2.2</span> Learners</a>
  <ul>
<li><a href="#training" id="toc-training"><span class="header-section-number">2.2.1</span> Training</a></li>
  <li><a href="#predicting" id="toc-predicting"><span class="header-section-number">2.2.2</span> Predicting</a></li>
  <li><a href="#hyperparameters" id="toc-hyperparameters"><span class="header-section-number">2.2.3</span> Hyperparameters</a></li>
  <li><a href="#baseline-learners" id="toc-baseline-learners"><span class="header-section-number">2.2.4</span> Baseline Learners</a></li>
  </ul>
</li>
  <li>
<a href="#evaluation" id="toc-evaluation"><span class="header-section-number">2.3</span> Evaluation</a>
  <ul>
<li><a href="#measures" id="toc-measures"><span class="header-section-number">2.3.1</span> Measures</a></li>
  <li><a href="#scoring-predictions" id="toc-scoring-predictions"><span class="header-section-number">2.3.2</span> Scoring Predictions</a></li>
  <li><a href="#technical-measures" id="toc-technical-measures"><span class="header-section-number">2.3.3</span> Technical Measures</a></li>
  </ul>
</li>
  <li><a href="#our-first-regression-experiment" id="toc-our-first-regression-experiment"><span class="header-section-number">2.4</span> Our First Regression Experiment</a></li>
  <li>
<a href="#classification" id="toc-classification"><span class="header-section-number">2.5</span> Classification</a>
  <ul>
<li><a href="#our-first-classification-experiment" id="toc-our-first-classification-experiment"><span class="header-section-number">2.5.1</span> Our First Classification Experiment</a></li>
  <li><a href="#taskclassif" id="toc-taskclassif"><span class="header-section-number">2.5.2</span> TaskClassif</a></li>
  <li><a href="#learnerclassif-and-measureclassif" id="toc-learnerclassif-and-measureclassif"><span class="header-section-number">2.5.3</span> LearnerClassif and MeasureClassif</a></li>
  <li><a href="#predictionclassif-confusion-matrix-and-thresholding" id="toc-predictionclassif-confusion-matrix-and-thresholding"><span class="header-section-number">2.5.4</span> PredictionClassif, Confusion Matrix, and Thresholding</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#sec-performance" id="toc-sec-performance"><span class="header-section-number">3</span> Evaluation and Benchmarking</a>
  <ul>
<li><a href="#holdout-and-scoring" id="toc-holdout-and-scoring"><span class="header-section-number">3.1</span> Holdout and Scoring</a></li>
  <li>
<a href="#resampling" id="toc-resampling"><span class="header-section-number">3.2</span> Resampling</a>
  <ul>
<li><a href="#constructing-a-resampling-strategy" id="toc-constructing-a-resampling-strategy"><span class="header-section-number">3.2.1</span> Constructing a Resampling Strategy</a></li>
  <li><a href="#resampling-experiments" id="toc-resampling-experiments"><span class="header-section-number">3.2.2</span> Resampling Experiments</a></li>
  <li><a href="#resampleresult-objects" id="toc-resampleresult-objects"><span class="header-section-number">3.2.3</span> ResampleResult Objects</a></li>
  </ul>
</li>
  <li>
<a href="#sec-benchmarking" id="toc-sec-benchmarking"><span class="header-section-number">3.3</span> Benchmarking</a>
  <ul>
<li><a href="#benchmark" id="toc-benchmark"><span class="header-section-number">3.3.1</span> benchmark()</a></li>
  <li><a href="#benchmarkresult-objects" id="toc-benchmarkresult-objects"><span class="header-section-number">3.3.2</span> BenchmarkResult Objects</a></li>
  </ul>
</li>
  <li>
<a href="#evaluation-of-binary-classifiers" id="toc-evaluation-of-binary-classifiers"><span class="header-section-number">3.4</span> Evaluation of Binary Classifiers</a>
  <ul>
<li><a href="#confusion-matrix-1" id="toc-confusion-matrix-1"><span class="header-section-number">3.4.1</span> Confusion Matrix</a></li>
  <li><a href="#roc-analysis" id="toc-roc-analysis"><span class="header-section-number">3.4.2</span> ROC Analysis</a></li>
  </ul>
</li>
  </ul>
</li>
  <li><a href="#tuning-and-feature-selection" id="toc-tuning-and-feature-selection">Tuning and Feature Selection</a></li>
  <li>
<a href="#sec-optimization" id="toc-sec-optimization"><span class="header-section-number">4</span> Hyperparameter Optimization</a>
  <ul>
<li>
<a href="#model-tuning" id="toc-model-tuning"><span class="header-section-number">4.1</span> Model Tuning</a>
  <ul>
<li><a href="#learner-and-search-space" id="toc-learner-and-search-space"><span class="header-section-number">4.1.1</span> Learner and Search Space</a></li>
  <li><a href="#sec-terminator" id="toc-sec-terminator"><span class="header-section-number">4.1.2</span> Terminator</a></li>
  <li><a href="#tuning-instance-with-ti" id="toc-tuning-instance-with-ti"><span class="header-section-number">4.1.3</span> Tuning Instance with <code>ti</code></a></li>
  <li><a href="#tuner" id="toc-tuner"><span class="header-section-number">4.1.4</span> Tuner</a></li>
  <li><a href="#logarithmic-transformations" id="toc-logarithmic-transformations"><span class="header-section-number">4.1.5</span> Logarithmic Transformations</a></li>
  <li><a href="#analyzing-and-using-the-result" id="toc-analyzing-and-using-the-result"><span class="header-section-number">4.1.6</span> Analyzing and Using the Result</a></li>
  </ul>
</li>
  <li><a href="#convenient-tuning-with-tune-and-auto_tuner" id="toc-convenient-tuning-with-tune-and-auto_tuner"><span class="header-section-number">4.2</span> Convenient Tuning with <code>tune</code> and <code>auto_tuner</code></a></li>
  <li>
<a href="#sec-nested-resampling" id="toc-sec-nested-resampling"><span class="header-section-number">4.3</span> Nested Resampling</a>
  <ul>
<li><a href="#nested-resampling-with-an-autotuner" id="toc-nested-resampling-with-an-autotuner"><span class="header-section-number">4.3.1</span> Nested Resampling with an <code>AutoTuner</code></a></li>
  <li><a href="#the-right-and-wrong-way-to-estimate-performance" id="toc-the-right-and-wrong-way-to-estimate-performance"><span class="header-section-number">4.3.2</span> The Right (and Wrong) Way to Estimate Performance</a></li>
  </ul>
</li>
  <li>
<a href="#sec-defining-search-spaces" id="toc-sec-defining-search-spaces"><span class="header-section-number">4.4</span> More Advanced Search Spaces</a>
  <ul>
<li><a href="#scalar-parameter-tuning" id="toc-scalar-parameter-tuning"><span class="header-section-number">4.4.1</span> Scalar Parameter Tuning</a></li>
  <li><a href="#defining-search-spaces-with-ps" id="toc-defining-search-spaces-with-ps"><span class="header-section-number">4.4.2</span> Defining Search Spaces with <code>ps</code></a></li>
  <li><a href="#transformations-and-tuning-over-vectors" id="toc-transformations-and-tuning-over-vectors"><span class="header-section-number">4.4.3</span> Transformations and Tuning Over Vectors</a></li>
  <li><a href="#hyperparameter-dependencies" id="toc-hyperparameter-dependencies"><span class="header-section-number">4.4.4</span> Hyperparameter Dependencies</a></li>
  <li><a href="#recommended-search-spaces-with-mlrtuningspaces" id="toc-recommended-search-spaces-with-mlrtuningspaces"><span class="header-section-number">4.4.5</span> Recommended Search Spaces with <code>mlrtuningspaces</code></a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#sec-optimization-advanced" id="toc-sec-optimization-advanced"><span class="header-section-number">5</span> Advanced Tuning Methods and Black Box Optimization</a>
  <ul>
<li>
<a href="#error-handling-and-memory-management" id="toc-error-handling-and-memory-management"><span class="header-section-number">5.1</span> Error Handling and Memory Management</a>
  <ul>
<li><a href="#encapsulation-and-fallback-learner" id="toc-encapsulation-and-fallback-learner"><span class="header-section-number">5.1.1</span> Encapsulation and Fallback Learner</a></li>
  <li><a href="#memory-management" id="toc-memory-management"><span class="header-section-number">5.1.2</span> Memory Management</a></li>
  </ul>
</li>
  <li><a href="#multi-objective-tuning" id="toc-multi-objective-tuning"><span class="header-section-number">5.2</span> Multi-Objective Tuning</a></li>
  <li><a href="#sec-hyperband" id="toc-sec-hyperband"><span class="header-section-number">5.3</span> Multi-Fidelity Tuning via Hyperband</a></li>
  <li>
<a href="#sec-bayesian-optimization" id="toc-sec-bayesian-optimization"><span class="header-section-number">5.4</span> Bayesian Optimization</a>
  <ul>
<li><a href="#black-box-optimization" id="toc-black-box-optimization"><span class="header-section-number">5.4.1</span> Black Box Optimization</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#feature-selection" id="toc-feature-selection"><span class="header-section-number">6</span> Feature Selection</a>
  <ul>
<li>
<a href="#filters" id="toc-filters"><span class="header-section-number">6.1</span> Filters</a>
  <ul>
<li><a href="#calculating-filter-value" id="toc-calculating-filter-value"><span class="header-section-number">6.1.1</span> Calculating Filter Value</a></li>
  <li><a href="#sec-fs-var-imp-filters" id="toc-sec-fs-var-imp-filters"><span class="header-section-number">6.1.2</span> Feature Importance Filters</a></li>
  <li><a href="#embedded-methods" id="toc-embedded-methods"><span class="header-section-number">6.1.3</span> Embedded Methods</a></li>
  <li><a href="#filter-based-feature-selection" id="toc-filter-based-feature-selection"><span class="header-section-number">6.1.4</span> Filter-Based Feature Selection</a></li>
  </ul>
</li>
  <li>
<a href="#wrapper-methods" id="toc-wrapper-methods"><span class="header-section-number">6.2</span> Wrapper Methods</a>
  <ul>
<li><a href="#simple-forward-selection-example" id="toc-simple-forward-selection-example"><span class="header-section-number">6.2.1</span> Simple Forward Selection Example</a></li>
  <li><a href="#the-fselectinstance-class" id="toc-the-fselectinstance-class"><span class="header-section-number">6.2.2</span> The FSelectInstance Class</a></li>
  <li><a href="#the-fselector-class" id="toc-the-fselector-class"><span class="header-section-number">6.2.3</span> The FSelector Class</a></li>
  <li><a href="#starting-the-feature-selection" id="toc-starting-the-feature-selection"><span class="header-section-number">6.2.4</span> Starting the Feature Selection</a></li>
  <li><a href="#sec-multicrit-featsel" id="toc-sec-multicrit-featsel"><span class="header-section-number">6.2.5</span> Optimizing Multiple Performance Measures</a></li>
  <li><a href="#nested-resampling" id="toc-nested-resampling"><span class="header-section-number">6.2.6</span> Nested Resampling</a></li>
  </ul>
</li>
  </ul>
</li>
  <li><a href="#pipelines-and-preprocessing" id="toc-pipelines-and-preprocessing">Pipelines and Preprocessing</a></li>
  <li>
<a href="#sequential-pipelines" id="toc-sequential-pipelines"><span class="header-section-number">7</span> Sequential Pipelines</a>
  <ul>
<li><a href="#pipeop-pipeline-operators" id="toc-pipeop-pipeline-operators"><span class="header-section-number">7.1</span> PipeOp: Pipeline Operators</a></li>
  <li><a href="#graph-networks-of-popeops" id="toc-graph-networks-of-popeops"><span class="header-section-number">7.2</span> Graph: Networks of PopeOps</a></li>
  <li>
<a href="#sequential-learner-pipelines" id="toc-sequential-learner-pipelines"><span class="header-section-number">7.3</span> Sequential Learner-Pipelines</a>
  <ul>
<li><a href="#learners-as-pipeops-and-graphs-as-learners" id="toc-learners-as-pipeops-and-graphs-as-learners"><span class="header-section-number">7.3.1</span> Learners as PipeOps and Graphs as Learners</a></li>
  <li><a href="#inspecting-graphs" id="toc-inspecting-graphs"><span class="header-section-number">7.3.2</span> Inspecting Graphs</a></li>
  <li><a href="#configuring-pipeline-hyperparameters" id="toc-configuring-pipeline-hyperparameters"><span class="header-section-number">7.3.3</span> Configuring Pipeline Hyperparameters</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#non-sequential-pipelines-and-tuning" id="toc-non-sequential-pipelines-and-tuning"><span class="header-section-number">8</span> Non-sequential Pipelines and Tuning</a>
  <ul>
<li><a href="#selectors-and-parallel-pipelines" id="toc-selectors-and-parallel-pipelines"><span class="header-section-number">8.1</span> Selectors and Parallel Pipelines</a></li>
  <li>
<a href="#practical-pipelines-by-example" id="toc-practical-pipelines-by-example"><span class="header-section-number">8.2</span> Practical Pipelines by Example</a>
  <ul>
<li><a href="#bagging-with-greplicate-and-subsample" id="toc-bagging-with-greplicate-and-subsample"><span class="header-section-number">8.2.1</span> Bagging with “greplicate” and “subsample”</a></li>
  <li><a href="#stacking-with-polearner_cv" id="toc-stacking-with-polearner_cv"><span class="header-section-number">8.2.2</span> Stacking with <code>po(“learner_cv”)</code></a></li>
  </ul>
</li>
  <li>
<a href="#tuning-graphs" id="toc-tuning-graphs"><span class="header-section-number">8.3</span> Tuning Graphs</a>
  <ul>
<li><a href="#tuning-graph-hyperparameters" id="toc-tuning-graph-hyperparameters"><span class="header-section-number">8.3.1</span> Tuning Graph Hyperparameters</a></li>
  <li><a href="#tuning-alternative-paths-with-pobranch" id="toc-tuning-alternative-paths-with-pobranch"><span class="header-section-number">8.3.2</span> Tuning Alternative Paths with po(“branch”)</a></li>
  <li><a href="#sec-hyperband-example-svm" id="toc-sec-hyperband-example-svm"><span class="header-section-number">8.3.3</span> Hyperband with Subsampling</a></li>
  <li><a href="#sec-pipelines-featsel" id="toc-sec-pipelines-featsel"><span class="header-section-number">8.3.4</span> Feature Selection with Filter Pipelines</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#sec-preprocessing" id="toc-sec-preprocessing"><span class="header-section-number">9</span> Preprocessing</a>
  <ul>
<li><a href="#data-cleaning" id="toc-data-cleaning"><span class="header-section-number">9.1</span> Data Cleaning</a></li>
  <li><a href="#factor-encoding" id="toc-factor-encoding"><span class="header-section-number">9.2</span> Factor Encoding</a></li>
  <li><a href="#sec-preprocessing-missing" id="toc-sec-preprocessing-missing"><span class="header-section-number">9.3</span> Missing Values</a></li>
  <li><a href="#pipeline-robustify" id="toc-pipeline-robustify"><span class="header-section-number">9.4</span> Pipeline Robustify</a></li>
  <li><a href="#transforming-features-and-targets" id="toc-transforming-features-and-targets"><span class="header-section-number">9.5</span> Transforming Features and Targets</a></li>
  <li><a href="#functional-feature-extraction" id="toc-functional-feature-extraction"><span class="header-section-number">9.6</span> Functional Feature Extraction</a></li>
  </ul>
</li>
  <li><a href="#advanced-topics" id="toc-advanced-topics">Advanced Topics</a></li>
  <li><a href="#advanced-technical-aspects-of-mlr3" id="toc-advanced-technical-aspects-of-mlr3"><span class="header-section-number">10</span> Advanced Technical Aspects of mlr3</a></li>
  </ul></nav><div class="callout callout-style-default callout-note callout-titled" title="Progress">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Progress
</div>
</div>
<div class="callout-body-container callout-body">
<p>Learning Progress: 60%.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Learning Source">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Source
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://mlr3book.mlr-org.com/" class="uri">https://mlr3book.mlr-org.com/</a></li>
<li>中文翻译由 ChatGPT 3.5 提供</li>
</ul>
</div>
</div>
<section id="getting-started" class="level1 unnumbered"><h1 class="unnumbered">Getting Started</h1>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3verse.mlr-org.com">mlr3verse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3pipelines.mlr-org.com">mlr3pipelines</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3benchmark.mlr-org.com">mlr3benchmark</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3hyperband.mlr-org.com">mlr3hyperband</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com">data.table</a></span><span class="op">)</span></span></code></pre></div>
</div>
</section><section id="introduction-and-overview" class="level1" data-number="1"><h1 data-number="1">
<span class="header-section-number">1</span> Introduction and Overview</h1>
<p><code>mlr3</code> by Example:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span></span>
<span><span class="va">task</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">split</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">task</span><span class="op">)</span></span>
<span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">task</span>, row_ids <span class="op">=</span> <span class="va">split</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">model</span></span>
<span><span class="co">#&gt; n= 231 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; node), split, n, loss, yval, (yprob)</span></span>
<span><span class="co">#&gt;       * denotes terminal node</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1) root 231 129 Adelie (0.441558442 0.199134199 0.359307359)  </span></span>
<span><span class="co">#&gt;   2) flipper_length&lt; 206.5 144  44 Adelie (0.694444444 0.298611111 0.006944444)  </span></span>
<span><span class="co">#&gt;     4) bill_length&lt; 43.05 98   3 Adelie (0.969387755 0.030612245 0.000000000) *</span></span>
<span><span class="co">#&gt;     5) bill_length&gt;=43.05 46   6 Chinstrap (0.108695652 0.869565217 0.021739130) *</span></span>
<span><span class="co">#&gt;   3) flipper_length&gt;=206.5 87   5 Gentoo (0.022988506 0.034482759 0.942528736) *</span></span>
<span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">learner</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">task</span>, row_ids <span class="op">=</span> <span class="va">split</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="va">prediction</span></span>
<span><span class="co">#&gt; &lt;PredictionClassif&gt; for 113 observations:</span></span>
<span><span class="co">#&gt;     row_ids     truth  response</span></span>
<span><span class="co">#&gt;           1    Adelie    Adelie</span></span>
<span><span class="co">#&gt;           2    Adelie    Adelie</span></span>
<span><span class="co">#&gt;           3    Adelie    Adelie</span></span>
<span><span class="co">#&gt; ---                            </span></span>
<span><span class="co">#&gt;         328 Chinstrap Chinstrap</span></span>
<span><span class="co">#&gt;         331 Chinstrap    Adelie</span></span>
<span><span class="co">#&gt;         339 Chinstrap Chinstrap</span></span>
<span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.acc </span></span>
<span><span class="co">#&gt;   0.9557522</span></span></code></pre></div>
</div>
<p>The <code>mlr3</code> interface also lets you run more complicated experiments in just a few lines of code:</p>
<p>We use dictionaries to group large collections of relevant objects so they can be listed and retrieved easily. For example, you can see an overview of available learners (that are in loaded packages) and their properties with <code>as.data.table(mlr_learners)</code> or by calling the sugar function without any arguments, e.g. <code><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn()</a></code>.</p>
<blockquote>
<p>我们使用字典来分组大量相关对象，以便可以轻松地列出和检索它们。例如，您可以通过 <code>as.data.table(mlr_learners)</code> 查看可用学习器（位于加载的包中）及其属性的概述，或者通过调用糖函数而不带任何参数，例如 <code><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn()</a></code>。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">mlr_learners</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span>
<span><span class="co">#&gt; Warning in .recacheSubclasses(def@className, def, env): undefined subclass</span></span>
<span><span class="co">#&gt; "pcorMatrix" of class "AnyMatrix"; definition not updated</span></span>
<span><span class="co">#&gt;                    key                              label task_type</span></span>
<span><span class="co">#&gt; 1:   classif.cv_glmnet                               &lt;NA&gt;   classif</span></span>
<span><span class="co">#&gt; 2:       classif.debug   Debug Learner for Classification   classif</span></span>
<span><span class="co">#&gt; 3: classif.featureless Featureless Classification Learner   classif</span></span>
<span><span class="co">#&gt;                                           feature_types</span></span>
<span><span class="co">#&gt; 1:                              logical,integer,numeric</span></span>
<span><span class="co">#&gt; 2:     logical,integer,numeric,character,factor,ordered</span></span>
<span><span class="co">#&gt; 3: logical,integer,numeric,character,factor,ordered,...</span></span>
<span><span class="co">#&gt;                    packages</span></span>
<span><span class="co">#&gt; 1: mlr3,mlr3learners,glmnet</span></span>
<span><span class="co">#&gt; 2:                     mlr3</span></span>
<span><span class="co">#&gt; 3:                     mlr3</span></span>
<span><span class="co">#&gt;                                                               properties</span></span>
<span><span class="co">#&gt; 1:                         multiclass,selected_features,twoclass,weights</span></span>
<span><span class="co">#&gt; 2:                         hotstart_forward,missings,multiclass,twoclass</span></span>
<span><span class="co">#&gt; 3: featureless,importance,missings,multiclass,selected_features,twoclass</span></span>
<span><span class="co">#&gt;    predict_types</span></span>
<span><span class="co">#&gt; 1: response,prob</span></span>
<span><span class="co">#&gt; 2: response,prob</span></span>
<span><span class="co">#&gt; 3: response,prob</span></span></code></pre></div>
</div>
</section><section id="fundamentals" class="level1 unnumbered"><h1 class="unnumbered">Fundamentals</h1>
</section><section id="data-and-basic-modeling" class="level1" data-number="2"><h1 data-number="2">
<span class="header-section-number">2</span> Data and Basic Modeling</h1>
<section id="tasks" class="level2" data-number="2.1"><h2 data-number="2.1">
<span class="header-section-number">2.1</span> Tasks</h2>
<section id="constructing-tasks" class="level3" data-number="2.1.1"><h3 data-number="2.1.1">
<span class="header-section-number">2.1.1</span> Constructing Tasks</h3>
<p><code>mlr3</code> includes a few predefined machine learning tasks in the <code>mlr_tasks</code> Dictionary.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mlr_tasks</span></span>
<span><span class="co">#&gt; &lt;DictionaryTask&gt; with 21 stored values</span></span>
<span><span class="co">#&gt; Keys: ames_housing, bike_sharing, boston_housing, breast_cancer,</span></span>
<span><span class="co">#&gt;   german_credit, ilpd, iris, kc_housing, moneyball, mtcars, optdigits,</span></span>
<span><span class="co">#&gt;   penguins, penguins_simple, pima, ruspini, sonar, spam, titanic,</span></span>
<span><span class="co">#&gt;   usarrests, wine, zoo</span></span>
<span><span class="co"># the same as </span></span>
<span><span class="co"># tsk()</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_mtcars</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"mtcars"</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars</span></span>
<span><span class="co">#&gt; &lt;TaskRegr:mtcars&gt; (32 x 11): Motor Trends</span></span>
<span><span class="co">#&gt; * Target: mpg</span></span>
<span><span class="co">#&gt; * Properties: -</span></span>
<span><span class="co">#&gt; * Features (10):</span></span>
<span><span class="co">#&gt;   - dbl (10): am, carb, cyl, disp, drat, gear, hp, qsec, vs, wt</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># create my own regression task</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"mtcars"</span>, package <span class="op">=</span> <span class="st">"datasets"</span><span class="op">)</span></span>
<span><span class="va">mtcars_subset</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">mtcars</span>, select <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mpg"</span>, <span class="st">"cyl"</span>, <span class="st">"disp"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task_regr.html">as_task_regr</a></span><span class="op">(</span><span class="va">mtcars_subset</span>, target <span class="op">=</span> <span class="st">"mpg"</span>, id <span class="op">=</span> <span class="st">"cars"</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars</span></span>
<span><span class="co">#&gt; &lt;TaskRegr:cars&gt; (32 x 3)</span></span>
<span><span class="co">#&gt; * Target: mpg</span></span>
<span><span class="co">#&gt; * Properties: -</span></span>
<span><span class="co">#&gt; * Features (2):</span></span>
<span><span class="co">#&gt;   - dbl (2): cyl, disp</span></span></code></pre></div>
</div>
<p>The <code>id</code> argument is optional and specifies an identifier for the task that is used in plots and summaries; if omitted the variable name of the data will be used as the <code>id</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3viz.mlr-org.com">mlr3viz</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">tsk_mtcars</span>, type <span class="op">=</span> <span class="st">"pairs"</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section><section id="retrieving-data" class="level3" data-number="2.1.2"><h3 data-number="2.1.2">
<span class="header-section-number">2.1.2</span> Retrieving Data</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">tsk_mtcars</span><span class="op">$</span><span class="va">nrow</span>, <span class="va">tsk_mtcars</span><span class="op">$</span><span class="va">ncol</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 32  3</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>Features <span class="op">=</span> <span class="va">tsk_mtcars</span><span class="op">$</span><span class="va">feature_names</span>,</span>
<span>  Target <span class="op">=</span> <span class="va">tsk_mtcars</span><span class="op">$</span><span class="va">target_names</span><span class="op">)</span></span>
<span><span class="co">#&gt; Features1 Features2    Target </span></span>
<span><span class="co">#&gt;     "cyl"    "disp"     "mpg"</span></span></code></pre></div>
</div>
<p>Row IDs are not used as features when training or predicting but are metadata that allow access to individual observations. Note that row IDs are not the same as row numbers.</p>
<p>This design decision allows tasks and learners to transparently operate on real database management systems, where primary keys are required to be unique, but not necessarily consecutive.</p>
<blockquote>
<p>行ID在训练或预测时不作为特征使用，而是元数据，用于访问个别观测数据。需要注意的是，行ID与行号不同。</p>
<p>这种设计决策使得任务和学习器能够透明地在真实的数据库管理系统上运行，其中要求主键是唯一的，但不一定连续。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">task</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task_regr.html">as_task_regr</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                    target <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span></span>
<span><span class="va">task</span><span class="op">$</span><span class="va">row_ids</span></span>
<span><span class="co">#&gt; [1] 1 2 3 4 5</span></span>
<span></span>
<span><span class="va">task</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">task</span><span class="op">$</span><span class="va">row_ids</span></span>
<span><span class="co">#&gt; [1] 1 3 4</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_mtcars</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span>
<span><span class="co">#&gt;     mpg cyl disp</span></span>
<span><span class="co">#&gt; 1: 21.0   6  160</span></span>
<span><span class="co">#&gt; 2: 21.0   6  160</span></span>
<span><span class="co">#&gt; 3: 22.8   4  108</span></span>
<span><span class="va">tsk_mtcars</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span>rows <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">10</span><span class="op">)</span>, cols <span class="op">=</span> <span class="va">tsk_mtcars</span><span class="op">$</span><span class="va">feature_names</span><span class="op">)</span></span>
<span><span class="co">#&gt;    cyl  disp</span></span>
<span><span class="co">#&gt; 1:   6 160.0</span></span>
<span><span class="co">#&gt; 2:   8 360.0</span></span>
<span><span class="co">#&gt; 3:   6 167.6</span></span></code></pre></div>
</div>
</section><section id="task-mutators" class="level3" data-number="2.1.3"><h3 data-number="2.1.3">
<span class="header-section-number">2.1.3</span> Task Mutators</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_mtcars_small</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"mtcars"</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars_small</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="st">"cyl"</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars_small</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars_small</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;     mpg cyl</span></span>
<span><span class="co">#&gt; 1: 21.0   6</span></span>
<span><span class="co">#&gt; 2: 22.8   4</span></span></code></pre></div>
</div>
<p>As <code>R6</code> uses reference semantics, you need to use <code>$clone()</code> if you want to modify a task while keeping the original object intact.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_mtcars</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"mtcars"</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars_clone</span> <span class="op">=</span> <span class="va">tsk_mtcars</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars_clone</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars_clone</span><span class="op">$</span><span class="fu">head</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;    mpg am carb cyl disp drat gear  hp  qsec vs    wt</span></span>
<span><span class="co">#&gt; 1:  21  1    4   6  160  3.9    4 110 16.46  0 2.620</span></span>
<span><span class="co">#&gt; 2:  21  1    4   6  160  3.9    4 110 17.02  0 2.875</span></span></code></pre></div>
</div>
<p>To add extra rows and columns to a task, you can use <code>$rbind()</code> and <code>$cbind()</code> respectively:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_mtcars_small</span></span>
<span><span class="co">#&gt; &lt;TaskRegr:mtcars&gt; (2 x 2): Motor Trends</span></span>
<span><span class="co">#&gt; * Target: mpg</span></span>
<span><span class="co">#&gt; * Properties: -</span></span>
<span><span class="co">#&gt; * Features (1):</span></span>
<span><span class="co">#&gt;   - dbl (1): cyl</span></span>
<span><span class="va">tsk_mtcars_small</span><span class="op">$</span><span class="fu">cbind</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>disp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">150</span>, <span class="fl">160</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars_small</span><span class="op">$</span><span class="fu">rbind</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>mpg <span class="op">=</span> <span class="fl">23</span>, cyl <span class="op">=</span> <span class="fl">5</span>, disp <span class="op">=</span> <span class="fl">170</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars_small</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;     mpg cyl disp</span></span>
<span><span class="co">#&gt; 1: 21.0   6  150</span></span>
<span><span class="co">#&gt; 2: 22.8   4  160</span></span>
<span><span class="co">#&gt; 3: 23.0   5  170</span></span></code></pre></div>
</div>
</section></section><section id="learners" class="level2" data-number="2.2"><h2 data-number="2.2">
<span class="header-section-number">2.2</span> Learners</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># all the learners available in mlr3</span></span>
<span><span class="va">mlr_learners</span></span>
<span><span class="co">#&gt; &lt;DictionaryLearner&gt; with 46 stored values</span></span>
<span><span class="co">#&gt; Keys: classif.cv_glmnet, classif.debug, classif.featureless,</span></span>
<span><span class="co">#&gt;   classif.glmnet, classif.kknn, classif.lda, classif.log_reg,</span></span>
<span><span class="co">#&gt;   classif.multinom, classif.naive_bayes, classif.nnet, classif.qda,</span></span>
<span><span class="co">#&gt;   classif.ranger, classif.rpart, classif.svm, classif.xgboost,</span></span>
<span><span class="co">#&gt;   clust.agnes, clust.ap, clust.cmeans, clust.cobweb, clust.dbscan,</span></span>
<span><span class="co">#&gt;   clust.diana, clust.em, clust.fanny, clust.featureless, clust.ff,</span></span>
<span><span class="co">#&gt;   clust.hclust, clust.kkmeans, clust.kmeans, clust.MBatchKMeans,</span></span>
<span><span class="co">#&gt;   clust.mclust, clust.meanshift, clust.pam, clust.SimpleKMeans,</span></span>
<span><span class="co">#&gt;   clust.xmeans, regr.cv_glmnet, regr.debug, regr.featureless,</span></span>
<span><span class="co">#&gt;   regr.glmnet, regr.kknn, regr.km, regr.lm, regr.nnet, regr.ranger,</span></span>
<span><span class="co">#&gt;   regr.rpart, regr.svm, regr.xgboost</span></span>
<span><span class="co"># lrns()</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.rpart"</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;LearnerRegrRpart:regr.rpart&gt;: Regression Tree</span></span>
<span><span class="co">#&gt; * Model: -</span></span>
<span><span class="co">#&gt; * Parameters: xval=0</span></span>
<span><span class="co">#&gt; * Packages: mlr3, rpart</span></span>
<span><span class="co">#&gt; * Predict Types:  [response]</span></span>
<span><span class="co">#&gt; * Feature Types: logical, integer, numeric, factor, ordered</span></span>
<span><span class="co">#&gt; * Properties: importance, missings, selected_features, weights</span></span></code></pre></div>
</div>
<p>All <code>Learner</code> objects include the following metadata, which can be seen in the output above:</p>
<ul>
<li><p><code>$feature_types</code>: the type of features the learner can handle.</p></li>
<li><p><code>$packages</code>: the packages required to be installed to use the learner.</p></li>
<li><p><code>$properties</code>: the properties of the learner. For example, the “missings” properties means a model can handle missing data, and “importance” means it can compute the relative importance of each feature.</p></li>
<li><p><code>$predict_types</code>: the types of prediction that the model can make.</p></li>
<li><p><code>$param_set</code>: the set of available hyperparameters.</p></li>
</ul>
<section id="training" class="level3" data-number="2.2.1"><h3 data-number="2.2.1">
<span class="header-section-number">2.2.1</span> Training</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># load mtcars task</span></span>
<span><span class="va">tsk_mtcars</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"mtcars"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># load a regression tree</span></span>
<span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.rpart"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># pass the task to the learner via $train()</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_mtcars</span><span class="op">)</span></span></code></pre></div>
</div>
<p>After training, the fitted model is stored in the <code>$model</code> field for future inspection and prediction:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_rpart</span><span class="op">$</span><span class="va">model</span></span>
<span><span class="co">#&gt; n= 32 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; node), split, n, deviance, yval</span></span>
<span><span class="co">#&gt;       * denotes terminal node</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1) root 32 1126.04700 20.09062  </span></span>
<span><span class="co">#&gt;   2) cyl&gt;=5 21  198.47240 16.64762  </span></span>
<span><span class="co">#&gt;     4) hp&gt;=192.5 7   28.82857 13.41429 *</span></span>
<span><span class="co">#&gt;     5) hp&lt; 192.5 14   59.87214 18.26429 *</span></span>
<span><span class="co">#&gt;   3) cyl&lt; 5 11  203.38550 26.66364 *</span></span>
<span></span>
<span><span class="va">splits</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_mtcars</span><span class="op">)</span></span>
<span><span class="va">splits</span></span>
<span><span class="co">#&gt; $train</span></span>
<span><span class="co">#&gt;  [1]  1  2  3  4  5 21 25 27 32  7 13 15 16 17 22 23 29 31 18 26 28</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $test</span></span>
<span><span class="co">#&gt;  [1]  8  9 10 30  6 11 12 14 24 19 20</span></span>
<span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_mtcars</span>, row_ids <span class="op">=</span> <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span></code></pre></div>
</div>
</section><section id="predicting" class="level3" data-number="2.2.2"><h3 data-number="2.2.2">
<span class="header-section-number">2.2.2</span> Predicting</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_mtcars</span>, row_ids <span class="op">=</span> <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="va">prediction</span></span>
<span><span class="co">#&gt; &lt;PredictionRegr&gt; for 11 observations:</span></span>
<span><span class="co">#&gt;     row_ids truth response</span></span>
<span><span class="co">#&gt;           8  24.4 24.52000</span></span>
<span><span class="co">#&gt;           9  22.8 24.52000</span></span>
<span><span class="co">#&gt;          10  19.2 24.52000</span></span>
<span><span class="co">#&gt; ---                       </span></span>
<span><span class="co">#&gt;          24  13.3 15.13636</span></span>
<span><span class="co">#&gt;          19  30.4 24.52000</span></span>
<span><span class="co">#&gt;          20  33.9 24.52000</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">prediction</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mtcars_new</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/data.table.html">data.table</a></span><span class="op">(</span>cyl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">6</span><span class="op">)</span>, disp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">120</span><span class="op">)</span>,</span>
<span>  hp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">150</span><span class="op">)</span>, drat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">3.9</span><span class="op">)</span>, wt <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3.8</span>, <span class="fl">4.1</span><span class="op">)</span>,</span>
<span>  qsec <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">18</span>, <span class="fl">19.5</span><span class="op">)</span>, vs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>, am <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>  gear <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">4</span><span class="op">)</span>, carb <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">predict_newdata</span><span class="op">(</span><span class="va">mtcars_new</span><span class="op">)</span></span>
<span><span class="va">prediction</span></span>
<span><span class="co">#&gt; &lt;PredictionRegr&gt; for 2 observations:</span></span>
<span><span class="co">#&gt;  row_ids truth response</span></span>
<span><span class="co">#&gt;        1    NA    24.52</span></span>
<span><span class="co">#&gt;        2    NA    24.52</span></span></code></pre></div>
</div>
</section><section id="hyperparameters" class="level3" data-number="2.2.3"><h3 data-number="2.2.3">
<span class="header-section-number">2.2.3</span> Hyperparameters</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_rpart</span><span class="op">$</span><span class="va">param_set</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;                 id    class lower upper nlevels        default value</span></span>
<span><span class="co">#&gt;  1:             cp ParamDbl     0     1     Inf           0.01      </span></span>
<span><span class="co">#&gt;  2:     keep_model ParamLgl    NA    NA       2          FALSE      </span></span>
<span><span class="co">#&gt;  3:     maxcompete ParamInt     0   Inf     Inf              4      </span></span>
<span><span class="co">#&gt;  4:       maxdepth ParamInt     1    30      30             30      </span></span>
<span><span class="co">#&gt;  5:   maxsurrogate ParamInt     0   Inf     Inf              5      </span></span>
<span><span class="co">#&gt;  6:      minbucket ParamInt     1   Inf     Inf &lt;NoDefault[3]&gt;      </span></span>
<span><span class="co">#&gt;  7:       minsplit ParamInt     1   Inf     Inf             20      </span></span>
<span><span class="co">#&gt;  8: surrogatestyle ParamInt     0     1       2              0      </span></span>
<span><span class="co">#&gt;  9:   usesurrogate ParamInt     0     2       3              2      </span></span>
<span><span class="co">#&gt; 10:           xval ParamInt     0   Inf     Inf             10     0</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># change hyperparameter</span></span>
<span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.rpart"</span>, maxdepth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span></span>
<span><span class="co">#&gt; $xval</span></span>
<span><span class="co">#&gt; [1] 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $maxdepth</span></span>
<span><span class="co">#&gt; [1] 1</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># learned regression tree</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"mtcars"</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">model</span></span>
<span><span class="co">#&gt; n= 32 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; node), split, n, deviance, yval</span></span>
<span><span class="co">#&gt;       * denotes terminal node</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1) root 32 1126.0470 20.09062  </span></span>
<span><span class="co">#&gt;   2) cyl&gt;=5 21  198.4724 16.64762 *</span></span>
<span><span class="co">#&gt;   3) cyl&lt; 5 11  203.3855 26.66364 *</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># another way to update hyperparameters</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">maxdepth</span> <span class="op">=</span> <span class="fl">2</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span></span>
<span><span class="co">#&gt; $xval</span></span>
<span><span class="co">#&gt; [1] 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $maxdepth</span></span>
<span><span class="co">#&gt; [1] 2</span></span>
<span></span>
<span><span class="co"># now with depth 2</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"mtcars"</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">model</span></span>
<span><span class="co">#&gt; n= 32 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; node), split, n, deviance, yval</span></span>
<span><span class="co">#&gt;       * denotes terminal node</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1) root 32 1126.04700 20.09062  </span></span>
<span><span class="co">#&gt;   2) cyl&gt;=5 21  198.47240 16.64762  </span></span>
<span><span class="co">#&gt;     4) hp&gt;=192.5 7   28.82857 13.41429 *</span></span>
<span><span class="co">#&gt;     5) hp&lt; 192.5 14   59.87214 18.26429 *</span></span>
<span><span class="co">#&gt;   3) cyl&lt; 5 11  203.38550 26.66364 *</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># or with set_values()</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">set_values</span><span class="op">(</span>xval <span class="op">=</span> <span class="fl">2</span>, cp <span class="op">=</span> <span class="fl">.5</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span></span>
<span><span class="co">#&gt; $xval</span></span>
<span><span class="co">#&gt; [1] 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $maxdepth</span></span>
<span><span class="co">#&gt; [1] 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cp</span></span>
<span><span class="co">#&gt; [1] 0.5</span></span></code></pre></div>
</div>
</section><section id="baseline-learners" class="level3" data-number="2.2.4"><h3 data-number="2.2.4">
<span class="header-section-number">2.2.4</span> Baseline Learners</h3>
<p>Baselines are useful in model comparison and as fallback learners. For regression, we have implemented the baseline <code>lrn("regr.featureless")</code>, which always predicts new values to be the mean (or median, if the <code>robust</code> hyperparameter is set to <code>TRUE</code>) of the target in the training data:</p>
<p>基线在模型比较和作为备用学习器中非常有用。对于回归问题，我们已经实现了名为 <code>lrn("regr.featureless")</code> 的基线，它总是预测新值为训练数据中目标的均值（如果鲁棒性参数设置为 <code>TRUE</code>，则为中位数）：</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">task</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task_regr.html">as_task_regr</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                    target <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.featureless"</span><span class="op">)</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">task</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">995</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">task</span>, <span class="fl">996</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;PredictionRegr&gt; for 5 observations:</span></span>
<span><span class="co">#&gt;  row_ids    truth response</span></span>
<span><span class="co">#&gt;      996 1.484589 2.034983</span></span>
<span><span class="co">#&gt;      997 3.012537 2.034983</span></span>
<span><span class="co">#&gt;      998 1.964060 2.034983</span></span>
<span><span class="co">#&gt;      999 1.332658 2.034983</span></span>
<span><span class="co">#&gt;     1000 2.923380 2.034983</span></span></code></pre></div>
</div>
<p>It is good practice to test all new models against a baseline, and also to include baselines in experiments with multiple other models. In general, a model that does not outperform a baseline is a ‘bad’ model, on the other hand, a model is not necessarily ‘good’ if it outperforms the baseline.</p>
<blockquote>
<p>在实践中，对所有新模型进行与基线的测试是一个良好的做法，同时在与多个其他模型进行实验时也要包括基线。通常情况下，如果一个模型无法超越基线，那么它可以被视为是一个不好的模型；另一方面，如果一个模型超越了基线，也不一定就是一个好模型。</p>
</blockquote>
</section></section><section id="evaluation" class="level2" data-number="2.3"><h2 data-number="2.3">
<span class="header-section-number">2.3</span> Evaluation</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.rpart"</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"mtcars"</span><span class="op">)</span></span>
<span><span class="va">splits</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_mtcars</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_mtcars</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_mtcars</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span></code></pre></div>
</div>
<section id="measures" class="level3" data-number="2.3.1"><h3 data-number="2.3.1">
<span class="header-section-number">2.3.1</span> Measures</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span>
<span><span class="co">#&gt;            key                          label task_type          packages</span></span>
<span><span class="co">#&gt; 1:         aic   Akaike Information Criterion      &lt;NA&gt;              mlr3</span></span>
<span><span class="co">#&gt; 2:         bic Bayesian Information Criterion      &lt;NA&gt;              mlr3</span></span>
<span><span class="co">#&gt; 3: classif.acc        Classification Accuracy   classif mlr3,mlr3measures</span></span>
<span><span class="co">#&gt;    predict_type task_properties</span></span>
<span><span class="co">#&gt; 1:         &lt;NA&gt;                </span></span>
<span><span class="co">#&gt; 2:         &lt;NA&gt;                </span></span>
<span><span class="co">#&gt; 3:     response</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">measure</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"regr.mae"</span><span class="op">)</span></span>
<span><span class="va">measure</span></span>
<span><span class="co">#&gt; &lt;MeasureRegrSimple:regr.mae&gt;: Mean Absolute Error</span></span>
<span><span class="co">#&gt; * Packages: mlr3, mlr3measures</span></span>
<span><span class="co">#&gt; * Range: [0, Inf]</span></span>
<span><span class="co">#&gt; * Minimize: TRUE</span></span>
<span><span class="co">#&gt; * Average: macro</span></span>
<span><span class="co">#&gt; * Parameters: list()</span></span>
<span><span class="co">#&gt; * Properties: -</span></span>
<span><span class="co">#&gt; * Predict type: response</span></span></code></pre></div>
</div>
</section><section id="scoring-predictions" class="level3" data-number="2.3.2"><h3 data-number="2.3.2">
<span class="header-section-number">2.3.2</span> Scoring Predictions</h3>
<p>Note that all task types have default measures that are used if the argument to <code>$score()</code> is omitted, for regression this is the mean squared error (<code>msr("regr.mse")</code>).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; regr.mse </span></span>
<span><span class="co">#&gt; 18.44327</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measure</span><span class="op">)</span></span>
<span><span class="co">#&gt; regr.mae </span></span>
<span><span class="co">#&gt; 3.832168</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"regr.mse"</span>, <span class="st">"regr.mae"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;  regr.mse  regr.mae </span></span>
<span><span class="co">#&gt; 18.443271  3.832168</span></span></code></pre></div>
</div>
</section><section id="technical-measures" class="level3" data-number="2.3.3"><h3 data-number="2.3.3">
<span class="header-section-number">2.3.3</span> Technical Measures</h3>
<p><code>mlr3</code> also provides measures that do not quantify the quality of the predictions of a model, but instead provide ‘meta’-information about the model. These include:</p>
<ul>
<li><p><code>msr("time_train")</code>: The time taken to train a model.</p></li>
<li><p><code>msr("time_predict")</code>: The time taken for the model to make predictions.</p></li>
<li><p><code>msr("time_both")</code>: The total time taken to train the model and then make predictions.</p></li>
<li><p><code>msr("selected_features")</code>: The number of features selected by a model, which can only be used if the model has the “selected_features” property.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">measures</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"time_train"</span>, <span class="st">"time_predict"</span>, <span class="st">"time_both"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span>, learner <span class="op">=</span> <span class="va">lrn_rpart</span><span class="op">)</span></span>
<span><span class="co">#&gt;   time_train time_predict    time_both </span></span>
<span><span class="co">#&gt;            0            0            0</span></span></code></pre></div>
</div>
<p>These can be used after model training and predicting because we automatically store model run times whenever <code>$train()</code> and <code>$predict()</code> are called, so the measures above are equivalent to:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">lrn_rpart</span><span class="op">$</span><span class="va">timings</span>, both <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">lrn_rpart</span><span class="op">$</span><span class="va">timings</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;   train predict    both </span></span>
<span><span class="co">#&gt;       0       0       0</span></span></code></pre></div>
</div>
<p>The <code>selected_features</code> measure calculates how many features were used in the fitted model.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">msr_sf</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"selected_features"</span><span class="op">)</span></span>
<span><span class="va">msr_sf</span></span>
<span><span class="co">#&gt; &lt;MeasureSelectedFeatures:selected_features&gt;: Absolute or Relative Frequency of Selected Features</span></span>
<span><span class="co">#&gt; * Packages: mlr3</span></span>
<span><span class="co">#&gt; * Range: [0, Inf]</span></span>
<span><span class="co">#&gt; * Minimize: TRUE</span></span>
<span><span class="co">#&gt; * Average: macro</span></span>
<span><span class="co">#&gt; * Parameters: normalize=FALSE</span></span>
<span><span class="co">#&gt; * Properties: requires_task, requires_learner, requires_model</span></span>
<span><span class="co">#&gt; * Predict type: NA</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># accessed hyperparameters with `$param_set`</span></span>
<span><span class="va">msr_sf</span><span class="op">$</span><span class="va">param_set</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;           id    class lower upper nlevels default value</span></span>
<span><span class="co">#&gt; 1: normalize ParamLgl    NA    NA       2   FALSE FALSE</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">msr_sf</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">normalize</span> <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">msr_sf</span>, task <span class="op">=</span> <span class="va">tsk_mtcars</span>, learner <span class="op">=</span> <span class="va">lrn_rpart</span><span class="op">)</span></span>
<span><span class="co">#&gt; selected_features </span></span>
<span><span class="co">#&gt;               0.1</span></span></code></pre></div>
</div>
<p>Note that we passed the task and learner as the measure has the <code>requires_task</code> and <code>requires_learner</code> properties.</p>
</section></section><section id="our-first-regression-experiment" class="level2" data-number="2.4"><h2 data-number="2.4">
<span class="header-section-number">2.4</span> Our First Regression Experiment</h2>
<p>We have now seen how to train a model, make predictions and score them. What we have not yet attempted is to ascertain if our predictions are any ‘good’. So before look at how the building blocks of <code>mlr3</code> extend to classification, we will take a brief pause to put together everything above in a short experiment to assess the quality of our predictions. We will do this by comparing the performance of a featureless regression learner to a decision tree with changed hyperparameters.</p>
<blockquote>
<p>我们已经了解了如何训练模型、进行预测并对其进行评分。但是，我们尚未尝试确定我们的预测是否“好”。因此，在深入研究 <code>mlr3</code> 的构建模块如何扩展到分类之前，我们将简要停顿一下，通过一个简短的实验来评估我们预测的质量。我们将通过比较无特征的回归学习器与更改超参数的决策树的性能来进行评估。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">349</span><span class="op">)</span></span>
<span><span class="va">tsk_mtcars</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"mtcars"</span><span class="op">)</span></span>
<span><span class="va">splits</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_mtcars</span><span class="op">)</span></span>
<span><span class="va">lrn_featureless</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.featureless"</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.rpart"</span>, cp <span class="op">=</span> <span class="fl">.2</span>, maxdepth <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">measures</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"regr.mse"</span>, <span class="st">"regr.mae"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># train learners</span></span>
<span><span class="va">lrn_featureless</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_mtcars</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_mtcars</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="co"># make and score predictions</span></span>
<span><span class="va">lrn_featureless</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_mtcars</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span>
<span><span class="co">#&gt;  regr.mse  regr.mae </span></span>
<span><span class="co">#&gt; 26.726772  4.512987</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_mtcars</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span>
<span><span class="co">#&gt; regr.mse regr.mae </span></span>
<span><span class="co">#&gt; 6.932709 2.206494</span></span></code></pre></div>
</div>
</section><section id="classification" class="level2" data-number="2.5"><h2 data-number="2.5">
<span class="header-section-number">2.5</span> Classification</h2>
<section id="our-first-classification-experiment" class="level3" data-number="2.5.1"><h3 data-number="2.5.1">
<span class="header-section-number">2.5.1</span> Our First Classification Experiment</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">349</span><span class="op">)</span></span>
<span><span class="va">tsk_penguins</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">splits</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_penguins</span><span class="op">)</span></span>
<span><span class="va">lrn_featureless</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.featureless"</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, cp <span class="op">=</span> <span class="fl">.2</span>, maxdepth <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">measure</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># train learners</span></span>
<span><span class="va">lrn_featureless</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># make and score predictions</span></span>
<span><span class="va">lrn_featureless</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measure</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.acc </span></span>
<span><span class="co">#&gt;   0.4424779</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measure</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.acc </span></span>
<span><span class="co">#&gt;   0.9469027</span></span></code></pre></div>
</div>
</section><section id="taskclassif" class="level3" data-number="2.5.2"><h3 data-number="2.5.2">
<span class="header-section-number">2.5.2</span> TaskClassif</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsks</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="va">task_type</span> <span class="op">==</span> <span class="st">"classif"</span><span class="op">]</span></span>
<span><span class="co">#&gt;                 key                                     label task_type nrow</span></span>
<span><span class="co">#&gt;  1:   breast_cancer                   Wisconsin Breast Cancer   classif  683</span></span>
<span><span class="co">#&gt;  2:   german_credit                             German Credit   classif 1000</span></span>
<span><span class="co">#&gt;  3:            ilpd                 Indian Liver Patient Data   classif  583</span></span>
<span><span class="co">#&gt;  4:            iris                              Iris Flowers   classif  150</span></span>
<span><span class="co">#&gt;  5:       optdigits Optical Recognition of Handwritten Digits   classif 5620</span></span>
<span><span class="co">#&gt;  6:        penguins                           Palmer Penguins   classif  344</span></span>
<span><span class="co">#&gt;  7: penguins_simple                Simplified Palmer Penguins   classif  333</span></span>
<span><span class="co">#&gt;  8:            pima                      Pima Indian Diabetes   classif  768</span></span>
<span><span class="co">#&gt;  9:           sonar                    Sonar: Mines vs. Rocks   classif  208</span></span>
<span><span class="co">#&gt; 10:            spam                         HP Spam Detection   classif 4601</span></span>
<span><span class="co">#&gt; 11:         titanic                                   Titanic   classif 1309</span></span>
<span><span class="co">#&gt; 12:            wine                              Wine Regions   classif  178</span></span>
<span><span class="co">#&gt; 13:             zoo                               Zoo Animals   classif  101</span></span>
<span><span class="co">#&gt;     ncol properties lgl int dbl chr fct ord pxc</span></span>
<span><span class="co">#&gt;  1:   10   twoclass   0   0   0   0   0   9   0</span></span>
<span><span class="co">#&gt;  2:   21   twoclass   0   3   0   0  14   3   0</span></span>
<span><span class="co">#&gt;  3:   11   twoclass   0   4   5   0   1   0   0</span></span>
<span><span class="co">#&gt;  4:    5 multiclass   0   0   4   0   0   0   0</span></span>
<span><span class="co">#&gt;  5:   65   twoclass   0  64   0   0   0   0   0</span></span>
<span><span class="co">#&gt;  6:    8 multiclass   0   3   2   0   2   0   0</span></span>
<span><span class="co">#&gt;  7:   11 multiclass   0   3   7   0   0   0   0</span></span>
<span><span class="co">#&gt;  8:    9   twoclass   0   0   8   0   0   0   0</span></span>
<span><span class="co">#&gt;  9:   61   twoclass   0   0  60   0   0   0   0</span></span>
<span><span class="co">#&gt; 10:   58   twoclass   0   0  57   0   0   0   0</span></span>
<span><span class="co">#&gt; 11:   11   twoclass   0   2   2   3   2   1   0</span></span>
<span><span class="co">#&gt; 12:   14 multiclass   0   2  11   0   0   0   0</span></span>
<span><span class="co">#&gt; 13:   17 multiclass  15   1   0   0   0   0   0</span></span></code></pre></div>
</div>
<p>The <code>sonar</code> task is an example of a binary classification problem, as the target can only take two different values, in <code>mlr3</code> terminology it has the “twoclass” property:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_sonar</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span></span>
<span><span class="va">tsk_sonar</span></span>
<span><span class="co">#&gt; &lt;TaskClassif:sonar&gt; (208 x 61): Sonar: Mines vs. Rocks</span></span>
<span><span class="co">#&gt; * Target: Class</span></span>
<span><span class="co">#&gt; * Properties: twoclass</span></span>
<span><span class="co">#&gt; * Features (60):</span></span>
<span><span class="co">#&gt;   - dbl (60): V1, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19, V2,</span></span>
<span><span class="co">#&gt;     V20, V21, V22, V23, V24, V25, V26, V27, V28, V29, V3, V30, V31,</span></span>
<span><span class="co">#&gt;     V32, V33, V34, V35, V36, V37, V38, V39, V4, V40, V41, V42, V43,</span></span>
<span><span class="co">#&gt;     V44, V45, V46, V47, V48, V49, V5, V50, V51, V52, V53, V54, V55,</span></span>
<span><span class="co">#&gt;     V56, V57, V58, V59, V6, V60, V7, V8, V9</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_sonar</span><span class="op">$</span><span class="va">class_names</span></span>
<span><span class="co">#&gt; [1] "M" "R"</span></span></code></pre></div>
</div>
<p>In contrast, <code>tsk("penguins")</code> is a multiclass problem as there are more than two species of penguins; it has the “multiclass” property:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_penguins</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">tsk_penguins</span><span class="op">$</span><span class="va">properties</span></span>
<span><span class="co">#&gt; [1] "multiclass"</span></span>
<span><span class="va">tsk_penguins</span><span class="op">$</span><span class="va">class_names</span></span>
<span><span class="co">#&gt; [1] "Adelie"    "Chinstrap" "Gentoo"</span></span></code></pre></div>
</div>
<p>A further difference between these tasks is that binary classification tasks have an extra field called <code>$positive</code>, which defines the ‘positive’ class. In binary classification, as there are only two possible class types, by convention one of these is known as the ‘positive’ class, and the other as the ‘negative’ class. It is arbitrary which is which, though often the more ‘important’ (and often smaller) class is set as the positive class. You can set the positive class during or after construction. If no positive class is specified then <code>mlr3</code> assumes the first level in the <code>target</code> column is the positive class, which can lead to misleading results.</p>
<blockquote>
<p>这两种任务之间的另一个区别是，二分类任务有一个额外的字段称为 <code>$positive</code>，它定义了“正类”（positive class）。在二分类问题中，由于只有两种可能的类别类型，按照惯例，其中一种被称为“正类”，另一种被称为“负类”。哪个是哪个是任意的，尽管通常更“重要”（通常更小）的类别被设置为正类。您可以在构建期间或之后设置正类。如果未指定正类，则 <code>mlr3</code> 假定目标列中的第一个级别是正类，这可能导致误导性的结果。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Sonar</span> <span class="op">=</span> <span class="va">tsk_sonar</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">tsk_classif</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task_classif.html">as_task_classif</a></span><span class="op">(</span><span class="va">Sonar</span>, target <span class="op">=</span> <span class="st">"Class"</span>, positive <span class="op">=</span> <span class="st">"R"</span><span class="op">)</span></span>
<span><span class="va">tsk_classif</span><span class="op">$</span><span class="va">positive</span></span>
<span><span class="co">#&gt; [1] "R"</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># changing after construction</span></span>
<span><span class="va">tsk_classif</span><span class="op">$</span><span class="va">positive</span> <span class="op">=</span> <span class="st">"M"</span></span>
<span><span class="va">tsk_classif</span><span class="op">$</span><span class="va">positive</span></span>
<span><span class="co">#&gt; [1] "M"</span></span></code></pre></div>
</div>
</section><section id="learnerclassif-and-measureclassif" class="level3" data-number="2.5.3"><h3 data-number="2.5.3">
<span class="header-section-number">2.5.3</span> LearnerClassif and MeasureClassif</h3>
<p>Classification learners, which inherit from <code>LearnerClassif</code>, have nearly the same interface as regression learners. However, a key difference is that the possible predictions in classification are either <code>"response"</code> – predicting an observation’s class (a penguin’s species in our example, this is sometimes called “hard labeling”) – or <code>"prob"</code> – predicting a vector of probabilities, also called “posterior probabilities”, of an observation belonging to each class. In classification, the latter can be more useful as it provides information about the confidence of the predictions:</p>
<blockquote>
<p>分类学习器（继承自 <code>LearnerClassif</code>）几乎具有与回归学习器相同的接口。然而，分类中的一个关键区别是，分类问题中可能的预测结果要么是 <code>"response"</code> （预测观测的类别，例如我们示例中的企鹅物种，有时称为“硬标签”），要么是 <code>"prob"</code> （预测属于每个类别的概率向量，也称为“后验概率”）。在分类中，后者可能更有用，因为它提供了有关预测的置信度信息：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="va">prediction</span></span>
<span><span class="co">#&gt; &lt;PredictionClassif&gt; for 113 observations:</span></span>
<span><span class="co">#&gt;     row_ids     truth  response prob.Adelie prob.Chinstrap prob.Gentoo</span></span>
<span><span class="co">#&gt;           2    Adelie    Adelie  0.97029703     0.02970297  0.00000000</span></span>
<span><span class="co">#&gt;           4    Adelie    Adelie  0.97029703     0.02970297  0.00000000</span></span>
<span><span class="co">#&gt;           7    Adelie    Adelie  0.97029703     0.02970297  0.00000000</span></span>
<span><span class="co">#&gt; ---                                                                   </span></span>
<span><span class="co">#&gt;         338 Chinstrap Chinstrap  0.04651163     0.93023256  0.02325581</span></span>
<span><span class="co">#&gt;         341 Chinstrap    Adelie  0.97029703     0.02970297  0.00000000</span></span>
<span><span class="co">#&gt;         344 Chinstrap Chinstrap  0.04651163     0.93023256  0.02325581</span></span></code></pre></div>
</div>
<p>Also, the interface for classification measures, which are of class <code>MeasureClassif</code>, is identical to regression measures. The key difference in usage is that you will need to ensure your selected measure evaluates the prediction type of interest. To evaluate “response” predictions, you will need measures with <code>predict_type = "response"</code>, or to evaluate probability predictions you will need <code>predict_type = "prob"</code>. The easiest way to find these measures is by filtering the <code>mlr_measures</code> dictionary:</p>
<blockquote>
<p>此外，分类度量标准的接口，其类别为 <code>MeasureClassif</code>，与回归度量标准完全相同。在使用上的主要区别在于，您需要确保所选的度量标准评估感兴趣的预测类型。要评估 <code>“response”</code> 预测，您需要使用 <code>predict_type = "response"</code> 的度量标准，或者要评估概率预测，您需要使用 <code>predict_type = "prob"</code> 的度量标准。查找这些度量标准的最简单方法是通过筛选 <code>mlr_measures</code> 字典：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">[</span></span>
<span>  <span class="va">task_type</span> <span class="op">==</span> <span class="st">"classif"</span> <span class="op">&amp;</span> <span class="va">predict_type</span> <span class="op">==</span> <span class="st">"prob"</span> <span class="op">&amp;</span></span>
<span>  <span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">task_properties</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="st">"twoclass"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">x</span><span class="op">)</span></span>
<span><span class="op">]</span></span>
<span><span class="co">#&gt;                  key                                      label task_type</span></span>
<span><span class="co">#&gt; 1:   classif.logloss                                   Log Loss   classif</span></span>
<span><span class="co">#&gt; 2: classif.mauc_au1p    Weighted average 1 vs. 1 multiclass AUC   classif</span></span>
<span><span class="co">#&gt; 3: classif.mauc_au1u             Average 1 vs. 1 multiclass AUC   classif</span></span>
<span><span class="co">#&gt; 4: classif.mauc_aunp Weighted average 1 vs. rest multiclass AUC   classif</span></span>
<span><span class="co">#&gt; 5: classif.mauc_aunu          Average 1 vs. rest multiclass AUC   classif</span></span>
<span><span class="co">#&gt; 6:    classif.mbrier                     Multiclass Brier Score   classif</span></span>
<span><span class="co">#&gt;             packages predict_type task_properties</span></span>
<span><span class="co">#&gt; 1: mlr3,mlr3measures         prob                </span></span>
<span><span class="co">#&gt; 2: mlr3,mlr3measures         prob                </span></span>
<span><span class="co">#&gt; 3: mlr3,mlr3measures         prob                </span></span>
<span><span class="co">#&gt; 4: mlr3,mlr3measures         prob                </span></span>
<span><span class="co">#&gt; 5: mlr3,mlr3measures         prob                </span></span>
<span><span class="co">#&gt; 6: mlr3,mlr3measures         prob</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">measures</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.mbrier"</span>, <span class="st">"classif.logloss"</span>, <span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span>
<span><span class="co">#&gt;  classif.mbrier classif.logloss     classif.acc </span></span>
<span><span class="co">#&gt;       0.1016821       0.2291407       0.9469027</span></span></code></pre></div>
</div>
</section><section id="predictionclassif-confusion-matrix-and-thresholding" class="level3" data-number="2.5.4"><h3 data-number="2.5.4">
<span class="header-section-number">2.5.4</span> PredictionClassif, Confusion Matrix, and Thresholding</h3>
<p><code>PredictionClassif</code> objects have two important differences from their regression analog. Firstly, the added field <code>$confusion</code>, and secondly the added method <code>$set_threshold()</code>.</p>
<blockquote>
<p><code>PredictionClassif</code> 对象与其回归模型的预测对象有两个重要的区别。首先是新增的字段 <code>$confusion</code>，其次是新增的方法 <code>$set_threshold()</code>。</p>
</blockquote>
<section id="confusion-matrix" class="level4" data-number="2.5.4.1"><h4 data-number="2.5.4.1">
<span class="header-section-number">2.5.4.1</span> Confusion Matrix</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prediction</span><span class="op">$</span><span class="va">confusion</span></span>
<span><span class="co">#&gt;            truth</span></span>
<span><span class="co">#&gt; response    Adelie Chinstrap Gentoo</span></span>
<span><span class="co">#&gt;   Adelie        49         3      0</span></span>
<span><span class="co">#&gt;   Chinstrap      1        18      1</span></span>
<span><span class="co">#&gt;   Gentoo         0         1     40</span></span></code></pre></div>
</div>
<p>The rows in a confusion matrix are the predicted class and the columns are the true class. All off-diagonal entries are incorrectly classified observations, and all diagonal entries are correctly classified. In this case, the classifier does fairly well classifying all penguins, but we could have found that it only classifies the Adelie species well but often conflates Chinstrap and Gentoo, for example.</p>
<blockquote>
<p>混淆矩阵中的行表示预测的类别，列表示真实的类别。所有非对角线条目都是被错误分类的观测值，而所有对角线条目都是被正确分类的。在这种情况下，分类器在对所有企鹅进行分类时表现得相当不错，但我们也可能发现它只能很好地对 Adelie 物种进行分类，但经常将 Chinstrap 和 Gentoo 混为一谈。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">prediction</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div id="fig-confusion_matrix" class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/fig-confusion_matrix-1.png" class="img-fluid" style="width:70.0%"></p>
<figcaption>Figure 2.1: Counts of each class label in the ground truth data (left) and predictions (right).</figcaption></figure>
</div>
</div>
</div>
<p>In the binary classification case, the top left entry corresponds to true positives, the top right to false positives, the bottom left to false negatives and the bottom right to true negatives. Taking <code>tsk_sonar</code> as an example with <code>M</code> as the positive class:</p>
<blockquote>
<p>在二分类情况下，左上角的条目对应于真正例（true positives），右上角对应于假正例（false positives），左下角对应于假负例（false negatives），右下角对应于真负例（true negatives）。以 <code>tsk_sonar</code> 为例，<code>M</code> 为正类：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">splits</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_sonar</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span></span>
<span>  <span class="fu">train</span><span class="op">(</span><span class="va">tsk_sonar</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">predict</span><span class="op">(</span><span class="va">tsk_sonar</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="va">confusion</span></span>
<span><span class="co">#&gt;         truth</span></span>
<span><span class="co">#&gt; response  M  R</span></span>
<span><span class="co">#&gt;        M 27 10</span></span>
<span><span class="co">#&gt;        R 10 22</span></span></code></pre></div>
</div>
</section><section id="thresholding" class="level4" data-number="2.5.4.2"><h4 data-number="2.5.4.2">
<span class="header-section-number">2.5.4.2</span> Thresholding</h4>
<p><strong>阈值化</strong></p>
<p>This 50% value is known as the threshold and it can be useful to change this threshold if there is class imbalance (when one class is over- or under-represented in a dataset), or if there are different costs associated with classes, or simply if there is a preference to ‘over’-predict one class. As an example, let us take <code>tsk("german_credit")</code> in which 700 customers have good credit and 300 have bad. Now we could easily build a model with around “70%” accuracy simply by always predicting a customer will have good credit:</p>
<blockquote>
<p>这个 50% 的值被称为阈值，如果数据集中存在类别不平衡（即一个类别在数据集中过多或过少出现），或者不同的类别具有不同的成本，或者只是有一种“过度”预测一种类别的倾向，那么更改这个阈值可能会很有用。举个例子，让我们看看 <code>tsk("german_credit")</code>，其中有 700 个客户信用良好，300 个客户信用不良。现在，我们可以很容易地构建一个模型，总是预测客户会有良好的信用，从而获得 “70%” 左右的准确性：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">task_credit</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"german_credit"</span><span class="op">)</span></span>
<span><span class="va">lrn_featureless</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.featureless"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">splits</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">task_credit</span><span class="op">)</span></span>
<span><span class="va">lrn_featureless</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">task_credit</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_featureless</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">task_credit</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.acc </span></span>
<span><span class="co">#&gt;         0.7</span></span></code></pre></div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>TODO：等待后续添加交叉引用 13.1</p>
</div>
</div>
<p>While this model may appear to have good performance on the surface, in fact, it just ignores all ‘bad’ customers – this can create big problems in this finance example, as well as in healthcare tasks and other settings where false positives cost more than false negatives (see Section 13.1 for cost-sensitive classification).</p>
<p>Thresholding allows classes to be selected with a different probability threshold, so instead of predicting that a customer has bad credit if P(good) &lt; 50%, we might predict bad credit if P(good) &lt; 70% – notice how we write this in terms of the positive class, which in this task is ‘good’. Let us see this in practice:</p>
<blockquote>
<p>虽然这个模型表面上看起来性能不错，但实际上它只是忽略了所有“不良”的客户 - 这在金融示例以及在医疗任务和其他一些情况下可能会带来很大问题，特别是在假阳性的成本高于假阴性的情况下（请参见第13.1节的成本敏感分类）。</p>
<p>阈值化允许使用不同的概率阈值选择类别，因此，与其在P(好) &lt; 50%时预测客户信用不良，我们可以在P(好) &lt; 70%时预测客户信用不良。请注意，我们是根据正类别来表示这一点，而在这个任务中正类别是“好”。让我们看看实际应用中的情况：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prediction</span><span class="op">$</span><span class="fu">set_threshold</span><span class="op">(</span><span class="fl">0.7</span><span class="op">)</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.acc </span></span>
<span><span class="co">#&gt;   0.5393939</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">task_credit</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">task_credit</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.acc </span></span>
<span><span class="co">#&gt;   0.6939394</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="va">confusion</span></span>
<span><span class="co">#&gt;         truth</span></span>
<span><span class="co">#&gt; response good bad</span></span>
<span><span class="co">#&gt;     good  194  64</span></span>
<span><span class="co">#&gt;     bad    37  35</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prediction</span><span class="op">$</span><span class="fu">set_threshold</span><span class="op">(</span><span class="fl">0.7</span><span class="op">)</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.acc </span></span>
<span><span class="co">#&gt;   0.6878788</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="va">confusion</span></span>
<span><span class="co">#&gt;         truth</span></span>
<span><span class="co">#&gt; response good bad</span></span>
<span><span class="co">#&gt;     good  181  53</span></span>
<span><span class="co">#&gt;     bad    50  46</span></span></code></pre></div>
</div>
</section></section></section></section><section id="sec-performance" class="level1" data-number="3"><h1 data-number="3">
<span class="header-section-number">3</span> Evaluation and Benchmarking</h1>
<p><strong>Resampling Does Not Avoid Model Overfitting</strong>: A common <strong>misunderstanding</strong> is that holdout and other more advanced resampling strategies can prevent model overfitting. In fact, these methods just make overfitting visible as we can separately evaluate train/test performance. Resampling strategies also allow us to make (nearly) unbiased estimations of the generalization error.</p>
<blockquote>
<p><strong>重采样不能避免模型过拟合</strong>：一个常见的误解是，留出策略和其他更高级的重采样策略可以防止模型过拟合。实际上，这些方法只是使过拟合问题更加显而易见，因为我们可以单独评估训练/测试性能。重采样策略还允许我们对泛化误差进行（几乎）无偏估计。</p>
</blockquote>
<section id="holdout-and-scoring" class="level2" data-number="3.1"><h2 data-number="3.1">
<span class="header-section-number">3.1</span> Holdout and Scoring</h2>
<p>In practice, one would usually create an intermediate model, which is trained on a subset of the available data and then tested on the remainder of the data. The performance of this intermediate model, obtained by comparing the model predictions to the ground truth, is an estimate of the generalization performance of the final model, which is the model fitted on all data.</p>
<blockquote>
<p>在实践中，通常会创建一个中间模型，该模型在可用数据的子集上进行训练，然后在剩余的数据上进行测试。通过将模型的预测与真实情况进行比较，中间模型的性能可以作为最终模型的泛化性能的估计。最终模型是在所有可用数据上训练的模型。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_penguins</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">splits</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_penguins</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.acc </span></span>
<span><span class="co">#&gt;   0.9380531</span></span></code></pre></div>
</div>
</section><section id="resampling" class="level2" data-number="3.2"><h2 data-number="3.2">
<span class="header-section-number">3.2</span> Resampling</h2>
<section id="constructing-a-resampling-strategy" class="level3" data-number="3.2.1"><h3 data-number="3.2.1">
<span class="header-section-number">3.2.1</span> Constructing a Resampling Strategy</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;            key                         label        params iters</span></span>
<span><span class="co">#&gt; 1:   bootstrap                     Bootstrap ratio,repeats    30</span></span>
<span><span class="co">#&gt; 2:      custom                 Custom Splits                  NA</span></span>
<span><span class="co">#&gt; 3:   custom_cv Custom Split Cross-Validation                  NA</span></span>
<span><span class="co">#&gt; 4:          cv              Cross-Validation         folds    10</span></span>
<span><span class="co">#&gt; 5:     holdout                       Holdout         ratio     1</span></span>
<span><span class="co">#&gt; 6:    insample           Insample Resampling                   1</span></span>
<span><span class="co">#&gt; 7:         loo                 Leave-One-Out                  NA</span></span>
<span><span class="co">#&gt; 8: repeated_cv     Repeated Cross-Validation folds,repeats   100</span></span>
<span><span class="co">#&gt; 9: subsampling                   Subsampling ratio,repeats    30</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"holdout"</span>, ratio <span class="op">=</span> <span class="fl">.8</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;ResamplingHoldout&gt;: Holdout</span></span>
<span><span class="co">#&gt; * Iterations: 1</span></span>
<span><span class="co">#&gt; * Instantiated: FALSE</span></span>
<span><span class="co">#&gt; * Parameters: ratio=0.8</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># three-fold CV</span></span>
<span><span class="va">cv3</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co"># subsampling with 3 repeats and 9/10 ratio</span></span>
<span><span class="va">ss390</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"subsampling"</span>, repeats <span class="op">=</span> <span class="fl">3</span>, ratio <span class="op">=</span> <span class="fl">.9</span><span class="op">)</span></span>
<span><span class="co"># 2-repeats 5-fold cv</span></span>
<span><span class="va">rcv25</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"repeated_cv"</span>, repeats <span class="op">=</span> <span class="fl">2</span>, folds <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code></pre></div>
</div>
<p>When a <code>"Resampling"</code> object is constructed, it is simply a definition for how the data splitting process will be performed on the task when running the resampling strategy. However, it is possible to manually instantiate a resampling strategy, i.e., generate all train-test splits, by calling the <code>$instantiate()</code> method on a given task.</p>
<blockquote>
<p>当构建一个 <code>"Resampling"</code> 对象时，它只是对在运行重采样策略时如何执行数据拆分过程的定义。然而，可以通过在给定任务上调用 <code>$instantiate()</code> 方法来手动实例化一个重采样策略，即生成所有的训练-测试拆分。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv3</span><span class="op">$</span><span class="fu">instantiate</span><span class="op">(</span><span class="va">tsk_penguins</span><span class="op">)</span></span>
<span><span class="co"># first 5 observations in first traininng set</span></span>
<span><span class="va">cv3</span><span class="op">$</span><span class="fu">train_set</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span>
<span><span class="co">#&gt; [1] 2 4 5 6 8</span></span>
<span><span class="co"># fitst 5 observations in thirt test set</span></span>
<span><span class="va">cv3</span><span class="op">$</span><span class="fu">test_set</span><span class="op">(</span><span class="fl">3</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span>
<span><span class="co">#&gt; [1]  1  9 12 17 20</span></span></code></pre></div>
</div>
<p>When the aim is to fairly compare multiple learners, best practice dictates that all learners being compared use the same training data to build a model and that they use the same test data to evaluate the model performance. Resampling strategies are instantiated automatically for you when using the <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> method. Therefore, manually instantiating resampling strategies is rarely required but might be useful for debugging or digging deeper into a model’s performance.</p>
<blockquote>
<p>当目标是公平比较多个学习器时，最佳实践要求所有进行比较的学习器都使用相同的训练数据来构建模型，并且它们使用相同的测试数据来评估模型性能。在使用 <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> 方法时，重采样策略会自动为您实例化。因此，手动实例化重采样策略很少是必需的，但在调试或深入研究模型性能时可能会有用。</p>
</blockquote>
</section><section id="resampling-experiments" class="level3" data-number="3.2.2"><h3 data-number="3.2.2">
<span class="header-section-number">3.2.2</span> Resampling Experiments</h3>
<p>The <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> function takes a given <code>Task</code>, <code>Learner</code>, and <code>Resampling</code> object to run the given resampling strategy. <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> repeatedly fits a model on training sets, makes predictions on the corresponding test sets and stores them in a <code>ResampleResult</code> object, which contains all the information needed to estimate the generalization performance.</p>
<p><code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> 函数接受给定的任务（<code>Task</code>）、学习器（<code>Learner</code>）和重采样（<code>Resampling</code>）对象，以运行给定的重采样策略。<code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> 函数会在训练集上反复拟合模型，在相应的测试集上进行预测，并将预测结果存储在 <code>ResampleResult</code> 对象中，该对象包含了估算泛化性能所需的所有信息。</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/resample.html">resample</a></span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">lrn_rpart</span>, <span class="va">cv3</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rr</span></span>
<span><span class="co">#&gt; &lt;ResampleResult&gt; with 3 resampling iterations</span></span>
<span><span class="co">#&gt;   task_id    learner_id resampling_id iteration warnings errors</span></span>
<span><span class="co">#&gt;  penguins classif.rpart            cv         1        0      0</span></span>
<span><span class="co">#&gt;  penguins classif.rpart            cv         2        0      0</span></span>
<span><span class="co">#&gt;  penguins classif.rpart            cv         3        0      0</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># calculate the score for each iteration</span></span>
<span><span class="va">acc</span> <span class="op">=</span> <span class="va">rr</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">acc</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">iteration</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;    iteration classif.ce</span></span>
<span><span class="co">#&gt; 1:         1 0.04347826</span></span>
<span><span class="co">#&gt; 2:         2 0.09565217</span></span>
<span><span class="co">#&gt; 3:         3 0.06140351</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># aggregated score across all resampling iterations</span></span>
<span><span class="va">rr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.ce </span></span>
<span><span class="co">#&gt; 0.06684465</span></span></code></pre></div>
</div>
<p>By default, the majority of measures will aggregate scores using a macro average, which first calculates the measure in each resampling iteration separately, and then averages these scores across all iterations. However, it is also possible to aggregate scores using a micro average, which pools predictions across resampling iterations into one <code>Prediction</code> object and then computes the measure on this directly:</p>
<blockquote>
<p>默认情况下，大多数性能度量会使用宏平均（macro average）来汇总分数，它首先在每个重采样迭代中分别计算度量，然后在所有迭代中对这些分数进行平均。但也可以使用微平均（micro average）来汇总分数，它将重采样迭代中的预测汇总到一个 <code>Prediction</code> 对象中，然后直接在该对象上计算度量：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span>, average <span class="op">=</span> <span class="st">"micro"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.ce </span></span>
<span><span class="co">#&gt; 0.06686047</span></span></code></pre></div>
</div>
<p>To visualize the resampling results, you can use the <code>autoplot.ResampleResult()</code> function to plot scores across folds as boxplots or histograms (<a href="#fig-resamp-viz">Figure 3.1</a>). Histograms can be useful to visually gauge the variance of the performance results across resampling iterations, whereas boxplots are often used when multiple learners are compared side-by-side (see <a href="#sec-benchmarking">Section 3.3</a>).</p>
<blockquote>
<p>要可视化重采样结果，您可以使用 <code>autoplot.ResampleResult()</code> 函数绘制跨折叠的分数箱线图或直方图（<a href="#fig-resamp-viz">Figure 3.1</a>）。直方图可以用于直观评估跨重采样迭代的性能结果方差，而箱线图通常用于比较多个学习器并排放置在一起时（请参阅 <a href="#sec-benchmarking">Section 3.3</a>）。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/resample.html">resample</a></span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">lrn_rpart</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">rr</span>, measure <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span>, type <span class="op">=</span> <span class="st">"boxplot"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">rr</span>, measure <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span>, type <span class="op">=</span> <span class="st">"histogram"</span><span class="op">)</span></span></code></pre></div>
<div id="fig-resamp-viz" class="cell quarto-layout-panel">
<figure><div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-resamp-viz-1" class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/fig-resamp-viz-1.png" class="img-fluid" alt="Left: a boxplot ranging from 0.875 to 1.0 and the interquartile range between 0.925 and 0.7. Right: a histogram with five bars in a roughly normal distribution with mean 0.95, minimum 0.875 and maximum 1.0." data-ref-parent="fig-resamp-viz"></p>
<figcaption>(a) Boxplot of accuracy scores.</figcaption></figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-resamp-viz-2" class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/fig-resamp-viz-2.png" class="img-fluid" alt="Left: a boxplot ranging from 0.875 to 1.0 and the interquartile range between 0.925 and 0.7. Right: a histogram with five bars in a roughly normal distribution with mean 0.95, minimum 0.875 and maximum 1.0." data-ref-parent="fig-resamp-viz"></p>
<figcaption>(b) Histogram of accuracy scores.</figcaption></figure>
</div>
</div>
</div>
<p><figcaption>Figure 3.1: Boxplot and Histogram of accuracy scores.</figcaption></p>
</figure>
</div>
</div>
</section><section id="resampleresult-objects" class="level3" data-number="3.2.3"><h3 data-number="3.2.3">
<span class="header-section-number">3.2.3</span> ResampleResult Objects</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># list of prediction objects</span></span>
<span><span class="va">rrp</span> <span class="op">=</span> <span class="va">rr</span><span class="op">$</span><span class="fu">predictions</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co"># print first two</span></span>
<span><span class="va">rrp</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; &lt;PredictionClassif&gt; for 35 observations:</span></span>
<span><span class="co">#&gt;     row_ids     truth  response</span></span>
<span><span class="co">#&gt;           7    Adelie    Adelie</span></span>
<span><span class="co">#&gt;          20    Adelie Chinstrap</span></span>
<span><span class="co">#&gt;          32    Adelie    Adelie</span></span>
<span><span class="co">#&gt; ---                            </span></span>
<span><span class="co">#&gt;         326 Chinstrap Chinstrap</span></span>
<span><span class="co">#&gt;         330 Chinstrap Chinstrap</span></span>
<span><span class="co">#&gt;         337 Chinstrap Chinstrap</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span>
<span><span class="co">#&gt; &lt;PredictionClassif&gt; for 35 observations:</span></span>
<span><span class="co">#&gt;     row_ids     truth  response</span></span>
<span><span class="co">#&gt;           1    Adelie    Adelie</span></span>
<span><span class="co">#&gt;           5    Adelie    Adelie</span></span>
<span><span class="co">#&gt;           9    Adelie    Adelie</span></span>
<span><span class="co">#&gt; ---                            </span></span>
<span><span class="co">#&gt;         334 Chinstrap Chinstrap</span></span>
<span><span class="co">#&gt;         339 Chinstrap Chinstrap</span></span>
<span><span class="co">#&gt;         340 Chinstrap Chinstrap</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># macro averaged performance</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">rrp</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.05823529</span></span></code></pre></div>
</div>
<p>By default, the intermediate models produced at each resampling iteration are discarded after the prediction step to reduce memory consumption of the <code>ResampleResult</code> object (only the predictions are required to calculate most performance measures). However, it can sometimes be useful to inspect, compare, or extract information from these intermediate models. We can configure the <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> function to keep the fitted intermediate models by setting <code>store_models = TRUE</code>. Each model trained in a specific resampling iteration can then be accessed via <code>$learners[[i]]$model</code>, where <code>i</code> refers to the <code>i</code>-th resampling iteration:</p>
<blockquote>
<p>默认情况下，在进行预测步骤后，每个重新采样迭代产生的中间模型都会被丢弃，以降低 <code>ResampleResult</code> 对象的内存消耗（大多数性能指标仅需要预测）。然而，有时候检查、比较或从这些中间模型中提取信息可能是有用的。我们可以通过设置 <code>store_models = TRUE</code> 来配置 <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> 函数以保留拟合的中间模型。然后，可以通过 <code>$learners[[i]]$model</code> 来访问在特定重新采样迭代中训练的每个模型，其中 <code>i</code> 指的是第 <code>i</code> 个重新采样迭代：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/resample.html">resample</a></span><span class="op">(</span><span class="va">tsk_penguins</span>, <span class="va">lrn_rpart</span>, <span class="va">cv3</span>, store_models <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get the model from the first iteration</span></span>
<span><span class="va">rr</span><span class="op">$</span><span class="va">learners</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">model</span></span>
<span><span class="co">#&gt; n= 229 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; node), split, n, loss, yval, (yprob)</span></span>
<span><span class="co">#&gt;       * denotes terminal node</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1) root 229 130 Adelie (0.432314410 0.205240175 0.362445415)  </span></span>
<span><span class="co">#&gt;   2) flipper_length&lt; 206.5 142  45 Adelie (0.683098592 0.309859155 0.007042254)  </span></span>
<span><span class="co">#&gt;     4) bill_length&lt; 44.65 97   3 Adelie (0.969072165 0.030927835 0.000000000) *</span></span>
<span><span class="co">#&gt;     5) bill_length&gt;=44.65 45   4 Chinstrap (0.066666667 0.911111111 0.022222222) *</span></span>
<span><span class="co">#&gt;   3) flipper_length&gt;=206.5 87   5 Gentoo (0.022988506 0.034482759 0.942528736) *</span></span></code></pre></div>
</div>
<p>In this example, we could then inspect the most important variables in each iteration to help us learn more about the respective fitted models:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># print 2nd and 3rd iteration</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="va">rr</span><span class="op">$</span><span class="va">learners</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">$</span><span class="va">model</span><span class="op">$</span><span class="va">variable.importance</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; flipper_length    bill_length     bill_depth      body_mass         island </span></span>
<span><span class="co">#&gt;       88.52870       88.07438       71.51814       67.04826       55.13690 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span>
<span><span class="co">#&gt;    bill_length flipper_length     bill_depth      body_mass         island </span></span>
<span><span class="co">#&gt;       82.18794       75.92820       66.94285       57.14539       50.29049</span></span></code></pre></div>
</div>
</section></section><section id="sec-benchmarking" class="level2" data-number="3.3"><h2 data-number="3.3">
<span class="header-section-number">3.3</span> Benchmarking</h2>
<section id="benchmark" class="level3" data-number="3.3.1"><h3 data-number="3.3.1">
<span class="header-section-number">3.3.1</span> benchmark()</h3>
<p>Benchmark experiments in <code>mlr3</code> are conducted with <code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code>, which simply runs <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> on each task and learner separately, then collects the results. The provided resampling strategy is automatically instantiated on each task to ensure that all learners are compared against the same training and test data.</p>
<p>To use the <code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code> function we first call <code><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid()</a></code>, which constructs an exhaustive <em>design</em> to describe all combinations of the learners, tasks and resamplings to be used in a benchmark experiment, and instantiates the resampling strategies.</p>
<blockquote>
<p><code>mlr3</code> 中的基准实验是使用 <code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code> 函数进行的，该函数简单地在每个任务和学习器上分别运行 <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code>，然后收集结果。提供的重新采样策略会自动在每个任务上进行实例化，以确保所有学习器都与相同的训练和测试数据进行比较。</p>
<p>要使用 <code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code> 函数，我们首先调用 <code><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid()</a></code> 函数，该函数构建一个详尽的设计来描述在基准实验中要使用的所有学习器、任务和重新采样的组合，并实例化重新采样策略。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tasks</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsks</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"german_credit"</span>, <span class="st">"sonar"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrns</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, <span class="st">"classif.ranger"</span>, <span class="st">"classif.featureless"</span><span class="op">)</span>,</span>
<span>                predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">rsmp_cv5</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">design</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tasks</span>, <span class="va">learners</span>, <span class="va">rsmp_cv5</span><span class="op">)</span></span>
<span><span class="va">design</span></span>
<span><span class="co">#&gt;             task             learner resampling</span></span>
<span><span class="co">#&gt; 1: german_credit       classif.rpart         cv</span></span>
<span><span class="co">#&gt; 2: german_credit      classif.ranger         cv</span></span>
<span><span class="co">#&gt; 3: german_credit classif.featureless         cv</span></span>
<span><span class="co">#&gt; 4:         sonar       classif.rpart         cv</span></span>
<span><span class="co">#&gt; 5:         sonar      classif.ranger         cv</span></span>
<span><span class="co">#&gt; 6:         sonar classif.featureless         cv</span></span></code></pre></div>
</div>
<p>By default, <code><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid()</a></code> instantiates the resamplings on the tasks, which means that concrete train-test splits are generated. Since this process is stochastic, it is necessary to set a seed <strong>before</strong> calling <code><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid()</a></code> to ensure reproducibility of the data splits.</p>
<blockquote>
<p>在默认情况下，<code><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid()</a></code> 会在任务上实例化重新采样，这意味着会生成具体的训练-测试拆分。由于这个过程是随机的，所以在调用 <code><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid()</a></code> 之前需要设置一个种子，以确保数据拆分的可重现性。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># pass design to benchmark()</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span></span>
<span><span class="co">#&gt; &lt;BenchmarkResult&gt; of 30 rows with 6 resampling runs</span></span>
<span><span class="co">#&gt;  nr       task_id          learner_id resampling_id iters warnings errors</span></span>
<span><span class="co">#&gt;   1 german_credit       classif.rpart            cv     5        0      0</span></span>
<span><span class="co">#&gt;   2 german_credit      classif.ranger            cv     5        0      0</span></span>
<span><span class="co">#&gt;   3 german_credit classif.featureless            cv     5        0      0</span></span>
<span><span class="co">#&gt;   4         sonar       classif.rpart            cv     5        0      0</span></span>
<span><span class="co">#&gt;   5         sonar      classif.ranger            cv     5        0      0</span></span>
<span><span class="co">#&gt;   6         sonar classif.featureless            cv     5        0      0</span></span></code></pre></div>
</div>
<p>As <code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code> is just an extension of <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code>, we can once again use <code>$score()</code>, or <code>$aggregate()</code> depending on your use-case, though note that in this case <code>$score()</code> will return results over each fold of each learner/task/resampling combination.</p>
<blockquote>
<p>由于 <code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code> 只是 <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> 的扩展，因此我们可以再次使用 <code>$score()</code> 或 <code>$aggregate()</code>，具体取决于您的用例，但请注意，在这种情况下，<code>$score()</code> 将返回每个学习器/任务/重新采样组合的每个折叠的结果。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">7</span>, <span class="fl">13</span><span class="op">)</span>, <span class="fu">.</span><span class="op">(</span><span class="va">iteration</span>, <span class="va">task_id</span>, <span class="va">learner_id</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;    iteration       task_id          learner_id classif.ce</span></span>
<span><span class="co">#&gt; 1:         1 german_credit       classif.rpart      0.335</span></span>
<span><span class="co">#&gt; 2:         2 german_credit      classif.ranger      0.240</span></span>
<span><span class="co">#&gt; 3:         3 german_credit classif.featureless      0.300</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">task_id</span>, <span class="va">learner_id</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;          task_id          learner_id classif.ce</span></span>
<span><span class="co">#&gt; 1: german_credit       classif.rpart  0.2870000</span></span>
<span><span class="co">#&gt; 2: german_credit      classif.ranger  0.2230000</span></span>
<span><span class="co">#&gt; 3: german_credit classif.featureless  0.3000000</span></span>
<span><span class="co">#&gt; 4:         sonar       classif.rpart  0.3026713</span></span>
<span><span class="co">#&gt; 5:         sonar      classif.ranger  0.1921022</span></span>
<span><span class="co">#&gt; 6:         sonar classif.featureless  0.4659698</span></span></code></pre></div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>TODO：等待后续添加交叉引用 11.3</p>
</div>
</div>
<p>This would conclude a basic benchmark experiment where you can draw tentative conclusions about model performance, in this case we would possibly conclude that the random forest is the best of all three models on each task. We draw conclusions cautiously here as we have not run any statistical tests or included standard errors of measures, so we cannot definitively say if one model outperforms the other.</p>
<p>As the results of <code>$score()</code> and <code>$aggregate()</code> are returned in a <code>data.table</code>, you can post-process and analyze the results in any way you want. A common mistake is to average the learner performance across all tasks when the tasks vary significantly. This is a mistake as averaging the performance will miss out important insights into how learners compare on ‘easier’ or more ‘difficult’ predictive problems. A more robust alternative to compare the overall algorithm performance across multiple tasks is to compute the ranks of each learner on each task separately and then calculate the average ranks. This can provide a better comparison as task-specific ‘quirks’ are taken into account by comparing learners within tasks before comparing them across tasks. However, using ranks will lose information about the numerical differences between the calculated performance scores. Analysis of benchmark experiments, including statistical tests, is covered in more detail in Section 11.3.</p>
<blockquote>
<p>这将总结了一个基本的基准实验，您可以初步得出关于模型性能的结论，在这种情况下，我们可能会得出结论，随机森林在每个任务上都是三个模型中最好的。我们在这里谨慎地得出结论，因为我们没有进行任何统计测试，也没有包括性能度量的标准错误，因此我们不能明确地说一个模型是否优于另一个。</p>
<p>由于 <code>$score()</code> 和 <code>$aggregate()</code> 的结果以 <code>data.table</code> 返回，您可以以任何您想要的方式进行后处理和分析结果。一个常见的错误是在任务差异明显的情况下，对所有任务的学习器性能进行平均。这是一个错误，因为对性能进行平均将错过对学习器在“更容易”或“更困难”的预测问题上的比较重要的洞察。比较多个任务上的整体算法性能的更强大的替代方法是分别计算每个任务上每个学习器的排名，然后计算平均排名。这可以提供更好的比较，因为通过在比较任务之前在任务内部比较学习器，可以考虑到特定于任务的“怪癖”。然而，使用排名会丢失关于计算的性能分数之间的数值差异的信息。关于基准实验的分析，包括统计测试，在第11.3节中将更详细地介绍。</p>
</blockquote>
</section><section id="benchmarkresult-objects" class="level3" data-number="3.3.2"><h3 data-number="3.3.2">
<span class="header-section-number">3.3.2</span> BenchmarkResult Objects</h3>
<p>A <code>BenchmarkResult</code> object is a collection of multiple <code>ResampleResult</code> objects.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmrdt</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">bmr</span><span class="op">)</span></span>
<span><span class="va">bmrdt</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="fu">.</span><span class="op">(</span><span class="va">task</span>, <span class="va">learner</span>, <span class="va">resampling</span>, <span class="va">iteration</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;                 task                   learner         resampling iteration</span></span>
<span><span class="co">#&gt; 1: &lt;TaskClassif[51]&gt; &lt;LearnerClassifRpart[38]&gt; &lt;ResamplingCV[20]&gt;         1</span></span>
<span><span class="co">#&gt; 2: &lt;TaskClassif[51]&gt; &lt;LearnerClassifRpart[38]&gt; &lt;ResamplingCV[20]&gt;         2</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rr1</span> <span class="op">=</span> <span class="va">bmr</span><span class="op">$</span><span class="fu">resample_result</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">rr2</span> <span class="op">=</span> <span class="va">bmr</span><span class="op">$</span><span class="fu">resample_result</span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">rr1</span></span>
<span><span class="co">#&gt; &lt;ResampleResult&gt; with 5 resampling iterations</span></span>
<span><span class="co">#&gt;        task_id    learner_id resampling_id iteration warnings errors</span></span>
<span><span class="co">#&gt;  german_credit classif.rpart            cv         1        0      0</span></span>
<span><span class="co">#&gt;  german_credit classif.rpart            cv         2        0      0</span></span>
<span><span class="co">#&gt;  german_credit classif.rpart            cv         3        0      0</span></span>
<span><span class="co">#&gt;  german_credit classif.rpart            cv         4        0      0</span></span>
<span><span class="co">#&gt;  german_credit classif.rpart            cv         5        0      0</span></span></code></pre></div>
</div>
<p>In addition, <code><a href="https://mlr3.mlr-org.com/reference/as_benchmark_result.html">as_benchmark_result()</a></code> can be used to convert objects from <code>ResampleResult</code> to <code>BenchmarkResult.</code> The <code><a href="https://rdrr.io/r/base/c.html">c()</a></code>-method can be used to combine multiple <code>BenchmarkResult</code> objects, which can be useful when conducting experiments across multiple machines:</p>
<blockquote>
<p>此外，可以使用 <code><a href="https://mlr3.mlr-org.com/reference/as_benchmark_result.html">as_benchmark_result()</a></code> 将 <code>ResampleResult</code> 对象转换为 <code>BenchmarkResult</code>。<code><a href="https://rdrr.io/r/base/c.html">c()</a></code> 方法可用于组合多个 <code>BenchmarkResult</code> 对象，这在跨多台计算机进行实验时非常有用：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr1</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_benchmark_result.html">as_benchmark_result</a></span><span class="op">(</span><span class="va">rr1</span><span class="op">)</span></span>
<span><span class="va">bmr2</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_benchmark_result.html">as_benchmark_result</a></span><span class="op">(</span><span class="va">rr2</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bmr1</span>, <span class="va">bmr2</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;BenchmarkResult&gt; of 10 rows with 2 resampling runs</span></span>
<span><span class="co">#&gt;  nr       task_id     learner_id resampling_id iters warnings errors</span></span>
<span><span class="co">#&gt;   1 german_credit  classif.rpart            cv     5        0      0</span></span>
<span><span class="co">#&gt;   2 german_credit classif.ranger            cv     5        0      0</span></span></code></pre></div>
</div>
<p>Boxplots are most commonly used to visualize benchmark experiments as they can intuitively summarize results across tasks and learners simultaneously.</p>
<blockquote>
<p>箱线图最常用于可视化基准实验，因为它们可以直观地同时总结任务和学习器之间的结果。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">bmr</span>, measure <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div id="fig-benchmark-box" class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/fig-benchmark-box-1.png" class="img-fluid" style="width:70.0%"></p>
<figcaption>Figure 3.2: Boxplots of accuracy scores for each learner across resampling iterations and the three tasks. Random forests (<code>lrn("classif.ranger")</code>) consistently outperforms the other learners.</figcaption></figure>
</div>
</div>
</div>
</section></section><section id="evaluation-of-binary-classifiers" class="level2" data-number="3.4"><h2 data-number="3.4">
<span class="header-section-number">3.4</span> Evaluation of Binary Classifiers</h2>
<section id="confusion-matrix-1" class="level3" data-number="3.4.1"><h3 data-number="3.4.1">
<span class="header-section-number">3.4.1</span> Confusion Matrix</h3>
<p>It is possible for a classifier to have a good classification accuracy but to overlook the nuances provided by a full confusion matrix, as in the following <code>tsk("german_credit")</code> example:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_german</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"german_credit"</span><span class="op">)</span></span>
<span><span class="va">lrn_ranger</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.ranger"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">splits</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_german</span>, ratio <span class="op">=</span> <span class="fl">.8</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lrn_ranger</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_german</span>, <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_ranger</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_german</span>, <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.acc </span></span>
<span><span class="co">#&gt;        0.74</span></span>
<span><span class="va">prediction</span><span class="op">$</span><span class="va">confusion</span></span>
<span><span class="co">#&gt;         truth</span></span>
<span><span class="co">#&gt; response good bad</span></span>
<span><span class="co">#&gt;     good  124  36</span></span>
<span><span class="co">#&gt;     bad    16  24</span></span></code></pre></div>
</div>
<p>On their own, the absolute numbers in a confusion matrix can be less useful when there is class imbalance. Instead, several normalized measures can be derived (<a href="#fig-confusion">Figure 3.3</a>):</p>
<ul>
<li><p><strong>True Positive Rate (TPR)</strong>, <strong>Sensitivity</strong> or <strong>Recall</strong>: How many of the true positives did we predict as positive?</p></li>
<li><p><strong>True Negative Rate (TNR)</strong> or <strong>Specificity</strong>: How many of the true negatives did we predict as negative?</p></li>
<li><p><strong>False Positive Rate (FPR)</strong>, or <span class="math inline">\(1 -\)</span> <strong>Specificity</strong>: How many of the true negatives did we predict as positive?</p></li>
<li><p><strong>Positive Predictive Value (PPV)</strong> or <strong>Precision</strong>: If we predict positive how likely is it a true positive?</p></li>
<li><p><strong>Negative Predictive Value (NPV)</strong>: If we predict negative how likely is it a true negative?</p></li>
<li><p><strong>Accuracy (ACC)</strong>: The proportion of correctly classified instances out of the total number of instances.</p></li>
<li><p><strong>F1-score</strong>: The harmonic mean of precision and recall, which balances the trade-off between precision and recall. It is calculated as <span class="math inline">\(2 \times \frac{Precision \times Recall}{Precision + Recall}\)</span>.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-confusion" class="quarto-figure quarto-figure-center">
<figure><p><img src="imgs/confusion_matrix.svg" class="img-fluid" style="width:70.0%"></p>
<figcaption>Figure 3.3: Binary confusion matrix of ground truth class vs. predicted class.</figcaption></figure>
</div>
</div>
</div>
<p>The <code>mlr3measures</code> package allows you to compute several common confusion matrix-based measures using the <code>confusion_matrix()</code> function:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">mlr3measures</span><span class="fu">::</span><span class="fu"><a href="https://mlr3measures.mlr-org.com/reference/confusion_matrix.html">confusion_matrix</a></span><span class="op">(</span></span>
<span>  truth <span class="op">=</span> <span class="va">prediction</span><span class="op">$</span><span class="va">truth</span>,</span>
<span>  response <span class="op">=</span> <span class="va">prediction</span><span class="op">$</span><span class="va">response</span>,</span>
<span>  positive <span class="op">=</span> <span class="va">tsk_german</span><span class="op">$</span><span class="va">positive</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;         truth</span></span>
<span><span class="co">#&gt; response good bad</span></span>
<span><span class="co">#&gt;     good  124  36</span></span>
<span><span class="co">#&gt;     bad    16  24</span></span>
<span><span class="co">#&gt; acc :  0.7400; ce  :  0.2600; dor :  5.1667; f1  :  0.8267 </span></span>
<span><span class="co">#&gt; fdr :  0.2250; fnr :  0.1143; fomr:  0.4000; fpr :  0.6000 </span></span>
<span><span class="co">#&gt; mcc :  0.3273; npv :  0.6000; ppv :  0.7750; tnr :  0.4000 </span></span>
<span><span class="co">#&gt; tpr :  0.8857</span></span></code></pre></div>
</div>
</section><section id="roc-analysis" class="level3" data-number="3.4.2"><h3 data-number="3.4.2">
<span class="header-section-number">3.4.2</span> ROC Analysis</h3>
<p>The ROC curve is a line graph with TPR on the y-axis and the FPR on the x-axis.</p>
<p>Consider classifiers that predict probabilities instead of discrete classes. Using different thresholds to cut off predicted probabilities and assign them to the positive and negative class will lead to different TPRs and FPRs and by plotting these values across different thresholds we can characterize the behavior of a binary classifier – this is the ROC curve.</p>
<blockquote>
<p>考虑预测概率而不是离散类别的分类器。使用不同的阈值来截断预测的概率并将其分配到正类别和负类别将导致不同的 TPR 和 FPR，并通过在不同的阈值上绘制这些值，我们可以表征二元分类器的行为 - 这就是 ROC 曲线。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">prediction</span>, type <span class="op">=</span> <span class="st">"roc"</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div id="fig-basics-roc-ranger" class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/fig-basics-roc-ranger-1.png" class="img-fluid" style="width:70.0%"></p>
<figcaption>Figure 3.4: ROC-curve based on the <code>german_credit</code> dataset and the <code>classif.ranger</code> random forest learner. Recall FPR = <span class="math inline">\(1 -\)</span> Specificity and TPR = Sensitivity.</figcaption></figure>
</div>
</div>
</div>
<p>A natural performance measure that can be derived from the ROC curve is the area under the curve (AUC), implemented in <code>msr("classif.auc")</code>. The AUC can be interpreted as the probability that a randomly chosen positive instance has a higher predicted probability of belonging to the positive class than a randomly chosen negative instance. Therefore, higher values (closer to ) indicate better performance. Random classifiers (such as the featureless baseline) will always have an AUC of (approximately, when evaluated empirically) 0.5.</p>
<blockquote>
<p>从 ROC 曲线中可以导出的一个自然性能度量是曲线下面积（AUC），在 <code>msr("classif.auc")</code> 中实现。AUC 可以解释为随机选择的正实例具有较高的预测概率，属于正类别，而不是随机选择的负实例的概率。因此，较高的值（越接近 1）表示更好的性能。随机分类器（例如没有特征的基线）的AUC总是为（在经验上评估时约为 0.5）。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.auc"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.auc </span></span>
<span><span class="co">#&gt;   0.7407143</span></span></code></pre></div>
</div>
<p>We can also plot the precision-recall curve (PRC) which visualizes the PPV/precision vs. TPR/recall. The main difference between ROC curves and PR curves is that the number of true-negatives are ignored in the latter. This can be useful in imbalanced populations where the positive class is rare, and where a classifier with high TPR may still not be very informative and have low PPV. See Davis and Goadrich (2006) for a detailed discussion about the relationship between the PRC and ROC curves.</p>
<blockquote>
<p>我们还可以绘制精确度-召回曲线（PRC），该曲线可视化了 PPV/精确度 与 TPR/召回 之间的关系。ROC曲线和PR曲线之间的主要区别在于后者忽略了真负例的数量。在不平衡的人群中，正类别很少见的情况下，具有高TPR的分类器可能仍然不太具有信息性，并且具有较低的PPV。有关PRC和ROC曲线之间关系的详细讨论，请参阅 Davis 和 Goadrich（2006）。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">prediction</span>, type <span class="op">=</span> <span class="st">"prc"</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div id="fig-basics-prc-ranger" class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/fig-basics-prc-ranger-1.png" class="img-fluid" style="width:70.0%"></p>
<figcaption>Figure 3.5: Precision-Recall curve based on <code>tsk("german_credit")</code> and <code>lrn("classif.ranger")</code>.</figcaption></figure>
</div>
</div>
</div>
<p>Finally, we can visualize ROC/PR curves for a <code>BenchmarkResult</code> to compare multiple learners on the same <code>Task</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">design</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span></span>
<span>  tasks <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"german_credit"</span><span class="op">)</span>,</span>
<span>  learners <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrns</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, <span class="st">"classif.ranger"</span><span class="op">)</span>,</span>
<span>                  predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span>,</span>
<span>  resamplings <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">bmr</span>, type <span class="op">=</span> <span class="st">"roc"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">bmr</span>, type <span class="op">=</span> <span class="st">"prc"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://patchwork.data-imaginist.com/reference/plot_layout.html">plot_layout</a></span><span class="op">(</span>guides <span class="op">=</span> <span class="st">"collect"</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div id="fig-basics-rocpr-bmr" class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/fig-basics-rocpr-bmr-1.png" class="img-fluid" style="width:70.0%"></p>
<figcaption>Figure 3.6: Comparing random forest (green) and decision tree (purple) using ROC and PR Curves.</figcaption></figure>
</div>
</div>
</div>
</section></section></section><section id="tuning-and-feature-selection" class="level1 unnumbered"><h1 class="unnumbered">Tuning and Feature Selection</h1>
</section><section id="sec-optimization" class="level1" data-number="4"><h1 data-number="4">
<span class="header-section-number">4</span> Hyperparameter Optimization</h1>
<p>Hyperparameter optimization (HPO) closely relates to model evaluation (<a href="#sec-performance">Chapter 3</a>) as the objective is to find a hyperparameter configuration that optimizes the generalization performance. Broadly speaking, we could think of finding the optimal model configuration in the same way as selecting a model from a benchmark experiment, where in this case each model in the experiment is the same algorithm but with different hyperparameter configurations. For example, we could benchmark three support vector machines (SVMs) with three different <code>cost</code> values.</p>
<blockquote>
<p>HPO与模型评估（<a href="#sec-performance">Chapter 3</a>）密切相关，因为目标是找到一个优化泛化性能的超参数配置。从广义上讲，我们可以将找到最佳模型配置视为从基准实验中选择模型的方式，其中在这种情况下，实验中的每个模型都是相同的算法，但具有不同的超参数配置。例如，我们可以使用三个不同 <code>cost</code> 值来进行支持向量机（SVM）的基准测试。</p>
</blockquote>
<section id="model-tuning" class="level2" data-number="4.1"><h2 data-number="4.1">
<span class="header-section-number">4.1</span> Model Tuning</h2>
<p><code>mlr3tuning</code> is the hyperparameter optimization package of the <code>mlr3</code> ecosystem. At the heart of the package are the R6 classes</p>
<ul>
<li><p><code>TuningInstanceSingleCrit</code>, a tuning ‘instance’ that describes the optimization problem and store the results; and</p></li>
<li><p><code>Tuner</code> which is used to configure and run optimization algorithms.</p></li>
</ul>
<section id="learner-and-search-space" class="level3" data-number="4.1.1"><h3 data-number="4.1.1">
<span class="header-section-number">4.1.1</span> Learner and Search Space</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.svm"</span><span class="op">)</span><span class="op">$</span><span class="va">param_set</span><span class="op">)</span><span class="op">[</span>,</span>
<span>                                      <span class="fu">.</span><span class="op">(</span><span class="va">id</span>, <span class="va">class</span>, <span class="va">lower</span>, <span class="va">upper</span>, <span class="va">nlevels</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;                  id    class lower upper nlevels</span></span>
<span><span class="co">#&gt;  1:       cachesize ParamDbl  -Inf   Inf     Inf</span></span>
<span><span class="co">#&gt;  2:   class.weights ParamUty    NA    NA     Inf</span></span>
<span><span class="co">#&gt;  3:           coef0 ParamDbl  -Inf   Inf     Inf</span></span>
<span><span class="co">#&gt;  4:            cost ParamDbl     0   Inf     Inf</span></span>
<span><span class="co">#&gt;  5:           cross ParamInt     0   Inf     Inf</span></span>
<span><span class="co">#&gt;  6: decision.values ParamLgl    NA    NA       2</span></span>
<span><span class="co">#&gt;  7:          degree ParamInt     1   Inf     Inf</span></span>
<span><span class="co">#&gt;  8:         epsilon ParamDbl     0   Inf     Inf</span></span>
<span><span class="co">#&gt;  9:          fitted ParamLgl    NA    NA       2</span></span>
<span><span class="co">#&gt; 10:           gamma ParamDbl     0   Inf     Inf</span></span>
<span><span class="co">#&gt; 11:          kernel ParamFct    NA    NA       4</span></span>
<span><span class="co">#&gt; 12:              nu ParamDbl  -Inf   Inf     Inf</span></span>
<span><span class="co">#&gt; 13:           scale ParamUty    NA    NA     Inf</span></span>
<span><span class="co">#&gt; 14:       shrinking ParamLgl    NA    NA       2</span></span>
<span><span class="co">#&gt; 15:       tolerance ParamDbl     0   Inf     Inf</span></span>
<span><span class="co">#&gt; 16:            type ParamFct    NA    NA       2</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.svm"</span>,</span>
<span>    type <span class="op">=</span> <span class="st">"C-classification"</span>,</span>
<span>    kernel <span class="op">=</span> <span class="st">"radial"</span>,</span>
<span>    cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1e5</span><span class="op">)</span>,</span>
<span>    gamma <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">learner</span></span>
<span><span class="co">#&gt; &lt;LearnerClassifSVM:classif.svm&gt;</span></span>
<span><span class="co">#&gt; * Model: -</span></span>
<span><span class="co">#&gt; * Parameters: type=C-classification, kernel=radial,</span></span>
<span><span class="co">#&gt;   cost=&lt;RangeTuneToken&gt;, gamma=&lt;RangeTuneToken&gt;</span></span>
<span><span class="co">#&gt; * Packages: mlr3, mlr3learners, e1071</span></span>
<span><span class="co">#&gt; * Predict Types:  [response], prob</span></span>
<span><span class="co">#&gt; * Feature Types: logical, integer, numeric</span></span>
<span><span class="co">#&gt; * Properties: multiclass, twoclass</span></span></code></pre></div>
</div>
</section><section id="sec-terminator" class="level3" data-number="4.1.2"><h3 data-number="4.1.2">
<span class="header-section-number">4.1.2</span> Terminator</h3>
<p><code>mlr3tuning</code> includes many methods to specify when to terminate an algorithm (<a href="#tbl-terms">Table 4.1</a>), which are implemented in <code>Terminator</code> classes. Terminators are stored in the <code>mlr_terminators</code> dictionary and are constructed with the sugar function <code><a href="https://bbotk.mlr-org.com/reference/trm.html">trm()</a></code>.</p>
<div id="tbl-terms">
<table>
<caption>Table 4.1: Terminators available in <code>mlr3tuning</code> at the time of publication, their function call and default parameters. A complete and up-to-date list can be found at <a href="https://mlr-org.com/terminators.html" class="uri">https://mlr-org.com/terminators.html</a>.</caption>
<thead><tr class="header">
<th>Terminator</th>
<th>Function call and default parameters</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Clock Time</td>
<td><code>trm("clock_time")</code></td>
</tr>
<tr class="even">
<td>Combo</td>
<td><code>trm("combo", any = TRUE)</code></td>
</tr>
<tr class="odd">
<td>None</td>
<td><code>trm("none")</code></td>
</tr>
<tr class="even">
<td>Number of Evaluations</td>
<td><code>trm("evals", n_evals = 100, k = 0)</code></td>
</tr>
<tr class="odd">
<td>Performance Level</td>
<td><code>trm("perf_reached", level = 0.1)</code></td>
</tr>
<tr class="even">
<td>Run Time</td>
<td><code>trm("run_time", secs = 30)</code></td>
</tr>
<tr class="odd">
<td>Stagnation</td>
<td><code>trm("stagnation", iters = 10, threshold = 0)</code></td>
</tr>
</tbody>
</table>
</div>
<p>The most commonly used terminators are those that stop the tuning after a certain time (<code>trm("run_time")</code>) or a given number of evaluations (<code>trm("evals")</code>). Choosing a runtime is often based on practical considerations and intuition. Using a time limit can be important on compute clusters where a maximum runtime for a compute job may need to be specified. <code>trm("perf_reached")</code> stops the tuning when a specified performance level is reached, which can be helpful if a certain performance is seen as sufficient for the practical use of the model, however, if this is set too optimistically the tuning may never terminate. <code>trm("stagnation")</code> stops when no progress greater than the threshold has been made for a set number of iterations. The threshold can be difficult to select as the optimization could stop too soon for complex search spaces despite room for (possibly significant) improvement. <code>trm("none")</code> is used for tuners that control termination themselves and so this terminator does nothing. Finally, any of these terminators can be freely combined by using <code>trm("combo")</code>, which can be used to specify if HPO finishes when any (<code>any = TRUE</code>) terminator is triggered or when all (<code>any = FALSE</code>) are triggered.</p>
<blockquote>
<p>最常用的终止条件通常是那些在一定时间（<code>trm("run_time")</code>）或给定的评估次数（<code>trm("evals")</code>）之后停止调优的条件。选择运行时间通常基于实际考虑和直觉。在计算集群上使用时间限制可能很重要，因为可能需要为计算作业指定最大运行时间。<code>trm("perf_reached")</code>在达到指定性能水平时停止调优，这可以在某种性能被视为足够实际使用的情况下很有帮助，但如果设置得过于乐观，调优可能永远不会结束。<code>trm("stagnation")</code>在一定迭代次数内没有超过阈值的进展时停止，阈值的选择可能很困难，因为尽管可能有改进的空间（可能很大），但对于复杂的搜索空间，优化可能会过早停止。<code>trm("none")</code>用于控制自己终止的调谐器，因此该终止条件什么也不做。最后，任何这些终止条件都可以通过使用<code>trm("combo")</code>自由组合，可以用来指定HPO是否在任何（<code>any = TRUE</code>）终止条件触发时结束，或者在所有（<code>any = FALSE</code>）终止条件触发时结束。</p>
</blockquote>
</section><section id="tuning-instance-with-ti" class="level3" data-number="4.1.3"><h3 data-number="4.1.3">
<span class="header-section-number">4.1.3</span> Tuning Instance with <code>ti</code>
</h3>
<p>The tuning instance collects the tuner-agnostic information required to optimize a model, i.e., all information about the tuning process, except for the tuning algorithm itself. This includes the task to tune over, the learner to tune, the resampling method and measure used to analytically compare hyperparameter optimization configurations, and the terminator to determine when the measure has been optimized ‘enough’. This implicitly defines a “black box” objective function, mapping hyperparameter configurations to (stochastic) performance values, to be optimized. This concept will be revisited in <a href="#sec-optimization-advanced">Chapter 5</a>.</p>
<blockquote>
<p>调优实例收集了优化模型所需的与调谐器无关的信息，即所有与调优过程有关的信息，除了调谐算法本身。这包括要调优的任务、要调优的学习器、用于分析比较超参数优化配置的重抽样方法和度量，以及确定度量何时已经被优化到足够程度的终止条件。这隐式地定义了一个“黑盒”目标函数，将超参数配置映射到（随机的）性能值，以便进行优化。这个概念将在 <a href="#sec-optimization-advanced">Chapter 5</a> 中重新讨论。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb89"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_sonar</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti</a></span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="va">tsk_sonar</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">learner</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>  measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"none"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">instance</span></span>
<span><span class="co">#&gt; &lt;TuningInstanceSingleCrit&gt;</span></span>
<span><span class="co">#&gt; * State:  Not optimized</span></span>
<span><span class="co">#&gt; * Objective: &lt;ObjectiveTuning:classif.svm_on_sonar&gt;</span></span>
<span><span class="co">#&gt; * Search Space:</span></span>
<span><span class="co">#&gt;       id    class lower upper nlevels</span></span>
<span><span class="co">#&gt; 1:  cost ParamDbl   0.1 1e+05     Inf</span></span>
<span><span class="co">#&gt; 2: gamma ParamDbl   0.1 1e+00     Inf</span></span>
<span><span class="co">#&gt; * Terminator: &lt;TerminatorNone&gt;</span></span></code></pre></div>
</div>
</section><section id="tuner" class="level3" data-number="4.1.4"><h3 data-number="4.1.4">
<span class="header-section-number">4.1.4</span> Tuner</h3>
<p>With all the pieces of our tuning problem assembled, we can now decide how to tune our model. There are multiple <code>Tuner</code> classes in <code>mlr3tuning</code>, which implement different HPO (or more generally speaking black box optimization) algorithms (<a href="#tbl-tuners">Table 4.2</a>).</p>
<div id="tbl-tuners">
<table>
<caption>Table 4.2: Tuning algorithms available in <code>mlr3tuning</code>, their function call and the package in which the algorithm is implemented. A complete and up-to-date list can be found at <a href="https://mlr-org.com/tuners.html" class="uri">https://mlr-org.com/tuners.html</a>.</caption>
<thead><tr class="header">
<th>Tuner</th>
<th>Function call</th>
<th>Package</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Random Search</td>
<td><code>tnr("random_search")</code></td>
<td><code>mlr3tuning</code></td>
</tr>
<tr class="even">
<td>Grid Search</td>
<td><code>tnr("grid_search")</code></td>
<td><code>mlr3tuning</code></td>
</tr>
<tr class="odd">
<td>Bayesian Optimization</td>
<td><code>tnr("mbo")</code></td>
<td><code>mlr3mbo</code></td>
</tr>
<tr class="even">
<td>CMA-ES</td>
<td><code>tnr("cmaes")</code></td>
<td><code>adagio</code></td>
</tr>
<tr class="odd">
<td>Iterated Racing</td>
<td><code>tnr("irace")</code></td>
<td><code>irace</code></td>
</tr>
<tr class="even">
<td>Hyperband</td>
<td><code>tnr("hyperband")</code></td>
<td><code>mlr3hyperband</code></td>
</tr>
<tr class="odd">
<td>Generalized Simulated Annealing</td>
<td><code>tnr("gensa")</code></td>
<td><code>GenSA</code></td>
</tr>
<tr class="even">
<td>Nonlinear Optimization</td>
<td><code>tnr("nloptr")</code></td>
<td><code>nloptr</code></td>
</tr>
</tbody>
</table>
</div>
<section id="search-strategies" class="level4" data-number="4.1.4.1"><h4 data-number="4.1.4.1">
<span class="header-section-number">4.1.4.1</span> Search Strategies</h4>
<p>Grid search and random search (Bergstra and Bengio 2012) are the most basic algorithms and are often selected first in initial experiments. The idea of grid search is to exhaustively evaluate every possible combination of given hyperparameter values. Categorical hyperparameters are usually evaluated over all possible values they can take. Numeric and integer hyperparameter values are then spaced equidistantly in their box constraints (upper and lower bounds) according to a given resolution, which is the number of distinct values to try per hyperparameter. Random search involves randomly selecting values for each hyperparameter independently from a pre-specified distribution, usually uniform. Both methods are non-adaptive, which means each proposed configuration ignores the performance of previous configurations. Due to their simplicity, both grid search and random search can handle mixed search spaces (i.e., hyperparameters can be numeric, integer, or categorical) as well as hierarchical search spaces (<a href="#sec-defining-search-spaces">Section 4.4</a>).</p>
<blockquote>
<p>网格搜索和随机搜索（Bergstra和Bengio 2012）是最基本的算法，通常在初始实验中首选。网格搜索的思想是详尽地评估给定超参数值的每种可能组合。通常会对分类超参数评估它们可以取的所有可能值。然后，数值和整数超参数值将根据给定的分辨率均匀分布在它们的箱约束（上下界）中，分辨率是每个超参数要尝试的不同值的数量。随机搜索涉及从预先指定的分布（通常是均匀分布）中独立地随机选择每个超参数的值。这两种方法都是非自适应的，这意味着每个提出的配置都忽略了先前配置的性能。由于它们的简单性，网格搜索和随机搜索可以处理混合搜索空间（即，超参数可以是数值、整数或分类的）以及分层搜索空间（<a href="#sec-defining-search-spaces">Section 4.4</a>）。</p>
</blockquote>
</section><section id="adaptive-algorithms" class="level4" data-number="4.1.4.2"><h4 data-number="4.1.4.2">
<span class="header-section-number">4.1.4.2</span> Adaptive Algorithms</h4>
<p>Adaptive algorithms learn from previously evaluated configurations to find good configurations quickly, examples in <code>mlr3</code> include Bayesian optimization (also called model-based optimization), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), Iterated Racing, and Hyperband.</p>
<p>Bayesian optimization (e.g., Snoek, Larochelle, and Adams 2012) describes a family of iterative optimization algorithms that use a surrogate model to approximate the unknown function that is to be optimized – in HPO this would be the mapping from a hyperparameter configuration to the estimated generalization performance. If a suitable surrogate model is chosen, e.g. a random forest, Bayesian optimization can be quite flexible and even handle mixed and hierarchical search spaces. Bayesian optimization is discussed in full detail in <a href="#sec-bayesian-optimization">Section 5.4</a>.</p>
<p>CMA-ES (Hansen and Auger 2011) is an evolutionary strategy that maintains a probability distribution over candidate points, with the distribution represented by a mean vector and covariance matrix. A new set of candidate points is generated by sampling from this distribution, with the probability of each candidate being proportional to its performance. The covariance matrix is adapted over time to reflect the performance landscape. Further evolutionary strategies are available in <code>mlr3</code> via the <code>miesmuschel</code> package, however, these will not be covered in this book.</p>
<p>Racing algorithms work by iteratively discarding configurations that show poor performance, as determined by statistical tests. Iterated Racing (López-Ibáñez et al. 2016) starts by ‘racing’ down an initial population of randomly sampled configurations from a parameterized density and then uses the surviving configurations of the race to stochastically update the density of the subsequent race to focus on promising regions of the search space, and so on.</p>
<p>Multi-fidelity HPO is an adaptive method that leverages the predictive power of computationally cheap lower fidelity evaluations (i.e., poorer quality predictions such as those arising from neural networks with a small number of epochs) to improve the overall optimization efficiency. This concept is used in Hyperband (Li et al. 2018), a popular multi-fidelity hyperparameter optimization algorithm that dynamically allocates increasingly more resources to promising configurations and terminates low-performing ones. Hyperband is discussed in full detail in <a href="#sec-hyperband">Section 5.3</a>.</p>
<p>Other implemented algorithms for numeric search spaces are Generalized Simulated Annealing (Xiang et al. 2013; Tsallis and Stariolo 1996) and various nonlinear optimization algorithms.</p>
<blockquote>
<p>自适应算法通过学习先前评估的配置来快速找到良好的配置，<code>mlr3</code>中的示例包括贝叶斯优化（也称为基于模型的优化）、协方差矩阵自适应进化策略（CMA-ES）、迭代比赛和Hyperband。</p>
<p>贝叶斯优化（例如，Snoek、Larochelle和Adams 2012）描述了一族迭代优化算法，这些算法使用替代模型来近似待优化的未知函数——在HPO中，这将是从超参数配置到估计的泛化性能的映射。如果选择了合适的替代模型，例如随机森林，贝叶斯优化可以非常灵活，甚至可以处理混合和分层搜索空间。贝叶斯优化将在 <a href="#sec-bayesian-optimization">Section 5.4</a> 中详细讨论。</p>
<p>CMA-ES（Hansen和Auger 2011）是一种进化策略，它维护了候选点的概率分布，分布由均值向量和协方差矩阵表示。通过从该分布中抽样生成一组新的候选点，每个候选点的选择概率与其性能成正比。协方差矩阵会随着时间的推移而适应反映性能景观。通过<code>mlr3</code>中的<code>miesmuschel</code>包，还提供了其他进化策略，不过本书不会涵盖这些内容。</p>
<p>比赛算法通过迭代地丢弃显示性能较差的配置，这是通过统计测试确定的。迭代比赛（López-Ibáñez等人2016）首先通过从参数化密度中随机抽样生成的一组初始配置进行“比赛”，然后使用比赛的生存配置来随机更新后续比赛的密度，以便集中在搜索空间的有前途的区域，依此类推。</p>
<p>多保真度HPO是一种自适应方法，利用计算成本低的低保真度评估（即质量较差的预测，例如由具有较少周期的神经网络产生的预测）来提高整体优化效率。这个概念在Hyperband（Li等人2018）中得到了应用，这是一种流行的多保真度超参数优化算法，动态分配更多资源给有前途的配置并终止性能较低的配置。Hyperband将在 <a href="#sec-hyperband">Section 5.3</a> 中详细讨论。</p>
<p>对于数值搜索空间，其他已实现的算法包括广义模拟退火（Xiang等人2013；Tsallis和Stariolo 1996）和各种非线性优化算法。</p>
</blockquote>
</section><section id="choosing-strategies" class="level4" data-number="4.1.4.3"><h4 data-number="4.1.4.3">
<span class="header-section-number">4.1.4.3</span> Choosing Strategies</h4>
<p>As a rule of thumb, if the search space is small or does not have a complex structure, grid search may be able to exhaustively evaluate the entire search space in a reasonable time. However, grid search is generally not recommended due to the curse of dimensionality – the grid size ‘blows up’ very quickly as the number of parameters to tune increases – and insufficient coverage of numeric search spaces. By construction, grid search cannot evaluate a large number of unique values per hyperparameter, which is suboptimal when some hyperparameters have minimal impact on performance while others do. In such scenarios, random search is often a better choice as it considers more unique values per hyperparameter compared to grid search.</p>
<p>For higher-dimensional search spaces or search spaces with more complex structure, more guided optimization algorithms such as evolutionary strategies or Bayesian optimization tend to perform better and are more likely to result in peak performance. When choosing between evolutionary strategies and Bayesian optimization, the cost of function evaluation is highly relevant. If hyperparameter configurations can be evaluated quickly, evolutionary strategies often work well. On the other hand, if model evaluations are time-consuming and the optimization budget is limited, Bayesian optimization is usually preferred, as it is quite sample efficient compared to other algorithms, i.e., less function evaluations are needed to find good configurations. Hence, Bayesian optimization is usually recommended for HPO. While the optimization overhead of Bayesian optimization is comparably large (e.g., in each iteration, training of the surrogate model and optimizing the acquisition function), this has less of an impact in the context of relatively costly function evaluations such as resampling of ML models.</p>
<p>Finally, in cases where the hyperparameter optimization problem involves a meaningful fidelity parameter (e.g., number of epochs, number of trees, number of boosting rounds) and where the optimization budget needs to be spent efficiently, multi-fidelity hyperparameter optimization algorithms like Hyperband may be worth considering. For further details on different tuners and practical recommendations, we refer to Bischl et al. (2023).</p>
<blockquote>
<p>作为一个经验法则，如果搜索空间较小或没有复杂的结构，网格搜索可能能够在合理的时间内详尽地评估整个搜索空间。然而，通常不建议使用网格搜索，因为维度的诅咒问题——随着要调整的参数数量的增加，网格大小会迅速增加——以及对数值搜索空间的不足覆盖。从构造上来说，网格搜索不能评估每个超参数的大量唯一值，这在某些超参数对性能影响较小而其他超参数对性能有显著影响的情况下是不够优化的。在这种情况下，随机搜索通常是更好的选择，因为它考虑了每个超参数的更多唯一值，相对于网格搜索而言。</p>
<p>对于维度较高的搜索空间或搜索空间具有更复杂结构的情况，更有导向性的优化算法，如进化策略或贝叶斯优化，往往表现更好，并更有可能产生最佳性能。在选择进化策略和贝叶斯优化之间，函数评估成本非常重要。如果可以快速评估超参数配置，通常进化策略效果良好。另一方面，如果模型评估需要耗费时间，且优化预算有限，通常首选贝叶斯优化，因为与其他算法相比，它相对高效，即需要更少的函数评估来找到好的配置。因此，通常建议在HPO中使用贝叶斯优化。虽然贝叶斯优化的优化开销相对较大（例如，在每个迭代中，训练替代模型和优化获取函数），但在相对昂贵的函数评估环境中，例如ML模型的重新抽样，这影响较小。</p>
<p>最后，在超参数优化问题涉及有意义的保真度参数（例如，周期数、树数、提升轮数）且需要高效利用优化预算的情况下，可能值得考虑使用多保真度超参数优化算法，例如Hyperband。关于不同调谐器和实际建议的更多详细信息，请参阅Bischl等人（2023）。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tuner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"grid_search"</span>, resolution <span class="op">=</span> <span class="fl">5</span>, batch_size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">tuner</span></span>
<span><span class="co">#&gt; &lt;TunerGridSearch&gt;: Grid Search</span></span>
<span><span class="co">#&gt; * Parameters: resolution=5, batch_size=10</span></span>
<span><span class="co">#&gt; * Parameter classes: ParamLgl, ParamInt, ParamDbl, ParamFct</span></span>
<span><span class="co">#&gt; * Properties: dependencies, single-crit, multi-crit</span></span>
<span><span class="co">#&gt; * Packages: mlr3tuning</span></span></code></pre></div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>TODO：等待后续添加交叉引用 10.1.3</p>
</div>
</div>
<p>For our SVM example, we will use a grid search with a resolution of five for runtime reasons here (in practice a larger resolution would be preferred). The resolution is the number of distinct values to try per hyperparameter, which means in our example the tuner will construct a 5x5 grid of 25 configurations of equally spaced points between the specified upper and lower bounds. All configurations will be tried by the tuner (in random order) until either all configurations are evaluated or the terminator (<a href="#sec-terminator">Section 4.1.2</a>) signals that the budget is exhausted. For grid and random search tuners, the <code>batch_size</code> parameter controls how many configurations are evaluated at the same time when parallelization is enabled (see Section 10.1.3), and also determines how many configurations should be applied before the terminator should check if the termination criterion has been reached.</p>
<blockquote>
<p>对于我们的SVM示例，出于运行时的原因，我们将使用具有五个分辨率的网格搜索（在实践中，更大的分辨率将更可取）。分辨率是每个超参数要尝试的不同值的数量，这意味着在我们的示例中，调谐器将构建一个5x5的网格，其中包含25个在指定上限和下限之间等间距点的配置。调谐器将尝试所有配置（以随机顺序），直到所有配置都被评估或终止器（<a href="#sec-terminator">Section 4.1.2</a>）发出预算已用尽的信号。对于网格搜索和随机搜索调谐器，<code>batch_size</code> 参数控制在启用并行化时同时评估多少个配置（请参阅第10.1.3节），并确定在终止器检查是否达到终止标准之前应用多少个配置。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tuner</span><span class="op">$</span><span class="va">param_set</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;                   id    class lower upper nlevels        default value</span></span>
<span><span class="co">#&gt; 1:        batch_size ParamInt     1   Inf     Inf &lt;NoDefault[3]&gt;    10</span></span>
<span><span class="co">#&gt; 2:        resolution ParamInt     1   Inf     Inf &lt;NoDefault[3]&gt;     5</span></span>
<span><span class="co">#&gt; 3: param_resolutions ParamUty    NA    NA     Inf &lt;NoDefault[3]&gt;</span></span></code></pre></div>
</div>
<p>While changing the control parameters of the tuner can improve optimal performance, we have to take care that is likely the default settings will fit most needs. While it is not possible to cover all application cases, <code>mlr3tuning</code>’s defaults were chosen to work well in most cases. However, some control parameters like <code>batch_size</code> often interact with the parallelization setup (further described in Section 10.1.3) and may need to be adjusted accordingly.</p>
<blockquote>
<p>尽管更改调谐器的控制参数可以改善最优性能，但我们必须注意，通常情况下默认设置将适用于大多数需求。虽然不可能涵盖所有应用情况，但<code>mlr3tuning</code>的默认设置被选择为在大多数情况下表现良好。但是，一些控制参数，<code>如batch_size</code>，通常与并行化设置互动（在第10.1.3节中进一步描述），可能需要相应地进行调整。</p>
</blockquote>
</section><section id="triggering-the-tuning-process" class="level4" data-number="4.1.4.4"><h4 data-number="4.1.4.4">
<span class="header-section-number">4.1.4.4</span> Triggering the tuning process</h4>
<p>Now that we have introduced all our components, we can start the tuning process. To do this we simply pass the constructed TuningInstanceSingleCrit to the $optimize() method of the initialized Tuner.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb92"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tuner</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">result</span><span class="op">$</span><span class="va">learner_param_vals</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$type</span></span>
<span><span class="co">#&gt; [1] "C-classification"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kernel</span></span>
<span><span class="co">#&gt; [1] "radial"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$cost</span></span>
<span><span class="co">#&gt; [1] 50000.05</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$gamma</span></span>
<span><span class="co">#&gt; [1] 0.1</span></span></code></pre></div>
</div>
</section></section><section id="logarithmic-transformations" class="level3" data-number="4.1.5"><h3 data-number="4.1.5">
<span class="header-section-number">4.1.5</span> Logarithmic Transformations</h3>
<p>To add this transformation to a hyperparameter we simply pass <code>logscale = TRUE</code> to <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.svm"</span>, </span>
<span>    cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-5</span>, <span class="fl">1e5</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>    gamma <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-5</span>, <span class="fl">1e5</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>    kernel <span class="op">=</span> <span class="st">"radial"</span>,</span>
<span>    type <span class="op">=</span> <span class="st">"C-classification"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti</a></span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="va">tsk_sonar</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">learner</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>  measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"none"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">tuner</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Note that the fields <code>cost</code> and <code>gamma</code> show the optimal values before transformation, whereas <code>x_domain</code> and <code>learner_param_vals</code> contain optimal values <em>after</em> transformation, it is these latter fields you would take forward for future model use.</p>
<blockquote>
<p>请注意，<code>cost</code>和<code>gamma</code>字段显示了变换之前的最佳值，而<code>x_domain</code>和<code>learner_param_vals</code>包含了变换之后的最佳值，对于未来的模型使用，您应该使用后者的字段。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb95"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">result</span><span class="op">$</span><span class="va">x_domain</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$cost</span></span>
<span><span class="co">#&gt; [1] 1e+05</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$gamma</span></span>
<span><span class="co">#&gt; [1] 0.003162278</span></span></code></pre></div>
</div>
</section><section id="analyzing-and-using-the-result" class="level3" data-number="4.1.6"><h3 data-number="4.1.6">
<span class="header-section-number">4.1.6</span> Analyzing and Using the Result</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fu">.</span><span class="op">(</span><span class="va">cost</span>, <span class="va">gamma</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;         cost      gamma classif.ce</span></span>
<span><span class="co">#&gt; 1: -5.756463   0.000000  0.4663216</span></span>
<span><span class="co">#&gt; 2: -5.756463   5.756463  0.4663216</span></span>
<span><span class="co">#&gt; 3:  0.000000 -11.512925  0.4663216</span></span></code></pre></div>
</div>
<p>Another powerful feature of the instance is that we can score the internal <code>ResampleResults</code> on a different performance measure, for example looking at false negative rate and false positive rate as well as classification error:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb97"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span></span>
<span>  <span class="va">instance</span><span class="op">$</span><span class="va">archive</span>,</span>
<span>  measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.fpr"</span>, <span class="st">"classif.fnr"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="fu">.</span><span class="op">(</span><span class="va">cost</span>, <span class="va">gamma</span>, <span class="va">classif.ce</span>, <span class="va">classif.fpr</span>, <span class="va">classif.fnr</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;         cost      gamma classif.ce classif.fpr classif.fnr</span></span>
<span><span class="co">#&gt; 1: -5.756463   0.000000  0.4663216    1.000000   0.0000000</span></span>
<span><span class="co">#&gt; 2: -5.756463   5.756463  0.4663216    1.000000   0.0000000</span></span>
<span><span class="co">#&gt; 3:  0.000000 -11.512925  0.4663216    1.000000   0.0000000</span></span>
<span><span class="co">#&gt; 4:  0.000000  -5.756463  0.2400966    0.277289   0.2077999</span></span>
<span><span class="co">#&gt; 5:  0.000000  11.512925  0.4663216    1.000000   0.0000000</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">instance</span>, type <span class="op">=</span> <span class="st">"surface"</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div id="fig-surface" class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/fig-surface-1.png" class="img-fluid" style="width:70.0%"></p>
<figcaption>Figure 4.1: Model performance with different configurations for <code>cost</code> and <code>gamma</code>. Bright yellow regions represent the model performing worse and dark blue performing better. We can see that high <code>cost</code> values and low <code>gamma</code> values achieve the best performance. Note that we should not directly infer the performance of new unseen values from the heatmap since it is only an interpolation based on a surrogate model (<code>regr.ranger</code>). However, we can see the general interaction between the hyperparameters.</figcaption></figure>
</div>
</div>
</div>
<p>Once we found good hyperparameters for our learner through tuning, we can use them to train a final model on the whole data. To do this we simply construct a new learner with the same underlying algorithm and set the learner hyperparameters to the optimal configuration:</p>
<blockquote>
<p>在通过调整找到学习器的良好超参数之后，我们可以使用它们在整个数据集上训练最终模型。为此，我们只需构建一个新的学习器，使用相同的底层算法，并将学习器的超参数设置为最佳配置：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb99"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_svm_tuned</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.svm"</span><span class="op">)</span></span>
<span><span class="va">lrn_svm_tuned</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span> <span class="op">=</span> <span class="va">instance</span><span class="op">$</span><span class="va">result_learner_param_vals</span></span>
<span><span class="va">lrn_svm_tuned</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_sonar</span><span class="op">)</span><span class="op">$</span><span class="va">model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; svm.default(x = data, y = task$truth(), type = "C-classification", </span></span>
<span><span class="co">#&gt;     kernel = "radial", gamma = 0.00316227766016838, cost = 1e+05, </span></span>
<span><span class="co">#&gt;     probability = (self$predict_type == "prob"))</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Parameters:</span></span>
<span><span class="co">#&gt;    SVM-Type:  C-classification </span></span>
<span><span class="co">#&gt;  SVM-Kernel:  radial </span></span>
<span><span class="co">#&gt;        cost:  1e+05 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Support Vectors:  93</span></span></code></pre></div>
</div>
</section></section><section id="convenient-tuning-with-tune-and-auto_tuner" class="level2" data-number="4.2"><h2 data-number="4.2">
<span class="header-section-number">4.2</span> Convenient Tuning with <code>tune</code> and <code>auto_tuner</code>
</h2>
<p>In the previous section, we looked at constructing and manually putting together the components of HPO by creating a tuning instance using <code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code>, passing this to the tuner, and then calling <code>$optimize()</code> to start the tuning process. <code>mlr3tuning</code> includes two helper methods to simplify this process further.</p>
<p>The first helper function is <code><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune()</a></code>, which creates the tuning instance and calls <code>$optimize()</code> for you. You may prefer the manual method with <code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code> if you want to view and make changes to the instance before tuning.</p>
<blockquote>
<p>在上一节中，我们看到了通过使用<code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code>创建调整实例，将其传递给调整器，然后调用<code>$optimize()</code>来启动调整过程，来构建和手动组合HPO的组件。<code>mlr3tuning</code>包括两个辅助方法，以进一步简化这个过程。</p>
<p>第一个辅助函数是<code><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune()</a></code>，它创建调整实例并为您调用<code>$optimize()</code>。如果您想在调整之前查看并对实例进行更改，可能更喜欢使用<code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code>的手动方法。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tnr_grid_search</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"grid_search"</span>, resolution <span class="op">=</span> <span class="fl">5</span>, batch_size <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">lrn_svm</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span></span>
<span>  <span class="st">"classif.svm"</span>,</span>
<span>  cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-5</span>, <span class="fl">1e5</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  gamma <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-5</span>, <span class="fl">1e5</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  kernel <span class="op">=</span> <span class="st">"radial"</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"C-classification"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">rsmp_cv3</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">msr_ce</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune</a></span><span class="op">(</span></span>
<span>  tuner <span class="op">=</span> <span class="va">tnr_grid_search</span>,</span>
<span>  task <span class="op">=</span> <span class="va">tsk_sonar</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">lrn_svm</span>,</span>
<span>  resampling <span class="op">=</span> <span class="va">rsmp_cv3</span>,</span>
<span>  measures <span class="op">=</span> <span class="va">msr_ce</span></span>
<span><span class="op">)</span></span>
<span><span class="va">instance</span><span class="op">$</span><span class="va">result</span></span></code></pre></div>
</div>
<p>The other helper function is <code>auto_tuner</code>, which creates an object of class <code>AutoTuner</code>. The <code>AutoTuner</code> inherits from the <code>Learner</code> class and wraps all the information needed for tuning, which means you can treat a learner waiting to be optimized just like any other learner. Under the hood, the <code>AutoTuner</code> essentially runs <code><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune()</a></code> on the data that is passed to the model when <code>$train()</code> is called and then sets the learner parameters to the optimal configuration.</p>
<blockquote>
<p>另一个辅助函数是<code>auto_tuner</code>，它创建一个<code>AutoTuner</code>类的对象。<code>AutoTuner</code>继承自<code>Learner</code>类，并包装了所有需要进行调整的信息，这意味着您可以像处理任何其他学习器一样处理等待优化的学习器。在底层，<code>AutoTuner</code>实际上在调用<code>$train()</code>时对传递给模型的数据上运行了<code><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune()</a></code>，然后将学习器参数设置为最佳配置。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb101"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">at</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner</a></span><span class="op">(</span></span>
<span>  tuner <span class="op">=</span> <span class="va">tnr_grid_search</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">lrn_svm</span>,</span>
<span>  resampling <span class="op">=</span> <span class="va">rsmp_cv3</span>,</span>
<span>  measure <span class="op">=</span> <span class="va">msr_ce</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">at</span></span>
<span><span class="co">#&gt; &lt;AutoTuner:classif.svm.tuned&gt;</span></span>
<span><span class="co">#&gt; * Model: list</span></span>
<span><span class="co">#&gt; * Search Space:</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;       id    class     lower    upper nlevels        default value</span></span>
<span><span class="co">#&gt; 1:  cost ParamDbl -11.51293 11.51293     Inf &lt;NoDefault[3]&gt;      </span></span>
<span><span class="co">#&gt; 2: gamma ParamDbl -11.51293 11.51293     Inf &lt;NoDefault[3]&gt;      </span></span>
<span><span class="co">#&gt; Trafo is set.</span></span>
<span><span class="co">#&gt; * Packages: mlr3, mlr3tuning, mlr3learners, e1071</span></span>
<span><span class="co">#&gt; * Predict Type: response</span></span>
<span><span class="co">#&gt; * Feature Types: logical, integer, numeric</span></span>
<span><span class="co">#&gt; * Properties: multiclass, twoclass</span></span></code></pre></div>
</div>
<p>And we can now call <code>$train()</code>, which will first tune the hyperparameters in the search space listed above before fitting the optimal model.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">split</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_sonar</span><span class="op">)</span></span>
<span><span class="va">at</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_sonar</span>, row_ids <span class="op">=</span> <span class="va">split</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">at</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_sonar</span>, row_ids <span class="op">=</span> <span class="va">split</span><span class="op">$</span><span class="va">test</span><span class="op">)</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<p>The <code>AutoTuner</code> contains a tuning instance that can be analyzed like any other instance.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">at</span><span class="op">$</span><span class="va">tuning_instance</span><span class="op">$</span><span class="va">result</span></span>
<span><span class="co">#&gt;        cost     gamma learner_param_vals  x_domain classif.ce</span></span>
<span><span class="co">#&gt; 1: 5.756463 -11.51293          &lt;list[4]&gt; &lt;list[2]&gt;  0.2377428</span></span></code></pre></div>
</div>
<p>We could also pass the <code>AutoTuner</code> to <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> and <code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code>, which would result in a nested resampling, discussed next.</p>
</section><section id="sec-nested-resampling" class="level2" data-number="4.3"><h2 data-number="4.3">
<span class="header-section-number">4.3</span> Nested Resampling</h2>
<p>Nested resampling separates model optimization from the process of estimating the performance of the tuned model by adding an additional resampling, i.e., while model performance is estimated using a resampling method in the ‘usual way’, tuning is then performed by resampling the resampled data (<a href="#fig-nested-resampling">Figure 4.2</a>).</p>
<blockquote>
<p>嵌套重抽样通过添加额外的重抽样来将模型优化与估计调整模型性能的过程分开，即在“通常方式”中使用重抽样方法来估计模型性能，然后通过对重抽样数据进行重抽样来进行调整（<a href="#fig-nested-resampling">Figure 4.2</a>）。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-nested-resampling" class="quarto-figure quarto-figure-center">
<figure><p><img src="imgs/mlr3book_figures-11.svg" class="img-fluid" style="width:70.0%" alt="The image shows three rows of large blocks representing three-fold CV for the outer resampling. Below the blocks are four further rows of small blocks representing four-fold CV for the inner resampling. Text annotations highlight how tuned parameters from the inner resampling are passed to the outer resampling."></p>
<figcaption>Figure 4.2: An illustration of nested resampling. The large blocks represent three-fold CV for the outer resampling for model evaluation and the small blocks represent four-fold CV for the inner resampling for HPO. The light blue blocks are the training sets and the dark blue blocks are the test sets.</figcaption></figure>
</div>
</div>
</div>
<p><a href="#fig-nested-resampling">Figure 4.2</a> represents the following example of nested resampling:</p>
<ol type="1">
<li><p>Outer resampling start – Instantiate three-fold CV to create different testing and training datasets.</p></li>
<li><p>Inner resampling – Within the outer training data instantiate four-fold CV to create different inner testing and training datasets.</p></li>
<li><p>HPO – Tune the hyperparameters on the outer training set (large, light blue blocks) using the inner data splits.</p></li>
<li><p>Training – Fit the learner on the outer training dataset using the optimal hyperparameter configuration obtained from the inner resampling (small blocks).</p></li>
<li><p>Evaluation – Evaluate the performance of the learner on the outer testing data (large, dark blue block).</p></li>
<li><p>Outer resampling repeats – Repeat (2)-(5) for each of the three outer folds.</p></li>
<li><p>Aggregation – Take the sample mean of the three performance values for an unbiased performance estimate.</p></li>
</ol>
<p>The inner resampling produces generalization performance estimates for each configuration and selects the optimal configuration to be evaluated on the outer resampling. The outer resampling then produces generalization estimates for these optimal configurations. The result from the outer resampling can be used for comparison to other models trained and tested on the same outer folds.</p>
<blockquote>
<p><a href="#fig-nested-resampling">Figure 4.2</a> 表示嵌套重抽样的以下示例：</p>
<ol type="1">
<li><p>外部重抽样开始 - 实例化三折交叉验证以创建不同的测试和训练数据集。</p></li>
<li><p>内部重抽样 - 在外部训练数据中实例化四折交叉验证以创建不同的内部测试和训练数据集。</p></li>
<li><p>HPO - 使用内部数据拆分在外部训练集（大的浅蓝色块）上调整超参数。</p></li>
<li><p>训练 - 使用从内部重抽样获得的最佳超参数配置在外部训练数据集上拟合学习器（小块）。</p></li>
<li><p>评估 - 在外部测试数据上评估学习器的性能（大的深蓝色块）。</p></li>
<li><p>外部重抽样重复 - 对三个外部折叠中的每一个重复步骤（2）-(5)。</p></li>
<li><p>聚合 - 取三个性能值的样本均值以获得无偏性能估计。</p></li>
</ol>
<p>内部重抽样为每个配置生成泛化性能估计，并选择要在外部重抽样中评估的最佳配置。然后，外部重抽样为这些最佳配置生成泛化估计。外部重抽样的结果可以用于与在相同外部折叠上训练和测试的其他模型进行比较。</p>
</blockquote>
<p>A common mistake is to think of nested resampling as a method to select optimal model configurations. Nested resampling is a method to compare models and to estimate the generalization performance of a tuned model, however, this is the performance based on multiple different configurations (one from each outer fold) and not performance based on a single configuration. If you are interested in identifying optimal configurations, then use <code><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune()</a></code>/<code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code> or <code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code> with <code>$train()</code> on the complete dataset.</p>
<blockquote>
<p>一个常见的错误是将嵌套重抽样视为选择最佳模型配置的方法。嵌套重抽样是一种用于比较模型和估计调整后模型的泛化性能的方法，但这是基于多种不同配置的性能（每个配置来自于外部折叠的一个），而不是基于单个配置的性能。如果您有兴趣确定最佳配置，那么请使用<code><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune()</a></code>/<code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code>或<code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code>与<code>$train()</code>在完整数据集上进行操作。</p>
</blockquote>
<section id="nested-resampling-with-an-autotuner" class="level3" data-number="4.3.1"><h3 data-number="4.3.1">
<span class="header-section-number">4.3.1</span> Nested Resampling with an <code>AutoTuner</code>
</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">at</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner</a></span><span class="op">(</span></span>
<span>  tuner <span class="op">=</span> <span class="va">tnr_grid_search</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">lrn_svm</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,</span>
<span>  measure <span class="op">=</span> <span class="va">msr_ce</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">rr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/resample.html">resample</a></span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="va">tsk_sonar</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">at</span>,</span>
<span>  resampling <span class="op">=</span> <span class="va">rsmp_cv3</span>,</span>
<span>  store_models <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">rr</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.ce </span></span>
<span><span class="co">#&gt;  0.1733609</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/extract_inner_tuning_results.html">extract_inner_tuning_results</a></span><span class="op">(</span><span class="va">rr</span><span class="op">)</span><span class="op">[</span>,</span>
<span>           <span class="fu">.</span><span class="op">(</span><span class="va">iteration</span>, <span class="va">cost</span>, <span class="va">gamma</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;    iteration     cost     gamma classif.ce</span></span>
<span><span class="co">#&gt; 1:         1 11.51293 -5.756463  0.2533613</span></span>
<span><span class="co">#&gt; 2:         2 11.51293 -5.756463  0.1573529</span></span>
<span><span class="co">#&gt; 3:         3 11.51293 -5.756463  0.1441176</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/extract_inner_tuning_archives.html">extract_inner_tuning_archives</a></span><span class="op">(</span><span class="va">rr</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>,</span>
<span>              <span class="fu">.</span><span class="op">(</span><span class="va">iteration</span>, <span class="va">cost</span>, <span class="va">gamma</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;    iteration       cost    gamma classif.ce</span></span>
<span><span class="co">#&gt; 1:         1 -11.512925  0.00000  0.5728992</span></span>
<span><span class="co">#&gt; 2:         1  -5.756463  0.00000  0.5728992</span></span>
<span><span class="co">#&gt; 3:         1  -5.756463 11.51293  0.5728992</span></span></code></pre></div>
</div>
</section><section id="the-right-and-wrong-way-to-estimate-performance" class="level3" data-number="4.3.2"><h3 data-number="4.3.2">
<span class="header-section-number">4.3.2</span> The Right (and Wrong) Way to Estimate Performance</h3>
<p>In this short section we will empirically demonstrate that directly reporting tuning performance without nested resampling results in optimistically biased performance estimates.</p>
<blockquote>
<p>在这个简短的部分中，我们将通过实验证明，直接报告调优性能而不使用嵌套重抽样会导致性能估计存在乐观偏差。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_xgboost</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span></span>
<span>  <span class="st">"classif.xgboost"</span>,</span>
<span>  eta <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-4</span>, <span class="fl">1</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  max_depth <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">20</span><span class="op">)</span>,</span>
<span>  colsample_bytree <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>  colsample_bylevel <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-3</span>, <span class="fl">1e3</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  alpha <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-3</span>, <span class="fl">1e3</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  subsample <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">tsk_moons</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tgen</a></span><span class="op">(</span><span class="st">"moons"</span><span class="op">)</span></span>
<span><span class="va">tsk_moons_train</span> <span class="op">=</span> <span class="va">tsk_moons</span><span class="op">$</span><span class="fu">generate</span><span class="op">(</span><span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">tsk_moons_test</span> <span class="op">=</span> <span class="va">tsk_moons</span><span class="op">$</span><span class="fu">generate</span><span class="op">(</span><span class="fl">1e6</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Now we will tune the learner with respect to the classification error, using holdout resampling and random search with 700 evaluations. We then report the tuning performance without nested resampling.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tnr_random</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"random_search"</span><span class="op">)</span></span>
<span><span class="va">rsmp_holdout</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"holdout"</span><span class="op">)</span></span>
<span><span class="va">trm_evals700</span> <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"evals"</span>, n_evals <span class="op">=</span> <span class="fl">700</span><span class="op">)</span></span>
<span></span>
<span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune</a></span><span class="op">(</span></span>
<span>  tuner <span class="op">=</span> <span class="va">tnr_random</span>,</span>
<span>  task <span class="op">=</span> <span class="va">tsk_moons_train</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">lrn_xgboost</span>,</span>
<span>  resampling <span class="op">=</span> <span class="va">rsmp_holdout</span>,</span>
<span>  measures <span class="op">=</span> <span class="va">msr_ce</span>,</span>
<span>  terminator <span class="op">=</span> <span class="va">trm_evals700</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">insample</span> <span class="op">=</span> <span class="va">instance</span><span class="op">$</span><span class="va">result_y</span></span></code></pre></div>
</div>
<p>Next, we estimate generalization error by nested resampling (below we use an outer five-fold CV), using an <code>AutoTuner</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># same setup as above</span></span>
<span><span class="va">at</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner</a></span><span class="op">(</span></span>
<span>  tuner <span class="op">=</span> <span class="va">tnr_random</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">lrn_xgboost</span>,</span>
<span>  resampling <span class="op">=</span> <span class="va">rsmp_holdout</span>,</span>
<span>  measure <span class="op">=</span> <span class="va">msr_ce</span>,</span>
<span>  terminator <span class="op">=</span> <span class="va">trm_evals700</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">rsmp_cv5</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">outsample</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/resample.html">resample</a></span><span class="op">(</span><span class="va">tsk_moons_train</span>, <span class="va">at</span>, <span class="va">rsmp_cv5</span><span class="op">)</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<p>And finally, we estimate the generalization error by training the tuned learner (i.e., using the values from the <code>instance</code> above) on the full training data again and predicting on the test data.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_xgboost_tuned</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.xgboost"</span><span class="op">)</span></span>
<span><span class="va">lrn_xgboost_tuned</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">set_values</span><span class="op">(</span></span>
<span>  .values <span class="op">=</span> <span class="va">instance</span><span class="op">$</span><span class="va">result_learner_param_vals</span><span class="op">)</span></span>
<span><span class="va">generalization</span> <span class="op">=</span> <span class="va">lrn_xgboost_tuned</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_moons_train</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">predict</span><span class="op">(</span><span class="va">tsk_moons_test</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">score</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Now we can compare these three values:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>  true_generalization <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">generalization</span><span class="op">)</span>,</span>
<span>  without_nested_resampling <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">insample</span><span class="op">)</span>,</span>
<span>  with_nest_resampling <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">outsample</span><span class="op">)</span></span>
<span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt;       true_generalization without_nested_resampling      with_nest_resampling </span></span>
<span><span class="co">#&gt;                      0.29                      0.09                      0.21</span></span></code></pre></div>
</div>
<p>We find that the performance estimate from unnested tuning optimistically overestimates the true performance (which could indicate ‘meta-overfitting’ to the specific inner holdout-splits), while the outer estimate from nested resampling works much better.</p>
<blockquote>
<p>我们发现，未经嵌套重抽样的调优性能估计会乐观地高估真实性能（这可能表明对特定内部保留集的‘元过拟合’），而来自嵌套重抽样的外部估计效果要好得多。</p>
</blockquote>
</section></section><section id="sec-defining-search-spaces" class="level2" data-number="4.4"><h2 data-number="4.4">
<span class="header-section-number">4.4</span> More Advanced Search Spaces</h2>
<section id="scalar-parameter-tuning" class="level3" data-number="4.4.1"><h3 data-number="4.4.1">
<span class="header-section-number">4.4.1</span> Scalar Parameter Tuning</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span></span>
<span>  <span class="st">"classif.svm"</span>,</span>
<span>  cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1e5</span><span class="op">)</span>,</span>
<span>  gamma <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>  kernel <span class="op">=</span> <span class="st">"radial"</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"C-classification"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">search_space</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;       id    class lower upper nlevels        default value</span></span>
<span><span class="co">#&gt; 1:  cost ParamDbl   0.1 1e+05     Inf &lt;NoDefault[3]&gt;      </span></span>
<span><span class="co">#&gt; 2: gamma ParamDbl   0.1 1e+00     Inf &lt;NoDefault[3]&gt;</span></span></code></pre></div>
</div>
<p>In this example, we can see that <code>gamma</code> hyperparameter has class <code>ParamDbl</code>, with <code>lower = 0.1</code> and <code>upper = 1</code>, which was automatically created by <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code> as we passed two numeric values to this function. If we wanted to tune over a non-numeric hyperparameter, we can still use <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code>, which will infer the correct class to construct in the resulting parameter set. For example, say we wanted to tune the numeric <code>cost</code>, factor <code>kernel</code>, and logical <code>scale</code> hyperparameter in our SVM:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span></span>
<span>  <span class="st">"classif.svm"</span>,</span>
<span>  cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1e5</span><span class="op">)</span>,</span>
<span>  kernel <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"radial"</span>, <span class="st">"linear"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  shrinking <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"C-classification"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">search_space</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;           id    class lower upper nlevels        default value</span></span>
<span><span class="co">#&gt; 1:      cost ParamDbl   0.1 1e+05     Inf &lt;NoDefault[3]&gt;      </span></span>
<span><span class="co">#&gt; 2:    kernel ParamFct    NA    NA       2 &lt;NoDefault[3]&gt;      </span></span>
<span><span class="co">#&gt; 3: shrinking ParamLgl    NA    NA       2           TRUE</span></span></code></pre></div>
</div>
<p>Here the <code>kernel</code> hyperparameter is a factor, so we simply pass in a vector corresponding to the levels we want to tune over. The <code>shrinking</code> hyperparameter is a logical, there are only two possible values this could take so we do not need to pass anything to <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code>, it will automatically recognize this is a logical from <code>learner$param_set</code> and passes this detail to <code>learner$param_set$search_space()</code>. Similarly, for factor parameters, we could also use <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code> without any arguments if we want to tune over all possible values. Finally, we can use <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code> to treat numeric parameters as factors if we want to discretize them over a small subset of possible values, for example, if we wanted to find the optimal number of trees in a random forest we might only consider three scenarios: 100, 200, or 400 trees:</p>
<blockquote>
<p>在这里，<code>kernel</code> 超参数是一个因子，因此我们只需传入一个与我们要调整的级别相对应的向量。<code>shrinking</code> 超参数是一个逻辑型的，它只有两个可能的取值，所以我们不需要传递任何参数给 <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code>，它会自动识别这是一个逻辑型，然后将这个细节传递给 <code>learner$param_set$search_space()</code>。类似地，对于因子参数，如果我们想要调整所有可能的值，我们也可以使用 <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code> 而不带任何参数。最后，如果我们想要将数值参数视为因子，并希望将其离散化为可能值的一小部分，例如，如果我们想要找到随机森林中最佳的树的数量，我们可能只考虑三种情况：100、200 或 400 棵树：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.ranger"</span>, num.trees <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">200</span>, <span class="fl">400</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
</section><section id="defining-search-spaces-with-ps" class="level3" data-number="4.4.2"><h3 data-number="4.4.2">
<span class="header-section-number">4.4.2</span> Defining Search Spaces with <code>ps</code>
</h3>
<p>As a simple example, let us look at how to create a search space to tune <code>cost</code> and <code>gamma</code> again:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">search_space</span> <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/ps.html">ps</a></span><span class="op">(</span></span>
<span>  cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="fl">1e-1</span>, upper <span class="op">=</span> <span class="fl">1e5</span><span class="op">)</span>,</span>
<span>  kernel <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_fct</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"radial"</span>, <span class="st">"linear"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  shrinking <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_lgl</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<p>This search space would then be passed to the <code>search_space</code> argument in <code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti</a></span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="va">tsk_sonar</span>,</span>
<span>  learner <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.svm"</span>, type <span class="op">=</span> <span class="st">"C-classification"</span><span class="op">)</span>,</span>
<span>  resampling <span class="op">=</span> <span class="va">rsmp_cv3</span>,</span>
<span>  measures <span class="op">=</span> <span class="va">msr_ce</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"none"</span><span class="op">)</span>,</span>
<span>  search_space <span class="op">=</span> <span class="va">search_space</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;TuningInstanceSingleCrit&gt;</span></span>
<span><span class="co">#&gt; * State:  Not optimized</span></span>
<span><span class="co">#&gt; * Objective: &lt;ObjectiveTuning:classif.svm_on_sonar&gt;</span></span>
<span><span class="co">#&gt; * Search Space:</span></span>
<span><span class="co">#&gt;           id    class lower upper nlevels</span></span>
<span><span class="co">#&gt; 1:      cost ParamDbl   0.1 1e+05     Inf</span></span>
<span><span class="co">#&gt; 2:    kernel ParamFct    NA    NA       2</span></span>
<span><span class="co">#&gt; 3: shrinking ParamLgl    NA    NA       2</span></span>
<span><span class="co">#&gt; * Terminator: &lt;TerminatorNone&gt;</span></span></code></pre></div>
</div>
</section><section id="transformations-and-tuning-over-vectors" class="level3" data-number="4.4.3"><h3 data-number="4.4.3">
<span class="header-section-number">4.4.3</span> Transformations and Tuning Over Vectors</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.svm"</span>, cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-5</span>, <span class="fl">1e5</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">search_space</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;      id    class     lower    upper nlevels        default value</span></span>
<span><span class="co">#&gt; 1: cost ParamDbl -11.51293 11.51293     Inf &lt;NoDefault[3]&gt;      </span></span>
<span><span class="co">#&gt; Trafo is set.</span></span></code></pre></div>
</div>
<p>Notice that now the <code>lower</code> and <code>upper</code> fields correspond to the transformed bounds, i.e. <span class="math inline">\([\log(1e-5), \log(1e5)]\)</span>. To manually create the same transformation, we can pass the transformation to the <code>trafo</code> argument in <code><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl()</a></code> and set the bounds:</p>
<blockquote>
<p>请注意，现在<code>lower</code>和<code>upper</code>字段对应于经过变换的界限，即<span class="math inline">\([\log(1e-5), \log(1e5)]\)</span>。要手动创建相同的变换，我们可以将变换传递给<code><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl()</a></code>中的<code>trafo</code>参数，并设置界限：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">search_space</span> <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/ps.html">ps</a></span><span class="op">(</span>cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">1e-5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">1e5</span><span class="op">)</span>,</span>
<span>                               trafo <span class="op">=</span> \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">search_space</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;      id    class     lower    upper nlevels        default value</span></span>
<span><span class="co">#&gt; 1: cost ParamDbl -11.51293 11.51293     Inf &lt;NoDefault[3]&gt;      </span></span>
<span><span class="co">#&gt; Trafo is set.</span></span></code></pre></div>
</div>
<p>We can confirm it is correctly set by making use of the <code>$trafo()</code> method, which takes a named list and applies the specified transformations</p>
<blockquote>
<p>我们可以通过使用<code>$trafo()</code>方法来确认它是否设置正确，该方法接受一个命名的列表并应用指定的转换。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">search_space</span><span class="op">$</span><span class="fu">trafo</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>cost <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; $cost</span></span>
<span><span class="co">#&gt; [1] 2.718282</span></span></code></pre></div>
</div>
<p>Where transformations become the most powerful is in the ability to pass arbitrary functions that can act on single parameters or even the entire parameter set. As an example, consider a simple transformation to add ‘2’ to our range:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">search_space</span> <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/ps.html">ps</a></span><span class="op">(</span>cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span>, trafo <span class="op">=</span> \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span> <span class="op">+</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">search_space</span><span class="op">$</span><span class="fu">trafo</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>cost <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; $cost</span></span>
<span><span class="co">#&gt; [1] 3</span></span></code></pre></div>
</div>
<p>Simple transformations such as this can even be added directly to a learner by passing a <code>Param</code> object to <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.svm"</span>,</span>
<span>    cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span>, trafo <span class="op">=</span> \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span> <span class="op">+</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<p>More complex transformations that require multiple arguments should be passed to the <code>.extra_trafo</code> parameter in <code><a href="https://paradox.mlr-org.com/reference/ps.html">ps()</a></code>. <code>.extra_trafo</code> takes a function with parameters <code>x</code> and <code>param_set</code> where, during tuning, <code>x</code> will be a list containing the configuration being tested, and <code>param_set</code> is the whole parameter set. Below we first exponentiate the value of <code>cost</code> and then add ‘2’ if the <code>kernel</code> is <code>"polynomial"</code>.</p>
<blockquote>
<p>需要多个参数的更复杂的转换应该通过 <code><a href="https://paradox.mlr-org.com/reference/ps.html">ps()</a></code> 中的 <code>.extra_trafo</code> 参数传递。<code>.extra_trafo</code> 接受一个带有参数 <code>x</code> 和 <code>param_set</code> 的函数，在调整过程中，<code>x</code> 将是一个包含正在测试的配置的列表，而 <code>param_set</code> 则是整个参数集。在下面的示例中，我们首先将 <code>cost</code> 的值取幂，然后如果 <code>kernel</code> 是 “polynomial”，就加上 ‘2’。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">search_space</span> <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/ps.html">ps</a></span><span class="op">(</span></span>
<span>  cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, trafo <span class="op">=</span> \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  kernel <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_fct</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"polynomial"</span>, <span class="st">"radial"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  .extra_trafo <span class="op">=</span> \<span class="op">(</span><span class="va">x</span>, <span class="va">param_set</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">kernel</span> <span class="op">==</span> <span class="st">"polynomial"</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">x</span><span class="op">$</span><span class="va">cost</span> <span class="op">=</span> <span class="va">x</span><span class="op">$</span><span class="va">cost</span> <span class="op">+</span> <span class="fl">2</span></span>
<span>    <span class="op">}</span></span>
<span>    <span class="va">x</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">search_space</span><span class="op">$</span><span class="fu">trafo</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>cost <span class="op">=</span> <span class="fl">1</span>, kernel <span class="op">=</span> <span class="st">"radial"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; $cost</span></span>
<span><span class="co">#&gt; [1] 2.718282</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $kernel</span></span>
<span><span class="co">#&gt; [1] "radial"</span></span>
<span><span class="va">search_space</span><span class="op">$</span><span class="fu">trafo</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>cost <span class="op">=</span> <span class="fl">1</span>, kernel <span class="op">=</span> <span class="st">"polynomial"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; $cost</span></span>
<span><span class="co">#&gt; [1] 4.718282</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $kernel</span></span>
<span><span class="co">#&gt; [1] "polynomial"</span></span></code></pre></div>
</div>
</section><section id="hyperparameter-dependencies" class="level3" data-number="4.4.4"><h3 data-number="4.4.4">
<span class="header-section-number">4.4.4</span> Hyperparameter Dependencies</h3>
<p>Hyperparameter dependencies occur when a hyperparameter should only be set if another hyperparameter has a particular value. For example, the <code>degree</code> parameter in SVM is only valid when <code>kernel</code> is <code>"polynomial"</code>. In the <code><a href="https://paradox.mlr-org.com/reference/ps.html">ps()</a></code> function, we specify this using the depends argument, which takes a named argument of the form <code>&lt;param&gt; == value</code> or <code>&lt;param&gt; %in% &lt;vector&gt;</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb124"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paradox.mlr-org.com/reference/ps.html">ps</a></span><span class="op">(</span></span>
<span>  kernel <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_fct</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"polynomial"</span>, <span class="st">"radial"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  degree <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_int</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, depends <span class="op">=</span> <span class="op">(</span><span class="va">kernel</span> <span class="op">==</span> <span class="st">"polynomial"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  gamma <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl</a></span><span class="op">(</span><span class="fl">1e-5</span>, <span class="fl">1e5</span>,</span>
<span>                depends <span class="op">=</span> <span class="op">(</span><span class="va">kernel</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"polynomial"</span>, <span class="st">"radial"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;        id    class lower upper nlevels        default parents value</span></span>
<span><span class="co">#&gt; 1: degree ParamInt 1e+00 3e+00       3 &lt;NoDefault[3]&gt;  kernel      </span></span>
<span><span class="co">#&gt; 2:  gamma ParamDbl 1e-05 1e+05     Inf &lt;NoDefault[3]&gt;  kernel      </span></span>
<span><span class="co">#&gt; 3: kernel ParamFct    NA    NA       2 &lt;NoDefault[3]&gt;</span></span></code></pre></div>
</div>
<p>Above we have said that <code>degree</code> should only be set if <code>kernel</code> is (<code>==</code>) <code>"polynomial"</code>, and <code>gamma</code> should only be set if <code>kernel</code> is one of (<code>%in%</code>) <code>"polynomial"</code> or <code>"radial"</code>. In practice, some underlying implementations ignore unused parameters and others throw errors, either way, this is problematic during tuning if, for example, we were wasting time trying to tune <code>degree</code> when the kernel was not polynomial. Hence setting the dependency tells the tuning process to tune <code>degree</code> if <code>kernel</code> is <code>"polynomial"</code> and to ignore it otherwise.</p>
<p>Dependencies can also be passed straight into a learner using <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code>:</p>
<blockquote>
<p>在上面的示例中，我们说过<code>degree</code>只有在<code>kernel</code>为(<code>==</code>) <code>"polynomial"</code>时才应设置，而<code>gamma</code>只有在<code>kernel</code>是(<code>%in%</code>) <code>"polynomial"</code>或<code>"radial"</code>之一时才应设置。<br>
实际上，一些底层实现会忽略未使用的参数，而其他一些则会引发错误，无论哪种情况，在调优过程中都会造成问题，例如，当内核不是多项式时，浪费时间尝试调整<code>degree</code>。<br>
因此，设置依赖关系告诉调整过程，如果<code>kernel</code>是<code>"polynomial"</code>，则调整<code>degree</code>，否则忽略它。</p>
<p>依赖关系也可以直接传递给学习器，使用 <code><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune()</a></code>：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb125"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span></span>
<span>  <span class="st">"classif.svm"</span>,</span>
<span>  kernel <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"polynomial"</span>, <span class="st">"radial"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  degree <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_int</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, depends <span class="op">=</span> <span class="op">(</span><span class="va">kernel</span> <span class="op">==</span> <span class="st">"polynomial"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">search_space</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;        id    class lower upper nlevels        default       parents value</span></span>
<span><span class="co">#&gt; 1: degree ParamInt     1     3       3 &lt;NoDefault[3]&gt; kernel,kernel      </span></span>
<span><span class="co">#&gt; 2: kernel ParamFct    NA    NA       2 &lt;NoDefault[3]&gt;</span></span></code></pre></div>
</div>
</section><section id="recommended-search-spaces-with-mlrtuningspaces" class="level3" data-number="4.4.5"><h3 data-number="4.4.5">
<span class="header-section-number">4.4.5</span> Recommended Search Spaces with <code>mlrtuningspaces</code>
</h3>
<p>Selected search spaces can require a lot of background knowledge or expertise. The package <code>mlr3tuningspaces</code> tries to make HPO more accessible by providing implementations of published search spaces for many popular machine learning algorithms, the hope is that these search spaces are applicable to a wide range of datasets. The search spaces are stored in the dictionary <code>mlr_tuning_spaces</code>.</p>
<blockquote>
<p>所选的搜索空间可能需要大量的背景知识或专业知识。包<code>mlr3tuningspaces</code>试图通过提供许多流行的机器学习算法的已发表搜索空间的实现来使HPO更加可访问，希望这些搜索空间适用于各种各样的数据集。这些搜索空间存储在<code>mlr_tuning_spaces</code>字典中。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb126"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3tuningspaces.mlr-org.com">mlr3tuningspaces</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">mlr_tuning_spaces</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fu">.</span><span class="op">(</span><span class="va">key</span>, <span class="va">label</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;                       key                             label</span></span>
<span><span class="co">#&gt; 1: classif.glmnet.default   Classification GLM with Default</span></span>
<span><span class="co">#&gt; 2:    classif.glmnet.rbv1 Classification GLM with RandomBot</span></span>
<span><span class="co">#&gt; 3:    classif.glmnet.rbv2 Classification GLM with RandomBot</span></span></code></pre></div>
</div>
<p>The tuning spaces are named according to the scheme <code>{learner-id}.{tuning-space-id}</code>. The <code>default</code> tuning spaces are published in Bischl et al. (2023), other tuning spaces are part of the random bot experiments <code>rbv1</code> and <code>rbv2</code> published in Kuehn et al. (2018) and Binder, Pfisterer, and Bischl (2020). The sugar function <code><a href="https://mlr3tuningspaces.mlr-org.com/reference/lts.html">lts()</a></code> (learner tuning space) is used to retrieve a <code>TuningSpace.</code></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lts_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuningspaces.mlr-org.com/reference/lts.html">lts</a></span><span class="op">(</span><span class="st">"classif.rpart.default"</span><span class="op">)</span></span>
<span><span class="va">lts_rpart</span></span>
<span><span class="co">#&gt; &lt;TuningSpace:classif.rpart.default&gt;: Classification Rpart with Default</span></span>
<span><span class="co">#&gt;           id lower upper levels logscale</span></span>
<span><span class="co">#&gt; 1:  minsplit 2e+00 128.0            TRUE</span></span>
<span><span class="co">#&gt; 2: minbucket 1e+00  64.0            TRUE</span></span>
<span><span class="co">#&gt; 3:        cp 1e-04   0.1            TRUE</span></span></code></pre></div>
</div>
<p>A tuning space can be passed to <code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code> or <code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code> as the <code>search_space.</code></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb128"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti</a></span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="va">tsk_sonar</span>,</span>
<span>  learner <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>  measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"evals"</span>, n_evals <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>,</span>
<span>  search_space <span class="op">=</span> <span class="va">lts_rpart</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<p>Alternatively, as loaded search spaces are just a collection of tune tokens, we could also pass these straight to a learner:</p>
<blockquote>
<p>或者，由于加载的搜索空间只是一组调整令牌，我们还可以将它们直接传递给学习器：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb129"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">vals</span> <span class="op">=</span> <span class="va">lts_rpart</span><span class="op">$</span><span class="va">values</span></span>
<span><span class="va">vals</span></span>
<span><span class="co">#&gt; $minsplit</span></span>
<span><span class="co">#&gt; Tuning over:</span></span>
<span><span class="co">#&gt; range [2, 128] (log scale)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $minbucket</span></span>
<span><span class="co">#&gt; Tuning over:</span></span>
<span><span class="co">#&gt; range [1, 64] (log scale)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cp</span></span>
<span><span class="co">#&gt; Tuning over:</span></span>
<span><span class="co">#&gt; range [1e-04, 0.1] (log scale)</span></span>
<span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">set_values</span><span class="op">(</span>.values <span class="op">=</span> <span class="va">vals</span><span class="op">)</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;                 id    class lower upper nlevels        default</span></span>
<span><span class="co">#&gt;  1:             cp ParamDbl     0     1     Inf           0.01</span></span>
<span><span class="co">#&gt;  2:     keep_model ParamLgl    NA    NA       2          FALSE</span></span>
<span><span class="co">#&gt;  3:     maxcompete ParamInt     0   Inf     Inf              4</span></span>
<span><span class="co">#&gt;  4:       maxdepth ParamInt     1    30      30             30</span></span>
<span><span class="co">#&gt;  5:   maxsurrogate ParamInt     0   Inf     Inf              5</span></span>
<span><span class="co">#&gt;  6:      minbucket ParamInt     1   Inf     Inf &lt;NoDefault[3]&gt;</span></span>
<span><span class="co">#&gt;  7:       minsplit ParamInt     1   Inf     Inf             20</span></span>
<span><span class="co">#&gt;  8: surrogatestyle ParamInt     0     1       2              0</span></span>
<span><span class="co">#&gt;  9:   usesurrogate ParamInt     0     2       3              2</span></span>
<span><span class="co">#&gt; 10:           xval ParamInt     0   Inf     Inf             10</span></span>
<span><span class="co">#&gt;                   value</span></span>
<span><span class="co">#&gt;  1: &lt;RangeTuneToken[2]&gt;</span></span>
<span><span class="co">#&gt;  2:                    </span></span>
<span><span class="co">#&gt;  3:                    </span></span>
<span><span class="co">#&gt;  4:                    </span></span>
<span><span class="co">#&gt;  5:                    </span></span>
<span><span class="co">#&gt;  6: &lt;RangeTuneToken[2]&gt;</span></span>
<span><span class="co">#&gt;  7: &lt;RangeTuneToken[2]&gt;</span></span>
<span><span class="co">#&gt;  8:                    </span></span>
<span><span class="co">#&gt;  9:                    </span></span>
<span><span class="co">#&gt; 10:                   0</span></span></code></pre></div>
</div>
<p>We could also apply the default search spaces from Bischl et al. (2023) by passing the learner to <code><a href="https://mlr3tuningspaces.mlr-org.com/reference/lts.html">lts()</a></code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3tuningspaces.mlr-org.com/reference/lts.html">lts</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;LearnerClassifRpart:classif.rpart&gt;: Classification Tree</span></span>
<span><span class="co">#&gt; * Model: -</span></span>
<span><span class="co">#&gt; * Parameters: xval=0, minsplit=&lt;RangeTuneToken&gt;,</span></span>
<span><span class="co">#&gt;   minbucket=&lt;RangeTuneToken&gt;, cp=&lt;RangeTuneToken&gt;</span></span>
<span><span class="co">#&gt; * Packages: mlr3, rpart</span></span>
<span><span class="co">#&gt; * Predict Types:  [response], prob</span></span>
<span><span class="co">#&gt; * Feature Types: logical, integer, numeric, factor, ordered</span></span>
<span><span class="co">#&gt; * Properties: importance, missings, multiclass, selected_features,</span></span>
<span><span class="co">#&gt;   twoclass, weights</span></span></code></pre></div>
</div>
<p>Finally, it is possible to overwrite a predefined tuning space in construction, for example, changing the range of the <code>maxdepth</code> hyperparameter in a decision tree:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb131"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3tuningspaces.mlr-org.com/reference/lts.html">lts</a></span><span class="op">(</span><span class="st">"classif.rpart.rbv2"</span>, maxdepth <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; &lt;TuningSpace:classif.rpart.rbv2&gt;: Classification Rpart with RandomBot</span></span>
<span><span class="co">#&gt;           id lower upper levels logscale</span></span>
<span><span class="co">#&gt; 1:        cp 1e-04     1            TRUE</span></span>
<span><span class="co">#&gt; 2:  maxdepth 1e+00    20           FALSE</span></span>
<span><span class="co">#&gt; 3: minbucket 1e+00   100           FALSE</span></span>
<span><span class="co">#&gt; 4:  minsplit 1e+00   100           FALSE</span></span></code></pre></div>
</div>
</section></section></section><section id="sec-optimization-advanced" class="level1" data-number="5"><h1 data-number="5">
<span class="header-section-number">5</span> Advanced Tuning Methods and Black Box Optimization</h1>
<section id="error-handling-and-memory-management" class="level2" data-number="5.1"><h2 data-number="5.1">
<span class="header-section-number">5.1</span> Error Handling and Memory Management</h2>
<section id="encapsulation-and-fallback-learner" class="level3" data-number="5.1.1"><h3 data-number="5.1.1">
<span class="header-section-number">5.1.1</span> Encapsulation and Fallback Learner</h3>
<p>Even in simple machine learning problems, there is a lot of potential for things to go wrong. For example, when learners do not converge, run out of memory, or terminate with an error due to issues in the underlying data. As a common issue, learners can fail if there are factor levels present in the test data that were not in the training data, models fail in this case as there have been no weights/coefficients trained for these new factor levels:</p>
<blockquote>
<p>即使在简单的机器学习问题中，出现问题的可能性也很大。例如，当学习器不收敛、耗尽内存或由于底层数据问题而出现错误终止时。作为一个常见问题，如果测试数据中存在训练数据中没有的因子水平，那么学习器可能会失败，因为针对这些新的因子水平没有进行权重/系数的训练：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb132"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_pen</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># remove rows with missing values</span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">$</span><span class="va">row_ids</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html">complete.cases</a></span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">rsmp_custom</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"custom"</span><span class="op">)</span></span>
<span><span class="va">rsmp_custom</span><span class="op">$</span><span class="fu">instantiate</span><span class="op">(</span></span>
<span>  <span class="va">tsk_pen</span>,</span>
<span>  train_sets <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">$</span><span class="va">row_ids</span><span class="op">[</span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">island</span> <span class="op">!=</span> <span class="st">"Torgersen"</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  test_sets <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">$</span><span class="va">row_ids</span><span class="op">[</span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">island</span> <span class="op">==</span> <span class="st">"Torgersen"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">msr_ce</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span></span>
<span><span class="va">tnr_random</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"random_search"</span><span class="op">)</span></span>
<span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.lda"</span>, method <span class="op">=</span> <span class="st">"t"</span>, nu <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune</a></span><span class="op">(</span><span class="va">tnr_random</span>, <span class="va">tsk_pen</span>, <span class="va">learner</span>, <span class="va">rsmp_custom</span>, <span class="va">msr_ce</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; INFO  [23:31:47.588] [bbotk] Starting to optimize 1 parameter(s) with '&lt;OptimizerRandomSearch&gt;' and '&lt;TerminatorEvals&gt; [n_evals=10, k=0]'</span></span>
<span><span class="co">#&gt; INFO  [23:31:47.620] [bbotk] Evaluating 1 configuration(s)</span></span>
<span><span class="co">#&gt; INFO  [23:31:47.659] [mlr3] Running benchmark with 1 resampling iterations</span></span>
<span><span class="co">#&gt; INFO  [23:31:47.670] [mlr3] Applying learner 'classif.lda' on task 'penguins' (iter 1/1)</span></span>
<span><span class="co">#&gt; Error in lda.default(x, grouping, ...): variable 6 appears to be constant within groups</span></span></code></pre></div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>TODO：等待后续添加交叉引用 10.2.1</p>
</div>
</div>
<p>In the above example, we can see the tuning process breaks and we lose all information about the hyperparameter optimization process. This is even worse in nested resampling or benchmarking when errors could cause us to lose all progress across multiple configurations or even learners and tasks.</p>
<p>Encapsulation (Section 10.2.1) allows errors to be isolated and handled, without disrupting the tuning process. We can tell a learner to encapsulate an error by setting the <code>$encapsulate</code> field as follows:</p>
<blockquote>
<p>在上述示例中，我们可以看到调优过程中断，我们失去了有关超参数优化过程的所有信息。在嵌套重抽样或基准测试中，当错误可能导致我们失去跨多个配置甚至学习器和任务的所有进展时，情况会变得更糟。</p>
<p>封装（第10.2.1节）允许隔离和处理错误，而不会干扰调优过程。我们可以通过设置<code>$encapsulate</code>字段来告诉学习器封装错误，如下所示：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb133"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span><span class="op">$</span><span class="va">encapsulate</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>train <span class="op">=</span> <span class="st">"evaluate"</span>, predict <span class="op">=</span> <span class="st">"evaluate"</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Note by passing <code>"evaluate"</code> to both <code>train</code> and <code>predict</code>, we are telling the learner to set up encapsulation in both the training and prediction stages (see Section 10.2 for other encapsulation options).</p>
<p>Another common issue that cannot be easily solved during HPO is learners not converging and the process running indefinitely. We can prevent this from happening by setting the <code>timeout</code> field in a learner, which signals the learner to stop if it has been running for that much time (in seconds), again this can be set for training and prediction individually:</p>
<blockquote>
<p>请注意，通过在<code>train</code>和<code>predict</code>中都传递<code>"evaluate"</code>，我们告诉学习器在训练和预测阶段都设置封装（有关其他封装选项，请参见第10.2节）。</p>
<p>另一个在HPO期间难以轻松解决的常见问题是学习器不收敛，进程无限运行。我们可以通过在学习器中设置<code>timeout</code>字段来防止这种情况发生，该字段表示如果学习器运行了这么长时间（以秒为单位），则应停止运行。同样，这可以分别为训练和预测设置：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb134"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span><span class="op">$</span><span class="va">timeout</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>train <span class="op">=</span> <span class="fl">30</span>, predict <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Now if either an error occurs, or the model timeout threshold is reached, then instead of breaking, the learner will simply not make predictions when errors are found and the result is <code>NA</code> for resampling iterations with errors. When this happens, our hyperparameter optimization experiment will fail as we cannot aggregate results across resampling iterations. Therefore it is essential to select a fallback learner (Section 10.2.2), which is a learner that will be fitted if the learner of interest fails.</p>
<p>A common approach is to use a featureless baseline (<code>lrn("regr.featureless"</code>) or <code>lrn("classif.featureless"))</code>. Below we set <code>lrn("classif.featureless")</code>, which always predicts the majority class, by passing this learner to the <code>$fallback</code> field.</p>
<blockquote>
<p>如果出现错误或达到模型超时阈值，那么学习器将不会中断，而是在发现错误时不进行预测，对于出现错误的重抽样迭代，结果将是<code>NA</code>。当发生这种情况时，我们的超参数优化实验将失败，因为我们无法在重抽样迭代之间聚合结果。因此，选择一个回退学习器（第10.2.2节）非常重要，这是一种在感兴趣的学习器失败时将要训练的备用学习器。</p>
<p>一个常见的方法是使用一个没有特征的基线学习器（<code>lrn("regr.featureless"</code>或<code>lrn("classif.featureless")</code>）。下面我们设置了<code>lrn("classif.featureless")</code>，它总是预测多数类别，通过将这个学习器传递给<code>$fallback</code>字段来实现。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb135"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span><span class="op">$</span><span class="va">fallback</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.featureless"</span><span class="op">)</span></span></code></pre></div>
</div>
<p>We can now run our experiment and see errors that occurred during tuning in the archive.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb136"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune</a></span><span class="op">(</span><span class="va">tnr_random</span>, <span class="va">tsk_pen</span>, <span class="va">learner</span>, <span class="va">rsmp_custom</span>, <span class="va">msr_ce</span>, <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb137"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fu">.</span><span class="op">(</span><span class="va">df</span>, <span class="va">classif.ce</span>, <span class="va">errors</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;               df classif.ce errors</span></span>
<span><span class="co">#&gt; 1: &lt;function[1]&gt;          1      1</span></span>
<span><span class="co">#&gt; 2: &lt;function[1]&gt;          1      1</span></span>
<span><span class="co">#&gt; 3: &lt;function[1]&gt;          1      1</span></span>
<span></span>
<span><span class="co"># reading the error in the first resample result</span></span>
<span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">$</span><span class="fu">resample_result</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">$</span><span class="va">errors</span></span>
<span><span class="co">#&gt;    iteration                                             msg</span></span>
<span><span class="co">#&gt; 1:         1 variable 6 appears to be constant within groups</span></span></code></pre></div>
</div>
<p>The learner was tuned without breaking because the errors were encapsulated and logged before the fallback learners were used for fitting and predicting:</p>
<blockquote>
<p>由于错误被封装并在使用回退学习器进行拟合和预测之前进行了记录，学习器在没有中断的情况下进行了调优：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb138"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">result</span></span>
<span><span class="co">#&gt;    nu learner_param_vals  x_domain classif.ce</span></span>
<span><span class="co">#&gt; 1:  8          &lt;list[2]&gt; &lt;list[1]&gt;          1</span></span></code></pre></div>
</div>
</section><section id="memory-management" class="level3" data-number="5.1.2"><h3 data-number="5.1.2">
<span class="header-section-number">5.1.2</span> Memory Management</h3>
<p>Running a large tuning experiment can use a lot of memory, especially when using nested resampling. Most of the memory is consumed by the models since each resampling iteration creates one new model. Storing the models is therefore disabled by default and in most cases is not required. The option <code>store_models</code> in the functions <code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code> and <code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code> allows us to enable the storage of the models.</p>
<p>The archive stores a <code>ResampleResult</code> for each evaluated hyperparameter configuration. The contained <code>Prediction</code> objects can also take up a lot of memory, especially with large datasets and many resampling iterations. We can disable the storage of the resample results by setting <code>store_benchmark_result = FALSE</code> in the functions <code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code> and <code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code>. Note that without the resample results, it is no longer possible to score the configurations with another measure.</p>
<p>When we run nested resampling with many outer resampling iterations, additional memory can be saved if we set <code>store_tuning_instance = FALSE</code> in the <code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code> function. However, the functions <code><a href="https://mlr3tuning.mlr-org.com/reference/extract_inner_tuning_results.html">extract_inner_tuning_results()</a></code> and <code><a href="https://mlr3tuning.mlr-org.com/reference/extract_inner_tuning_archives.html">extract_inner_tuning_archives()</a></code> will then no longer work.</p>
<p>The option <code>store_models = TRUE</code> sets <code>store_benchmark_result</code> and <code>store_tuning_instance</code> to <code>TRUE</code> because the models are stored in the benchmark results which in turn is part of the instance. This also means that <code>store_benchmark_result = TRUE</code> sets <code>store_tuning_instance</code> to <code>TRUE.</code></p>
<p>Finally, we can set <code>store_models = FALSE</code> in the <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> or <code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code> functions to disable the storage of the auto tuners when running nested resampling. This way we can still access the aggregated performance (<code>rr$aggregate()</code>) but lose information about the inner resampling.</p>
<blockquote>
<p>运行大型调优实验可能会使用大量内存，特别是在使用嵌套重抽样时。大多数内存被模型消耗，因为每个重抽样迭代都会创建一个新模型。默认情况下禁用存储模型，而在大多数情况下也不需要存储模型。在函数<code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code>和<code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code>中，选项<code>store_models</code>允许我们启用模型的存储。</p>
<p>归档存储了每个评估的超参数配置的<code>ResampleResult</code>。包含的<code>Prediction</code>对象在大型数据集和许多重抽样迭代时可能占用大量内存。我们可以通过在函数<code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code>和<code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code>中设置<code>store_benchmark_result = FALSE</code>来禁用重抽样结果的存储。请注意，如果没有重抽样结果，就不再可能使用另一个度量来评分配置。</p>
<p>当我们运行具有许多外部重抽样迭代的嵌套重抽样时，如果在<code><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner()</a></code>函数中设置<code>store_tuning_instance = FALSE</code>，还可以节省额外的内存。然而，<code><a href="https://mlr3tuning.mlr-org.com/reference/extract_inner_tuning_results.html">extract_inner_tuning_results()</a></code>和<code><a href="https://mlr3tuning.mlr-org.com/reference/extract_inner_tuning_archives.html">extract_inner_tuning_archives()</a></code>函数将不再起作用。</p>
<p>选项<code>store_models = TRUE</code>会将<code>store_benchmark_result</code>和<code>store_tuning_instance</code>设置为<code>TRUE</code>，因为模型存储在基准结果中，而基准结果又是实例的一部分。这也意味着<code>store_benchmark_result = TRUE</code>会将<code>store_tuning_instance</code>设置为<code>TRUE</code>。</p>
<p>最后，在运行嵌套重抽样时，可以在<code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code>或<code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code>函数中设置<code>store_models = FALSE</code>以禁用自动调整器的存储。这样我们仍然可以访问聚合性能（<code>rr$aggregate()</code>），但会失去有关内部重抽样的信息。</p>
</blockquote>
</section></section><section id="multi-objective-tuning" class="level2" data-number="5.2"><h2 data-number="5.2">
<span class="header-section-number">5.2</span> Multi-Objective Tuning</h2>
<p>So far we have considered optimizing a model with respect to one metric, but multi-criteria, or multi-objective optimization, is also possible. A simple example of multi-objective optimization might be optimizing a classifier to simultaneously maximize true positive predictions and minimize false negative predictions. In another example, consider the single-objective problem of tuning a neural network to minimize classification error. The best-performing model is likely to be quite complex, possibly with many layers that will have drawbacks like being harder to deploy on devices with limited resources. In this case, we might want to simultaneously minimize the classification error and model complexity.</p>
<p>By definition, optimization of multiple metrics means these will be in competition (otherwise we would only optimize one of them) and therefore in general no single configuration exists that optimizes all metrics. Therefore, we instead focus on the concept of Pareto optimality. One hyperparameter configuration is said to Pareto-dominate another if the resulting model is equal or better in all metrics and strictly better in at least one metric.</p>
<p>The goal of multi-objective hyperparameter optimization is to find a set of non-dominated solutions so that their corresponding metric values approximate the Pareto front.</p>
<blockquote>
<p>到目前为止，我们考虑了根据一个度量来优化模型，但多标准或多目标优化也是可能的。多目标优化的一个简单示例可能是优化分类器，同时最大化真正例预测和最小化假负例预测。在另一个示例中，考虑单一目标问题，即调整神经网络以最小化分类错误。性能最佳的模型可能相当复杂，可能具有许多层，具有诸如在资源有限的设备上部署更困难等缺点。在这种情况下，我们可能希望同时最小化分类错误和模型复杂性。</p>
<p>根据定义，多个度量的优化意味着它们将竞争（否则我们只会优化其中一个），因此通常不存在单个配置可以优化所有度量。因此，我们转而关注帕累托最优的概念。如果得到的模型在所有度量上相等或更好，且至少在一个度量上严格更好，则一个超参数配置被认为帕累托优于另一个。</p>
<p>多目标超参数优化的目标是找到一组非支配解，以便它们对应的度量值近似于帕累托前沿。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, cp <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-04</span>, <span class="fl">1e-1</span><span class="op">)</span>,</span>
<span>              minsplit <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">64</span><span class="op">)</span>, maxdepth <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">30</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">measures</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.ce"</span>, <span class="st">"selected_features"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<p>As we are tuning with respect to multiple measures, the function <code><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti()</a></code> automatically creates a <code>TuningInstanceMultiCrit</code> instead of a <code>TuningInstanceSingleCrit.</code> Below we set <code>store_models = TRUE</code> as this is required by the selected features measure.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb140"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti</a></span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">learner</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>  measures <span class="op">=</span> <span class="va">measures</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"evals"</span>, n_evals <span class="op">=</span> <span class="fl">30</span><span class="op">)</span>,</span>
<span>  store_models <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span><span class="va">instance</span></span>
<span><span class="co">#&gt; &lt;TuningInstanceMultiCrit&gt;</span></span>
<span><span class="co">#&gt; * State:  Not optimized</span></span>
<span><span class="co">#&gt; * Objective: &lt;ObjectiveTuning:classif.rpart_on_sonar&gt;</span></span>
<span><span class="co">#&gt; * Search Space:</span></span>
<span><span class="co">#&gt;          id    class lower upper nlevels</span></span>
<span><span class="co">#&gt; 1:       cp ParamDbl 1e-04   0.1     Inf</span></span>
<span><span class="co">#&gt; 2: minsplit ParamInt 2e+00  64.0      63</span></span>
<span><span class="co">#&gt; 3: maxdepth ParamInt 1e+00  30.0      30</span></span>
<span><span class="co">#&gt; * Terminator: &lt;TerminatorEvals&gt;</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb141"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tuner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"random_search"</span><span class="op">)</span></span>
<span><span class="va">tuner</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Finally, we inspect the best-performing configurations, i.e., the Pareto set. Note that the <code>selected_features</code> measure is averaged across the folds, so the values in the archive may not always be integers.</p>
<blockquote>
<p>最后，我们检查性能最佳的配置，即帕累托集。请注意，所选择的特征度量是在交叉验证折叠上进行平均的，因此归档中的值可能不总是整数。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb142"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">$</span><span class="fu">best</span><span class="op">(</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">cp</span>, <span class="va">minsplit</span>, <span class="va">maxdepth</span>, <span class="va">classif.ce</span>, <span class="va">selected_features</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;            cp minsplit maxdepth classif.ce selected_features</span></span>
<span><span class="co">#&gt; 1: 0.06225493       30        7  0.2645273                 3</span></span>
<span><span class="co">#&gt; 2: 0.01311655       59        1  0.2792271                 1</span></span>
<span><span class="co">#&gt; 3: 0.06088867       40        1  0.2792271                 1</span></span></code></pre></div>
</div>
</section><section id="sec-hyperband" class="level2" data-number="5.3"><h2 data-number="5.3">
<span class="header-section-number">5.3</span> Multi-Fidelity Tuning via Hyperband</h2>
<p>Increasingly large datasets and search spaces and increasingly complex models make hyperparameter optimization a time-consuming and computationally expensive task. To tackle this, some HPO methods make use of evaluating a configuration at multiple fidelity levels. Multi-fidelity HPO is motivated by the idea that the performance of a lower-fidelity model is indicative of the full-fidelity model, which can be used to make HPO more efficient (as we will soon see with Hyperband).</p>
<p>To unpack what these terms mean and to motivate multi-fidelity tuning, say that we think a gradient boosting algorithm with up to 1000 rounds will be a very good fit to our training data. However, we are concerned this model will take too long to tune and train. Therefore, we want to gauge the performance of this model using a similar model that is quicker to train by setting a smaller number of rounds. In this example, the hyperparameter controlling the number of rounds is a fidelity parameter, as it controls the tradeoff between model performance and speed. The different configurations of this parameter are known as fidelity levels. We refer to the model with 1000 rounds as the model at full-fidelity and we want to approximate this model’s performance using models at different fidelity levels. Lower fidelity levels result in low-fidelity models that are quicker to train but may poorly predict the full-fidelity model’s performance. On the other hand, higher fidelity levels result in high-fidelity models that are slower to train but may better indicate the full-fidelity model’s performance.</p>
<p>Other common models that have natural fidelity parameters include neural networks (number of epochs) and random forests (number of trees). The proportion of data to subsample before running any algorithm can also be viewed as a model-agnostic fidelity parameter, we will return to this in <a href="#sec-hyperband-example-svm">Section 8.3.3</a>.</p>
<blockquote>
<p>随着数据集和搜索空间的不断增大，以及模型的日益复杂，超参数优化变成了一项耗时且计算成本高昂的任务。为了解决这个问题，一些超参数优化方法利用多个保真度水平（fidelity levels）对配置进行评估。多保真度（Multi-fidelity）超参数优化的动机在于，较低保真度模型的性能可作为完全保真度模型的指示，从而提高超参数优化的效率（正如我们即将看到的 Hyperband 算法）。</p>
<p>为了解释这些术语的含义并推动多保真度调整的动机，假设我们认为一个带有最多1000轮的梯度提升算法将非常适合我们的训练数据。然而，我们担心这个模型调优和训练的时间会太长。因此，我们希望使用一个训练时间更短的类似模型来评估这个模型的性能，方法是设置较少的轮数。在这个例子中，控制轮数的超参数被称为保真度参数，因为它控制了模型性能和速度之间的权衡。该参数的不同配置被称为保真度水平。我们将拥有1000轮的模型称为全保真度模型，我们希望使用不同保真度水平的模型来近似该模型的性能。较低的保真度水平会产生训练速度更快但可能较差的低保真度模型，而较高的保真度水平则会产生训练速度较慢但可能更好地指示全保真度模型性能的高保真度模型。</p>
<p>其他常见的自然带有保真度参数的模型包括神经网络（轮数）和随机森林（树的数量）。在运行任何算法之前对数据进行子采样的比例也可以看作是一种不依赖于特定模型的保真度参数，我们将在第 <a href="#sec-hyperband-example-svm">Section 8.3.3</a> 中详细讨论此点。</p>
</blockquote>
<p>The Successive Halving and Hyperband algorithms are implemented in <code>mlr3hyperband</code> as <code>tnr("successive_halving")</code> and <code>tnr("hyperband")</code> respectively; in this section, we will only showcase the Hyperband method.</p>
<p>By example, we will optimize <code>lrn("classif.xgboost")</code> on <code>tsk("sonar")</code> and use the number of boosting iterations (<code>nrounds</code>) as the fidelity parameter, this is a suitable choice as increasing iterations increases model training time but generally also improves performance. Hyperband will allocate increasingly more boosting iterations to well-performing hyperparameter configurations.</p>
<p>We will load the learner and define the search space. We specify a range from 16 (<span class="math inline">\(r_{min}\)</span> ) to 128 (<span class="math inline">\(`r_{max}`\)</span>) boosting iterations and tag the parameter with <code>"budget"</code> to identify it as a fidelity parameter. For the other hyperparameters, we take the search space for XGBoost from Bischl et al. (2023), which usually works well for a wide range of datasets.</p>
<blockquote>
<p>在<code>mlr3hyperband</code>中，连续加倍算法和Hyperband算法分别被实现为<code>tuner("successive_halving")</code>和<code>tuner("hyperband")</code>。在本节中，我们将仅展示Hyperband方法的使用。</p>
<p>举例来说，我们将在<code>tsk("sonar")</code>上优化<code>lrn("classif.xgboost")</code>，并使用提升迭代次数（<code>nrounds</code>）作为保真度参数。这是一个合适的选择，因为增加迭代次数会增加模型训练时间，但通常也会提高性能。Hyperband将为性能良好的超参数配置分配越来越多的提升迭代次数。</p>
<p>我们将加载学习器并定义搜索空间。我们指定了从16（最小值）到128（最大值）的提升迭代次数范围，并将该参数标记为<code>"budget"</code>，以识别它为保真度参数。对于其他超参数，我们采用了来自Bischl等人（2023年）的XGBoost搜索空间，通常适用于各种数据集。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb143"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.xgboost"</span><span class="op">)</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">set_values</span><span class="op">(</span></span>
<span>  nrounds           <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_int</a></span><span class="op">(</span><span class="fl">16</span>, <span class="fl">128</span>, tags <span class="op">=</span> <span class="st">"budget"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  eta               <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-4</span>, <span class="fl">1</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  max_depth         <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">20</span><span class="op">)</span>,</span>
<span>  colsample_bytree  <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>  colsample_bylevel <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>  lambda            <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-3</span>, <span class="fl">1e3</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  alpha             <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-3</span>, <span class="fl">1e3</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  subsample         <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-1</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<p>We now construct the tuning instance and a hyperband tuner with <code>eta = 2</code>. We use <code>trm("none")</code> and set the <code>repetitions</code> control parameter to <code>1</code> so that Hyperband can terminate itself after all brackets have been evaluated a single time. Note that setting <code>repetition = Inf</code> can be useful if you want a terminator to stop the optimization, for example, based on runtime. The <code><a href="https://mlr3hyperband.mlr-org.com/reference/hyperband_schedule.html">hyperband_schedule()</a></code> function can be used to display the schedule across the given fidelity levels and budget increase factor.</p>
<blockquote>
<p>现在，我们构建调优实例和一个<code>eta = 2</code>的Hyperband调优器。我们使用<code>tuner("none")</code>并将<code>repetitions</code>控制参数设置为<code>1</code>，以便Hyperband在所有档次都被评估一次后自动终止。请注意，如果你希望终止器根据运行时间等因素停止优化，将<code>repetition = Inf</code>设置为无穷大可能会更有用。<code><a href="https://mlr3hyperband.mlr-org.com/reference/hyperband_schedule.html">hyperband_schedule()</a></code>函数可以用来显示在给定的保真度水平和预算增加因子下的调度计划。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb144"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/ti.html">ti</a></span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">learner</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"holdout"</span><span class="op">)</span>,</span>
<span>  measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"none"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">tuner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"hyperband"</span>, eta <span class="op">=</span> <span class="fl">2</span>, repetitions <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://mlr3hyperband.mlr-org.com/reference/hyperband_schedule.html">hyperband_schedule</a></span><span class="op">(</span>r_min <span class="op">=</span> <span class="fl">16</span>, r_max <span class="op">=</span> <span class="fl">128</span>, eta <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt;     bracket stage budget n</span></span>
<span><span class="co">#&gt;  1:       3     0     16 8</span></span>
<span><span class="co">#&gt;  2:       3     1     32 4</span></span>
<span><span class="co">#&gt;  3:       3     2     64 2</span></span>
<span><span class="co">#&gt;  4:       3     3    128 1</span></span>
<span><span class="co">#&gt;  5:       2     0     32 6</span></span>
<span><span class="co">#&gt;  6:       2     1     64 3</span></span>
<span><span class="co">#&gt;  7:       2     2    128 1</span></span>
<span><span class="co">#&gt;  8:       1     0     64 4</span></span>
<span><span class="co">#&gt;  9:       1     1    128 2</span></span>
<span><span class="co">#&gt; 10:       0     0    128 4</span></span></code></pre></div>
</div>
<p>Finally, we can tune as normal and print the result and archive. Note that the archive resulting from a Hyperband run contains the additional columns <code>bracket</code> and <code>stage</code> which break down the results by the corresponding bracket and stage.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb145"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tuner</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb146"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">result</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">classif.ce</span>, <span class="va">nrounds</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;    classif.ce nrounds</span></span>
<span><span class="co">#&gt; 1:   0.115942     128</span></span>
<span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">)</span><span class="op">[</span>,</span>
<span>      <span class="fu">.</span><span class="op">(</span><span class="va">bracket</span>, <span class="va">stage</span>, <span class="va">classif.ce</span>, <span class="va">eta</span>, <span class="va">max_depth</span>, <span class="va">colsample_bytree</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;     bracket stage classif.ce        eta max_depth colsample_bytree</span></span>
<span><span class="co">#&gt;  1:       3     0  0.2173913 -6.1473299        18        0.2682654</span></span>
<span><span class="co">#&gt;  2:       3     0  0.1884058 -3.7454399        16        0.3176791</span></span>
<span><span class="co">#&gt;  3:       3     0  0.1739130 -2.5016375         2        0.4581766</span></span>
<span><span class="co">#&gt;  4:       3     0  0.5362319 -2.2100532        18        0.5085491</span></span>
<span><span class="co">#&gt;  5:       3     0  0.6086957 -6.0429444        15        0.6123156</span></span>
<span><span class="co">#&gt;  6:       3     0  0.2173913 -5.5454764        12        0.9558323</span></span>
<span><span class="co">#&gt;  7:       3     0  0.1739130 -2.1431612        15        0.2202503</span></span>
<span><span class="co">#&gt;  8:       3     0  0.1884058 -8.1914882         9        0.2529409</span></span>
<span><span class="co">#&gt;  9:       2     0  0.5217391 -7.8775215         8        0.7266177</span></span>
<span><span class="co">#&gt; 10:       2     0  0.4927536 -2.9998440        19        0.8676653</span></span>
<span><span class="co">#&gt; 11:       2     0  0.1304348 -4.4386442         7        0.4786818</span></span>
<span><span class="co">#&gt; 12:       2     0  0.1739130 -3.8798192         3        0.7369849</span></span>
<span><span class="co">#&gt; 13:       2     0  0.1594203 -4.8825970        15        0.4897578</span></span>
<span><span class="co">#&gt; 14:       2     0  0.2318841 -7.9417063         7        0.1743294</span></span>
<span><span class="co">#&gt; 15:       3     1  0.1884058 -2.5016375         2        0.4581766</span></span>
<span><span class="co">#&gt; 16:       3     1  0.1884058 -2.1431612        15        0.2202503</span></span>
<span><span class="co">#&gt; 17:       3     1  0.2173913 -3.7454399        16        0.3176791</span></span>
<span><span class="co">#&gt; 18:       3     1  0.1884058 -8.1914882         9        0.2529409</span></span>
<span><span class="co">#&gt; 19:       1     0  0.2318841 -0.1615695        14        0.4256436</span></span>
<span><span class="co">#&gt; 20:       1     0  0.2173913 -3.3216321        20        0.9882602</span></span>
<span><span class="co">#&gt; 21:       1     0  0.1739130 -1.4650905        18        0.7402125</span></span>
<span><span class="co">#&gt; 22:       1     0  0.5942029 -8.4080737        14        0.7843144</span></span>
<span><span class="co">#&gt; 23:       3     2  0.2318841 -2.5016375         2        0.4581766</span></span>
<span><span class="co">#&gt; 24:       3     2  0.1304348 -2.1431612        15        0.2202503</span></span>
<span><span class="co">#&gt; 25:       2     1  0.1304348 -4.4386442         7        0.4786818</span></span>
<span><span class="co">#&gt; 26:       2     1  0.1884058 -4.8825970        15        0.4897578</span></span>
<span><span class="co">#&gt; 27:       2     1  0.1884058 -3.8798192         3        0.7369849</span></span>
<span><span class="co">#&gt; 28:       0     0  0.1884058 -2.9062650        18        0.2968872</span></span>
<span><span class="co">#&gt; 29:       0     0  0.2173913 -6.0356643        18        0.3754443</span></span>
<span><span class="co">#&gt; 30:       0     0  0.2028986 -8.9505985        10        0.7234403</span></span>
<span><span class="co">#&gt; 31:       0     0  0.1884058 -6.2335288        15        0.8755801</span></span>
<span><span class="co">#&gt; 32:       3     3  0.1594203 -2.1431612        15        0.2202503</span></span>
<span><span class="co">#&gt; 33:       2     2  0.1159420 -4.4386442         7        0.4786818</span></span>
<span><span class="co">#&gt; 34:       1     1  0.2173913 -1.4650905        18        0.7402125</span></span>
<span><span class="co">#&gt; 35:       1     1  0.2028986 -3.3216321        20        0.9882602</span></span>
<span><span class="co">#&gt;     bracket stage classif.ce        eta max_depth colsample_bytree</span></span></code></pre></div>
</div>
</section><section id="sec-bayesian-optimization" class="level2" data-number="5.4"><h2 data-number="5.4">
<span class="header-section-number">5.4</span> Bayesian Optimization</h2>
<p>In hyperparameter optimization (<a href="#sec-optimization">Chapter 4</a>), learners are passed a hyperparameter configuration and evaluated on a given task via a resampling technique to estimate its generalization performance with the goal to find the optimal hyperparameter configuration. In general, no analytical description for the mapping from hyperparameter configuration to performance exists and gradient information is also not available. HPO is, therefore, a prime example for black box optimization, which considers the optimization of a function whose mathematical structure and analytical description is unknown or unexploitable. As a result, the only observable information is the output value (i.e., generalization performance) of the function given an input value (i.e., hyperparameter configuration). In fact, as evaluating the performance of a learner can take a substantial amount of time, HPO is quite an expensive black box optimization problem. Black box optimization problems occur in the real-world, for example they are encountered quite often in engineering such as in modeling experiments like crash tests or chemical reactions.</p>
<p>Many optimization algorithm classes exist that can be used for black box optimization, which differ in how they tackle this problem; for example we saw in <a href="#sec-optimization">Chapter 4</a> methods including grid/random search and briefly discussed evolutionary strategies. Bayesian optimization refers to a class of sample-efficient iterative global black box optimization algorithms that rely on a ‘surrogate model’ trained on observed data to model the black box function. This surrogate model is typically a non-linear regression model that tries to capture the unknown function using limited observed data. During each iteration, BO algorithms employ an ‘acquisition function’ to determine the next candidate point for evaluation. This function measures the expected ‘utility’ of each point within the search space based on the prediction of the surrogate model. The algorithm then selects the candidate point with the best acquisition function value and evaluates the black box function at that point to then update the surrogate model. This iterative process continues until a termination criterion is met, such as reaching a pre-specified maximum number of evaluations or achieving a desired level of performance. BO is a powerful method that often results in good optimization performance, especially if the cost of the black box evaluation becomes expensive and the optimization budget is tight.</p>
<p>As a running example throughout this section, we will optimize the sinusoidal function <span class="math inline">\(f: [0, 1] \rightarrow \mathbb{R}, x \mapsto 2x + \sin(14x)\)</span> (<a href="#fig-bayesian-optimization-sinusoidal">Figure 5.1</a>), which is characterized by two local minima and one global minimum.</p>
<blockquote>
<p>在超参数优化（<a href="#sec-optimization">Chapter 4</a>）中，学习器会接收一个超参数配置，并通过重新采样技术在给定任务上进行评估，以估算其泛化性能，目标是找到最优的超参数配置。通常情况下，超参数配置到性能的映射没有解析描述，也无法获得梯度信息。因此，HPO是黑盒优化的一个典型例子，它考虑的是一种函数的优化，该函数的数学结构和解析描述是未知的或无法利用的。因此，唯一可观察到的信息是在给定输入值（即，超参数配置）的情况下，函数的输出值（即，泛化性能）。实际上，由于评估学习器的性能可能需要大量时间，HPO是一个非常昂贵的黑盒优化问题。黑盒优化问题在现实世界中经常出现，例如在工程领域，例如在建模实验中，如碰撞测试或化学反应。</p>
<p>存在许多可用于黑盒优化的优化算法类别，它们在解决这个问题时的方式各不相同；例如，在 <a href="#sec-optimization">Chapter 4</a> 中我们介绍了一些方法，包括网格/随机搜索，并简要讨论了进化策略。贝叶斯优化是指一类基于样本高效迭代的全局黑盒优化算法，它依赖于在观察到的数据上训练的“代理模型”来对黑盒函数进行建模。这个代理模型通常是一个非线性回归模型，它试图使用有限的观察数据来捕捉未知函数。在每次迭代中，BO算法使用一个“采集函数”来确定下一个待评估的候选点。该函数基于代理模型的预测，测量搜索空间内每个点的预期“效用”。然后，算法选择具有最佳采集函数值的候选点，并在该点处评估黑盒函数，然后更新代理模型。这个迭代过程会持续进行，直到满足终止准则，例如达到预先指定的最大评估次数或达到所需的性能水平。BO是一种强大的方法，通常在性能评估的成本昂贵且优化预算有限的情况下表现良好。</p>
<p>在本节的整个过程中，我们将优化正弦函数 <span class="math inline">\(f: [0, 1] \rightarrow \mathbb{R}, x \mapsto 2x + \sin(14x)\)</span> （<a href="#fig-bayesian-optimization-sinusoidal">Figure 5.1</a>），该函数具有两个局部最小值和一个全局最小值，作为一个运行示例。</p>
</blockquote>
<section id="black-box-optimization" class="level3" data-number="5.4.1"><h3 data-number="5.4.1">
<span class="header-section-number">5.4.1</span> Black Box Optimization</h3>
<p>To start translating our problem to code we will use the <code>ObjectiveRFun</code> class to take a single configuration as input. The <code>Objective</code> requires specification of the function to optimize its domain and codomain. By tagging the codomain with <code>"minimize"</code> or <code>"maximize"</code> we specify the optimization direction. Note how below our optimization function takes a <code>list</code> as an input with one element called <code>x</code>.</p>
<blockquote>
<p>为了开始将我们的问题转化为代码，我们将使用<code>ObjectiveRFun</code>类以单个配置作为输入。<code>Objective</code>函数需要指定优化其定义域和共域的函数。通过将共域标记为<code>"minimize"</code>或<code>"maximize"</code>，我们可以指定优化的方向。请注意，在下面的例子中，我们的优化函数以一个名为x的元素的列表作为输入。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb147"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://bbotk.mlr-org.com">bbotk</a></span><span class="op">)</span></span>
<span><span class="va">sinus_1D</span> <span class="op">=</span> \<span class="op">(</span><span class="va">xs</span><span class="op">)</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">xs</span><span class="op">$</span><span class="va">x</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="fl">14</span> <span class="op">*</span> <span class="va">xs</span><span class="op">$</span><span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="va">domain</span> <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/ps.html">ps</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">codomain</span> <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/ps.html">ps</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl</a></span><span class="op">(</span>tags <span class="op">=</span> <span class="st">"minimize"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">objective</span> <span class="op">=</span> <span class="va"><a href="https://bbotk.mlr-org.com/reference/ObjectiveRFun.html">ObjectiveRFun</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">sinus_1D</span>, domain <span class="op">=</span> <span class="va">domain</span>, codomain <span class="op">=</span> <span class="va">codomain</span><span class="op">)</span></span></code></pre></div>
</div>
<p>We can visualize our objective by generating a grid of points on which we evaluate the function (<a href="#fig-bayesian-optimization-sinusoidal">Figure 5.1</a>), this will help us identify its local minima and global minimum.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb148"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">xydt</span> <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/generate_design_grid.html">generate_design_grid</a></span><span class="op">(</span><span class="va">domain</span>, resolution <span class="op">=</span> <span class="fl">1001</span><span class="op">)</span><span class="op">$</span><span class="va">data</span></span>
<span><span class="va">xydt</span><span class="op">[</span>, <span class="va">y</span> <span class="op">:=</span> <span class="va">objective</span><span class="op">$</span><span class="fu">eval_dt</span><span class="op">(</span><span class="va">xydt</span><span class="op">)</span><span class="op">$</span><span class="va">y</span><span class="op">]</span></span>
<span><span class="va">optima</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/data.table.html">data.table</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.3509406</span>, <span class="fl">0.7918238</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">optima</span><span class="op">[</span>, <span class="va">y</span> <span class="op">:=</span> <span class="va">objective</span><span class="op">$</span><span class="fu">eval_dt</span><span class="op">(</span><span class="va">optima</span><span class="op">)</span><span class="op">$</span><span class="va">y</span><span class="op">]</span></span>
<span><span class="va">optima</span><span class="op">[</span>, <span class="va">type</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"local"</span>, <span class="st">"local"</span>, <span class="st">"global"</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">xydt</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">optima</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>pch <span class="op">=</span> <span class="va">type</span><span class="op">)</span>,</span>
<span>             color <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div id="fig-bayesian-optimization-sinusoidal" class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/fig-bayesian-optimization-sinusoidal-1.png" class="img-fluid" style="width:70.0%"></p>
<figcaption>Figure 5.1: Visualization of the sinusoidal function. Local minima in triangles and global minimum in the circle.</figcaption></figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb149"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">xydt</span><span class="op">[</span><span class="va">y</span> <span class="op">==</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="co">#&gt;        x         y</span></span>
<span><span class="co">#&gt; 1: 0.792 -1.577239</span></span></code></pre></div>
</div>
<p>With the objective function defined, we can proceed to optimize it using <code>OptimInstanceSingleCrit</code>. This class allows us to wrap the objective function and explicitly specify a search space. The search space defines the set of input values we want to optimize over, and it is typically a subset or transformation of the domain, though by default the entire domain is taken as the search space. In black box optimization, it is common for the domain, and hence also the search space, to have finite box constraints. Similarly to HPO, transformations can sometimes be used to more efficiently search the space.</p>
<p>In the following, we use a simple random search to optimize the sinusoidal function over the whole domain and inspect the result from the instance in the usual way. Analogously to tuners, Optimizers in bbotk are stored in the mlr_optimizers dictionary and can be constructed with opt().</p>
<blockquote>
<p>有了目标函数的定义，我们可以使用<code>OptimInstanceSingleCrit</code>来进行优化。这个类允许我们封装目标函数并显式地指定一个搜索空间。搜索空间定义了我们想要在其上进行优化的输入值集合，通常它是域的一个子集或变换，尽管默认情况下整个域被视为搜索空间。在黑盒优化中，域，因此也是搜索空间，通常具有有限的区间约束。类似于HPO，有时可以使用变换来更有效地搜索空间。</p>
<p>在接下来的例子中，我们使用简单的随机搜索来在整个域上优化正弦函数，并以通常的方式检查实例的结果。与调优器类似，在<code>bbotk</code>中，优化器存储在<code>mlr_optimizers</code>字典中，可以使用<code><a href="https://bbotk.mlr-org.com/reference/opt.html">opt()</a></code>构建。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb150"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span> <span class="op">=</span> <span class="va"><a href="https://bbotk.mlr-org.com/reference/OptimInstanceSingleCrit.html">OptimInstanceSingleCrit</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span></span>
<span>  <span class="va">objective</span>,</span>
<span>  search_space <span class="op">=</span> <span class="va">domain</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"evals"</span>, n_evals <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">optimizer</span> <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/opt.html">opt</a></span><span class="op">(</span><span class="st">"random_search"</span>, batch_size <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span><span class="va">optimizer</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Similarly to how we can use <code><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune()</a></code> to construct a tuning instance, here we can use <code><a href="https://bbotk.mlr-org.com/reference/bb_optimize.html">bb_optimize()</a></code>, which returns a list with elements <code>"par"</code> (best found parameters), <code>"val"</code> (optimal outcome), and “instance” (the optimization instance); the values given as <code>"par"</code> and <code>"val"</code> are the same as the values found in <code>instance$result</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb151"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">optimal</span> <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/bb_optimize.html">bb_optimize</a></span><span class="op">(</span><span class="va">objective</span>, method <span class="op">=</span> <span class="st">"random_search"</span>, max_evals <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb152"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">optimal</span><span class="op">$</span><span class="va">instance</span><span class="op">$</span><span class="va">result</span></span>
<span><span class="co">#&gt;            x  x_domain         y</span></span>
<span><span class="co">#&gt; 1: 0.7876307 &lt;list[1]&gt; -1.574492</span></span></code></pre></div>
</div>
<p>Now we have introduced the basic black box optimization setup, we can introduce the building blocks of any Bayesian optimization algorithm.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>跳过了贝叶斯优化部分。</p>
</div>
</div>
<!-- ### Bayesian Optimization for HPO -->
<!-- `mlr3mbo` can be used for HPO by making use of `TunerMbo`, which is a wrapper around `OptimizerMbo` and works in the exact same way. -->
<!-- ```{r} -->
<!-- bayesopt_ego = mlr_loop_functions$get("bayesopt_ego") -->
<!-- surrogate = srlrn(lrn("regr.km", covtype = "matern5_2", -->
<!--   optim.method = "BFGS", control = list(trace = FALSE))) -->
<!-- acq_function = acqf("ei") -->
<!-- acq_optimizer = acqo(opt("nloptr", algorithm = "NLOPT_GN_ORIG_DIRECT"), -->
<!--   terminator = trm("stagnation", iters = 100, threshold = 1e-5)) -->
<!-- ``` -->
</section></section></section><section id="feature-selection" class="level1" data-number="6"><h1 data-number="6">
<span class="header-section-number">6</span> Feature Selection</h1>
<p>Feature selection, also known as variable or descriptor selection, is the process of finding a subset of features to use with a given task and learner. Using an optimal set of features can have several benefits:</p>
<ul>
<li><p>improved predictive performance, since we reduce overfitting on irrelevant features,</p></li>
<li><p>robust models that do not rely on noisy features,</p></li>
<li><p>simpler models that are easier to interpret,</p></li>
<li><p>faster model fitting, e.g. for model updates,</p></li>
<li><p>faster prediction, and</p></li>
<li><p>no need to collect potentially expensive features.</p></li>
</ul>
<p>However, these objectives will not necessarily be optimized by the same set of features and thus feature selection can be seen as a multi-objective optimization problem. In this chapter, we mostly focus on feature selection as a means of improving predictive performance, but also briefly cover the optimization of multiple criteria (<a href="#sec-multicrit-featsel">Section 6.2.5</a>).</p>
<p>Reducing the number of features can improve models across many scenarios, but it can be especially helpful in datasets that have a high number of features in comparison to the number of data points. Many learners perform implicit, also called embedded, feature selection, e.g. via the choice of variables used for splitting in a decision tree. Most other feature selection methods are model agnostic, i.e. they can be used together with any learner.</p>
<blockquote>
<p>特征选择，也称为变量或描述符选择，是找到适用于给定任务和学习器的特征子集的过程。使用最优特征集合可以带来几个好处：</p>
<ol type="1">
<li><p>提高预测性能，因为我们减少了对无关特征的过拟合。</p></li>
<li><p>构建不依赖噪声特征的稳健模型。</p></li>
<li><p>创建更容易解释的简单模型。</p></li>
<li><p>更快的模型拟合，例如用于模型更新。</p></li>
<li><p>更快的预测速度。</p></li>
<li><p>无需收集可能昂贵的特征。</p></li>
</ol>
<p>然而，这些目标不一定会被相同的特征集合最优化，因此特征选择可以被看作是一个多目标优化问题。在本章中，我们主要关注特征选择作为提高预测性能的手段，但也简要介绍了多标准优化的方法（请参见 <a href="#sec-multicrit-featsel">Section 6.2.5</a>）。</p>
<p>在许多情况下，减少特征数量可以提高模型性能，但在与数据点数量相比特征数量较多的数据集中，特别有帮助。许多学习器通过隐式的、也称为嵌入式的特征选择方法，例如在决策树中用于分割的变量选择中执行特征选择。大多数其他特征选择方法是与模型无关的，即它们可以与任何学习器一起使用。在识别相关特征的许多不同方法中，我们将重点放在两个通用概念上，它们在下面详细描述：过滤方法和包装方法。</p>
</blockquote>
<section id="filters" class="level2" data-number="6.1"><h2 data-number="6.1">
<span class="header-section-number">6.1</span> Filters</h2>
<p>Filter algorithms select features by assigning numeric scores to each feature, e.g. correlation between features and target variable, use these to rank the features and select a feature subset based on the ranking. Features that are assigned lower scores are then omitted in subsequent modeling steps.</p>
<p>The learner used in a feature importance or embedded filter is independent of learners used in subsequent modeling steps. For example, one might use feature importance of a random forest for feature selection and train a neural network on the reduced feature set.</p>
<p>Most of the filter methods have some limitations, for example, the correlation filter can only be calculated for regression tasks with numeric features. For a full list of all implemented filter methods, we refer the reader to <a href="https://mlr3filters.mlr-org.com" class="uri">https://mlr3filters.mlr-org.com</a>, which also shows the supported task and features types. A benchmark of filter methods was performed by Bommert et al. (2020), who recommend not to rely on a single filter method but to try several ones if the available computational resources allow. If only a single filter method is to be used, the authors recommend to use a feature importance filter using random forest permutation importance (see <a href="#sec-fs-var-imp-filters">Section 6.1.2</a>), similar to the permutation method described above, but also the JMIM and AUC filters performed well in their comparison.</p>
<blockquote>
<p>过滤算法通过为每个特征分配数值分数（例如，特征与目标变量之间的相关性）来选择特征，然后使用这些分数对特征进行排序，并基于排名选择一个特征子集。分配较低分数的特征将在后续建模步骤中被省略。</p>
<p>在特征重要性或嵌入式过滤器中使用的学习器与后续建模步骤中使用的学习器是相互独立的。例如，可以使用随机森林的特征重要性进行特征选择，然后在减少后的特征集上训练神经网络。</p>
<p>大多数过滤方法都有一些限制，例如，相关性过滤只能用于具有数值特征的回归任务。有关所有已实现的过滤方法的完整列表，我们建议读者访问<a href="https://mlr3filters.mlr-org.com" class="uri">https://mlr3filters.mlr-org.com</a>，该网站还显示了支持的任务和特征类型。Bommert等人（2020年）进行了一项过滤方法的基准测试，他们建议不要仅依赖于单个过滤方法，而是在计算资源允许的情况下尝试多种方法。如果只想使用单个过滤方法，作者建议使用基于随机森林排列重要性的特征重要性过滤器（参见 <a href="#sec-fs-var-imp-filters">Section 6.1.2</a> ），类似于上述描述的排列方法，但JMIM和AUC过滤器在他们的比较中也表现良好。</p>
</blockquote>
<section id="calculating-filter-value" class="level3" data-number="6.1.1"><h3 data-number="6.1.1">
<span class="header-section-number">6.1.1</span> Calculating Filter Value</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb153"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flt_gain</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3filters.mlr-org.com/reference/flt.html">flt</a></span><span class="op">(</span><span class="st">"information_gain"</span><span class="op">)</span></span>
<span><span class="va">tsk_pen</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">flt_gain</span><span class="op">$</span><span class="fu">calculate</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">flt_gain</span><span class="op">)</span></span>
<span><span class="co">#&gt;           feature       score</span></span>
<span><span class="co">#&gt; 1: flipper_length 0.581167901</span></span>
<span><span class="co">#&gt; 2:    bill_length 0.544896584</span></span>
<span><span class="co">#&gt; 3:     bill_depth 0.538718879</span></span>
<span><span class="co">#&gt; 4:         island 0.520157171</span></span>
<span><span class="co">#&gt; 5:      body_mass 0.442879511</span></span>
<span><span class="co">#&gt; 6:            sex 0.007244168</span></span>
<span><span class="co">#&gt; 7:           year 0.000000000</span></span></code></pre></div>
</div>
<p>This shows that the flipper and bill measurements are the most informative features for predicting the species of a penguin in this dataset, whereas sex and year are the least informative. Some filters have hyperparameters that can be changed in the same way as <code>Learner</code> hyperparameters. For example, to calculate <code>"spearman"</code> instead of <code>"pearson"</code> correlation with the correlation filter:</p>
<blockquote>
<p>这显示了在这个数据集中，翅膀和嘴巴的测量是预测企鹅物种最具信息量的特征，而性别和年份则是最不具信息量的特征。一些过滤器具有可以像<code>Learner</code>超参数一样更改的超参数。例如，要使用相关性过滤器计算<code>"Spearman"</code>相关性而不是<code>"Pearson"</code>相关性：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb154"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flt_cor</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3filters.mlr-org.com/reference/flt.html">flt</a></span><span class="op">(</span><span class="st">"correlation"</span>, method <span class="op">=</span> <span class="st">"spearman"</span><span class="op">)</span></span>
<span><span class="va">flt_cor</span><span class="op">$</span><span class="va">param_set</span></span>
<span><span class="co">#&gt; &lt;ParamSet&gt;</span></span>
<span><span class="co">#&gt;        id    class lower upper nlevels    default    value</span></span>
<span><span class="co">#&gt; 1:    use ParamFct    NA    NA       5 everything         </span></span>
<span><span class="co">#&gt; 2: method ParamFct    NA    NA       3    pearson spearman</span></span></code></pre></div>
</div>
</section><section id="sec-fs-var-imp-filters" class="level3" data-number="6.1.2"><h3 data-number="6.1.2">
<span class="header-section-number">6.1.2</span> Feature Importance Filters</h3>
<p>To use feature importance filters, we can use a learner with with an <code>$importance()</code> method that reports feature importance. All learners with the property “importance” have this functionality. A list of all learners with this property can be found with</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb155"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">mlr_learners</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">properties</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="st">"importance"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">x</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
</div>
<p>For some learners, the desired filter method needs to be set as a hyperparameter. For example, <code>lrn("classif.ranger")</code> comes with multiple integrated methods, which can be selected during construction: To use the feature importance method <code>"impurity"</code>, select it during learner construction:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb156"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.ranger"</span><span class="op">)</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">levels</span><span class="op">$</span><span class="va">importance</span></span>
<span><span class="co">#&gt; [1] "none"               "impurity"           "impurity_corrected"</span></span>
<span><span class="co">#&gt; [4] "permutation"</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb157"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_ranger</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.ranger"</span>, importance <span class="op">=</span> <span class="st">"impurity"</span><span class="op">)</span></span></code></pre></div>
</div>
<p>We first have to remove missing data because the learner cannot handle missing data, i.e. it does not have the property “missing”. Note we use the <code>$filter()</code> method to remove rows; the “filter” name is unrelated to feature filtering, however.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb158"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_pen</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">$</span><span class="va">row_ids</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html">complete.cases</a></span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Now we can use <code>flt("importance")</code> to calculate importance values:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb159"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flt_importance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3filters.mlr-org.com/reference/flt.html">flt</a></span><span class="op">(</span><span class="st">"importance"</span>, learner <span class="op">=</span> <span class="va">lrn_ranger</span><span class="op">)</span></span>
<span><span class="va">flt_importance</span><span class="op">$</span><span class="fu">calculate</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">flt_importance</span><span class="op">)</span></span>
<span><span class="co">#&gt;           feature      score</span></span>
<span><span class="co">#&gt; 1:    bill_length 78.0962951</span></span>
<span><span class="co">#&gt; 2: flipper_length 43.7041810</span></span>
<span><span class="co">#&gt; 3:     bill_depth 32.8321326</span></span>
<span><span class="co">#&gt; 4:      body_mass 28.9420070</span></span>
<span><span class="co">#&gt; 5:         island 25.0781338</span></span>
<span><span class="co">#&gt; 6:            sex  1.3817846</span></span>
<span><span class="co">#&gt; 7:           year  0.9791097</span></span></code></pre></div>
</div>
</section><section id="embedded-methods" class="level3" data-number="6.1.3"><h3 data-number="6.1.3">
<span class="header-section-number">6.1.3</span> Embedded Methods</h3>
<p>Many learners internally select a subset of the features which they find helpful for prediction, but ignore other features. For example, a decision tree might never select some features for splitting. These subsets can be used for feature selection, which we call embedded methods because the feature selection is embedded in the learner. The selected features (and those not selected) can be queried if the learner has the <code>"selected_features"</code> property. As above, we can find those learners with</p>
<blockquote>
<p>许多学习器在内部选择对预测有帮助的特征子集，但忽略其他特征。例如，决策树可能永远不会选择某些特征进行分割。这些子集可以用于特征选择，我们称之为嵌入方法，因为特征选择嵌入在学习器中。如果学习器具有<code>"selected_features"</code>属性，那么可以查询所选特征（以及未被选择的特征）。与上述类似，我们可以找到那些带有该属性的学习器：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb160"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">mlr_learners</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">properties</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="st">"selected_features"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">x</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb161"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_pen</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">selected_features</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "flipper_length" "bill_length"    "island"</span></span></code></pre></div>
</div>
<p>The features selected by the model can be extracted by a <code>Filter</code> object, where <code>$calculate()</code> corresponds to training the learner on the given task:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb162"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flt_selected</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3filters.mlr-org.com/reference/flt.html">flt</a></span><span class="op">(</span><span class="st">"selected_features"</span>, learner <span class="op">=</span> <span class="va">lrn_rpart</span><span class="op">)</span></span>
<span><span class="va">flt_selected</span><span class="op">$</span><span class="fu">calculate</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">flt_selected</span><span class="op">)</span></span>
<span><span class="co">#&gt;           feature score</span></span>
<span><span class="co">#&gt; 1:         island     1</span></span>
<span><span class="co">#&gt; 2: flipper_length     1</span></span>
<span><span class="co">#&gt; 3:    bill_length     1</span></span>
<span><span class="co">#&gt; 4:            sex     0</span></span>
<span><span class="co">#&gt; 5:     bill_depth     0</span></span>
<span><span class="co">#&gt; 6:      body_mass     0</span></span>
<span><span class="co">#&gt; 7:           year     0</span></span></code></pre></div>
</div>
<p>Contrary to other filter methods, embedded methods just return values of <code>1</code> (selected features) and <code>0</code> (dropped feature).</p>
</section><section id="filter-based-feature-selection" class="level3" data-number="6.1.4"><h3 data-number="6.1.4">
<span class="header-section-number">6.1.4</span> Filter-Based Feature Selection</h3>
<p>After calculating a score for each feature, one has to select the features to be kept or those to be dropped from further modeling steps. For the <code>"selected_features"</code> filter described in embedded methods, this step is straight-forward since the methods assign either a value of 1 for a feature to be kept or 0 for a feature to be dropped. Below, we find the names of features with a value of 1 and select those features with <code>task$select()</code>. At first glance it may appear a bit convoluted to have a filter assign scores based on the feature names returned by <code>$selected_features()</code>, only to turn these scores back into the names of the features to be kept. However, this approach allows us to use the same interface for all filter methods, which is especially useful when we want to automate the feature selection process in pipelines, as we will see in <a href="#sec-pipelines-featsel">Section 8.3.4</a>.</p>
<blockquote>
<p>在为每个特征计算分数之后，需要选择要保留的特征或要在进一步建模步骤中舍弃的特征。对于嵌入方法中描述的<code>"selected_features"</code>筛选器来说，这一步骤非常直接，因为该方法为要保留的特征分配值1，为要舍弃的特征分配值0。在下面的代码中，我们查找值为1的特征的名称，并使用<code>task$select()</code>选择这些特征。乍一看，这似乎有点繁琐，因为我们让一个筛选器基于<code>$selected_features()</code>返回的特征名称分配分数，然后再将这些分数转换回要保留的特征的名称。然而，这种方法使我们能够为所有筛选方法使用相同的接口，尤其在我们想要在管道中自动化特征选择过程时特别有用，正如我们将在 <a href="#sec-pipelines-featsel">Section 8.3.4</a> 中看到的那样。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb163"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flt_selected</span><span class="op">$</span><span class="fu">calculate</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># select all features used by rpart</span></span>
<span><span class="va">keep</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">flt_selected</span><span class="op">$</span><span class="va">scores</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="va">keep</span><span class="op">)</span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="va">feature_names</span></span>
<span><span class="co">#&gt; [1] "bill_length"    "flipper_length" "island"</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb164"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># select the top k(= 3) features</span></span>
<span><span class="va">tsk_pen</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">flt_gain</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3filters.mlr-org.com/reference/flt.html">flt</a></span><span class="op">(</span><span class="st">"information_gain"</span><span class="op">)</span></span>
<span><span class="va">flt_gain</span><span class="op">$</span><span class="fu">calculate</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">)</span></span>
<span></span>
<span><span class="va">keep</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">flt_gain</span><span class="op">$</span><span class="va">scores</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="va">keep</span><span class="op">)</span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="va">feature_names</span></span>
<span><span class="co">#&gt; [1] "bill_depth"     "bill_length"    "flipper_length"</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb165"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Select all features with a score (&gt; 0.5)</span></span>
<span><span class="va">tsk_pen</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">flt_gain</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3filters.mlr-org.com/reference/flt.html">flt</a></span><span class="op">(</span><span class="st">"information_gain"</span><span class="op">)</span></span>
<span><span class="va">flt_gain</span><span class="op">$</span><span class="fu">calculate</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">)</span></span>
<span></span>
<span><span class="va">keep</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">flt_gain</span><span class="op">$</span><span class="va">scores</span> <span class="op">&gt;</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="va">keep</span><span class="op">)</span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="va">feature_names</span></span>
<span><span class="co">#&gt; [1] "bill_depth"     "bill_length"    "flipper_length" "island"</span></span></code></pre></div>
</div>
</section></section><section id="wrapper-methods" class="level2" data-number="6.2"><h2 data-number="6.2">
<span class="header-section-number">6.2</span> Wrapper Methods</h2>
<p>Wrapper methods work by fitting models on selected feature subsets and evaluating their performance (Kohavi and John 1997). This can be done in a sequential fashion, e.g. by iteratively adding features to the model in sequential forward selection, or in a parallel fashion, e.g. by evaluating random feature subsets in a random search. Below, we describe these simple approaches in a common framework along with more advanced methods such as genetic search. We further show how to select features by optimizing multiple performance measures and how to wrap a learner with feature selection to use it in pipelines or benchmarks.</p>
<p>In more detail, wrapper methods iteratively evaluate subsets of features by resampling a learner restricted to this feature subset and with a chosen performance metric (with holdout or a more expensive CV), and using the resulting performance to guide the search. The specific search strategy iteration is defined by a <code>FSelector</code> object. A simple example is the sequential forward selection that starts with computing each single-feature model, selects the best one, and then iteratively always adds the feature that leads to the largest performance improvement.</p>
<p>Wrapper methods can be used with any learner, but need to train or even resample the learner potentially many times, leading to a computationally intensive method. All wrapper methods are implemented via the package <code>mlr3fselect</code>.</p>
<blockquote>
<p>包装方法通过在选择的特征子集上拟合模型并评估其性能来工作（Kohavi和John，1997年）。这可以以顺序方式进行，例如通过在顺序前向选择中迭代地将特征添加到模型中，也可以以并行方式进行，例如通过在随机搜索中评估随机特征子集。在下面，我们描述了这些简单方法，以及更高级的方法，比如遗传搜索，都在一个共同的框架下。我们还展示了如何通过优化多个性能指标来选择特征，以及如何用特征选择包装一个学习器，使其可以在管道或基准测试中使用。</p>
<p>更详细地说，包装方法通过对特征子集进行迭代评估，方法是通过对一个受限于该特征子集的学习器进行重抽样，选择一个选定的性能指标（使用留出法或更昂贵的交叉验证），并使用得到的性能来引导搜索。具体的搜索策略迭代是由一个<code>FSelector</code>对象定义的。一个简单的例子是顺序前向选择，它从计算每个单特征模型开始，选择最好的模型，然后迭代地添加导致性能提升最大的特征。</p>
<p>包装方法可以与任何学习器一起使用，但可能需要多次训练甚至重抽样学习器，因此是一种计算密集型的方法。所有的包装方法都是通过<code>mlr3fselect</code>包实现的。</p>
</blockquote>
<section id="simple-forward-selection-example" class="level3" data-number="6.2.1"><h3 data-number="6.2.1">
<span class="header-section-number">6.2.1</span> Simple Forward Selection Example</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb166"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_pen</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"bill_depth"</span>, <span class="st">"bill_length"</span>, <span class="st">"body_mass"</span>, <span class="st">"flipper_length"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3fselect.mlr-org.com/reference/fselect.html">fselect</a></span><span class="op">(</span></span>
<span>  fselector <span class="op">=</span> <span class="fu"><a href="https://mlr3fselect.mlr-org.com/reference/fs.html">fs</a></span><span class="op">(</span><span class="st">"sequential"</span><span class="op">)</span>,</span>
<span>  task <span class="op">=</span> <span class="va">tsk_pen</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">lrn_rpart</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>  measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb167"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dt</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">)</span></span>
<span><span class="va">dt</span><span class="op">[</span><span class="va">batch_nr</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span>
<span><span class="co">#&gt;    bill_depth bill_length body_mass flipper_length classif.acc</span></span>
<span><span class="co">#&gt; 1:       TRUE       FALSE     FALSE          FALSE   0.7239003</span></span>
<span><span class="co">#&gt; 2:      FALSE        TRUE     FALSE          FALSE   0.7646326</span></span>
<span><span class="co">#&gt; 3:      FALSE       FALSE      TRUE          FALSE   0.6888126</span></span>
<span><span class="co">#&gt; 4:      FALSE       FALSE     FALSE           TRUE   0.7762777</span></span></code></pre></div>
</div>
<p>We see that the feature <code>flipper_length</code> achieved the highest prediction performance in the first iteration and is thus selected. We plot the performance over the iterations:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb168"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">instance</span>, type <span class="op">=</span> <span class="st">"performance"</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-173-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>In the plot, we can see that adding a second feature further improves the performance to over 90%. To see which feature was added, we can go back to the archive and look at the second iteration:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb169"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dt</span><span class="op">[</span><span class="va">batch_nr</span> <span class="op">==</span> <span class="fl">2</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span>
<span><span class="co">#&gt;    bill_depth bill_length body_mass flipper_length classif.acc</span></span>
<span><span class="co">#&gt; 1:       TRUE       FALSE     FALSE           TRUE   0.7762777</span></span>
<span><span class="co">#&gt; 2:      FALSE        TRUE     FALSE           TRUE   0.9128146</span></span>
<span><span class="co">#&gt; 3:      FALSE       FALSE      TRUE           TRUE   0.7644038</span></span></code></pre></div>
</div>
<p>The improvement in batch three is small so we may even prefer to select a marginally worse model with two features to reduce data size.</p>
<p>To directly show the best feature set, we can use <code>$result_feature_set</code> which returns the features in alphabetical order (not order selected):</p>
<blockquote>
<p>在第三次迭代中的改进很小，因此我们甚至可能更愿意选择一个带有两个特征的性能稍差一点的模型，以减小数据集的大小。</p>
<p>要直接显示最佳特征集，我们可以使用<code>$result_feature_set</code>，该属性返回按字母顺序排列的特征（而不是选择的顺序）：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb170"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">result_feature_set</span></span>
<span><span class="co">#&gt; [1] "bill_depth"     "bill_length"    "flipper_length"</span></span></code></pre></div>
</div>
</section><section id="the-fselectinstance-class" class="level3" data-number="6.2.2"><h3 data-number="6.2.2">
<span class="header-section-number">6.2.2</span> The FSelectInstance Class</h3>
<p>To create an <code>FSelectInstanceSingleCrit</code> object, we use the sugar function <code><a href="https://mlr3fselect.mlr-org.com/reference/fsi.html">fsi()</a></code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb171"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3fselect.mlr-org.com/reference/fsi.html">fsi</a></span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="va">tsk_pen</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">lrn_rpart</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>  measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"evals"</span>, n_evals <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
</section><section id="the-fselector-class" class="level3" data-number="6.2.3"><h3 data-number="6.2.3">
<span class="header-section-number">6.2.3</span> The FSelector Class</h3>
<p>The <code>FSelector</code> class is the base class for different feature selection algorithms. The following algorithms are currently implemented in <code>mlr3fselect</code>:</p>
<ul>
<li><p>Random search, trying random feature subsets until termination (<code>fs("random_search")</code>)</p></li>
<li><p>Exhaustive search, trying all possible feature subsets (<code>fs("exhaustive_search")</code>)</p></li>
<li><p>Sequential search, i.e. sequential forward or backward selection (<code>fs("sequential")</code>)</p></li>
<li><p>Recursive feature elimination, which uses a learner’s importance scores to iteratively remove features with low feature importance (<code>fs("rfe")</code>)</p></li>
<li><p>Design points, trying all user-supplied feature sets (<code>fs("design_points")</code>)</p></li>
<li><p>Genetic search, implementing a genetic algorithm which treats the features as a binary sequence and tries to find the best subset with mutations (<code>fs("genetic_search")</code>)</p></li>
<li><p>Shadow variable search, which adds permuted copies of all features (shadow variables), performs forward selection, and stops when a shadow variable is selected (<code>fs("shadow_variable_search")</code>)</p></li>
</ul>
<p>Note that all these methods can be stopped (early) with a terminator, e.g. an exhaustive search can be stopped after a given number of evaluations. In this example, we will use a simple random search and retrieve it from the <code>mlr_fselectors</code> dictionary with <code><a href="https://mlr3fselect.mlr-org.com/reference/fs.html">fs()</a></code>.</p>
<blockquote>
<p><code>FSelector</code>类是不同特征选择算法的基类。目前在<code>mlr3fselect</code>中实现了以下算法：</p>
<ul>
<li><p>随机搜索，直到满足终止条件为止尝试随机特征子集 (<code>fs("random_search")</code>)</p></li>
<li><p>穷举搜索，尝试所有可能的特征子集 (<code>fs("exhaustive_search")</code>)</p></li>
<li><p>顺序搜索，即顺序前向或顺序后向选择 (<code>fs("sequential")</code>)</p></li>
<li><p>递归特征消除，它使用学习器的重要性分数，迭代地删除具有较低重要性的特征 (<code>fs("rfe")</code>)</p></li>
<li><p>设计点，尝试所有用户提供的特征集 (<code>fs("design_points")</code>)</p></li>
<li><p>遗传搜索，实现将特征视为二进制序列的遗传算法，并尝试通过突变找到最佳子集 (<code>fs("genetic_search")</code>)</p></li>
<li><p>影子变量搜索，它将所有特征的排列副本（影子变量）添加到特征集中，执行前向选择，并在选择了影子变量时停止 (<code>fs("shadow_variable_search")</code>)</p></li>
</ul>
<p>请注意，所有这些方法都可以（提前）通过终止条件停止，例如，穷举搜索可以在给定数量的评估后停止。在本例中，我们将使用简单的随机搜索，并使用<code><a href="https://mlr3fselect.mlr-org.com/reference/fs.html">fs()</a></code>函数从<code>mlr_fselectors</code>字典中检索它。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb172"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fselector</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3fselect.mlr-org.com/reference/fs.html">fs</a></span><span class="op">(</span><span class="st">"random_search"</span><span class="op">)</span></span></code></pre></div>
</div>
</section><section id="starting-the-feature-selection" class="level3" data-number="6.2.4"><h3 data-number="6.2.4">
<span class="header-section-number">6.2.4</span> Starting the Feature Selection</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb173"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fselector</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb174"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># access the best feature subset and the corresponding measured performance</span></span>
<span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">instance</span><span class="op">$</span><span class="va">result</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">features</span>, <span class="va">classif.acc</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;                                features classif.acc</span></span>
<span><span class="co">#&gt; 1: bill_length,body_mass,flipper_length    0.921434</span></span></code></pre></div>
</div>
<p>Now the optimized feature subset can be used to subset the task and fit the model on all observations:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb175"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_pen</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">tsk_pen</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="va">instance</span><span class="op">$</span><span class="va">result_feature_set</span><span class="op">)</span></span>
<span><span class="va">lrn_rpart</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_pen</span><span class="op">)</span></span></code></pre></div>
</div>
</section><section id="sec-multicrit-featsel" class="level3" data-number="6.2.5"><h3 data-number="6.2.5">
<span class="header-section-number">6.2.5</span> Optimizing Multiple Performance Measures</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb176"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3fselect.mlr-org.com/reference/fsi.html">fsi</a></span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">lrn_rpart</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"holdout"</span><span class="op">)</span>,</span>
<span>  measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.tpr"</span>, <span class="st">"classif.tnr"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"evals"</span>, n_evals <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb177"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fselector</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3fselect.mlr-org.com/reference/fs.html">fs</a></span><span class="op">(</span><span class="st">"random_search"</span><span class="op">)</span></span>
<span><span class="va">fselector</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Note that these two measures cannot both be optimal at the same time (except for the perfect classifier) and we expect several Pareto-optimal solutions.</p>
<blockquote>
<p>请注意，这两个指标在同一时间不能都达到最优（除了完美的分类器），我们期望会有多个帕累托最优解。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb178"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># access the best feature subsets</span></span>
<span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">instance</span><span class="op">$</span><span class="va">result</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">features</span>, <span class="va">classif.tpr</span>, <span class="va">classif.tnr</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;                       features classif.tpr classif.tnr</span></span>
<span><span class="co">#&gt; 1: V10,V14,V17,V18,V19,V28,...   0.8888889   0.6363636</span></span>
<span><span class="co">#&gt; 2:  V1,V10,V11,V13,V14,V15,...   0.7500000   0.7272727</span></span>
<span><span class="co">#&gt; 3:  V1,V10,V11,V12,V13,V14,...   0.8055556   0.6969697</span></span>
<span><span class="co">#&gt; 4:  V11,V20,V25,V26,V27,V3,...   0.6388889   0.7878788</span></span>
<span><span class="co">#&gt; 5:  V1,V10,V11,V12,V13,V14,...   0.7500000   0.7272727</span></span>
<span><span class="co">#&gt; 6:  V1,V10,V11,V12,V13,V14,...   0.7500000   0.7272727</span></span>
<span><span class="co">#&gt; 7:  V1,V10,V11,V13,V14,V15,...   0.8055556   0.6969697</span></span></code></pre></div>
</div>
<p>We see different tradeoffs of sensitivity and specificity but no feature subset is dominated by another, i.e. has worse sensitivity and specificity than any other subset.</p>
<blockquote>
<p>我们看到了不同灵敏度和特异性的权衡，但没有任何特征子集被另一个支配，即没有任何子集的灵敏度和特异性都比其他子集差。</p>
</blockquote>
</section><section id="nested-resampling" class="level3" data-number="6.2.6"><h3 data-number="6.2.6">
<span class="header-section-number">6.2.6</span> Nested Resampling</h3>
<p>As in tuning, the performance estimate of the finally selected feature subset is usually optimistically biased. To obtain unbiased performance estimates, nested resampling is required and can be set up analogously to HPO (see <a href="#sec-nested-resampling">Section 4.3</a>). We now show this as an example on the <code>sonar</code> task. The <code>AutoFSelector</code> class wraps a learner and augments it with automatic feature selection. Because the <code>AutoFSelector</code> itself inherits from the <code>Learner</code> base class, it can be used like any other learner. In the example below, a logistic regression learner is created. This learner is then wrapped in a random search feature selector that uses holdout (inner) resampling for performance evaluation. The sugar function <code>auto_fselector</code> can be used to create an instance of <code>AutoFSelector</code>:</p>
<blockquote>
<p>与调优中一样，最终选择的特征子集的性能估计通常是乐观偏倚的。为了获得无偏的性能估计，需要进行嵌套重抽样，并且可以类似于HPO进行设置（请参见 <a href="#sec-nested-resampling">Section 4.3</a>）。下面的例子中，我们展示了在声纳任务上使用嵌套重抽样的示例。<code>AutoFSelector</code>类将学习器封装，并增加了自动特征选择功能。因为<code>AutoFSelector</code>本身继承自<code>Learner</code>基类，所以它可以像其他学习器一样使用。在下面的例子中，我们创建了一个逻辑回归学习器。然后，将该学习器包装在一个使用留出法（内部）重抽样进行性能评估的随机搜索特征选择器中。<code>auto_fselector</code>函数可以用来创建<code>AutoFSelector</code>的实例：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb179"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">afs</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3fselect.mlr-org.com/reference/auto_fselector.html">auto_fselector</a></span><span class="op">(</span></span>
<span>  fselector <span class="op">=</span> <span class="fu"><a href="https://mlr3fselect.mlr-org.com/reference/fs.html">fs</a></span><span class="op">(</span><span class="st">"random_search"</span><span class="op">)</span>,</span>
<span>  learner <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.log_reg"</span><span class="op">)</span>,</span>
<span>  resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"holdout"</span><span class="op">)</span>,</span>
<span>  measure <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html">trm</a></span><span class="op">(</span><span class="st">"evals"</span>, n_evals <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">afs</span></span>
<span><span class="co">#&gt; &lt;AutoFSelector:classif.log_reg.fselector&gt;</span></span>
<span><span class="co">#&gt; * Model: list</span></span>
<span><span class="co">#&gt; * Packages: mlr3, mlr3fselect, mlr3learners, stats</span></span>
<span><span class="co">#&gt; * Predict Type: response</span></span>
<span><span class="co">#&gt; * Feature Types: logical, integer, numeric, character, factor, ordered</span></span>
<span><span class="co">#&gt; * Properties: loglik, twoclass</span></span></code></pre></div>
</div>
<p>The <code>AutoFSelector</code> can then be passed to <code><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark()</a></code> or <code><a href="https://mlr3.mlr-org.com/reference/resample.html">resample()</a></code> for nested resampling (<a href="#sec-nested-resampling">Section 4.3</a>). Below we compare our wrapped learner <code>afs</code> with a normal logistic regression <code>lrn("classif.log_reg")</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb180"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">grid</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">afs</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.log_reg"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                      <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">grid</span><span class="op">)</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb181"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">bmr</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">classif.acc</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;                   learner_id classif.acc</span></span>
<span><span class="co">#&gt; 1: classif.log_reg.fselector   0.7363009</span></span>
<span><span class="co">#&gt; 2:           classif.log_reg   0.6537612</span></span></code></pre></div>
</div>
<p>We can see that, in this example, the feature selection improves prediction performance.</p>
</section></section></section><section id="pipelines-and-preprocessing" class="level1 unnumbered"><h1 class="unnumbered">Pipelines and Preprocessing</h1>
</section><section id="sequential-pipelines" class="level1" data-number="7"><h1 data-number="7">
<span class="header-section-number">7</span> Sequential Pipelines</h1>
<p><code>mlr3</code> aims to provide a layer of abstraction for ML practitioners, allowing users to quickly swap one algorithm for another without needing expert knowledge of the underlying implementation. A unified interface for <code>Task</code>, <code>Learner</code>, and <code>Measure</code> objects means that complex benchmark and tuning experiments can be run in just a few lines of code for any off-the-shelf model, i.e., if you just want to run an experiment using the basic implementation from the underlying algorithm, we hope we have made this easy for you to do.</p>
<p><code>mlr3pipelines</code> (Binder et al. 2021) takes this modularity one step further, extending it to workflows that may also include data preprocessing (<a href="#sec-preprocessing">Chapter 9</a>), building ensemble-models, or even more complicated meta-models. mlr3pipelines makes it possible to build individual steps within a <code>Learner</code> out of building blocks, which inherit from the <code>PipeOp</code> class. <code>PipeOps</code> can be connected using directed edges to form a <code>Graph</code> or ‘pipeline’, which represent the flow of data between operations. During model training, the <code>PipeOps</code> in a <code>Graph</code> transform a given Task and subsequent <code>PipeOps</code> receive the transformed <code>Task</code> as input. As well as transforming data, <code>PipeOps</code> generate a state, which is used to inform the <code>PipeOps</code> operation during prediction, similar to how learners learn and store model parameters/weights during training that go on to inform model prediction.</p>
<blockquote>
<p><code>mlr3</code>旨在为机器学习从业者提供一个抽象层，使用户能够快速替换一个算法为另一个算法，而无需了解底层实现的专业知识。统一的<code>Task</code>（任务）、<code>Learner</code>（学习器）和<code>Measure</code>（度量）对象接口意味着，可以使用极少的代码行数运行任何现成模型的复杂基准和调优实验，即，如果你只想使用底层算法的基本实现来运行一个实验，我们希望我们已经让这变得容易了。</p>
<p><code>mlr3pipelines</code>（Binder等人，2021年）将这种模块化推进了一步，将其扩展到可能还包括数据预处理（<a href="#sec-preprocessing">Chapter 9</a>）、构建集成模型，甚至更复杂的元模型的工作流中。<code>mlr3pipelines</code>使得可以用继承自<code>PipeOp</code>类的构建块构建<code>Learner</code>内部的各个步骤。<code>PipeOps</code>可以使用有向边连接，形成一个<code>Graph</code>（图）或“管道”，它表示操作之间的数据流。在模型训练期间，<code>Graph</code>中的<code>PipeOps</code>会转换给定的<code>Task</code>，随后的<code>PipeOps</code>以转换后的<code>Task</code>作为输入。除了转换数据外，<code>PipeOps</code>还生成一个状态，用于在预测期间通知<code>PipeOps</code>的操作，类似于学习器在训练期间学习和存储模型参数/权重，然后用于模型预测。</p>
</blockquote>
<section id="pipeop-pipeline-operators" class="level2" data-number="7.1"><h2 data-number="7.1">
<span class="header-section-number">7.1</span> PipeOp: Pipeline Operators</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb182"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span></span>
<span><span class="co">#&gt;               key                                      label</span></span>
<span><span class="co">#&gt; 1:         boxcox Box-Cox Transformation of Numeric Features</span></span>
<span><span class="co">#&gt; 2:         branch                             Path Branching</span></span>
<span><span class="co">#&gt; 3:          chunk          Chunk Input into Multiple Outputs</span></span>
<span><span class="co">#&gt; 4: classbalancing                            Class Balancing</span></span>
<span><span class="co">#&gt; 5:     classifavg                   Majority Vote Prediction</span></span>
<span><span class="co">#&gt; 6:   classweights         Class Weights for Sample Weighting</span></span></code></pre></div>
</div>
<p>Let us now take a look at a <code>PipeOp</code> in practice using principal component analysis (PCA) as an example, which is implemented in <code>PipeOpPCA</code>. Below we construct the <code>PipeOp</code> using its ID <code>"pca"</code> and inspect it.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb183"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">po_pca</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"pca"</span>, center <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">po_pca</span></span>
<span><span class="co">#&gt; PipeOp: &lt;pca&gt; (not trained)</span></span>
<span><span class="co">#&gt; values: &lt;center=TRUE&gt;</span></span>
<span><span class="co">#&gt; Input channels &lt;name [train type, predict type]&gt;:</span></span>
<span><span class="co">#&gt;   input [Task,Task]</span></span>
<span><span class="co">#&gt; Output channels &lt;name [train type, predict type]&gt;:</span></span>
<span><span class="co">#&gt;   output [Task,Task]</span></span></code></pre></div>
</div>
<p>A <code>PipeOp</code> can be trained using <code>$train()</code>, which can have multiple inputs and outputs. Both inputs and outputs are passed as elements in a single <code>list</code>. The <code>"pca"</code> <code>PipeOp</code> takes as input the original task and after training returns the task with features replaced by their principal components.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb184"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_small</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins_simple"</span><span class="op">)</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"bill_depth"</span>, <span class="st">"bill_length"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">poin</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">tsk_small</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">poout</span> <span class="op">=</span> <span class="va">po_pca</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">poin</span><span class="op">)</span>  <span class="co"># poin: Task in a list</span></span>
<span><span class="va">poout</span>  <span class="co"># list with a single element 'output'</span></span>
<span><span class="co">#&gt; $output</span></span>
<span><span class="co">#&gt; &lt;TaskClassif:penguins&gt; (5 x 3): Simplified Palmer Penguins</span></span>
<span><span class="co">#&gt; * Target: species</span></span>
<span><span class="co">#&gt; * Properties: multiclass</span></span>
<span><span class="co">#&gt; * Features (2):</span></span>
<span><span class="co">#&gt;   - dbl (2): PC1, PC2</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb185"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">poout</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">head</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;    species        PC1          PC2</span></span>
<span><span class="co">#&gt; 1:  Adelie  0.1561004  0.005716376</span></span>
<span><span class="co">#&gt; 2:  Adelie  1.2676891  0.789534280</span></span>
<span><span class="co">#&gt; 3:  Adelie  1.5336113 -0.174460208</span></span>
<span><span class="co">#&gt; 4:  Adelie -2.1096077  0.998977117</span></span>
<span><span class="co">#&gt; 5:  Adelie -0.8477930 -1.619767566</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb186"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">po_pca</span><span class="op">$</span><span class="va">state</span></span>
<span><span class="co">#&gt; Standard deviations (1, .., p=2):</span></span>
<span><span class="co">#&gt; [1] 1.512660 1.033856</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Rotation (n x k) = (2 x 2):</span></span>
<span><span class="co">#&gt;                    PC1        PC2</span></span>
<span><span class="co">#&gt; bill_depth  -0.6116423 -0.7911345</span></span>
<span><span class="co">#&gt; bill_length  0.7911345 -0.6116423</span></span></code></pre></div>
</div>
<p>Once trained, the <code>$predict()</code> function can then access the saved state to operate on the test data, which again is passed as a <code>list</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb187"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_onepenguin</span> <span class="op">=</span> <span class="va">tsk_small</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">poin</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">tsk_onepenguin</span><span class="op">)</span></span>
<span><span class="va">poout</span> <span class="op">=</span> <span class="va">po_pca</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">poin</span><span class="op">)</span></span>
<span><span class="va">poout</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;    species      PC1       PC2</span></span>
<span><span class="co">#&gt; 1:  Adelie 1.554877 -1.454908</span></span></code></pre></div>
</div>
</section><section id="graph-networks-of-popeops" class="level2" data-number="7.2"><h2 data-number="7.2">
<span class="header-section-number">7.2</span> Graph: Networks of PopeOps</h2>
<p><code>PipeOps</code> represent individual computational steps in machine learning pipelines. These pipelines themselves are defined by <code>Graph</code> objects. A <code>Graph</code> is a collection of <code>PipeOps</code> with “edges” that guide the flow of data.</p>
<p>The most convenient way of building a <code>Graph</code> is to connect a sequence of <code>PipeOps</code> using the <code>%&gt;&gt;%</code>-operator (read “double-arrow”) operator. When given two <code>PipeOp</code>s, this operator creates a <code>Graph</code> that first executes the left-hand <code>PipeOp</code>, followed by the right-hand one. It can also be used to connect a <code>Graph</code> with a <code>PipeOp</code>, or with another Graph. The following example uses <code>po("mutate")</code> to add a new feature to the task, and <code>po("scale")</code> to then scale and center all numeric features.</p>
<blockquote>
<p><code>PipeOps</code>代表机器学习管道中的单个计算步骤。这些管道本身由<code>Graph</code>对象定义。<code>Graph</code>是一个包含<code>PipeOps</code>的集合，其“边”指导着数据的流动。</p>
<p>构建<code>Graph</code>的最方便的方法是使用<code>%&gt;&gt;%</code>（读作“双箭头”）操作符连接一系列<code>PipeOps</code>。当给定两个<code>PipeOp</code>时，此操作符创建一个<code>Graph</code>，首先执行左侧的<code>PipeOp</code>，然后执行右侧的。它也可以用于将<code>Graph</code>与<code>PipeOp</code>或另一个<code>Graph</code>连接。以下示例使用<code>po("mutate")</code>将一个新特征添加到任务，然后使用<code>po("scale")</code>对所有数值特征进行缩放和居中处理。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb188"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">po_mutate</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span></span>
<span>  <span class="st">"mutate"</span>,</span>
<span>  mutation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>bill_ratio <span class="op">=</span> <span class="op">~</span> <span class="va">bill_length</span> <span class="op">/</span> <span class="va">bill_depth</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">po_scale</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"scale"</span><span class="op">)</span></span>
<span><span class="va">graph</span> <span class="op">=</span> <span class="va">po_mutate</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="va">po_scale</span></span>
<span><span class="va">graph</span></span>
<span><span class="co">#&gt; Graph with 2 PipeOps:</span></span>
<span><span class="co">#&gt;      ID         State sccssors prdcssors</span></span>
<span><span class="co">#&gt;  mutate &lt;&lt;UNTRAINED&gt;&gt;    scale          </span></span>
<span><span class="co">#&gt;   scale &lt;&lt;UNTRAINED&gt;&gt;             mutate</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb189"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>horizontal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-194-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb190"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph</span><span class="op">$</span><span class="va">pipeops</span></span>
<span><span class="co">#&gt; $mutate</span></span>
<span><span class="co">#&gt; PipeOp: &lt;mutate&gt; (not trained)</span></span>
<span><span class="co">#&gt; values: &lt;mutation=&lt;list&gt;, delete_originals=FALSE&gt;</span></span>
<span><span class="co">#&gt; Input channels &lt;name [train type, predict type]&gt;:</span></span>
<span><span class="co">#&gt;   input [Task,Task]</span></span>
<span><span class="co">#&gt; Output channels &lt;name [train type, predict type]&gt;:</span></span>
<span><span class="co">#&gt;   output [Task,Task]</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $scale</span></span>
<span><span class="co">#&gt; PipeOp: &lt;scale&gt; (not trained)</span></span>
<span><span class="co">#&gt; values: &lt;robust=FALSE&gt;</span></span>
<span><span class="co">#&gt; Input channels &lt;name [train type, predict type]&gt;:</span></span>
<span><span class="co">#&gt;   input [Task,Task]</span></span>
<span><span class="co">#&gt; Output channels &lt;name [train type, predict type]&gt;:</span></span>
<span><span class="co">#&gt;   output [Task,Task]</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb191"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph</span><span class="op">$</span><span class="va">edges</span></span>
<span><span class="co">#&gt;    src_id src_channel dst_id dst_channel</span></span>
<span><span class="co">#&gt; 1: mutate      output  scale       input</span></span></code></pre></div>
</div>
<p>Instead of using <code>%&gt;&gt;%</code>, you can also create a <code>Graph</code> explicitly using the <code>$add_pipeop()</code> and <code>$add_edge()</code> methods to create <code>PipeOps</code> and the edges connecting them:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb192"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph</span> <span class="op">=</span> <span class="va"><a href="https://mlr3pipelines.mlr-org.com/reference/Graph.html">Graph</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">add_pipeop</span><span class="op">(</span><span class="va">po_mutate</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">add_pipeop</span><span class="op">(</span><span class="va">po_scale</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">add_edge</span><span class="op">(</span><span class="st">"mutate"</span>, <span class="st">"scale"</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Once built, a <code>Graph</code> can be used by calling <code>$train()</code> and <code>$predict()</code> as if it were a <code>Learner</code> (though it still outputs a <code>list</code> during training and prediction):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb193"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">=</span> <span class="va">graph</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_small</span><span class="op">)</span></span>
<span><span class="va">result</span></span>
<span><span class="co">#&gt; $scale.output</span></span>
<span><span class="co">#&gt; &lt;TaskClassif:penguins&gt; (333 x 4): Simplified Palmer Penguins</span></span>
<span><span class="co">#&gt; * Target: species</span></span>
<span><span class="co">#&gt; * Properties: multiclass</span></span>
<span><span class="co">#&gt; * Features (3):</span></span>
<span><span class="co">#&gt;   - dbl (3): bill_depth, bill_length, bill_ratio</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb194"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span>
<span><span class="co">#&gt;    species bill_depth bill_length bill_ratio</span></span>
<span><span class="co">#&gt; 1:  Adelie  0.7795590  -0.8946955 -1.0421499</span></span>
<span><span class="co">#&gt; 2:  Adelie  0.1194043  -0.8215515 -0.6804365</span></span>
<span><span class="co">#&gt; 3:  Adelie  0.4240910  -0.6752636 -0.7434640</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb195"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span> <span class="op">=</span> <span class="va">graph</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_onepenguin</span><span class="op">)</span></span>
<span><span class="va">result</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">head</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;    species bill_depth bill_length bill_ratio</span></span>
<span><span class="co">#&gt; 1:  Adelie  0.9319023  -0.5289757 -0.8963212</span></span></code></pre></div>
</div>
</section><section id="sequential-learner-pipelines" class="level2" data-number="7.3"><h2 data-number="7.3">
<span class="header-section-number">7.3</span> Sequential Learner-Pipelines</h2>
<p>Possibly the most common application for <code>mlr3pipelines</code> is to use it to perform preprocessing tasks, such as missing value imputation or factor encoding, and to then feed the resulting data into a <code>Learner</code> – we will see more of this in practice in <a href="#sec-preprocessing">Chapter 9</a>. A <code>Graph</code> representing this workflow manipulates data and fits a <code>Learner</code>-model during training, ensuring that the data is processed the same way during the prediction stage. Conceptually, the process may look as shown in Figure 7.3.</p>
<blockquote>
<p><code>mlr3pipelines</code>可能最常见的应用之一是用它来执行预处理任务，比如缺失值填充或因子编码，然后将处理后的数据输入到一个学习器中 - 我们将在 <a href="#sec-preprocessing">Chapter 9</a> 的实践中更多地了解到这方面的内容。代表这种工作流程的图形在训练期间操作数据并拟合学习器模型，确保数据在预测阶段以相同的方式被处理。</p>
</blockquote>
<section id="learners-as-pipeops-and-graphs-as-learners" class="level3" data-number="7.3.1"><h3 data-number="7.3.1">
<span class="header-section-number">7.3.1</span> Learners as PipeOps and Graphs as Learners</h3>
<p><code>Learner</code> objects can be converted to <code>PipeOps</code> with <code><a href="https://mlr3pipelines.mlr-org.com/reference/as_pipeop.html">as_pipeop()</a></code>, however, this is only necessary if you choose to manually create a graph instead of using <code>%&gt;&gt;%</code>. With either method, internally Learners are passed to <code>po("learner")</code>. The following code creates a <code>Graph</code> that uses <code>po("imputesample")</code> to impute missing values by sampling from observed values (<a href="#sec-preprocessing-missing">Section 9.3</a>) then fits a logistic regression on the transformed task.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb196"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_logreg</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.log_reg"</span><span class="op">)</span></span>
<span><span class="va">graph</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"imputesample"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="va">lrn_logreg</span></span>
<span><span class="va">graph</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>horizontal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-201-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>We have seen how training and predicting <code>Graphs</code> is possible but has a slightly different design to <code>Learner</code> objects, i.e., inputs and outputs during both training and predicting are <code>list</code> objects. To use a <code>Graph</code> as a <code>Learner</code> with an identical interface, it can be wrapped in a <code>GraphLearner</code> object with <code><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner()</a></code>. The <code>Graph</code> can then be used like any other <code>Learner</code>, so now we can benchmark our pipeline to decide if we should impute by sampling or with the mode of observed values (<code>po("imputemode")</code>):</p>
<blockquote>
<p>我们已经看到，训练和预测<code>图（Graphs）</code>是可能的，但与<code>学习器（Learner）</code>对象相比，设计略有不同，即在训练和预测过程中，输入和输出都是<code>列表（list）</code>对象。要将<code>图（Graph）</code>作为具有相同接口的<code>学习器（Learner）</code>使用，可以使用<code><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner()</a></code>将其封装为<code>图学习器（GraphLearner）</code>对象。然后，该<code>图（Graph）</code>就可以像任何其他<code>学习器（Learner）</code>一样使用，因此现在我们可以对我们的管道进行基准测试，以决定是使用从观察到的值中抽样填补还是使用观察到的值的模式进行填补（<code>po("imputemode")</code>）：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb197"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_sample</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">graph</span><span class="op">)</span></span>
<span><span class="va">glrn_mode</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"imputemode"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="va">lrn_logreg</span><span class="op">)</span></span>
<span></span>
<span><span class="va">design</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"pima"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">glrn_sample</span>, <span class="va">glrn_mode</span><span class="op">)</span>,</span>
<span>                        <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb198"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;                      learner_id classif.ce</span></span>
<span><span class="co">#&gt; 1: imputesample.classif.log_reg  0.2395833</span></span>
<span><span class="co">#&gt; 2:   imputemode.classif.log_reg  0.2408854</span></span></code></pre></div>
</div>
</section><section id="inspecting-graphs" class="level3" data-number="7.3.2"><h3 data-number="7.3.2">
<span class="header-section-number">7.3.2</span> Inspecting Graphs</h3>
<p>You may want to inspect pipelines and the flow of data to learn more about your pipeline or to debug them. We first need to set the <code>$keep_results</code> flag to be <code>TRUE</code> so that intermediate results are retained, which is turned off by default to save memory.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb199"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_sample</span><span class="op">$</span><span class="va">graph_model</span><span class="op">$</span><span class="va">keep_results</span> <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="va">glrn_sample</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"pima"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">imputesample_output</span> <span class="op">=</span> <span class="va">glrn_sample</span><span class="op">$</span><span class="va">graph_model</span><span class="op">$</span><span class="va">pipeops</span><span class="op">$</span><span class="va">imputesample</span><span class="op">$</span><span class="va">.result</span></span>
<span><span class="va">imputesample_output</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">missings</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; diabetes      age pedigree pregnant  glucose  insulin     mass pressure </span></span>
<span><span class="co">#&gt;        0        0        0        0        0        0        0        0 </span></span>
<span><span class="co">#&gt;  triceps </span></span>
<span><span class="co">#&gt;        0</span></span></code></pre></div>
</div>
</section><section id="configuring-pipeline-hyperparameters" class="level3" data-number="7.3.3"><h3 data-number="7.3.3">
<span class="header-section-number">7.3.3</span> Configuring Pipeline Hyperparameters</h3>
<p><code>PipeOp</code> hyperparameters are collected together in the <code>$param_set</code> of a graph and prefixed with the ID of the <code>PipeOp</code> to avoid parameter name clashes. Below we use the same <code>PipeOp</code> twice but set the <code>id</code> to ensure their IDs are unique.</p>
<blockquote>
<p>管道操作（PipeOp）的超参数被集中存储在图的<code>$param_set</code>中，并且在名称前加上管道操作的ID，以避免参数名称冲突。在下面的例子中，我们使用相同的管道操作两次，但设置了ID以确保它们的ID是唯一的。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb200"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"scale"</span>, center <span class="op">=</span> <span class="cn">FALSE</span>, scale <span class="op">=</span> <span class="cn">TRUE</span>, id <span class="op">=</span> <span class="st">"scale"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"scale"</span>, center <span class="op">=</span> <span class="cn">TRUE</span>, scale <span class="op">=</span> <span class="cn">FALSE</span>, id <span class="op">=</span> <span class="st">"center"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, cp <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">graph</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">)</span></span>
<span><span class="co">#&gt;       scale.robust       scale.center        scale.scale      center.robust </span></span>
<span><span class="co">#&gt;                  0                  0                  1                  0 </span></span>
<span><span class="co">#&gt;      center.center       center.scale classif.rpart.xval   classif.rpart.cp </span></span>
<span><span class="co">#&gt;                  1                  0                  0                  1</span></span></code></pre></div>
</div>
<p>Whether a pipeline is treated as a <code>Graph</code> or <code>GraphLearner</code>, hyperparameters are updated and accessed in the same way.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb201"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">classif.rpart.maxdepth</span> <span class="op">=</span> <span class="fl">5</span></span>
<span><span class="va">graph_learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">graph</span><span class="op">)</span></span>
<span><span class="va">graph_learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">classif.rpart.minsplit</span> <span class="op">=</span> <span class="fl">2</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">graph_learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">)</span></span>
<span><span class="co">#&gt;           scale.center            scale.scale           scale.robust </span></span>
<span><span class="co">#&gt;                      0                      1                      0 </span></span>
<span><span class="co">#&gt;          center.center           center.scale          center.robust </span></span>
<span><span class="co">#&gt;                      1                      0                      0 </span></span>
<span><span class="co">#&gt;       classif.rpart.cp classif.rpart.maxdepth classif.rpart.minsplit </span></span>
<span><span class="co">#&gt;                      1                      5                      2 </span></span>
<span><span class="co">#&gt;     classif.rpart.xval </span></span>
<span><span class="co">#&gt;                      0</span></span></code></pre></div>
</div>
</section></section></section><section id="non-sequential-pipelines-and-tuning" class="level1" data-number="8"><h1 data-number="8">
<span class="header-section-number">8</span> Non-sequential Pipelines and Tuning</h1>
<p>By using the <code><a href="https://mlr3pipelines.mlr-org.com/reference/gunion.html">gunion()</a></code> function, we can instead combine multiple <code>PipeOps</code>, <code>Graphs</code>, or a mixture of both, into a parallel <code>Graph</code>.</p>
<p>In the following example, we create a <code>Graph</code> that centers its inputs (<code>po("scale")</code>) and then copies the centered data to two parallel streams: one replaces the data with columns that indicate whether data is missing (<code>po("missind")</code>), and the other imputes missing data using the median (<code>po("imputemedian")</code>), which we will return to in <a href="#sec-preprocessing-missing">Section 9.3</a>. The outputs of both streams are then combined into a single dataset using <code>po("featureunion")</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb202"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"scale"</span>, center <span class="op">=</span> <span class="cn">TRUE</span>, scale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/gunion.html">gunion</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"missind"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"imputemedian"</span><span class="op">)</span></span>
<span>  <span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"featureunion"</span><span class="op">)</span></span>
<span><span class="fl">1</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="va">graph</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>horizontal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-207-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>When applied to the first three rows of the <code>"pima"</code> task we can see how this imputes missing data and adds a column indicating where values were missing.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb203"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_pima_head</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"pima"</span><span class="op">)</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">tsk_pima_head</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span>cols <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"diabetes"</span>, <span class="st">"insulin"</span>, <span class="st">"triceps"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;    diabetes insulin triceps</span></span>
<span><span class="co">#&gt; 1:      pos      NA      35</span></span>
<span><span class="co">#&gt; 2:      neg      NA      29</span></span>
<span><span class="co">#&gt; 3:      pos      NA      NA</span></span>
<span><span class="va">result</span> <span class="op">=</span> <span class="va">graph</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_pima_head</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">result</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span>cols <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"diabetes"</span>, <span class="st">"insulin"</span>, <span class="st">"missing_insulin"</span>, <span class="st">"triceps"</span>, <span class="st">"missing_triceps"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;    diabetes insulin missing_insulin triceps missing_triceps</span></span>
<span><span class="co">#&gt; 1:      pos       0         missing       3         present</span></span>
<span><span class="co">#&gt; 2:      neg       0         missing      -3         present</span></span>
<span><span class="co">#&gt; 3:      pos       0         missing       0         missing</span></span></code></pre></div>
</div>
<section id="selectors-and-parallel-pipelines" class="level2" data-number="8.1"><h2 data-number="8.1">
<span class="header-section-number">8.1</span> Selectors and Parallel Pipelines</h2>
<p>It is common in <code>Graphs</code> for an operation to be applied to a subset of features. In <code>mlr3pipelines</code> this can be achieved in two ways: either by passing the column subset to the <code>affect_columns</code> hyperparameter of a <code>PipeOp</code> (assuming it has that hyperparameter), which controls which columns should be affected by the <code>PipeOp</code>; or, one can use the <code>PipeOpSelect</code> operator to create operations in parallel on specified feature subsets, and then unite the result using <code>PipeOpFeatureUnion</code>.</p>
<blockquote>
<p>在<code>图（Graphs）</code>中，常常会对特征的子集应用操作。在<code>mlr3pipelines</code>中，可以通过两种方式实现这一点：一种方式是将列子集传递给<code>PipeOp</code>的<code>affect_columns</code>超参数（假设该超参数存在），它控制哪些列应该受到<code>PipeOp</code>的影响；另一种方式是使用<code>PipeOpSelect</code>运算符，针对指定的特征子集并行创建操作，然后使用<code>PipeOpFeatureUnion</code>将结果合并。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb204"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sel_bill</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/Selector.html">selector_grep</a></span><span class="op">(</span><span class="st">"^bill"</span><span class="op">)</span></span>
<span><span class="va">sel_not_bill</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/Selector.html">selector_invert</a></span><span class="op">(</span><span class="va">sel_bill</span><span class="op">)</span></span>
<span></span>
<span><span class="va">graph</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"scale"</span>, affect_columns <span class="op">=</span> <span class="va">sel_not_bill</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"pca"</span>, affect_columns <span class="op">=</span> <span class="va">sel_bill</span><span class="op">)</span></span>
<span></span>
<span><span class="va">result</span> <span class="op">=</span> <span class="va">graph</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins_simple"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">result</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span>
<span><span class="co">#&gt;    species       PC1        PC2  body_mass flipper_length</span></span>
<span><span class="co">#&gt; 1:  Adelie -5.014734  1.0716828 -0.5676206     -1.4246077</span></span>
<span><span class="co">#&gt; 2:  Adelie -4.495124 -0.1852998 -0.5055254     -1.0678666</span></span>
<span><span class="co">#&gt; 3:  Adelie -3.754628  0.4867612 -1.1885721     -0.4257325</span></span></code></pre></div>
</div>
<p>The biggest advantage of this method is that it creates a very simple, sequential <code>Graph</code>. However, one disadvantage of the <code>affect_columns</code> method is that it is relatively easy to have unexpected results if the ordering of <code>PipeOps</code> is mixed up. For example, if we had reversed the order of <code>po("pca")</code> and <code>po("scale")</code> above then we would have first created columns <code>"PC1"</code> and <code>"PC2"</code> and then erroneously scaled these, since their names do not start with “bill” and they are therefore matched by <code>sel_not_bill</code>. Creating parallel paths with <code>po("select")</code> can help mitigate such errors by selecting features given by the Selector and creating independent data processing streams with the given feature subset. Below we pass the parallel pipelines to <code><a href="https://mlr3pipelines.mlr-org.com/reference/gunion.html">gunion()</a></code> as a list to ensure they receive the same input, and then combine the outputs with <code>po("featureunion")</code>.</p>
<blockquote>
<p>这种方法的最大优势在于它创建了一个非常简单、顺序的图形结构。然而，<code>affect_columns</code> 方法的一个缺点是，如果 PipeOps 的顺序混乱，很容易产生意外的结果。例如，如果我们在上述例子中颠倒了 <code>po("pca")</code> 和 <code>po("scale")</code> 的顺序，那么我们首先会创建 <code>"PC1"</code> 和 <code>"PC2"</code> 这两列，然后错误地对它们进行了缩放，因为它们的列名不以 “bill” 开头，所以被 <code>sel_not_bill</code> 匹配到了。使用 <code>po("select")</code> 创建并行路径可以帮助减轻此类错误，它根据选择器给定的特征选择功能，并使用给定的特征子集创建独立的数据处理流。在下面的例子中，我们将并行流程以列表形式传递给 <code><a href="https://mlr3pipelines.mlr-org.com/reference/gunion.html">gunion()</a></code> 以确保它们接收相同的输入，然后使用 <code>po("featureunion")</code> 组合它们的输出结果。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb205"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">po_select_bill</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"select"</span>, id <span class="op">=</span> <span class="st">"s_bill"</span>, selector <span class="op">=</span> <span class="va">sel_bill</span><span class="op">)</span></span>
<span><span class="va">po_select_not_bill</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"select"</span>, id <span class="op">=</span> <span class="st">"s_notbill"</span>, selector <span class="op">=</span> <span class="va">sel_not_bill</span><span class="op">)</span></span>
<span></span>
<span><span class="va">path_pca</span> <span class="op">=</span> <span class="va">po_select_bill</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"pca"</span><span class="op">)</span></span>
<span><span class="va">path_scale</span> <span class="op">=</span> <span class="va">po_select_not_bill</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"scale"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">graph</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/gunion.html">gunion</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">path_pca</span>, <span class="va">path_scale</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"featureunion"</span><span class="op">)</span></span>
<span><span class="va">graph</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>horizontal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-210-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>The <code>po("select")</code> method also has the significant advantage that it allows the same set of features to be used in multiple operations simultaneously, or to both transform features and keep their untransformed versions (by using <code>po("nop")</code> in one path). <code>PipeOpNOP</code> performs no operation on its inputs and is thus useful when you only want to perform a transformation on a subset of features and leave the others untouched:</p>
<blockquote>
<p><code>po("select")</code> 方法的另一个重要优势是，它允许同时在多个操作中使用相同的特征集，或者在进行特征转换的同时保留它们的未转换版本（通过在其中一个路径中使用 <code>po("nop")</code>）。<code>PipeOpNOP</code> 在其输入上不执行任何操作，因此当你只想对某些特征子集进行转换而保持其他特征不变时，它非常有用：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb206"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/gunion.html">gunion</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="va">po_select_bill</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"scale"</span><span class="op">)</span>,</span>
<span>  <span class="va">po_select_not_bill</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"nop"</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"featureunion"</span><span class="op">)</span></span>
<span><span class="va">graph</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>horizontal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-211-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb207"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins_simple"</span><span class="op">)</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span>
<span><span class="co">#&gt;    species bill_depth bill_length body_mass flipper_length</span></span>
<span><span class="co">#&gt; 1:  Adelie  0.7795590  -0.8946955      3750            181</span></span>
<span><span class="co">#&gt; 2:  Adelie  0.1194043  -0.8215515      3800            186</span></span>
<span><span class="co">#&gt; 3:  Adelie  0.4240910  -0.6752636      3250            195</span></span></code></pre></div>
</div>
</section><section id="practical-pipelines-by-example" class="level2" data-number="8.2"><h2 data-number="8.2">
<span class="header-section-number">8.2</span> Practical Pipelines by Example</h2>
<section id="bagging-with-greplicate-and-subsample" class="level3" data-number="8.2.1"><h3 data-number="8.2.1">
<span class="header-section-number">8.2.1</span> Bagging with “greplicate” and “subsample”</h3>
<p>The basic idea of bagging (from <strong>b</strong>ootstrapp <strong>agg</strong>regat<strong>ing</strong>), introduced by Breiman (1996), is to aggregate multiple predictors into a single, more powerful predictor. Predictions are usually aggregated by the arithmetic mean for regression tasks or majority vote for classification. The underlying intuition behind bagging is that averaging a set of unstable and diverse (i.e., only weakly correlated) predictors can reduce the variance of the overall prediction. Each learner is trained on a different random sample of the original data.</p>
<p>Although we have already seen that a pre-constructed bagging pipeline is available with <code>ppl("bagging")</code>, in this section we will build our own pipeline from scratch to showcase how to construct a complex Graph, which will look something like <a href="#fig-pipelines-bagging">Figure 8.1</a>.</p>
<blockquote>
<p>装袋（bagging）的基本思想（来自<strong>b</strong>ootstrapp <strong>agg</strong>regat<strong>ing</strong>，由Breiman（1996）引入）是将多个预测器聚合成一个更强大的预测器。在回归任务中，通常通过算术平均值来聚合预测结果，而在分类任务中则采用多数投票法。装袋背后的基本直觉是，将一组不稳定且多样化的（即仅弱相关的）预测器进行平均，可以减小整体预测的方差。每个学习器都是在原始数据的不同随机样本上训练得到的。</p>
<p>尽管我们已经看到在<code>ppl("bagging")</code>中提供了一个预先构建的装袋管道，但在本节中，我们将从零开始构建我们自己的管道，以展示如何构建一个复杂的图形，类似于 <a href="#fig-pipelines-bagging">Figure 8.1</a> 所示。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-pipelines-bagging" class="quarto-figure quarto-figure-center">
<figure><p><img src="imgs/mlr3book_figures-26.svg" class="img-fluid" style="width:70.0%" alt='Graph shows "Dtrain" with arrows to four separate po("subsample") boxes that each have a separate arrow to four more po("classif.rpart") boxes that each have an arrow to the same one po("classif.avg") box.'></p>
<figcaption>Figure 8.1: Graph that performs Bagging by independently subsampling data and fitting individual decision tree learners. The resulting predictions are aggregated by a majority vote <code>PipeOp</code>.</figcaption></figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb208"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gr_single_pred</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"subsample"</span>, frac <span class="op">=</span> <span class="fl">.7</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span></span>
<span><span class="va">gr_pred_set</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/ppl.html">ppl</a></span><span class="op">(</span><span class="st">"greplicate"</span>, graph <span class="op">=</span> <span class="va">gr_single_pred</span>, n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">gr_bagging</span> <span class="op">=</span> <span class="va">gr_pred_set</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"classifavg"</span>, innum <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">gr_bagging</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-214-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Now let us see how well our bagging pipeline compares to the single decision tree and a random forest when benchmarked against <code>tsk("sonar")</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb209"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_bagging</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">gr_bagging</span><span class="op">)</span></span>
<span><span class="va">glrn_bagging</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"bagging"</span></span>
<span></span>
<span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">glrn_bagging</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.ranger"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span>, <span class="va">learners</span>,</span>
<span>                               <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb210"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;        learner_id classif.ce</span></span>
<span><span class="co">#&gt; 1:        bagging  0.2452036</span></span>
<span><span class="co">#&gt; 2:  classif.rpart  0.3360939</span></span>
<span><span class="co">#&gt; 3: classif.ranger  0.1827467</span></span></code></pre></div>
</div>
<p>To automatically recreate this pipeline, you can construct <code>ppl("bagging")</code> by specifying the learner to ‘bag’, the number of iterations, the fraction of data to sample, and the <code>PipeOp</code> to average the predictions, as shown in the code below. Note we set <code>collect_multiplicity = TRUE</code> which collects the predictions across paths, that technically use the <code>Multiplicity</code> method, which we will not discuss here but refer the reader to the documentation.</p>
<blockquote>
<p>要自动重新创建这个管道，您可以通过在代码中指定学习器为‘bag’、迭代次数、采样的数据比例以及用于平均预测的<code>PipeOp</code>来构建<code>ppl("bagging")</code>，如下所示。请注意，我们设置了<code>collect_multiplicity = TRUE</code>，这样可以在路径间收集预测结果，这实际上使用了<code>Multiplicity</code>方法，但我们在这里不会讨论详细内容，读者可以参考文档了解更多信息。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb211"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/ppl.html">ppl</a></span><span class="op">(</span><span class="st">"bagging"</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span>, iterations <span class="op">=</span> <span class="fl">10</span>, frac <span class="op">=</span> <span class="fl">0.7</span>,</span>
<span>    averager <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"classifavg"</span>, collect_multiplicity <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<p>The main difference between our pipeline and a random forest is that the latter also performs feature subsampling, where only a random subset of available features is considered at each split point. While we cannot implement this directly with <code>mlr3pipelines</code>, we can use a custom <code>Selector</code> method to approximate this method. We will create this <code>Selector</code> by passing a function that takes as input the task and returns a sample of the features, we sample the square root of the number of features to mimic the implementation in <code>ranger</code>. For efficiency, we will now use <code>ppl("bagging")</code> to recreate the steps above:</p>
<blockquote>
<p>我们的管道与随机森林之间的主要区别在于，后者还执行特征子抽样，即在每个分裂点只考虑可用特征的一个随机子集。虽然我们无法直接在<code>mlr3pipelines</code>中实现这一点，但我们可以使用自定义的选择器方法来近似这个方法。我们将通过传递一个接受任务作为输入并返回特征样本的函数来创建这个选择器。我们将对特征进行采样，采样数量为特征数量的平方根，以模仿<code>ranger</code>中的实现。为了提高效率，我们现在将使用<code>ppl("bagging")</code>来重新创建上述步骤：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb212"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># custom selector</span></span>
<span><span class="va">selector_subsample</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">task</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">task</span><span class="op">$</span><span class="va">feature_names</span>, <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">task</span><span class="op">$</span><span class="va">feature_names</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># bagging pipeline with out selector</span></span>
<span><span class="va">gr_bagging_quasi_rf</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/ppl.html">ppl</a></span><span class="op">(</span></span>
<span>  <span class="st">"bagging"</span>,</span>
<span>  graph <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"select"</span>, selector <span class="op">=</span> <span class="va">selector_subsample</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, minsplit <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>  iterations <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  averager <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"classifavg"</span>, collect_multiplicity <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># bootstrap resampling</span></span>
<span><span class="va">gr_bagging_quasi_rf</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">subsample.replace</span> <span class="op">=</span> <span class="cn">TRUE</span></span>
<span></span>
<span><span class="co"># convert to learner</span></span>
<span><span class="va">glrn_quasi_rf</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">gr_bagging_quasi_rf</span><span class="op">)</span></span>
<span><span class="va">glrn_quasi_rf</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"quasi.rf"</span></span>
<span></span>
<span><span class="co"># benchmark</span></span>
<span><span class="va">design</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsks</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span>,</span>
<span>  learners <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">glrn_quasi_rf</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.ranger"</span>, num.trees <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb213"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;        learner_id classif.ce</span></span>
<span><span class="co">#&gt; 1:       quasi.rf  0.1828107</span></span>
<span><span class="co">#&gt; 2: classif.ranger  0.1641115</span></span></code></pre></div>
</div>
<p>In only a few lines of code, we took a weaker learner and turned it into a powerful model that we can see is comparable to the implementation in <code><a href="https://rdrr.io/pkg/ranger/man/ranger.html">ranger::ranger</a></code>.</p>
</section><section id="stacking-with-polearner_cv" class="level3" data-number="8.2.2"><h3 data-number="8.2.2">
<span class="header-section-number">8.2.2</span> Stacking with <code>po(“learner_cv”)</code>
</h3>
<p>Stacking (Wolpert 1992) is another very popular ensembling technique that can significantly improve predictive performance. The basic idea behind stacking is to use predictions from multiple models (usually referred to as level 0 models) as features for a subsequent model (the level 1 model) which in turn combines these predictions (<a href="#fig-pipelines-stacking">Figure 8.2</a>). A simple combination can be a linear model (possibly regularized if you have many level 0 models), since a weighted sum of level 0 models is often plausible and good enough. Though, non-linear level 1 models can also be used, and it is also possible for the level 1 model to access the input features as well as the level 0 predictions. Stacking can be built with more than two levels (both conceptually, and in <code>mlr3</code>) but we limit ourselves to this simpler setup here, which often also performs well in practice.</p>
<p>As with bagging, we will demonstrate how to create a stacking pipeline manually, although a pre-constructed pipeline is available with <code>ppl("stacking")</code>.</p>
<blockquote>
<p>堆叠（Stacking）（Wolpert 1992）是另一种非常流行的集成技术，可以显著提高预测性能。堆叠背后的基本思想是使用来自多个模型的预测（通常称为第0级模型）作为后续模型（第1级模型）的特征，后者再结合这些预测（ <a href="#fig-pipelines-stacking">Figure 8.2</a> ）。简单的组合可以是一个线性模型（如果你有很多第0级模型，可能需要正则化），因为第0级模型的加权和通常是合理且足够好的。当然，也可以使用非线性的第1级模型，并且第1级模型还可以访问输入特征以及第0级的预测。堆叠可以建立多个级别（在概念上和在<code>mlr</code>3中都可以），但在这里我们限制自己使用这种较简单的设置，因为在实践中它通常也表现得很好。</p>
<p>与装袋类似，我们将演示如何手动创建一个堆叠管道，尽管<code>ppl("stacking")</code>中也提供了一个预先构建的管道。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-pipelines-stacking" class="quarto-figure quarto-figure-center">
<figure><p><img src="imgs/mlr3book_figures-27.svg" class="img-fluid" style="width:70.0%" alt='Graph shows "Dtrain" with arrows to three boxes: "Decision Tree", "KNN", and "Lasso Regression". Each of these points to the same "Feature Union -&gt; Logistic Regression".'></p>
<figcaption>Figure 8.2: Graph that performs Stacking by fitting three models and using their outputs as features for another model after combining with <code>PipeOpFeatureUnion</code>.</figcaption></figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb214"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">po_rparv_cv</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"learner_cv"</span>, learner <span class="op">=</span> <span class="va">lrn_rpart</span>,</span>
<span>                 resampling.folds <span class="op">=</span> <span class="fl">2</span>, id <span class="op">=</span> <span class="st">"rpart_cv"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lrn_knn</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.kknn"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">po_knn_cv</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"learner_cv"</span>, learner <span class="op">=</span> <span class="va">lrn_knn</span>,</span>
<span>               resampling.folds <span class="op">=</span> <span class="fl">2</span>, id <span class="op">=</span> <span class="st">"knn_cv"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lrn_glmnet</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.glmnet"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">po_glmnet_cv</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"learner_cv"</span>, learner <span class="op">=</span> <span class="va">lrn_glmnet</span>,</span>
<span>                  resampling.folds <span class="op">=</span> <span class="fl">2</span>, id <span class="op">=</span> <span class="st">"glmnet_cv"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">gr_level_0</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/gunion.html">gunion</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">po_rparv_cv</span>, <span class="va">po_knn_cv</span>, <span class="va">po_glmnet_cv</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">gr_combined</span> <span class="op">=</span> <span class="va">gr_level_0</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"featureunion"</span><span class="op">)</span></span></code></pre></div>
</div>
<p>The resulting task contains the predicted probabilities for both classes made from each of the level 0 learners. However, as the probabilities always add up to , we only need the predictions for one of the classes (as this is a binary classification task), so we can use <code>po("select")</code> to only keep predictions for one class (we choose <code>"M"</code> in this example).</p>
<blockquote>
<p>生成的任务包含了从第0级学习器中得到的两个类别的预测概率。然而，由于这些概率总是加起来等于1，我们只需要其中一个类别的预测结果（因为这是一个二元分类任务），所以我们可以使用<code>po("select")</code>来仅保留其中一个类别的预测（在这个示例中我们选择了<code>"M"</code>类别）。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb215"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gr_stack</span> <span class="op">=</span> <span class="va">gr_combined</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"select"</span>, selector <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/Selector.html">selector_grep</a></span><span class="op">(</span><span class="st">"\\.M$"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Finally, we can combine our pipeline with the final model that will take these predictions as its input. Below we use logistic regression, which combines the level 0 predictions in a weighted linear sum.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb216"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gr_stack</span> <span class="op">=</span> <span class="va">gr_stack</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"learner"</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.log_reg"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">gr_stack</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>horizontal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-223-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>As our final model was an interpretable logistic regression, we can inspect the weights of the level 0 learners by looking at the final trained model:</p>
<blockquote>
<p>由于我们的最终模型是一个可解释的逻辑回归模型，我们可以通过查看最终训练好的模型来检查第0级学习器的权重。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb217"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_stack</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">gr_stack</span><span class="op">)</span></span>
<span><span class="va">glrn_stack</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: Multiple lambdas have been fit. Lambda will be set to 0.01 (see parameter 's').</span></span>
<span><span class="co">#&gt; This happened PipeOp glmnet_cv's $train()</span></span>
<span></span>
<span><span class="co">#&gt; Warning: Multiple lambdas have been fit. Lambda will be set to 0.01 (see parameter 's').</span></span>
<span><span class="co">#&gt; This happened PipeOp glmnet_cv's $train()</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb218"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_stack</span><span class="op">$</span><span class="fu">base_learner</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  stats::glm(formula = task$formula(), family = "binomial", data = data, </span></span>
<span><span class="co">#&gt;     model = FALSE)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;      (Intercept)   rpart_cv.prob.M     knn_cv.prob.M  glmnet_cv.prob.M  </span></span>
<span><span class="co">#&gt;          -4.5631            2.0611            6.1736           -0.2419  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Degrees of Freedom: 207 Total (i.e. Null);  204 Residual</span></span>
<span><span class="co">#&gt; Null Deviance:       287.4 </span></span>
<span><span class="co">#&gt; Residual Deviance: 141.8     AIC: 149.8</span></span></code></pre></div>
</div>
<p>The model weights suggest that knn influences the predictions the most with the largest coefficient. To confirm this we can benchmark the individual models alongside the stacking pipeline.</p>
<blockquote>
<p>模型的权重表明，knn的影响最大，其系数最大。为了确认这一点，我们可以将单独的模型与堆叠管道进行基准测试。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb219"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_stack</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"stacking"</span></span>
<span><span class="va">design</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">lrn_rpart</span>, <span class="va">lrn_knn</span>, <span class="va">lrn_glmnet</span>, <span class="va">glrn_stack</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"repeated_cv"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
</div>
<p>This experiment confirms that of the individual models, the KNN learner performs the best, however, our stacking pipeline outperforms them all. Now that we have seen the inner workings of this pipeline, next time you might want to more efficiently create it using <code>ppl("stacking")</code>, to copy the example above you would run:</p>
<blockquote>
<p>这个实验证实了在单独的模型中，KNN学习器表现最好，但我们的堆叠管道的性能超过了它们所有。现在我们已经了解了这个管道的内部工作原理，下次您可能希望更高效地使用<code>ppl("stacking")</code>来创建它。如果要复制上述示例，您可以运行：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb220"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/ppl.html">ppl</a></span><span class="op">(</span><span class="st">"stacking"</span>,</span>
<span>    base_learners <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrns</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, <span class="st">"classif.kknn"</span>, <span class="st">"classif.glmnet"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    super_learner <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.log_reg"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Graph with 6 PipeOps:</span></span>
<span><span class="co">#&gt;                      ID         State        sccssors              prdcssors</span></span>
<span><span class="co">#&gt;  classif.rpart.class... &lt;&lt;UNTRAINED&gt;&gt;    featureunion                       </span></span>
<span><span class="co">#&gt;  classif.kknn.classi... &lt;&lt;UNTRAINED&gt;&gt;    featureunion                       </span></span>
<span><span class="co">#&gt;  classif.glmnet.clas... &lt;&lt;UNTRAINED&gt;&gt;    featureunion                       </span></span>
<span><span class="co">#&gt;                     nop &lt;&lt;UNTRAINED&gt;&gt;    featureunion                       </span></span>
<span><span class="co">#&gt;            featureunion &lt;&lt;UNTRAINED&gt;&gt; classif.log_reg classif.rpart.class...</span></span>
<span><span class="co">#&gt;         classif.log_reg &lt;&lt;UNTRAINED&gt;&gt;                           featureunion</span></span></code></pre></div>
</div>
</section></section><section id="tuning-graphs" class="level2" data-number="8.3"><h2 data-number="8.3">
<span class="header-section-number">8.3</span> Tuning Graphs</h2>
<p>By wrapping a pipeline inside a <code>GraphLearner</code>, we can tune it at two levels of complexity using <code>mlr3tuning</code>:</p>
<ol type="1">
<li><p>Tuning of a fixed, usually sequential pipeline, where preprocessing is combined with a given learner. This simply means the joint tuning of any subset of selected hyperparameters of operations in the pipeline. Conceptually and also technically in <code>mlr3</code>, this is not much different from tuning a learner that is not part of a pipeline.</p></li>
<li><p>Tuning not only the hyperparameters of a pipeline, whose structure is not completely fixed in terms of its included operations, but also which concrete <code>PipeOps</code> should be applied to data. This allows us to select these operations (e.g. which learner to use, which preprocessing to perform) in a data-driven manner known as “Combined Algorithm Selection and Hyperparameter optimization” (Thornton et al. 2013). As we will soon see, we can do this in <code>mlr3pipelines</code> by using the powerful branching and proxy meta operators. Through this, we can conveniently create our own “mini AutoML systems” (Hutter, Kotthoff, and Vanschoren 2019) in <code>mlr3</code>, which can even be geared for specific tasks.</p></li>
</ol>
<blockquote>
<p>通过将一个管道包装在<code>GraphLearner</code>内部，我们可以使用<code>mlr3tuning</code>在两个复杂度级别上进行调整：</p>
<ol type="1">
<li><p>对于一个固定的、通常是顺序执行的管道进行调整，其中预处理与指定的学习器结合在一起。这意味着对管道中操作的任意子集的超参数进行联合调整。从概念上讲，在<code>mlr3</code>中，这与调整不是管道一部分的学习器没有太大区别，技术上也是如此。</p></li>
<li><p>不仅调整管道的超参数，而且调整管道的结构在其包含的操作方面并不完全固定，还可以确定应该将哪些具体的PipeOps应用于数据。这使我们能够以一种数据驱动的方式选择这些操作（例如使用哪个学习器，进行哪种预处理），这被称为“联合算法选择和超参数优化”（Thornton等人，2013）。正如我们将很快看到的，我们可以通过使用强大的分支和代理元操作符在<code>mlr3pipelines</code>中实现这一点。通过这种方式，我们可以方便地在<code>mlr</code>3中创建我们自己的“小型AutoML系统”（Hutter、Kotthoff和Vanschoren，2019），甚至可以针对特定任务进行调整。</p></li>
</ol>
</blockquote>
<section id="tuning-graph-hyperparameters" class="level3" data-number="8.3.1"><h3 data-number="8.3.1">
<span class="header-section-number">8.3.1</span> Tuning Graph Hyperparameters</h3>
<p>The optimal setting of the <code>rank.</code> hyperparameter of our PCA <code>PipeOp</code> may realistically depend on the value of the <code>k</code> hyperparameter of the KNN model so jointly tuning them is reasonable.</p>
<blockquote>
<p>我们PCA <code>PipeOp</code>的<code>rank.</code>超参数的最佳设置可能实际上依赖于KNN模型的<code>k</code>超参数的值，因此联合调整它们是合理的。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb221"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_knn</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.kknn"</span>, k <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">32</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">po_pca</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"pca"</span>, rank. <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">graph_learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">po_pca</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="va">lrn_knn</span><span class="op">)</span></span>
<span><span class="va">graph_learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span></span>
<span><span class="co">#&gt; $pca.rank.</span></span>
<span><span class="co">#&gt; Tuning over:</span></span>
<span><span class="co">#&gt; range [2, 20]</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $classif.kknn.k</span></span>
<span><span class="co">#&gt; Tuning over:</span></span>
<span><span class="co">#&gt; range [1, 32]</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb222"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_tuned</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/auto_tuner.html">auto_tuner</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"random_search"</span><span class="op">)</span>, <span class="va">graph_learner</span>,</span>
<span>                        <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"holdout"</span><span class="op">)</span>, term_evals <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">glrn_untuned</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"pca"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.kknn"</span><span class="op">)</span></span>
<span><span class="va">design</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">glrn_tuned</span>, <span class="va">glrn_untuned</span><span class="op">)</span>,</span>
<span>                        <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb223"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;                learner_id classif.ce</span></span>
<span><span class="co">#&gt; 1: pca.classif.kknn.tuned  0.2643892</span></span>
<span><span class="co">#&gt; 2:       pca.classif.kknn  0.2694272</span></span></code></pre></div>
</div>
<p>Tuning pipelines will usually take longer than tuning individual learners as training steps are often more complex and the search space will be larger. Therefore, parallelization is often appropriate (Section 10.1) and/or more efficient tuning methods for searching large tuning spaces such as Bayesian optimization.</p>
<blockquote>
<p>通常，调整整个管道的时间通常比调整单个学习器的时间长，因为训练步骤通常更加复杂，搜索空间也更大。因此，通常情况下，可以考虑使用并行化（第10.1节）或者更高效的调优方法，比如搜索大型调优空间的贝叶斯优化。</p>
</blockquote>
</section><section id="tuning-alternative-paths-with-pobranch" class="level3" data-number="8.3.2"><h3 data-number="8.3.2">
<span class="header-section-number">8.3.2</span> Tuning Alternative Paths with po(“branch”)</h3>
<p>We will answer that question by making use of <code>PipeOpBranch</code> and <code>PipeOpUnbranch</code>, which make it possible to specify multiple alternative paths in a pipeline. <code>po("branch")</code> creates multiple paths such that data can only flow through one of these as determined by the <code>selection</code> hyperparameter (<a href="#fig-pipelines-branching">Figure 8.3</a>). This concept makes it possible to use tuning to decide which <code>PipeOps</code> and <code>Learners</code> to include in the pipeline, while also allowing all options in every path to be tuned.</p>
<blockquote>
<p>我们将利用<code>PipeOpBranch</code>和<code>PipeOpUnbranch</code>来回答这个问题，它们使得在管道中指定多个备选路径成为可能。<code>po("branch")</code>创建多个路径，数据只能流经其中一个，由选择超参数决定（<a href="#fig-pipelines-branching">Figure 8.3</a>）。这个概念使得我们能够使用调优来决定在管道中包括哪些<code>PipeOps</code>和学习器，同时也允许在每个路径中调整所有选项。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-pipelines-branching" class="quarto-figure quarto-figure-center">
<figure><p><img src="imgs/mlr3book_figures-24.svg" class="img-fluid" style="width:70.0%" alt='Graph with "Dtrain" on the left with an arrow to `po("branch", selection = "pca")` which then has a dark shaded arrow to a box that says "PCA". Above this box is a transparent box that says "PipeOpNOP" and below the "PCA" box is another transparent box that says "YeoJohnson", the implication is that only the "PCA" box is active. The "PCA" box then has an arrow to `po("unbranch")` -&gt; po("branch", selection = "XGBoost")` which has three arrows to another three boxes with "XGBoost" highlighted and "Random Forest" and "Decision Tree" transparent again. These finally have arrows to the same `po("unbranch")`.'></p>
<figcaption>Figure 8.3: Figure demonstrates the <code>po("branch")</code> and <code>po("unbranch")</code> operators where three separate branches are created and data only flows through the PCA, which is specified with the argument to <code>selection</code>.</figcaption></figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb224"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3oml.mlr-org.com">mlr3oml</a></span><span class="op">)</span></span>
<span><span class="va">otsk_mnist</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3oml.mlr-org.com/reference/otsk.html">otsk</a></span><span class="op">(</span>id <span class="op">=</span> <span class="fl">3573</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">tsk_mnist</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task.html">as_task</a></span><span class="op">(</span><span class="va">otsk_mnist</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">filter</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">70000</span>, <span class="fl">1000</span><span class="op">)</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">otsk_mnist</span><span class="op">$</span><span class="va">feature_names</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">700</span>, <span class="fl">100</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
</div>
<p><code>po("branch")</code> is initialized either with the number of branches or with a <code>character</code>-vector indicating the names of the branches, the latter makes the <code>selection</code> hyperparameter (discussed below) more readable. Below we create three branches: do nothing (<code>po("nop")</code>), apply PCA (<code>po("pca")</code>), remove constant features (<code>po("removeconstants")</code>) then apply the Yeo-Johnson transform (<code>po("yeojohnson")</code>). It is important to use <code>po("unbranch")</code> (with the same arguments as <code>"branch"</code>) to ensure that the outputs are merged into one result object.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb225"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">paths</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"nop"</span>, <span class="st">"pca"</span>, <span class="st">"yeojohnson"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">graph</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"branch"</span>, <span class="va">paths</span>, id <span class="op">=</span> <span class="st">"branchP0"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/gunion.html">gunion</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"nop"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"pca"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"removeconstants"</span>, id <span class="op">=</span> <span class="st">"rm_const"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>      <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"yeojohnson"</span>, id <span class="op">=</span> <span class="st">"YJ"</span><span class="op">)</span></span>
<span>  <span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"unbranch"</span>, <span class="va">paths</span>, id <span class="op">=</span> <span class="st">"unbranchP0"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">graph</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>horizontal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-233-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>We can see how the output of this <code>Graph</code> depends on the setting of the <code>branch.selection</code> hyperparameter:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb226"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># use the "PCA" path</span></span>
<span><span class="va">graph</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">branchP0.selection</span> <span class="op">=</span> <span class="st">"pca"</span></span>
<span><span class="co"># new PCA columns</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">graph</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_mnist</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">feature_names</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "PC1" "PC2" "PC3" "PC4" "PC5" "PC6"</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb227"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># use the "Np-Op" path</span></span>
<span><span class="va">graph</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">branchP0.selection</span> <span class="op">=</span> <span class="st">"nop"</span></span>
<span><span class="co"># same features</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">graph</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_mnist</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">feature_names</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "pixel6"  "pixel12" "pixel17" "pixel18" "pixel26" "pixel29"</span></span></code></pre></div>
</div>
<p>Branching can even be used to tune which of several learners is most appropriate for a given dataset. We extend our example further and add the choice between a decision tree and KKNN:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb228"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph_learner</span> <span class="op">=</span> <span class="va">graph</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/ppl.html">ppl</a></span><span class="op">(</span><span class="st">"branch"</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrns</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, <span class="st">"classif.kknn"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">graph_learner</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>horizontal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-236-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Tuning the selection hyperparameters can help determine which of the possible options work best in combination. We additionally tune the k hyperparameter of the KNN learner, as it may depend on the type of preprocessing performed. As this hyperparameter is only active when the “classif.kknn” path is chosen we will set a dependency:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb229"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">graph_learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">graph_learner</span><span class="op">)</span></span>
<span></span>
<span><span class="va">graph_learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">set_values</span><span class="op">(</span></span>
<span>  branchP0.selection <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="va">paths</span><span class="op">)</span>,</span>
<span>  branch.selection <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, <span class="st">"classif.kknn"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  classif.kknn.k <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_int</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">32</span>, </span>
<span>                                 depends <span class="op">=</span> <span class="va">branch.selection</span> <span class="op">==</span> <span class="st">"classif.kknn"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 实际应使用网格搜索</span></span>
<span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"random_search"</span><span class="op">)</span>, <span class="va">tsk_mnist</span>, <span class="va">graph_learner</span>,</span>
<span>                <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"repeated_cv"</span>, folds <span class="op">=</span> <span class="fl">3</span>, repeats <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>                <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span>, term_evals <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>  </span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb230"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">$</span><span class="va">data</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html">order</a></span><span class="op">(</span><span class="va">classif.ce</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span>,</span>
<span>          <span class="fu">.</span><span class="op">(</span><span class="va">branchP0.selection</span>, <span class="va">classif.kknn.k</span>, <span class="va">branch.selection</span>, <span class="va">classif.ce</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;    branchP0.selection classif.kknn.k branch.selection classif.ce</span></span>
<span><span class="co">#&gt; 1:         yeojohnson              9     classif.kknn  0.2550055</span></span>
<span><span class="co">#&gt; 2:                nop             15     classif.kknn  0.2736719</span></span>
<span><span class="co">#&gt; 3:                nop             25     classif.kknn  0.2863472</span></span>
<span><span class="co">#&gt; 4:                nop             27     classif.kknn  0.2883472</span></span>
<span><span class="co">#&gt; 5:                pca              9     classif.kknn  0.3480057</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb231"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-239-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section><section id="sec-hyperband-example-svm" class="level3" data-number="8.3.3"><h3 data-number="8.3.3">
<span class="header-section-number">8.3.3</span> Hyperband with Subsampling</h3>
<p>We previously saw how some learners have hyperparameters that can act naturally as fidelity parameters, such as the number of trees in a random forest. However, using pipelines, we can now create a fidelity parameter for any model using <code>po("subsample")</code>. The <code>frac</code> parameter of <code>po("subsample")</code> controls the amount of data fed into the subsequent <code>Learner</code>. In general, feeding less data to a <code>Learner</code> results in quicker model training but poorer quality predictions compared to when more training data is supplied. Resampling with less data will still give us some information about the relative performance of different model configurations, thus making the fraction of data to subsample the perfect candidate for a fidelity parameter.</p>
<blockquote>
<p>我们之前看到，一些学习器具有可以自然充当保真度参数的超参数，例如随机森林中的树的数量。然而，使用管道，我们现在可以使用<code>po("subsample")</code>为任何模型创建一个保真度参数。<code>po("subsample")</code>的<code>frac</code>参数控制了传递到后续学习器的数据量。通常情况下，向学习器提供更少的数据会导致模型训练更快，但与提供更多训练数据相比，预测质量较差。使用较少的数据重新采样仍然可以为我们提供有关不同模型配置相对性能的一些信息，因此将数据子采样的比例作为保真度参数是一个完美的选择。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb232"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.svm"</span>, id <span class="op">=</span> <span class="st">"svm"</span>, type <span class="op">=</span> <span class="st">"C-classification"</span>,</span>
<span>              kernel <span class="op">=</span> <span class="st">"radial"</span>, cost <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-5</span>, <span class="fl">1e5</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>              gamma <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1e-5</span>, <span class="fl">1e5</span>, logscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">graph_learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"subsample"</span>, frac <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html">p_dbl</a></span><span class="op">(</span><span class="fl">3</span><span class="op">^</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">1</span>, tags <span class="op">=</span> <span class="st">"budget"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>    <span class="va">learner</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">graph_learner</span><span class="op">$</span><span class="va">encapsulate</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>train <span class="op">=</span> <span class="st">"evaluate"</span>, predict <span class="op">=</span> <span class="st">"evaluate"</span><span class="op">)</span></span>
<span><span class="va">graph_learner</span><span class="op">$</span><span class="va">timeout</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>train <span class="op">=</span> <span class="fl">30</span>, predict <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span>
<span><span class="va">graph_learner</span><span class="op">$</span><span class="va">fallback</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.featureless"</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Now we can tune our SVM by tuning our <code>GraphLearner</code> as normal, below we set <code>eta = 3</code> for Hyperband.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb233"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"hyperband"</span>, eta <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"sonar"</span><span class="op">)</span>, <span class="va">graph_learner</span>,</span>
<span>                <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb234"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">result_x_domain</span></span>
<span><span class="co">#&gt; $subsample.frac</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $svm.cost</span></span>
<span><span class="co">#&gt; [1] 3397.206</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $svm.gamma</span></span>
<span><span class="co">#&gt; [1] 0.003112139</span></span></code></pre></div>
</div>
</section><section id="sec-pipelines-featsel" class="level3" data-number="8.3.4"><h3 data-number="8.3.4">
<span class="header-section-number">8.3.4</span> Feature Selection with Filter Pipelines</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb235"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">task_pen</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"penguins"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># combine filter (keep top 3 features) with learner</span></span>
<span><span class="va">po_flt</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"filter"</span>, filter <span class="op">=</span> <span class="fu"><a href="https://mlr3filters.mlr-org.com/reference/flt.html">flt</a></span><span class="op">(</span><span class="st">"information_gain"</span><span class="op">)</span>, filter.nfeat <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">graph</span> <span class="op">=</span> <span class="va">po_flt</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"learner"</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"filter"</span>, filter <span class="op">=</span> <span class="fu"><a href="https://mlr3filters.mlr-org.com/reference/flt.html">flt</a></span><span class="op">(</span><span class="st">"information_gain"</span><span class="op">)</span>, filter.nfeat <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">train</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">task_pen</span><span class="op">)</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">feature_names</span></span>
<span><span class="co">#&gt; [1] "bill_depth"     "bill_length"    "flipper_length"</span></span></code></pre></div>
</div>
<p>Choosing <code>3</code> as the cutoff was fairly arbitrary but by tuning a graph we can optimize this cutoff:</p>
<blockquote>
<p>选择<code>3</code>作为截止值是相当任意的，但通过调整一个图表，我们可以优化这个截止值：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb236"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span><span class="co"># tune between 1 and total number of features</span></span>
<span><span class="va">po_filter</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"filter"</span>, filter <span class="op">=</span> <span class="fu"><a href="https://mlr3filters.mlr-org.com/reference/flt.html">flt</a></span><span class="op">(</span><span class="st">"information_gain"</span><span class="op">)</span>,</span>
<span>               filter.nfeat <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/to_tune.html">to_tune</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">task_pen</span><span class="op">$</span><span class="va">ncol</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">graph</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">po_filter</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"learner"</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tune.html">tune</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr</a></span><span class="op">(</span><span class="st">"random_search"</span><span class="op">)</span>, <span class="va">task_pen</span>, <span class="va">graph</span>,</span>
<span>                <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>, term_evals <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb237"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">result</span></span>
<span><span class="co">#&gt;    information_gain.filter.nfeat learner_param_vals  x_domain classif.ce</span></span>
<span><span class="co">#&gt; 1:                             6          &lt;list[2]&gt; &lt;list[1]&gt; 0.05532672</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb238"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-246-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>In this example, <code>6</code> is the optimal number of features. It can be especially useful in feature selection to visualize the tuning results as there may be cases where the optimal result is only marginally better than a result with less features (which would lead to a model that is quicker to train and possibly easier to interpret).</p>
<p>Now we can see that four variables may be equally as good in this case so we could consider going forward by selecting four features and not six as suggested by <code>instance$result</code>.</p>
<blockquote>
<p>在这个示例中，<code>6</code>是最佳的特征数量。在特征选择中，将调整结果可视化呈现可能特别有用，因为有些情况下，最佳结果可能仅略优于具有较少特征的结果（这将导致模型训练更快，可能更容易解释）。</p>
<p>现在我们可以看到，在这种情况下，四个变量可能同样有效，因此我们可以考虑选择四个特征，而不是像<code>instance$result</code>建议的六个。</p>
</blockquote>
</section></section></section><section id="sec-preprocessing" class="level1" data-number="9"><h1 data-number="9">
<span class="header-section-number">9</span> Preprocessing</h1>
<p>In this book, preprocessing refers to everything that happens with data before it is used to fit a model, while postprocessing encompasses everything that occurs with predictions after the model is fitted.</p>
<p>Data cleaning is an important part of preprocessing that involves the removal of errors, noise, and redundancy in the data; we only consider data cleaning very briefly as it is usually performed outside of <code>mlr3</code> on the raw dataset.</p>
<p>Another aspect of preprocessing is feature engineering, which covers all other transformations of data before it is fed to the machine learning model, including the creation of features from possibly unstructured data, such as written text, sequences or images. The goal of feature engineering is to enable the data to be handled by a given learner, and/or to further improve predictive performance. It is important to note that feature engineering helps mostly for simpler algorithms, while highly complex models usually gain less from it and require little data preparation to be trained. Common difficulties in data that can be solved with feature engineering include features with skewed distributions, high cardinality categorical features, missing observations, high dimensionality and imbalanced classes in classification tasks. Deep learning has shown promising results in automating feature engineering, however, its effectiveness depends on the complexity and nature of the data being processed, as well as the specific problem being addressed. Typically it can work well with natural language processing and computer vision problems, while for standard tabular data, tree-based ensembles such as a random forest or gradient boosting are often still superior (and easier to handle). However, tabular deep learning approaches are currently catching up quickly. Hence, manual feature engineering is still often required but with <code>mlr3pipelines</code>, which can simplify the process as much as possible.</p>
<blockquote>
<p>在本书中，预处理指的是在数据用于拟合模型之前发生的一切，而后处理则包括在模型拟合后对预测进行的一切操作。</p>
<p>数据清理是预处理的重要部分，涉及到消除数据中的错误、噪音和冗余；我们只会简要地考虑数据清理，因为它通常是在原始数据集上进行的，而不是在<code>mlr3</code>上执行。</p>
<p>预处理的另一个方面是特征工程，它涵盖了在将数据提供给机器学习模型之前对数据进行的所有其他转换，包括从可能是非结构化数据（如书面文本、序列或图像）中创建特征。特征工程的目标是使数据能够被给定的学习器处理，和/或进一步提高预测性能。需要注意的是，特征工程主要有助于较简单的算法，而高度复杂的模型通常受益较少，并且需要较少的数据准备来进行训练。可以通过特征工程解决的数据常见问题包括具有倾斜分布的特征、高基数分类特征、缺失观测、高维度以及分类任务中的不平衡类。深度学习在自动化特征工程方面表现出有希望的结果，然而，其有效性取决于正在处理的数据的复杂性和性质，以及所解决的具体问题。通常情况下，它在自然语言处理和计算机视觉问题上表现良好，而对于标准表格数据，如随机森林或梯度提升等基于树的集成方法通常仍然更占优势（并且更易处理）。但是，表格型深度学习方法目前正在迅速赶超。因此，手动特征工程仍然经常需要，但使用<code>mlr3pipelines</code>可以尽可能简化这个过程。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb239"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ames</span> <span class="op">=</span> <span class="fu">mlr3data</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/mlr3data/man/ames_housing.html">ames_housing</a></span></span></code></pre></div>
</div>
<section id="data-cleaning" class="level2" data-number="9.1"><h2 data-number="9.1">
<span class="header-section-number">9.1</span> Data Cleaning</h2>
<p>As a first step, we explore the data and look for simple problems such as constant or duplicated features. This can be done quite efficiently with a package like <code>DataExplorer</code> or <code>skimr</code> which can be used to create a large number of informative plots.</p>

<!--

::: {.cell layout-align="center"}

```{.r .cell-code}
skimr::skim(ames)
```

::: {.cell-output-display}
Table: Data summary

|                         |     |
|:------------------------|:----|
|Name                     |ames |
|Number of rows           |2930 |
|Number of columns        |82   |
|Key                      |NULL |
|_______________________  |     |
|Column type frequency:   |     |
|factor                   |47   |
|numeric                  |35   |
|________________________ |     |
|Group variables          |None |


**Variable type: factor**

|skim_variable  | n_missing| complete_rate|ordered | n_unique|top_counts                              |
|:--------------|---------:|-------------:|:-------|--------:|:---------------------------------------|
|Alley          |      2732|          0.07|FALSE   |        2|Gra: 120, Pav: 78                       |
|Bldg_Type      |         0|          1.00|FALSE   |        5|One: 2425, Twn: 233, Dup: 109, Twn: 101 |
|Bsmt_Cond      |        80|          0.97|FALSE   |        5|Typ: 2616, Goo: 122, Fai: 104, Poo: 5   |
|Bsmt_Exposure  |        83|          0.97|FALSE   |        4|No: 1906, Av: 418, Gd: 284, Mn: 239     |
|Bsmt_Qual      |        80|          0.97|FALSE   |        5|Typ: 1283, Goo: 1219, Exc: 258, Fai: 88 |
|BsmtFin_Type_1 |        80|          0.97|FALSE   |        6|GLQ: 859, Unf: 851, ALQ: 429, Rec: 288  |
|BsmtFin_Type_2 |        81|          0.97|FALSE   |        6|Unf: 2499, Rec: 106, LwQ: 89, BLQ: 68   |
|Central_Air    |         0|          1.00|FALSE   |        2|Y: 2734, N: 196                         |
|Condition_1    |         0|          1.00|FALSE   |        9|Nor: 2522, Fee: 164, Art: 92, RRA: 50   |
|Condition_2    |         0|          1.00|FALSE   |        8|Nor: 2900, Fee: 13, Art: 5, Pos: 4      |
|Condition_3    |         0|          1.00|FALSE   |        8|Nor: 2900, Fee: 13, Art: 5, Pos: 4      |
|Electrical     |         1|          1.00|FALSE   |        5|SBr: 2682, Fus: 188, Fus: 50, Fus: 8    |
|Exter_Cond     |         0|          1.00|FALSE   |        5|Typ: 2549, Goo: 299, Fai: 67, Exc: 12   |
|Exter_Qual     |         0|          1.00|FALSE   |        4|Typ: 1799, Goo: 989, Exc: 107, Fai: 35  |
|Exterior_1st   |         0|          1.00|FALSE   |       16|Vin: 1026, Met: 450, HdB: 442, Wd : 420 |
|Exterior_2nd   |         0|          1.00|FALSE   |       17|Vin: 1015, Met: 447, HdB: 406, Wd : 397 |
|Fence          |      2358|          0.20|FALSE   |        4|Min: 330, Goo: 118, Goo: 112, Min: 12   |
|Fireplace_Qu   |      1422|          0.51|FALSE   |        5|Goo: 744, Typ: 600, Fai: 75, Poo: 46    |
|Foundation     |         0|          1.00|FALSE   |        6|PCo: 1310, CBl: 1244, Brk: 311, Sla: 49 |
|Functional     |         0|          1.00|FALSE   |        8|Typ: 2728, Min: 70, Min: 65, Mod: 35    |
|Garage_Cond    |       159|          0.95|FALSE   |        5|Typ: 2665, Fai: 74, Goo: 15, Poo: 14    |
|Garage_Finish  |       159|          0.95|FALSE   |        3|Unf: 1231, RFn: 812, Fin: 728           |
|Garage_Qual    |       159|          0.95|FALSE   |        5|Typ: 2615, Fai: 124, Goo: 24, Poo: 5    |
|Garage_Type    |       157|          0.95|FALSE   |        6|Att: 1731, Det: 782, Bui: 186, Bas: 36  |
|Heating        |         0|          1.00|FALSE   |        6|Gas: 2885, Gas: 27, Gra: 9, Wal: 6      |
|Heating_QC     |         0|          1.00|FALSE   |        5|Exc: 1495, Typ: 864, Goo: 476, Fai: 92  |
|House_Style    |         0|          1.00|FALSE   |        8|One: 1481, Two: 873, One: 314, SLv: 128 |
|Land_Contour   |         0|          1.00|FALSE   |        4|Lvl: 2633, HLS: 120, Bnk: 117, Low: 60  |
|Land_Slope     |         0|          1.00|FALSE   |        3|Gtl: 2789, Mod: 125, Sev: 16            |
|Lot_Config     |         0|          1.00|FALSE   |        5|Ins: 2140, Cor: 511, Cul: 180, FR2: 85  |
|Lot_Shape      |         0|          1.00|FALSE   |        4|Reg: 1859, Sli: 979, Mod: 76, Irr: 16   |
|Mas_Vnr_Type   |        23|          0.99|FALSE   |        5|Non: 1752, Brk: 880, Sto: 249, Brk: 25  |
|Misc_Feature   |      2824|          0.04|FALSE   |        5|She: 95, Gar: 5, Oth: 4, Ele: 1         |
|Misc_Feature_2 |         0|          1.00|FALSE   |        1|Oth: 2930                               |
|MS_SubClass    |         0|          1.00|FALSE   |       16|One: 1079, Two: 575, One: 287, One: 192 |
|MS_Zoning      |         0|          1.00|FALSE   |        7|Res: 2273, Res: 462, Flo: 139, Res: 27  |
|Neighborhood   |         0|          1.00|FALSE   |       28|Nor: 443, Col: 267, Old: 239, Edw: 194  |
|Overall_Cond   |         0|          1.00|FALSE   |        9|Ave: 1654, Abo: 533, Goo: 390, Ver: 144 |
|Overall_Qual   |         0|          1.00|FALSE   |       10|Ave: 825, Abo: 732, Goo: 602, Ver: 350  |
|Paved_Drive    |         0|          1.00|FALSE   |        3|Pav: 2652, Dir: 216, Par: 62            |
|Pool_QC        |      2917|          0.00|FALSE   |        4|Exc: 4, Goo: 4, Typ: 3, Fai: 2          |
|Roof_Matl      |         0|          1.00|FALSE   |        8|Com: 2887, Tar: 23, WdS: 9, WdS: 7      |
|Roof_Style     |         0|          1.00|FALSE   |        6|Gab: 2321, Hip: 551, Gam: 22, Fla: 20   |
|Sale_Condition |         0|          1.00|FALSE   |        6|Nor: 2413, Par: 245, Abn: 190, Fam: 46  |
|Sale_Type      |         0|          1.00|FALSE   |       10|WD : 2536, New: 239, COD: 87, Con: 26   |
|Street         |         0|          1.00|FALSE   |        2|Pav: 2918, Grv: 12                      |
|Utilities      |         0|          1.00|FALSE   |        3|All: 2927, NoS: 2, NoS: 1               |


**Variable type: numeric**

|skim_variable      | n_missing| complete_rate|      mean|       sd|       p0|       p25|       p50|       p75|      p100|hist  |
|:------------------|---------:|-------------:|---------:|--------:|--------:|---------:|---------:|---------:|---------:|:-----|
|Sale_Price         |         0|          1.00| 180796.06| 79886.69| 12789.00| 129500.00| 160000.00| 213500.00| 755000.00|▇▇▁▁▁ |
|Bedroom_AbvGr      |         0|          1.00|      2.85|     0.83|     0.00|      2.00|      3.00|      3.00|      8.00|▁▇▂▁▁ |
|Bsmt_Full_Bath     |         2|          1.00|      0.43|     0.52|     0.00|      0.00|      0.00|      1.00|      3.00|▇▆▁▁▁ |
|Bsmt_Half_Bath     |         2|          1.00|      0.06|     0.25|     0.00|      0.00|      0.00|      0.00|      2.00|▇▁▁▁▁ |
|Bsmt_Unf_SF        |         1|          1.00|    559.26|   439.49|     0.00|    219.00|    466.00|    802.00|   2336.00|▇▅▂▁▁ |
|BsmtFin_SF_1       |         1|          1.00|    442.63|   455.59|     0.00|      0.00|    370.00|    734.00|   5644.00|▇▁▁▁▁ |
|BsmtFin_SF_2       |         1|          1.00|     49.72|   169.17|     0.00|      0.00|      0.00|      0.00|   1526.00|▇▁▁▁▁ |
|Enclosed_Porch     |         0|          1.00|     23.01|    64.14|     0.00|      0.00|      0.00|      0.00|   1012.00|▇▁▁▁▁ |
|Fireplaces         |         0|          1.00|      0.60|     0.65|     0.00|      0.00|      1.00|      1.00|      4.00|▇▇▁▁▁ |
|First_Flr_SF       |         0|          1.00|   1159.56|   391.89|   334.00|    876.25|   1084.00|   1384.00|   5095.00|▇▃▁▁▁ |
|Full_Bath          |         0|          1.00|      1.57|     0.55|     0.00|      1.00|      2.00|      2.00|      4.00|▁▇▇▁▁ |
|Garage_Area        |         1|          1.00|    472.82|   215.05|     0.00|    320.00|    480.00|    576.00|   1488.00|▃▇▃▁▁ |
|Garage_Cars        |         1|          1.00|      1.77|     0.76|     0.00|      1.00|      2.00|      2.00|      5.00|▅▇▂▁▁ |
|Garage_Yr_Blt      |       159|          0.95|   1978.13|    25.53|  1895.00|   1960.00|   1979.00|   2002.00|   2207.00|▂▇▁▁▁ |
|Gr_Liv_Area        |         0|          1.00|   1499.69|   505.51|   334.00|   1126.00|   1442.00|   1742.75|   5642.00|▇▇▁▁▁ |
|Half_Bath          |         0|          1.00|      0.38|     0.50|     0.00|      0.00|      0.00|      1.00|      2.00|▇▁▅▁▁ |
|Kitchen_AbvGr      |         0|          1.00|      1.04|     0.21|     0.00|      1.00|      1.00|      1.00|      3.00|▁▇▁▁▁ |
|Lot_Area           |         0|          1.00|  10147.92|  7880.02|  1300.00|   7440.25|   9436.50|  11555.25| 215245.00|▇▁▁▁▁ |
|Lot_Area_m2        |         0|          1.00|    942.77|   732.08|   120.77|    691.22|    876.68|   1073.52|  19996.91|▇▁▁▁▁ |
|Lot_Frontage       |       490|          0.83|     69.22|    23.37|    21.00|     58.00|     68.00|     80.00|    313.00|▇▃▁▁▁ |
|Low_Qual_Fin_SF    |         0|          1.00|      4.68|    46.31|     0.00|      0.00|      0.00|      0.00|   1064.00|▇▁▁▁▁ |
|Mas_Vnr_Area       |        23|          0.99|    101.90|   179.11|     0.00|      0.00|      0.00|    164.00|   1600.00|▇▁▁▁▁ |
|Misc_Val           |         0|          1.00|     50.64|   566.34|     0.00|      0.00|      0.00|      0.00|  17000.00|▇▁▁▁▁ |
|Mo_Sold            |         0|          1.00|      6.22|     2.71|     1.00|      4.00|      6.00|      8.00|     12.00|▅▆▇▃▃ |
|Open_Porch_SF      |         0|          1.00|     47.53|    67.48|     0.00|      0.00|     27.00|     70.00|    742.00|▇▁▁▁▁ |
|Pool_Area          |         0|          1.00|      2.24|    35.60|     0.00|      0.00|      0.00|      0.00|    800.00|▇▁▁▁▁ |
|Screen_Porch       |         0|          1.00|     16.00|    56.09|     0.00|      0.00|      0.00|      0.00|    576.00|▇▁▁▁▁ |
|Second_Flr_SF      |         0|          1.00|    335.46|   428.40|     0.00|      0.00|      0.00|    703.75|   2065.00|▇▃▂▁▁ |
|Three_season_porch |         0|          1.00|      2.59|    25.14|     0.00|      0.00|      0.00|      0.00|    508.00|▇▁▁▁▁ |
|Total_Bsmt_SF      |         1|          1.00|   1051.61|   440.62|     0.00|    793.00|    990.00|   1302.00|   6110.00|▇▃▁▁▁ |
|TotRms_AbvGrd      |         0|          1.00|      6.44|     1.57|     2.00|      5.00|      6.00|      7.00|     15.00|▁▇▂▁▁ |
|Wood_Deck_SF       |         0|          1.00|     93.75|   126.36|     0.00|      0.00|      0.00|    168.00|   1424.00|▇▁▁▁▁ |
|Year_Built         |         0|          1.00|   1971.36|    30.25|  1872.00|   1954.00|   1973.00|   2001.00|   2010.00|▁▂▃▆▇ |
|Year_Remod_Add     |         0|          1.00|   1984.27|    20.86|  1950.00|   1965.00|   1993.00|   2004.00|   2010.00|▅▂▂▃▇ |
|Year_Sold          |         0|          1.00|   2007.79|     1.32|  2006.00|   2007.00|   2008.00|   2009.00|   2010.00|▇▇▇▇▃ |
:::
:::

-->
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb240"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 1. `Misc_Feature_2` is a factor with only a single level `Othr`.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">ames</span><span class="op">$</span><span class="va">Misc_Feature_2</span><span class="op">)</span></span>
<span><span class="co">#&gt; Othr </span></span>
<span><span class="co">#&gt; 2930</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb241"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 2. `Condition_2` and `Condition_3` are identical.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/identical.html">identical</a></span><span class="op">(</span><span class="va">ames</span><span class="op">$</span><span class="va">Condition_2</span>, <span class="va">ames</span><span class="op">$</span><span class="va">Condition_3</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb242"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 3. `Lot_Area` and `Lot_Area_m2` are same data on different scales</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">ames</span><span class="op">$</span><span class="va">Lot_Area</span>, <span class="va">ames</span><span class="op">$</span><span class="va">Lot_Area_m2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1</span></span></code></pre></div>
</div>
<p>For all three problems, simply removing the problematic features (or feature in a pair) might be the best course of action.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb243"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">to_remove</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Lot_Area_m2"</span>, <span class="st">"Condition_3"</span>, <span class="st">"Misc_Feature_2"</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Other typical problems that should be checked are:</p>
<ol type="1">
<li><p>ID columns, i.e., columns that are unique for every observation should be removed or tagged.</p></li>
<li><p><code>NA</code>s not correctly encoded, e.g. as <code>"NA"</code> or <code>""</code></p></li>
<li><p>Semantic errors in the data, e.g., negative <code>Lot_Area</code></p></li>
<li><p>Numeric features encoded as categorical for learners that can not handle such features.</p></li>
</ol>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb244"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tsk_ames</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task_regr.html">as_task_regr</a></span><span class="op">(</span><span class="va">ames</span>, target <span class="op">=</span> <span class="st">"Sale_Price"</span>, id <span class="op">=</span> <span class="st">"ames"</span><span class="op">)</span></span>
<span><span class="co"># remove problematic features</span></span>
<span><span class="va">tsk_ames</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sets.html">setdiff</a></span><span class="op">(</span><span class="va">tsk_ames</span><span class="op">$</span><span class="va">feature_names</span>, <span class="va">to_remove</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">msr_mae</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"regr.mae"</span><span class="op">)</span></span>
<span><span class="va">rsmp_cv3</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">rsmp_cv3</span><span class="op">$</span><span class="fu">instantiate</span><span class="op">(</span><span class="va">tsk_ames</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Lastly, we run a very simple experiment to verify our setup works as expected with a simple featureless baseline, note below we set <code>robust = TRUE</code> to always predict the <em>median</em> sale price as opposed to the <em>mean</em>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb245"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_baseline</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.featureless"</span>, robust <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">lrn_baseline</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"Baseline"</span></span>
<span><span class="va">rr_baseline</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/resample.html">resample</a></span><span class="op">(</span><span class="va">tsk_ames</span>, <span class="va">lrn_baseline</span>, <span class="va">rsmp_cv3</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb246"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rr_baseline</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">msr_mae</span><span class="op">)</span></span>
<span><span class="co">#&gt; regr.mae </span></span>
<span><span class="co">#&gt; 56167.48</span></span></code></pre></div>
</div>
</section><section id="factor-encoding" class="level2" data-number="9.2"><h2 data-number="9.2">
<span class="header-section-number">9.2</span> Factor Encoding</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb247"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lrn_xgb</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.xgboost"</span>, nrounds <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">lrn_xgb</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_ames</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error: &lt;TaskRegr:ames&gt; has the following unsupported feature types: factor</span></span></code></pre></div>
</div>
<p>Categorical features can be grouped by their cardinality, which refers to the number of levels they contain: binary features (two levels), low-cardinality features, and high-cardinality features; there is no universal threshold for when a feature should be considered high-cardinality and this threshold can even be tuned. For now, we will consider high-cardinality to be features with more than 10 levels:</p>
<blockquote>
<p>分类特征可以按其基数进行分组，基数指的是它们包含的级别数量：二元特征（两个级别）、低基数特征和高基数特征；对于何时将特征视为高基数特征，没有通用的阈值，这个阈值甚至可以进行调整。目前，我们将认为高基数特征是具有超过10个级别的特征：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb248"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lengths.html">lengths</a></span><span class="op">(</span><span class="va">tsk_ames</span><span class="op">$</span><span class="fu">levels</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Exterior_1st" "Exterior_2nd" "MS_SubClass"  "Neighborhood"</span></span></code></pre></div>
</div>
<p>Low-cardinality features can be handled by one-hot encoding. One-hot encoding is a process of converting categorical features into a binary representation, where each possible category is represented as a separate binary feature. Theoretically, it is sufficient to create one less binary feature than levels, as setting all binary features to zero is also a valid representation. This is typically called dummy or treatment encoding and is required if the learner is a generalized linear model (GLM) or additive model (GAM).</p>
<p>Some learners support handling categorical features but may still crash for high-cardinality features if they internally apply encodings that are only suitable for low-cardinality features, such as one-hot encoding. Impact encoding (Micci-Barreca 2001) is a good approach for handling high-cardinality features. Impact encoding converts categorical features into numeric values. The idea behind impact encoding is to use the target feature to create a mapping between the categorical feature and a numerical value that reflects its importance in predicting the target feature. Impact encoding involves the following steps:</p>
<ol type="1">
<li><p>Group the target variable by the categorical feature.</p></li>
<li><p>Compute the mean of the target variable for each group.</p></li>
<li><p>Compute the global mean of the target variable.</p></li>
<li><p>Compute the impact score for each group as the difference between the mean of the target variable for the group and the global mean of the target variable.</p></li>
<li><p>Replace the categorical feature with the impact scores.</p></li>
</ol>
<p>Impact encoding preserves the information of the categorical feature while also creating a numerical representation that reflects its importance in predicting the target. Compared to one-hot encoding, the main advantage is that only a single numeric feature is created regardless of the number of levels of the categorical features, hence it is especially useful for high-cardinality features. As information from the target is used to compute the impact scores, the encoding process must be embedded in cross-validation to avoid leakage between training and testing data.</p>
<p>As well as encoding features, other basic preprocessing steps for categorical features include removing constant features (which only have one level and may have been removed as part of data cleaning), and collapsing levels that occur very rarely. These types of problems can occur as artifacts of resampling as the dataset size is further reduced. Stratification on such features would be an alternative way to mitigate this.</p>
<p>In the code below we use <code>po("removeconstants")</code> to remove features with only one level, <code>po("collapsefactors")</code> to collapse levels that occur less than 1% of the time in the data, <code>po("encodeimpact")</code> to impact-encode high-cardinality features, <code>po("encode", method = "one-hot")</code> to one-hot encode low-cardinality features, and finally <code>po("encode", method = "treatment")</code> to treatment encode binary features.</p>
<blockquote>
<p>低基数特征可以通过独热编码进行处理。独热编码是一种将分类特征转换为二进制表示的过程，其中每个可能的类别都被表示为一个单独的二进制特征。从理论上讲，只需创建比级别少一个二进制特征就足够了，因为将所有二进制特征都设置为零也是有效的表示。这通常被称为虚拟编码或处理编码，如果学习器是广义线性模型（GLM）或加性模型（GAM），则需要这样的编码。</p>
<p>有些学习器支持处理分类特征，但如果它们在内部应用的编码仅适用于低基数特征（例如独热编码），则对于高基数特征仍可能出现问题。影响编码（Micci-Barreca 2001）是处理高基数特征的良好方法。影响编码将分类特征转换为数值值。影响编码的背后思想是使用目标特征来创建分类特征与预测目标特征中的重要性之间的映射。影响编码包括以下步骤：</p>
<ol type="1">
<li><p>通过分类特征对目标变量进行分组。</p></li>
<li><p>计算每个组的目标变量的平均值。</p></li>
<li><p>计算目标变量的全局平均值。</p></li>
<li><p>计算每个组的影响分数，作为该组目标变量平均值与目标变量的全局平均值之间的差异。</p></li>
<li><p>用影响分数替换分类特征。</p></li>
</ol>
<p>影响编码在保留分类特征信息的同时，还创建了一个反映其在预测目标中的重要性的数值表示。与独热编码相比，主要优点是无论分类特征的级别数如何多，都只创建一个数值特征，因此特别适用于高基数特征。由于使用了目标变量的信息来计算影响分数，编码过程必须嵌入交叉验证中，以避免训练数据和测试数据之间的信息泄漏。</p>
<p>除了编码特征，对于分类特征的其他基本预处理步骤包括删除常量特征（只有一个级别的特征，可能已被作为数据清理的一部分删除）和合并很少出现的级别。这些问题可能会出现在通过重采样减小数据集大小时。在这种情况下，对这些特征进行分层抽样可能是缓解的替代方法。</p>
<p>在下面的代码中，我们使用<code>po("removeconstants")</code>来删除只有一个级别的特征，<code>po("collapsefactors")</code>来合并数据中出现不到1%的级别，<code>po("encodeimpact")</code>来对高基数特征进行影响编码，<code>po("encode", method = "one-hot")</code>来独热编码低基数特征，最后使用<code>po("encode", method = "treatment")</code>来处理二元特征。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb249"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">factor_pipeline</span> <span class="op">=</span> </span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"removeconstants"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"collapsefactors"</span>, no_collapse_above_prevalence <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"encodeimpact"</span>,</span>
<span>     affect_columns <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/Selector.html">selector_cardinality_greater_than</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span>,</span>
<span>     id <span class="op">=</span> <span class="st">"high_card_enc"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"encode"</span>, method <span class="op">=</span> <span class="st">"one-hot"</span>,</span>
<span>     affect_columns <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/Selector.html">selector_cardinality_greater_than</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>     id <span class="op">=</span> <span class="st">"low_card_enc"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"encode"</span>, method <span class="op">=</span> <span class="st">"treatment"</span>,</span>
<span>     affect_columns <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/Selector.html">selector_type</a></span><span class="op">(</span><span class="st">"factor"</span><span class="op">)</span>, id <span class="op">=</span> <span class="st">"binary_enc"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb250"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_xgb_impact</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">factor_pipeline</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="va">lrn_xgb</span><span class="op">)</span></span>
<span><span class="va">glrn_xgb_impact</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"XGB_enc_impact"</span></span>
<span></span>
<span><span class="va">glrn_xgb_one_hot</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"encode"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="va">lrn_xgb</span><span class="op">)</span></span>
<span><span class="va">glrn_xgb_one_hot</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"XGB_enc_onehot"</span></span>
<span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_ames</span>,</span>
<span>                 <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">lrn_baseline</span>, <span class="va">glrn_xgb_impact</span>, <span class="va">glrn_xgb_one_hot</span><span class="op">)</span>,</span>
<span>                 <span class="va">rsmp_cv3</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb251"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">msr_mae</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">regr.mae</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;        learner_id regr.mae</span></span>
<span><span class="co">#&gt; 1:       Baseline 56167.48</span></span>
<span><span class="co">#&gt; 2: XGB_enc_impact 16178.42</span></span>
<span><span class="co">#&gt; 3: XGB_enc_onehot 16607.33</span></span></code></pre></div>
</div>
</section><section id="sec-preprocessing-missing" class="level2" data-number="9.3"><h2 data-number="9.3">
<span class="header-section-number">9.3</span> Missing Values</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb252"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># print first five with missing data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">tsk_ames</span><span class="op">$</span><span class="fu">missings</span><span class="op">(</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span>
<span><span class="co">#&gt; [1] "Alley"          "BsmtFin_SF_1"   "BsmtFin_SF_2"   "BsmtFin_Type_1"</span></span>
<span><span class="co">#&gt; [5] "BsmtFin_Type_2"</span></span></code></pre></div>
</div>
<p>The simplest data imputation method is to replace missing values by the feature’s mean <code>(po("imputemean")</code>), median (<code>po("imputemedian")</code>), or mode (<code>po("imputemode")</code>). Alternatively, one can impute by sampling from the empirical distribution of the feature, for example a histogram (<code>po("imputehist")</code>). Instead of guessing at what a missing feature might be, missing values could instead be replaced by a new level, for example, called <code>.MISSING</code> (<code>po("imputeoor")</code>). For numeric features, Ding and Simonoff (2010) show that for binary classification and tree-based models, encoding missing values out-of-range (OOR), e.g. a constant value above the largest observed value, is a reasonable approach.</p>
<blockquote>
<p>最简单的数据插补方法是用特征的均值（<code>po("imputemean")</code>），中位数（<code>po("imputemedian")</code>）或众数（<code>po("imputemode")</code>）来替代缺失值。另外，也可以通过从特征的经验分布中进行采样，例如使用直方图（<code>po("imputehist")</code>）。与猜测缺失特征可能是什么不同，缺失值可以被替换为一个新级别，例如称为<code>.MISSING</code>~（<code>po("imputeoor")</code>）。对于数值特征，Ding和Simonoff（2010）表明，对于二元分类和基于树的模型，编码超出范围（OOR）的缺失值，例如，一个大于观察到的最大值的常数值，是一个合理的方法。</p>
</blockquote>
<p>It is often important for predictive tasks that you keep track of missing data as it is common for missing data to be informative in itself. To preserve the information about which data was missing, imputation should be tracked by adding binary indicator features (one for each imputed feature) that are <code>1</code> if the feature was missing for an observation and <code>0</code> if it was present (<code>po("missind")</code>). It is important to note that recording this information will not prevent problems in model interpretation on its own. As a real-world example, medical data are typically collected more extensively for White communities than for racially minoritized communities. Imputing data from minoritized communities would at best mask this data bias, and at worst would make the data bias even worse by making vastly inaccurate assumptions (see Chapter 14 for data bias and algorithmic fairness).</p>
<blockquote>
<p>对于预测任务来说，跟踪缺失数据通常很重要，因为缺失数据本身常常包含有信息。为了保留有关哪些数据缺失的信息，插补应该通过添加二进制指示特征来进行跟踪（每个插补特征都有一个），如果观察中的特征缺失，则该特征为<code>1</code>，如果存在则为<code>0</code>（<code>po("missind")</code>）。需要注意的是，仅记录这些信息本身不会防止模型解释方面的问题。以现实世界的例子来说，医疗数据通常对白人社区进行的收集要比对少数民族社区进行的收集要详尽。从少数民族社区插补数据最多会掩盖数据偏差，最坏的情况下会通过进行极其不准确的假设而使数据偏差变得更严重（请参见第14章关于数据偏差和算法公平性的内容）。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb253"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">impute_hist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"missind"</span>, type <span class="op">=</span> <span class="st">"integer"</span>,</span>
<span>     affect_columns <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/Selector.html">selector_type</a></span><span class="op">(</span><span class="st">"integer"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"imputehist"</span>, affect_columns <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/Selector.html">selector_type</a></span><span class="op">(</span><span class="st">"integer"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"featureunion"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"imputeoor"</span>, affect_columns <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/Selector.html">selector_type</a></span><span class="op">(</span><span class="st">"factor"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">impute_hist</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>horizontal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-262-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Using this pipeline we can now run experiments with <code>lrn("regr.ranger")</code>, which cannot handle missing data; we also compare a simpler pipeline that only uses OOR imputation to demonstrate performance differences resulting from different strategies.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb254"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_rf_impute_hist</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">impute_hist</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.ranger"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">glrn_rf_impute_hist</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"RF_imp_Hist"</span></span>
<span></span>
<span><span class="va">glrn_rf_impute_oor</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"imputeoor"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.ranger"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">glrn_rf_impute_oor</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"RF_imp_OOR"</span></span>
<span></span>
<span><span class="va">design</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_ames</span>,</span>
<span>                        <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">glrn_rf_impute_hist</span>, <span class="va">glrn_rf_impute_oor</span><span class="op">)</span>,</span>
<span>                             <span class="va">rsmp_cv3</span><span class="op">)</span></span>
<span><span class="va">bmr_new</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb255"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">combine</span><span class="op">(</span><span class="va">bmr_new</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">msr_mae</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">regr.mae</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;        learner_id regr.mae</span></span>
<span><span class="co">#&gt; 1:       Baseline 56167.48</span></span>
<span><span class="co">#&gt; 2: XGB_enc_impact 16178.42</span></span>
<span><span class="co">#&gt; 3: XGB_enc_onehot 16607.33</span></span>
<span><span class="co">#&gt; 4:    RF_imp_Hist 16119.77</span></span>
<span><span class="co">#&gt; 5:     RF_imp_OOR 16180.46</span></span></code></pre></div>
</div>
<p>Similarly to encoding, we see limited differences in performance between the different imputation strategies. This is expected here and confirms the findings of Ding and Simonoff (2010) – out-of-range imputation is a simple yet effective imputation for tree-based methods.</p>
<p>Many more advanced imputation strategies exist, including model-based imputation where machine learning models are used to predict missing values, and multiple imputation where data is repeatedly resampled and imputed in each sample (e.g., by mean imputation) to attain more robust estimates. However, these more advanced techniques rarely improve the models predictive performance substantially and the simple imputation techniques introduced above are usually sufficient (Poulos and Valle 2018). Nevertheless, these methods are still important, as finding imputations that fit well to the distribution of the observed values allows a model to be fitted that can be interpreted and analyzed in a second step.</p>
<blockquote>
<p>与编码类似，我们在不同的插补策略之间看到了有限的性能差异。这在这里是预期的，并证实了Ding和Simonoff（2010）的研究结果 - 超出范围插补是树模型方法的一种简单而有效的插补方法。</p>
<p>还存在许多更高级的插补策略，包括基于模型的插补，其中使用机器学习模型来预测缺失值，以及多重插补，其中数据被重复重采样并在每个样本中进行插补（例如，通过均值插补），以获得更稳健的估计。然而，这些更高级的技术很少会显着改善模型的预测性能，上面介绍的简单插补技术通常已经足够了（Poulos和Valle 2018）。尽管如此，这些方法仍然很重要，因为找到与观测值的分布很好匹配的插补允许拟合一个可以在第二步中进行解释和分析的模型。</p>
</blockquote>
</section><section id="pipeline-robustify" class="level2" data-number="9.4"><h2 data-number="9.4">
<span class="header-section-number">9.4</span> Pipeline Robustify</h2>
<p><code>mlr3pipelines</code> offers a simple and reusable pipeline for (among other things) imputation and factor encoding called <code>ppl("robustify")</code>, which includes sensible defaults that can be used most of the time when encoding or imputing data. The pipeline includes the following <code>PipeOp</code>s (some are applied multiple times and most use selectors):</p>
<ol type="1">
<li><p><code>po("removeconstants")</code> – Constant features are removed.</p></li>
<li><p><code>po("colapply")</code> – Character and ordinal features are encoded as categorical, and date/time features are encoded as numeric.</p></li>
<li><p><code>po("imputehist")</code> – Numeric features are imputed by histogram sampling.</p></li>
<li><p><code>po("imputesample")</code> – Logical features are imputed by sampling from the empirical distribution – this only affects the <code>$predict()</code>-step.</p></li>
<li><p><code>po("missind")</code> – Missing data indicators are added for imputed numeric and logical variables.</p></li>
<li><p><code>po("imputeoor")</code> – Missing values of categorical features are encoded with a new level.</p></li>
<li><p><code>po("fixfactors")</code> – Fixes levels of categorical features such that the same levels are present during prediction and training (which may involve dropping empty factor levels).</p></li>
<li><p><code>po("imputesample")</code> – Missing values in categorical features introduced from dropping levels in the previous step are imputed by sampling from the empirical distributions.</p></li>
<li><p><code>po("collapsefactors")</code> – Categorical features levels are collapsed (starting from the rarest factors in the training data) until there are less than a certan number of levels, controlled by the <code>max_cardinality</code> argument (with a conservative default of <code>1000</code>).</p></li>
<li><p><code>po("encode")</code> – Categorical features are one-hot encoded.</p></li>
<li><p><code>po("removeconstants")</code> – Constant features that might have been created in the previous steps are removed.</p></li>
</ol>
<p><code>ppl("robustify")</code> has optional arguments <code>task</code> and <code>learner</code>. If these are provided, then the resulting pipeline will be set up to handle the given task and learner specifically, for example, it will not impute missing values if the learner has the <code>"missings"</code> property, or if there are no missing values in the task to begin with. By default, when <code>task</code> and <code>learner</code> are not provided, the graph is set up to be defensive: it imputes all missing values and converts all feature types to numerics.</p>
<p>Linear regression is a simple model that cannot handle most problems that we may face when processing data, but with the <code>ppl("robustify")</code> we can now include it in our experiment:</p>
<blockquote>
<p><code>mlr3pipelines</code>提供了一个用于插补和因子编码（以及其他任务）的简单且可重复使用的管道，称为<code>ppl("robustify")</code>，其中包括了通常在对数据进行编码或插补时可使用的明智默认设置。该管道包括以下<code>PipeOp</code>（一些被多次应用，大多数使用选择器）：</p>
<ol type="1">
<li><p><code>po("removeconstants")</code> - 删除常量特征。</p></li>
<li><p><code>po("colapply")</code> - 字符和序数特征被编码为分类特征，日期/时间特征被编码为数值特征。</p></li>
<li><p><code>po("imputehist")</code> - 通过直方图采样对数值特征进行插补。</p></li>
<li><p><code>po("imputesample")</code> - 通过从经验分布中进行采样对逻辑特征进行插补 - 这仅影响<code>$predict()</code>步骤。</p></li>
<li><p><code>po("missind")</code> - 为被插补的数值和逻辑变量添加缺失数据指示。</p></li>
<li><p><code>po("imputeoor")</code> - 使用新级别编码分类特征的缺失值。</p></li>
<li><p><code>po("fixfactors")</code> - 修复分类特征的级别，以便在预测和训练期间存在相同的级别（这可能涉及删除空的因子级别）。</p></li>
<li><p><code>po("imputesample")</code> - 通过从经验分布中进行采样来插补在前一步中删除级别引入的分类特征的缺失值。</p></li>
<li><p><code>po("collapsefactors")</code> - 折叠分类特征级别（从训练数据中最稀有的因子开始），直到级别少于由<code>max_cardinality</code>参数控制的某个数量（默认值为<code>1000</code>，具有保守性）。</p></li>
<li><p><code>po("encode")</code> - 对分类特征进行独热编码。</p></li>
<li><p><code>po("removeconstants")</code> - 删除可能在前一步中创建的常量特征。</p></li>
</ol>
<p><code>ppl("robustify")</code>具有可选参数<code>task</code>和<code>learner</code>。如果提供了这些参数，那么生成的管道将被设置为专门处理给定的任务和学习器，例如，如果学习器具有<code>"missings"</code>属性，或者任务一开始就没有缺失值，那么它将不会插补缺失值。默认情况下，当未提供<code>task</code>和<code>learner</code>时，图形被设置为具有防御性：它会对所有缺失值进行插补并将所有特征类型转换为数值型。</p>
<p>线性回归是一个简单的模型，无法处理我们在处理数据时可能面临的大多数问题，但使用<code>ppl("robustify")</code>，我们现在可以将它包括在我们的实验中。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb256"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_lm_robust</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/ppl.html">ppl</a></span><span class="op">(</span><span class="st">"robustify"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.lm"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">glrn_lm_robust</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"lm_roubst"</span></span>
<span></span>
<span><span class="va">bmr_new</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_ames</span>, <span class="va">glrn_lm_robust</span>, <span class="va">rsmp_cv3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb257"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">combine</span><span class="op">(</span><span class="va">bmr_new</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">msr_mae</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">regr.mae</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;        learner_id regr.mae</span></span>
<span><span class="co">#&gt; 1:       Baseline 56167.48</span></span>
<span><span class="co">#&gt; 2: XGB_enc_impact 16178.42</span></span>
<span><span class="co">#&gt; 3: XGB_enc_onehot 16607.33</span></span>
<span><span class="co">#&gt; 4:    RF_imp_Hist 16119.77</span></span>
<span><span class="co">#&gt; 5:     RF_imp_OOR 16180.46</span></span>
<span><span class="co">#&gt; 6:      lm_roubst 16276.56</span></span></code></pre></div>
</div>
</section><section id="transforming-features-and-targets" class="level2" data-number="9.5"><h2 data-number="9.5">
<span class="header-section-number">9.5</span> Transforming Features and Targets</h2>
<p>Simple transformations of features and the target can be beneficial (and sometimes essential) for certain learners. In particular, log transformation of the target can help in making the distribution more symmetrical and can help reduce the impact of outliers. Similarly, log transformation of skewed features can help to reduce the influence of outliers.</p>
<blockquote>
<p>对于某些学习算法，对特征和目标进行简单的转换可能是有益的（有时甚至是必不可少的）。特别是，对目标进行对数转换有助于使分布更对称，可以帮助减小异常值的影响。同样，对偏斜特征进行对数转换可以帮助减少异常值的影响。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb258"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># copy ames data</span></span>
<span><span class="va">log_ames</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/copy.html">copy</a></span><span class="op">(</span><span class="va">ames</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># log transform target</span></span>
<span><span class="va">log_ames</span><span class="op">[</span>, <span class="va">logSalePrice</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">Sale_Price</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task_regr.html">as_task_regr</a></span><span class="op">(</span><span class="va">log_ames</span>, target <span class="op">=</span> <span class="st">"Sale_Price"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task_regr.html">as_task_regr</a></span><span class="op">(</span><span class="va">log_ames</span>, target <span class="op">=</span> <span class="st">"logSalePrice"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-267-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Normalization of features may also be necessary to ensure features with a larger scale do not have a higher impact, which is especially important for distance-based methods such as k-nearest neighbors models or regularized parametric models such as Lasso or Elastic net. Many models internally scale the data if required by the algorithm so most of the time we do not need to manually do this in preprocessing, though if this is required then <code>po("scale")</code> can be used to center and scale numeric features.</p>
<p>Any transformations applied to the target during training must be inverted during model prediction to ensure predictions are made on the correct scale.</p>
<blockquote>
<p>对特征进行归一化可能也是必要的，以确保具有较大尺度的特征不会产生较大影响，这对于基于距离的方法（例如k最近邻模型）或正则化参数模型（例如Lasso或弹性网络）尤为重要。许多模型在算法需要时会自动对数据进行内部缩放，因此在预处理过程中通常不需要手动进行此操作，但如果需要的话，可以使用<code>po("scale")</code>来对数值特征进行居中和缩放。</p>
<p>在训练期间应用于目标的任何转换在模型预测期间必须被反转，以确保在正确的尺度上进行预测。</p>
</blockquote>
<p>We could manually transform and invert the target, however, this is much more complex when dealing with resampling and benchmarking experiments and so the pipeline <code>ppl("targettrafo")</code> will do this heavy lifting for you. The pipeline includes a parameter <code>targetmutate.trafo</code> for the transformation to be applied during training to the target, as well as <code>targetmutate.inverter</code> for the transformation to be applied to invert the original transformation during prediction. So now let us consider the log transformation by adding this pipeline to our robust linear regression model:</p>
<blockquote>
<p>]我们可以手动转换和反转目标变量，但是在处理重新采样和基准实验时，这会变得更加复杂。因此，管道<code>ppl("targettrafo")</code>将为您完成这项繁重的工作。该管道包括一个名为<code>targetmutate.trafo</code>的参数，用于在训练期间对目标变量应用的转换，以及一个名为<code>targetmutate.inverter</code>的参数，用于在预测时反转原始转换。现在让我们考虑通过将这个管道添加到我们的鲁棒线性回归模型中来进行对数变换：</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb259"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glrn_log_lm_robust</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/ppl.html">ppl</a></span><span class="op">(</span><span class="st">"targettrafo"</span>,</span>
<span>  graph <span class="op">=</span> <span class="va">glrn_lm_robust</span>,</span>
<span>  targetmutate.trafo <span class="op">=</span> \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,</span>
<span>  targetmutate.inverter <span class="op">=</span> \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>response <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">response</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">glrn_log_lm_robust</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"lm_robust_logtrafo"</span></span>
<span></span>
<span><span class="va">bmr_new</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_ames</span>, <span class="va">glrn_log_lm_robust</span>, <span class="va">rsmp_cv3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; This happened PipeOp lm_roubst's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; This happened PipeOp lm_roubst's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; This happened PipeOp lm_roubst's $predict()</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb260"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">combine</span><span class="op">(</span><span class="va">bmr_new</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">msr_mae</span><span class="op">)</span><span class="op">[</span>, <span class="fu">.</span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">regr.mae</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;            learner_id regr.mae</span></span>
<span><span class="co">#&gt; 1:           Baseline 56167.48</span></span>
<span><span class="co">#&gt; 2:     XGB_enc_impact 16178.42</span></span>
<span><span class="co">#&gt; 3:     XGB_enc_onehot 16607.33</span></span>
<span><span class="co">#&gt; 4:        RF_imp_Hist 16119.77</span></span>
<span><span class="co">#&gt; 5:         RF_imp_OOR 16180.46</span></span>
<span><span class="co">#&gt; 6:          lm_roubst 16276.56</span></span>
<span><span class="co">#&gt; 7: lm_robust_logtrafo 16016.36</span></span></code></pre></div>
</div>
<p>With the target transformation and the <code>ppl("robustify")</code>, the simple linear regression now appears to be the best-performing model.</p>
</section><section id="functional-feature-extraction" class="level2" data-number="9.6"><h2 data-number="9.6">
<span class="header-section-number">9.6</span> Functional Feature Extraction</h2>
<p>As a final step of data preprocessing, we will look at feature extraction from functional features. In Chapter 6 we look at automated feature selection and how automated approaches with filters and wrappers can be used to reduce a dataset to an optimized set of features. Functional feature extraction differs from this process as we are now interested in features that are dependent on one another and together may provide useful information but not individually. Figure 9.4 visualizes the difference between regular and functional features.</p>
<blockquote>
<p>作为数据预处理的最后一步，我们将看一下从功能性特征中提取特征。我们探讨了自动特征选择以及如何使用过滤器和包装器的自动方法来将数据集减少到一组优化的特征。功能性特征提取与此过程不同，因为我们现在关注的是彼此依赖的特征，它们共同可能提供有用的信息，但单独来看则不具备这种信息。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb261"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">energy_data</span> <span class="op">=</span> <span class="fu">mlr3data</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/mlr3data/man/energy_usage.html">energy_usage</a></span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb262"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">energy_data</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span><span class="op">)</span>,</span>
<span>       <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, x <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">720</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"2-Minute Interval"</span>, y <span class="op">=</span> <span class="st">"Power Consumption"</span><span class="op">)</span></span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img src="index_files/figure-html/unnamed-chunk-271-1.png" class="img-fluid" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Adding these 720 features to our full dataset is a bad idea as each individual feature does not provide meaningful information, similarly, we cannot automate selection of the best feature subset for the same reason. Instead, we can extract information about the curves to gain insights into the kitchen’s overall energy usage. For example, we could extract the maximum used wattage, overall used wattage, number of peaks, and other similar features.</p>
<p>To extract features we will write our own <code>PipeOp</code> that inherits from <code>PipeOpTaskPreprocSimple</code>. To do this we add a private method called <code>.transform_dt</code> that hardcodes the operations in our task. In this example, we select the functional features (which all start with “att”), extract the mean, minimum, maximum, and variance of the power consumption, and then remove the functional features. To read more about building custom PipeOps, open the corresponding vignette by running vignette(“extending”, package = “mlr3pipelines”) in R.</p>
<blockquote>
<p>将这720个特征添加到我们的完整数据集中是一个不好的主意，因为每个单独的特征并不提供有意义的信息，同样，由于同样的原因，我们也不能自动选择最佳的特征子集。相反，我们可以提取有关曲线的信息，以了解厨房整体能源使用情况。例如，我们可以提取最大功率使用量、总体功率使用量、峰值数量等类似的特征。</p>
<p>为了提取特征，我们将编写一个继承自<code>PipeOpTaskPreprocSimple</code>的自定义<code>PipeOp</code>。为此，我们添加一个名为<code>.transform_dt</code>的私有方法，其中包含我们任务中硬编码的操作。在这个例子中，我们选择功能性特征（它们都以“att”开头），提取功耗的均值、最小值、最大值和方差，然后删除功能性特征。要了解更多关于构建自定义<code>PipeOps</code>的信息，请在R中运行<code><a href="https://mlr3pipelines.mlr-org.com/articles/extending.html">vignette("extending", package = "mlr3pipelines")</a></code>以打开相应的文档。</p>
</blockquote>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb263"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">PipeOpFuncExtract</span> <span class="op">=</span> <span class="fu">R6</span><span class="fu">::</span><span class="kw"><a href="https://r6.r-lib.org/reference/R6Class.html">R6Class</a></span><span class="op">(</span></span>
<span>  <span class="st">"PipeOpFuncExtract"</span>,</span>
<span>  inherit <span class="op">=</span> <span class="fu">mlr3pipelines</span><span class="fu">::</span><span class="va"><a href="https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreprocSimple.html">PipeOpTaskPreprocSimple</a></span>,</span>
<span>  private <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>    .transform_dt <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">dt</span>, <span class="va">levels</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">ffeat_names</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"att"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">720</span><span class="op">)</span></span>
<span>      <span class="va">ffeats</span> <span class="op">=</span> <span class="va">dt</span><span class="op">[</span>, <span class="va">..ffeat_names</span><span class="op">]</span></span>
<span>      <span class="va">dt</span><span class="op">[</span>, <span class="va">energy_means</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">ffeats</span>, <span class="fl">1</span>, <span class="va">mean</span><span class="op">)</span><span class="op">]</span></span>
<span>      <span class="va">dt</span><span class="op">[</span>, <span class="va">energy_mins</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">ffeats</span>, <span class="fl">1</span>, <span class="va">min</span><span class="op">)</span><span class="op">]</span></span>
<span>      <span class="va">dt</span><span class="op">[</span>, <span class="va">energy_maxs</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">ffeats</span>, <span class="fl">1</span>, <span class="va">max</span><span class="op">)</span><span class="op">]</span></span>
<span>      <span class="va">dt</span><span class="op">[</span>, <span class="va">energy_vars</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">ffeats</span>, <span class="fl">1</span>, <span class="va">var</span><span class="op">)</span><span class="op">]</span></span>
<span>      <span class="va">dt</span><span class="op">[</span>, <span class="op">(</span><span class="va">ffeat_names</span><span class="op">)</span> <span class="op">:=</span> <span class="cn">NULL</span><span class="op">]</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb264"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># test PipeOp</span></span>
<span><span class="va">tsk_ames_ext</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">ames</span>, <span class="va">energy_data</span><span class="op">)</span></span>
<span><span class="va">tsk_ames_ext</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task_regr.html">as_task_regr</a></span><span class="op">(</span><span class="va">tsk_ames_ext</span>, <span class="st">"Sale_Price"</span>, <span class="st">"ames_ext"</span><span class="op">)</span></span>
<span><span class="co"># remove the redundant variables identified at the start of this chapter</span></span>
<span><span class="va">tsk_ames_ext</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sets.html">setdiff</a></span><span class="op">(</span><span class="va">tsk_ames_ext</span><span class="op">$</span><span class="va">feature_names</span>, <span class="va">to_remove</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">func_extractor</span> <span class="op">=</span> <span class="va">PipeOpFuncExtract</span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="st">"energy_extract"</span><span class="op">)</span></span>
<span><span class="va">tsk_ames_ext</span> <span class="op">=</span> <span class="va">func_extractor</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">tsk_ames_ext</span><span class="op">)</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">tsk_ames_ext</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="fl">1</span>,</span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"energy_means"</span>, <span class="st">"energy_mins"</span>, <span class="st">"energy_maxs"</span>, <span class="st">"energy_vars"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;    energy_means energy_mins energy_maxs energy_vars</span></span>
<span><span class="co">#&gt; 1:     1.061558  0.01426834    21.97755    3.708473</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb265"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">lrn_baseline</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.rpart"</span><span class="op">)</span>, <span class="va">glrn_xgb_impact</span>,</span>
<span>                <span class="va">glrn_rf_impute_oor</span>, <span class="va">glrn_lm_robust</span>, <span class="va">glrn_log_lm_robust</span><span class="op">)</span></span>
<span></span>
<span><span class="va">bmr_final</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">tsk_ames_ext</span>, <span class="va">tsk_ames</span><span class="op">)</span>, <span class="va">learners</span>, <span class="va">rsmp_cv3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; This happened PipeOp lm_roubst's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; This happened PipeOp lm_roubst's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; This happened PipeOp lm_roubst's $predict()</span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; This happened PipeOp lm_roubst's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; This happened PipeOp lm_roubst's $predict()</span></span>
<span></span>
<span><span class="co">#&gt; Warning in predict.lm(object = self$model, newdata = newdata, se.fit = se_fit): prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases</span></span>
<span><span class="co">#&gt; This happened PipeOp regr.lm's $predict()</span></span>
<span><span class="co">#&gt; This happened PipeOp lm_roubst's $predict()</span></span></code></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb266"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">perf</span> <span class="op">=</span> <span class="va">bmr_final</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">msr_mae</span><span class="op">)</span></span>
<span><span class="va">perf</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html">order</a></span><span class="op">(</span><span class="va">learner_id</span>, <span class="va">task_id</span><span class="op">)</span>, <span class="fu">.</span><span class="op">(</span><span class="va">task_id</span>, <span class="va">learner_id</span>, <span class="va">regr.mae</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;      task_id         learner_id regr.mae</span></span>
<span><span class="co">#&gt;  1:     ames           Baseline 56167.48</span></span>
<span><span class="co">#&gt;  2: ames_ext           Baseline 56167.48</span></span>
<span><span class="co">#&gt;  3:     ames         RF_imp_OOR 16204.70</span></span>
<span><span class="co">#&gt;  4: ames_ext         RF_imp_OOR 14092.83</span></span>
<span><span class="co">#&gt;  5:     ames     XGB_enc_impact 16178.42</span></span>
<span><span class="co">#&gt;  6: ames_ext     XGB_enc_impact 14354.96</span></span>
<span><span class="co">#&gt;  7:     ames lm_robust_logtrafo 16000.80</span></span>
<span><span class="co">#&gt;  8: ames_ext lm_robust_logtrafo 14036.96</span></span>
<span><span class="co">#&gt;  9:     ames          lm_roubst 16255.28</span></span>
<span><span class="co">#&gt; 10: ames_ext          lm_roubst 14856.21</span></span>
<span><span class="co">#&gt; 11:     ames         regr.rpart 28286.74</span></span>
<span><span class="co">#&gt; 12: ames_ext         regr.rpart 26433.50</span></span></code></pre></div>
</div>
<p>The final results indicate that adding these extracted features improved the performance of all models (except the featureless baseline).</p>
<p>In this example, we could have just applied the transformations to the dataset directly and not used a <code>PipeOp</code>. However, the advantage of using the <code>PipeOp</code> is that we could have chained it to a subset of learners to prevent a blow-up of experiments in the benchmark experiment.</p>
<blockquote>
<p>最终结果显示，添加这些提取的特征提高了所有模型的性能（除了没有特征的基线模型）。</p>
<p>在这个例子中，我们本可以直接将这些变换应用于数据集，而不使用<code>PipeOp</code>。然而，使用<code>PipeOp</code>的优势在于我们可以将它链接到一部分学习器上，以防止在基准实验中引发大规模的实验。</p>
</blockquote>
</section></section><section id="advanced-topics" class="level1 unnumbered"><h1 class="unnumbered">Advanced Topics</h1>
</section><section id="advanced-technical-aspects-of-mlr3" class="level1" data-number="10"><h1 data-number="10">
<span class="header-section-number">10</span> Advanced Technical Aspects of mlr3</h1>
<div class="callout callout-style-default callout-tip callout-titled" title="To be continued">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
To be continued
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="https://mlr3book.mlr-org.com/chapters/chapter10/advanced_technical_aspects_of_mlr3.html" class="uri">https://mlr3book.mlr-org.com/chapters/chapter10/advanced_technical_aspects_of_mlr3.html</a></li>
</ul>
</div>
</div>
<p>等待交叉引用：</p>
<ul>
<li>Section 10.1</li>
<li>10.1.3</li>
<li>10.2.1</li>
<li>11.3</li>
<li>13.1</li>
<li>Chapter 14</li>
</ul>
<div id="quarto-navigation-envelope" class="hidden">
<p><span class="hidden" data-render-id="quarto-int-sidebar-title">Learn-Shitao5</span> <span class="hidden" data-render-id="quarto-int-navbar-title">Learn-Shitao5</span> <span class="hidden" data-render-id="quarto-int-navbar:About">About</span> <span class="hidden" data-render-id="quarto-int-navbar:/about.html">/about.html</span> <span class="hidden" data-render-id="quarto-int-navbar:To Read">To Read</span> <span class="hidden" data-render-id="quarto-int-navbar:/toread.html">/toread.html</span> <span class="hidden" data-render-id="quarto-int-navbar:Shitao's Blog">Shitao’s Blog</span> <span class="hidden" data-render-id="quarto-int-navbar:https://shitao5.org/">https://shitao5.org/</span> <span class="hidden" data-render-id="quarto-int-navbar:https://github.com/Shitao5/">https://github.com/Shitao5/</span> <span class="hidden" data-render-id="quarto-int-navbar:/index.xml">/index.xml</span> <span class="hidden" data-render-id="footer-left">Copyright 2023, <a href="https://shitao5.org/">Shitao5</a></span> <span class="hidden" data-render-id="footer-right">This blog is built with <a href="https://quarto.org/">Quarto</a>❤️.</span></p>
</div>
<div id="quarto-meta-markdown" class="hidden">
<p><span class="hidden" data-render-id="quarto-metatitle">Learn-Shitao5 - Applied Machine Learning Using mlr3 in R</span> <span class="hidden" data-render-id="quarto-twittercardtitle">Learn-Shitao5 - Applied Machine Learning Using mlr3 in R</span> <span class="hidden" data-render-id="quarto-ogcardtitle">Learn-Shitao5 - Applied Machine Learning Using mlr3 in R</span> <span class="hidden" data-render-id="quarto-metasitename">Learn-Shitao5</span> <span class="hidden" data-render-id="quarto-twittercarddesc"></span> <span class="hidden" data-render-id="quarto-ogcardddesc"></span></p>
</div>
<!-- -->
<div class="quarto-embedded-source-code">
<div class="sourceCode" id="cb267" data-shortcodes="false"><pre class="sourceCode markdown"><code class="sourceCode markdown"><span id="cb267-1"><a href="#cb267-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb267-2"><a href="#cb267-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Applied Machine Learning Using mlr3 in R"</span></span>
<span id="cb267-3"><a href="#cb267-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-08-16"</span></span>
<span id="cb267-4"><a href="#cb267-4" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> "2023-10-23"</span></span>
<span id="cb267-5"><a href="#cb267-5" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "logo.png"</span></span>
<span id="cb267-6"><a href="#cb267-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> </span></span>
<span id="cb267-7"><a href="#cb267-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Machine Learning</span></span>
<span id="cb267-8"><a href="#cb267-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - R</span></span>
<span id="cb267-9"><a href="#cb267-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - mlr3</span></span>
<span id="cb267-10"><a href="#cb267-10" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb267-11"><a href="#cb267-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-12"><a href="#cb267-12" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title='Progress'}</span>
<span id="cb267-13"><a href="#cb267-13" aria-hidden="true" tabindex="-1"></a><span class="in">`r stfun::progress(9, 15)`</span></span>
<span id="cb267-14"><a href="#cb267-14" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb267-15"><a href="#cb267-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-16"><a href="#cb267-16" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Learning Source"}</span>
<span id="cb267-17"><a href="#cb267-17" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="ot">&lt;https://mlr3book.mlr-org.com/&gt;</span></span>
<span id="cb267-18"><a href="#cb267-18" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>中文翻译由 ChatGPT 3.5 提供</span>
<span id="cb267-19"><a href="#cb267-19" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb267-20"><a href="#cb267-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-21"><a href="#cb267-21" aria-hidden="true" tabindex="-1"></a><span class="fu"># Getting Started {.unnumbered}</span></span>
<span id="cb267-22"><a href="#cb267-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-23"><a href="#cb267-23" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-24"><a href="#cb267-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-25"><a href="#cb267-25" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-26"><a href="#cb267-26" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb267-27"><a href="#cb267-27" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb267-28"><a href="#cb267-28" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3pipelines)</span>
<span id="cb267-29"><a href="#cb267-29" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3benchmark)</span>
<span id="cb267-30"><a href="#cb267-30" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3hyperband)</span>
<span id="cb267-31"><a href="#cb267-31" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb267-32"><a href="#cb267-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb267-33"><a href="#cb267-33" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb267-34"><a href="#cb267-34" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-35"><a href="#cb267-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-36"><a href="#cb267-36" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-37"><a href="#cb267-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-38"><a href="#cb267-38" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-39"><a href="#cb267-39" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb267-40"><a href="#cb267-40" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb267-41"><a href="#cb267-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-42"><a href="#cb267-42" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span>
<span id="cb267-43"><a href="#cb267-43" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">datatable.print.topn =</span> <span class="dv">4</span>)</span>
<span id="cb267-44"><a href="#cb267-44" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-45"><a href="#cb267-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-46"><a href="#cb267-46" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction and Overview</span></span>
<span id="cb267-47"><a href="#cb267-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-48"><a href="#cb267-48" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3`</span> by Example:</span>
<span id="cb267-49"><a href="#cb267-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-50"><a href="#cb267-50" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-51"><a href="#cb267-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-52"><a href="#cb267-52" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-53"><a href="#cb267-53" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb267-54"><a href="#cb267-54" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb267-55"><a href="#cb267-55" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb267-56"><a href="#cb267-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-57"><a href="#cb267-57" aria-hidden="true" tabindex="-1"></a>task <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-58"><a href="#cb267-58" aria-hidden="true" tabindex="-1"></a>split <span class="ot">=</span> <span class="fu">partition</span>(task)</span>
<span id="cb267-59"><a href="#cb267-59" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>)</span>
<span id="cb267-60"><a href="#cb267-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-61"><a href="#cb267-61" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span><span class="fu">train</span>(task, <span class="at">row_ids =</span> split<span class="sc">$</span>train)</span>
<span id="cb267-62"><a href="#cb267-62" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span>model</span>
<span id="cb267-63"><a href="#cb267-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-64"><a href="#cb267-64" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> learner<span class="sc">$</span><span class="fu">predict</span>(task, <span class="at">row_ids =</span> split<span class="sc">$</span>test)</span>
<span id="cb267-65"><a href="#cb267-65" aria-hidden="true" tabindex="-1"></a>prediction</span>
<span id="cb267-66"><a href="#cb267-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-67"><a href="#cb267-67" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span>
<span id="cb267-68"><a href="#cb267-68" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-69"><a href="#cb267-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-70"><a href="#cb267-70" aria-hidden="true" tabindex="-1"></a>The <span class="in">`mlr3`</span> interface also lets you run more complicated experiments in just a few lines of code:</span>
<span id="cb267-71"><a href="#cb267-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-72"><a href="#cb267-72" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-73"><a href="#cb267-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-74"><a href="#cb267-74" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-75"><a href="#cb267-75" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-76"><a href="#cb267-76" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb267-77"><a href="#cb267-77" aria-hidden="true" tabindex="-1"></a>tasks <span class="ot">=</span> <span class="fu">tsks</span>(<span class="fu">c</span>(<span class="st">"breast_cancer"</span>, <span class="st">"sonar"</span>))</span>
<span id="cb267-78"><a href="#cb267-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-79"><a href="#cb267-79" aria-hidden="true" tabindex="-1"></a>glrn_rf_tuned <span class="ot">=</span> <span class="fu">as_learner</span>(</span>
<span id="cb267-80"><a href="#cb267-80" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ppl</span>(<span class="st">"robustify"</span>) <span class="sc">%&gt;&gt;%</span> </span>
<span id="cb267-81"><a href="#cb267-81" aria-hidden="true" tabindex="-1"></a>    <span class="fu">auto_tuner</span>(<span class="fu">tnr</span>(<span class="st">"grid_search"</span>, <span class="at">resolution =</span> <span class="dv">5</span>),</span>
<span id="cb267-82"><a href="#cb267-82" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>, <span class="at">num.trees =</span> <span class="fu">to_tune</span>(<span class="dv">200</span>, <span class="dv">500</span>)),</span>
<span id="cb267-83"><a href="#cb267-83" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rsmp</span>(<span class="st">"holdout"</span>))</span>
<span id="cb267-84"><a href="#cb267-84" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-85"><a href="#cb267-85" aria-hidden="true" tabindex="-1"></a>glrn_rf_tuned<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"RF"</span></span>
<span id="cb267-86"><a href="#cb267-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-87"><a href="#cb267-87" aria-hidden="true" tabindex="-1"></a><span class="co"># 这里报错</span></span>
<span id="cb267-88"><a href="#cb267-88" aria-hidden="true" tabindex="-1"></a>glrn_stack <span class="ot">=</span> <span class="fu">as_learner</span>(<span class="fu">ppl</span>(<span class="st">"robustify"</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">ppl</span>(<span class="st">"stacking"</span>,</span>
<span id="cb267-89"><a href="#cb267-89" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lrns</span>(<span class="fu">c</span>(<span class="st">"classif.rpart"</span>, <span class="st">"classif.kknn"</span>)),</span>
<span id="cb267-90"><a href="#cb267-90" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lrn</span>(<span class="st">"classif.log_reg"</span>)</span>
<span id="cb267-91"><a href="#cb267-91" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb267-92"><a href="#cb267-92" aria-hidden="true" tabindex="-1"></a>glrn_stack<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"Stack"</span></span>
<span id="cb267-93"><a href="#cb267-93" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-94"><a href="#cb267-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-95"><a href="#cb267-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-96"><a href="#cb267-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-97"><a href="#cb267-97" aria-hidden="true" tabindex="-1"></a>We use dictionaries to group large collections of relevant objects so they can be listed and retrieved easily.</span>
<span id="cb267-98"><a href="#cb267-98" aria-hidden="true" tabindex="-1"></a>For example, you can see an overview of available learners (that are in loaded packages) and their properties with <span class="in">`as.data.table(mlr_learners)`</span> or by calling the sugar function without any arguments, e.g. <span class="in">`lrn()`</span>.</span>
<span id="cb267-99"><a href="#cb267-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-100"><a href="#cb267-100" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们使用字典来分组大量相关对象，以便可以轻松地列出和检索它们。例如，您可以通过 </span><span class="in">`as.data.table(mlr_learners)`</span><span class="at"> 查看可用学习器（位于加载的包中）及其属性的概述，或者通过调用糖函数而不带任何参数，例如 </span><span class="in">`lrn()`</span><span class="at">。</span></span>
<span id="cb267-101"><a href="#cb267-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-102"><a href="#cb267-102" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-103"><a href="#cb267-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-104"><a href="#cb267-104" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-105"><a href="#cb267-105" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(mlr_learners)[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb267-106"><a href="#cb267-106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-107"><a href="#cb267-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-108"><a href="#cb267-108" aria-hidden="true" tabindex="-1"></a><span class="fu"># Fundamentals {.unnumbered}</span></span>
<span id="cb267-109"><a href="#cb267-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-110"><a href="#cb267-110" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data and Basic Modeling</span></span>
<span id="cb267-111"><a href="#cb267-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-112"><a href="#cb267-112" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tasks</span></span>
<span id="cb267-113"><a href="#cb267-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-114"><a href="#cb267-114" aria-hidden="true" tabindex="-1"></a><span class="fu">### Constructing Tasks</span></span>
<span id="cb267-115"><a href="#cb267-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-116"><a href="#cb267-116" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3`</span> includes a few predefined machine learning tasks in the <span class="in">`mlr_tasks`</span> Dictionary.</span>
<span id="cb267-117"><a href="#cb267-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-118"><a href="#cb267-118" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-119"><a href="#cb267-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-120"><a href="#cb267-120" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-121"><a href="#cb267-121" aria-hidden="true" tabindex="-1"></a>mlr_tasks</span>
<span id="cb267-122"><a href="#cb267-122" aria-hidden="true" tabindex="-1"></a><span class="co"># the same as </span></span>
<span id="cb267-123"><a href="#cb267-123" aria-hidden="true" tabindex="-1"></a><span class="co"># tsk()</span></span>
<span id="cb267-124"><a href="#cb267-124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-125"><a href="#cb267-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-126"><a href="#cb267-126" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-127"><a href="#cb267-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-128"><a href="#cb267-128" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-129"><a href="#cb267-129" aria-hidden="true" tabindex="-1"></a>tsk_mtcars <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"mtcars"</span>)</span>
<span id="cb267-130"><a href="#cb267-130" aria-hidden="true" tabindex="-1"></a>tsk_mtcars</span>
<span id="cb267-131"><a href="#cb267-131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-132"><a href="#cb267-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-133"><a href="#cb267-133" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-134"><a href="#cb267-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-135"><a href="#cb267-135" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-136"><a href="#cb267-136" aria-hidden="true" tabindex="-1"></a><span class="co"># create my own regression task</span></span>
<span id="cb267-137"><a href="#cb267-137" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"mtcars"</span>, <span class="at">package =</span> <span class="st">"datasets"</span>)</span>
<span id="cb267-138"><a href="#cb267-138" aria-hidden="true" tabindex="-1"></a>mtcars_subset <span class="ot">=</span> <span class="fu">subset</span>(mtcars, <span class="at">select =</span> <span class="fu">c</span>(<span class="st">"mpg"</span>, <span class="st">"cyl"</span>, <span class="st">"disp"</span>))</span>
<span id="cb267-139"><a href="#cb267-139" aria-hidden="true" tabindex="-1"></a>tsk_mtcars <span class="ot">=</span> <span class="fu">as_task_regr</span>(mtcars_subset, <span class="at">target =</span> <span class="st">"mpg"</span>, <span class="at">id =</span> <span class="st">"cars"</span>)</span>
<span id="cb267-140"><a href="#cb267-140" aria-hidden="true" tabindex="-1"></a>tsk_mtcars</span>
<span id="cb267-141"><a href="#cb267-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-142"><a href="#cb267-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-143"><a href="#cb267-143" aria-hidden="true" tabindex="-1"></a>The <span class="in">`id`</span> argument is optional and specifies an identifier for the task that is used in plots and summaries; if omitted the variable name of the data will be used as the <span class="in">`id`</span>.</span>
<span id="cb267-144"><a href="#cb267-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-145"><a href="#cb267-145" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-146"><a href="#cb267-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-147"><a href="#cb267-147" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-148"><a href="#cb267-148" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb267-149"><a href="#cb267-149" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3viz)</span>
<span id="cb267-150"><a href="#cb267-150" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tsk_mtcars, <span class="at">type =</span> <span class="st">"pairs"</span>)</span>
<span id="cb267-151"><a href="#cb267-151" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-152"><a href="#cb267-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-153"><a href="#cb267-153" aria-hidden="true" tabindex="-1"></a><span class="fu">### Retrieving Data</span></span>
<span id="cb267-154"><a href="#cb267-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-155"><a href="#cb267-155" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-156"><a href="#cb267-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-157"><a href="#cb267-157" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-158"><a href="#cb267-158" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(tsk_mtcars<span class="sc">$</span>nrow, tsk_mtcars<span class="sc">$</span>ncol)</span>
<span id="cb267-159"><a href="#cb267-159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-160"><a href="#cb267-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-161"><a href="#cb267-161" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-162"><a href="#cb267-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-163"><a href="#cb267-163" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-164"><a href="#cb267-164" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">Features =</span> tsk_mtcars<span class="sc">$</span>feature_names,</span>
<span id="cb267-165"><a href="#cb267-165" aria-hidden="true" tabindex="-1"></a>  <span class="at">Target =</span> tsk_mtcars<span class="sc">$</span>target_names)</span>
<span id="cb267-166"><a href="#cb267-166" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-167"><a href="#cb267-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-168"><a href="#cb267-168" aria-hidden="true" tabindex="-1"></a>Row IDs are not used as features when training or predicting but are metadata that allow access to individual observations. Note that row IDs are not the same as row numbers.</span>
<span id="cb267-169"><a href="#cb267-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-170"><a href="#cb267-170" aria-hidden="true" tabindex="-1"></a>This design decision allows tasks and learners to transparently operate on real database management systems, where primary keys are required to be unique, but not necessarily consecutive.</span>
<span id="cb267-171"><a href="#cb267-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-172"><a href="#cb267-172" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 行ID在训练或预测时不作为特征使用，而是元数据，用于访问个别观测数据。需要注意的是，行ID与行号不同。</span></span>
<span id="cb267-173"><a href="#cb267-173" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-174"><a href="#cb267-174" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 这种设计决策使得任务和学习器能够透明地在真实的数据库管理系统上运行，其中要求主键是唯一的，但不一定连续。</span></span>
<span id="cb267-175"><a href="#cb267-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-176"><a href="#cb267-176" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-177"><a href="#cb267-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-178"><a href="#cb267-178" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-179"><a href="#cb267-179" aria-hidden="true" tabindex="-1"></a>task <span class="ot">=</span> <span class="fu">as_task_regr</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">5</span>), <span class="at">y =</span> <span class="fu">runif</span>(<span class="dv">5</span>)),</span>
<span id="cb267-180"><a href="#cb267-180" aria-hidden="true" tabindex="-1"></a>                    <span class="at">target =</span> <span class="st">"y"</span>)</span>
<span id="cb267-181"><a href="#cb267-181" aria-hidden="true" tabindex="-1"></a>task<span class="sc">$</span>row_ids</span>
<span id="cb267-182"><a href="#cb267-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-183"><a href="#cb267-183" aria-hidden="true" tabindex="-1"></a>task<span class="sc">$</span><span class="fu">filter</span>(<span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb267-184"><a href="#cb267-184" aria-hidden="true" tabindex="-1"></a>task<span class="sc">$</span>row_ids</span>
<span id="cb267-185"><a href="#cb267-185" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-186"><a href="#cb267-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-187"><a href="#cb267-187" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-188"><a href="#cb267-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-189"><a href="#cb267-189" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-190"><a href="#cb267-190" aria-hidden="true" tabindex="-1"></a>tsk_mtcars<span class="sc">$</span><span class="fu">data</span>()[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb267-191"><a href="#cb267-191" aria-hidden="true" tabindex="-1"></a>tsk_mtcars<span class="sc">$</span><span class="fu">data</span>(<span class="at">rows =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>), <span class="at">cols =</span> tsk_mtcars<span class="sc">$</span>feature_names)</span>
<span id="cb267-192"><a href="#cb267-192" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-193"><a href="#cb267-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-194"><a href="#cb267-194" aria-hidden="true" tabindex="-1"></a><span class="fu">### Task Mutators</span></span>
<span id="cb267-195"><a href="#cb267-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-196"><a href="#cb267-196" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-197"><a href="#cb267-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-198"><a href="#cb267-198" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-199"><a href="#cb267-199" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_small <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"mtcars"</span>)</span>
<span id="cb267-200"><a href="#cb267-200" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_small<span class="sc">$</span><span class="fu">select</span>(<span class="st">"cyl"</span>)</span>
<span id="cb267-201"><a href="#cb267-201" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_small<span class="sc">$</span><span class="fu">filter</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>)</span>
<span id="cb267-202"><a href="#cb267-202" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_small<span class="sc">$</span><span class="fu">data</span>()</span>
<span id="cb267-203"><a href="#cb267-203" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-204"><a href="#cb267-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-205"><a href="#cb267-205" aria-hidden="true" tabindex="-1"></a>As <span class="in">`R6`</span> uses reference semantics, you need to use <span class="in">`$clone()`</span> if you want to modify a task while keeping the original object intact.</span>
<span id="cb267-206"><a href="#cb267-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-207"><a href="#cb267-207" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-208"><a href="#cb267-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-209"><a href="#cb267-209" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-210"><a href="#cb267-210" aria-hidden="true" tabindex="-1"></a>tsk_mtcars <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"mtcars"</span>)</span>
<span id="cb267-211"><a href="#cb267-211" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_clone <span class="ot">=</span> tsk_mtcars<span class="sc">$</span><span class="fu">clone</span>()</span>
<span id="cb267-212"><a href="#cb267-212" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_clone<span class="sc">$</span><span class="fu">filter</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)</span>
<span id="cb267-213"><a href="#cb267-213" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_clone<span class="sc">$</span><span class="fu">head</span>()</span>
<span id="cb267-214"><a href="#cb267-214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-215"><a href="#cb267-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-216"><a href="#cb267-216" aria-hidden="true" tabindex="-1"></a>To add extra rows and columns to a task, you can use <span class="in">`$rbind()`</span> and <span class="in">`$cbind()`</span> respectively:</span>
<span id="cb267-217"><a href="#cb267-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-218"><a href="#cb267-218" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-219"><a href="#cb267-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-220"><a href="#cb267-220" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-221"><a href="#cb267-221" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_small</span>
<span id="cb267-222"><a href="#cb267-222" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_small<span class="sc">$</span><span class="fu">cbind</span>(<span class="fu">data.frame</span>(<span class="at">disp =</span> <span class="fu">c</span>(<span class="dv">150</span>, <span class="dv">160</span>)))</span>
<span id="cb267-223"><a href="#cb267-223" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_small<span class="sc">$</span><span class="fu">rbind</span>(<span class="fu">data.frame</span>(<span class="at">mpg =</span> <span class="dv">23</span>, <span class="at">cyl =</span> <span class="dv">5</span>, <span class="at">disp =</span> <span class="dv">170</span>))</span>
<span id="cb267-224"><a href="#cb267-224" aria-hidden="true" tabindex="-1"></a>tsk_mtcars_small<span class="sc">$</span><span class="fu">data</span>()</span>
<span id="cb267-225"><a href="#cb267-225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-226"><a href="#cb267-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-227"><a href="#cb267-227" aria-hidden="true" tabindex="-1"></a><span class="fu">## Learners</span></span>
<span id="cb267-228"><a href="#cb267-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-229"><a href="#cb267-229" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-230"><a href="#cb267-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-231"><a href="#cb267-231" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-232"><a href="#cb267-232" aria-hidden="true" tabindex="-1"></a><span class="co"># all the learners available in mlr3</span></span>
<span id="cb267-233"><a href="#cb267-233" aria-hidden="true" tabindex="-1"></a>mlr_learners</span>
<span id="cb267-234"><a href="#cb267-234" aria-hidden="true" tabindex="-1"></a><span class="co"># lrns()</span></span>
<span id="cb267-235"><a href="#cb267-235" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-236"><a href="#cb267-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-237"><a href="#cb267-237" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-238"><a href="#cb267-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-239"><a href="#cb267-239" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-240"><a href="#cb267-240" aria-hidden="true" tabindex="-1"></a><span class="fu">lrn</span>(<span class="st">"regr.rpart"</span>)</span>
<span id="cb267-241"><a href="#cb267-241" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-242"><a href="#cb267-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-243"><a href="#cb267-243" aria-hidden="true" tabindex="-1"></a>All <span class="in">`Learner`</span> objects include the following metadata, which can be seen in the output above:</span>
<span id="cb267-244"><a href="#cb267-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-245"><a href="#cb267-245" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`$feature_types`</span>: the type of features the learner can handle.</span>
<span id="cb267-246"><a href="#cb267-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-247"><a href="#cb267-247" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`$packages`</span>: the packages required to be installed to use the learner.</span>
<span id="cb267-248"><a href="#cb267-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-249"><a href="#cb267-249" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`$properties`</span>: the properties of the learner. For example, the “missings” properties means a model can handle missing data, and “importance” means it can compute the relative importance of each feature.</span>
<span id="cb267-250"><a href="#cb267-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-251"><a href="#cb267-251" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`$predict_types`</span>: the types of prediction that the model can make.</span>
<span id="cb267-252"><a href="#cb267-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-253"><a href="#cb267-253" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`$param_set`</span>: the set of available hyperparameters.</span>
<span id="cb267-254"><a href="#cb267-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-255"><a href="#cb267-255" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training</span></span>
<span id="cb267-256"><a href="#cb267-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-257"><a href="#cb267-257" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-258"><a href="#cb267-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-259"><a href="#cb267-259" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-260"><a href="#cb267-260" aria-hidden="true" tabindex="-1"></a><span class="co"># load mtcars task</span></span>
<span id="cb267-261"><a href="#cb267-261" aria-hidden="true" tabindex="-1"></a>tsk_mtcars <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"mtcars"</span>)</span>
<span id="cb267-262"><a href="#cb267-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-263"><a href="#cb267-263" aria-hidden="true" tabindex="-1"></a><span class="co"># load a regression tree</span></span>
<span id="cb267-264"><a href="#cb267-264" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.rpart"</span>)</span>
<span id="cb267-265"><a href="#cb267-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-266"><a href="#cb267-266" aria-hidden="true" tabindex="-1"></a><span class="co"># pass the task to the learner via $train()</span></span>
<span id="cb267-267"><a href="#cb267-267" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(tsk_mtcars)</span>
<span id="cb267-268"><a href="#cb267-268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-269"><a href="#cb267-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-270"><a href="#cb267-270" aria-hidden="true" tabindex="-1"></a>After training, the fitted model is stored in the <span class="in">`$model`</span> field for future inspection and prediction:</span>
<span id="cb267-271"><a href="#cb267-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-272"><a href="#cb267-272" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-273"><a href="#cb267-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-274"><a href="#cb267-274" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-275"><a href="#cb267-275" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span>model</span>
<span id="cb267-276"><a href="#cb267-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-277"><a href="#cb267-277" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">=</span> <span class="fu">partition</span>(tsk_mtcars)</span>
<span id="cb267-278"><a href="#cb267-278" aria-hidden="true" tabindex="-1"></a>splits</span>
<span id="cb267-279"><a href="#cb267-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-280"><a href="#cb267-280" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(tsk_mtcars, <span class="at">row_ids =</span> splits<span class="sc">$</span>train)</span>
<span id="cb267-281"><a href="#cb267-281" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-282"><a href="#cb267-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-283"><a href="#cb267-283" aria-hidden="true" tabindex="-1"></a><span class="fu">### Predicting</span></span>
<span id="cb267-284"><a href="#cb267-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-285"><a href="#cb267-285" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-286"><a href="#cb267-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-287"><a href="#cb267-287" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-288"><a href="#cb267-288" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_rpart<span class="sc">$</span><span class="fu">predict</span>(tsk_mtcars, <span class="at">row_ids =</span> splits<span class="sc">$</span>test)</span>
<span id="cb267-289"><a href="#cb267-289" aria-hidden="true" tabindex="-1"></a>prediction</span>
<span id="cb267-290"><a href="#cb267-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-291"><a href="#cb267-291" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(prediction)</span>
<span id="cb267-292"><a href="#cb267-292" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-293"><a href="#cb267-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-294"><a href="#cb267-294" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-295"><a href="#cb267-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-296"><a href="#cb267-296" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-297"><a href="#cb267-297" aria-hidden="true" tabindex="-1"></a>mtcars_new <span class="ot">=</span> <span class="fu">data.table</span>(<span class="at">cyl =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>), <span class="at">disp =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">120</span>),</span>
<span id="cb267-298"><a href="#cb267-298" aria-hidden="true" tabindex="-1"></a>  <span class="at">hp =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">150</span>), <span class="at">drat =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="fl">3.9</span>), <span class="at">wt =</span> <span class="fu">c</span>(<span class="fl">3.8</span>, <span class="fl">4.1</span>),</span>
<span id="cb267-299"><a href="#cb267-299" aria-hidden="true" tabindex="-1"></a>  <span class="at">qsec =</span> <span class="fu">c</span>(<span class="dv">18</span>, <span class="fl">19.5</span>), <span class="at">vs =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="at">am =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb267-300"><a href="#cb267-300" aria-hidden="true" tabindex="-1"></a>  <span class="at">gear =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">4</span>), <span class="at">carb =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>))</span>
<span id="cb267-301"><a href="#cb267-301" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_rpart<span class="sc">$</span><span class="fu">predict_newdata</span>(mtcars_new)</span>
<span id="cb267-302"><a href="#cb267-302" aria-hidden="true" tabindex="-1"></a>prediction</span>
<span id="cb267-303"><a href="#cb267-303" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-304"><a href="#cb267-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-305"><a href="#cb267-305" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hyperparameters</span></span>
<span id="cb267-306"><a href="#cb267-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-307"><a href="#cb267-307" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-308"><a href="#cb267-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-309"><a href="#cb267-309" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-310"><a href="#cb267-310" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span>param_set</span>
<span id="cb267-311"><a href="#cb267-311" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-312"><a href="#cb267-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-313"><a href="#cb267-313" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-314"><a href="#cb267-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-315"><a href="#cb267-315" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-316"><a href="#cb267-316" aria-hidden="true" tabindex="-1"></a><span class="co"># change hyperparameter</span></span>
<span id="cb267-317"><a href="#cb267-317" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.rpart"</span>, <span class="at">maxdepth =</span> <span class="dv">1</span>)</span>
<span id="cb267-318"><a href="#cb267-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-319"><a href="#cb267-319" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span>param_set<span class="sc">$</span>values</span>
<span id="cb267-320"><a href="#cb267-320" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-321"><a href="#cb267-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-322"><a href="#cb267-322" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-323"><a href="#cb267-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-324"><a href="#cb267-324" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-325"><a href="#cb267-325" aria-hidden="true" tabindex="-1"></a><span class="co"># learned regression tree</span></span>
<span id="cb267-326"><a href="#cb267-326" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(<span class="fu">tsk</span>(<span class="st">"mtcars"</span>))<span class="sc">$</span>model</span>
<span id="cb267-327"><a href="#cb267-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-328"><a href="#cb267-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-329"><a href="#cb267-329" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-330"><a href="#cb267-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-331"><a href="#cb267-331" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-332"><a href="#cb267-332" aria-hidden="true" tabindex="-1"></a><span class="co"># another way to update hyperparameters</span></span>
<span id="cb267-333"><a href="#cb267-333" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span>param_set<span class="sc">$</span>values<span class="sc">$</span>maxdepth <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb267-334"><a href="#cb267-334" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span>param_set<span class="sc">$</span>values</span>
<span id="cb267-335"><a href="#cb267-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-336"><a href="#cb267-336" aria-hidden="true" tabindex="-1"></a><span class="co"># now with depth 2</span></span>
<span id="cb267-337"><a href="#cb267-337" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(<span class="fu">tsk</span>(<span class="st">"mtcars"</span>))<span class="sc">$</span>model</span>
<span id="cb267-338"><a href="#cb267-338" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-339"><a href="#cb267-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-340"><a href="#cb267-340" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-341"><a href="#cb267-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-342"><a href="#cb267-342" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-343"><a href="#cb267-343" aria-hidden="true" tabindex="-1"></a><span class="co"># or with set_values()</span></span>
<span id="cb267-344"><a href="#cb267-344" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">set_values</span>(<span class="at">xval =</span> <span class="dv">2</span>, <span class="at">cp =</span> .<span class="dv">5</span>)</span>
<span id="cb267-345"><a href="#cb267-345" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span>param_set<span class="sc">$</span>values</span>
<span id="cb267-346"><a href="#cb267-346" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-347"><a href="#cb267-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-348"><a href="#cb267-348" aria-hidden="true" tabindex="-1"></a><span class="fu">### Baseline Learners</span></span>
<span id="cb267-349"><a href="#cb267-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-350"><a href="#cb267-350" aria-hidden="true" tabindex="-1"></a>Baselines are useful in model comparison and as fallback learners. For regression, we have implemented the baseline <span class="in">`lrn("regr.featureless")`</span>, which always predicts new values to be the mean (or median, if the <span class="in">`robust`</span> hyperparameter is set to <span class="in">`TRUE`</span>) of the target in the training data:</span>
<span id="cb267-351"><a href="#cb267-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-352"><a href="#cb267-352" aria-hidden="true" tabindex="-1"></a>基线在模型比较和作为备用学习器中非常有用。对于回归问题，我们已经实现了名为 <span class="in">`lrn("regr.featureless")`</span> 的基线，它总是预测新值为训练数据中目标的均值（如果鲁棒性参数设置为 <span class="in">`TRUE`</span>，则为中位数）：</span>
<span id="cb267-353"><a href="#cb267-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-354"><a href="#cb267-354" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-355"><a href="#cb267-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-356"><a href="#cb267-356" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-357"><a href="#cb267-357" aria-hidden="true" tabindex="-1"></a>task <span class="ot">=</span> <span class="fu">as_task_regr</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">1000</span>), <span class="at">y =</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="dv">2</span>, <span class="dv">1</span>)),</span>
<span id="cb267-358"><a href="#cb267-358" aria-hidden="true" tabindex="-1"></a>                    <span class="at">target =</span> <span class="st">"y"</span>)</span>
<span id="cb267-359"><a href="#cb267-359" aria-hidden="true" tabindex="-1"></a><span class="fu">lrn</span>(<span class="st">"regr.featureless"</span>)<span class="sc">$</span><span class="fu">train</span>(task, <span class="dv">1</span><span class="sc">:</span><span class="dv">995</span>)<span class="sc">$</span><span class="fu">predict</span>(task, <span class="dv">996</span><span class="sc">:</span><span class="dv">1000</span>)</span>
<span id="cb267-360"><a href="#cb267-360" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-361"><a href="#cb267-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-362"><a href="#cb267-362" aria-hidden="true" tabindex="-1"></a>It is good practice to test all new models against a baseline, and also to include baselines in experiments with multiple other models. In general, a model that does not outperform a baseline is a ‘bad’ model, on the other hand, a model is not necessarily ‘good’ if it outperforms the baseline.</span>
<span id="cb267-363"><a href="#cb267-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-364"><a href="#cb267-364" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在实践中，对所有新模型进行与基线的测试是一个良好的做法，同时在与多个其他模型进行实验时也要包括基线。通常情况下，如果一个模型无法超越基线，那么它可以被视为是一个不好的模型；另一方面，如果一个模型超越了基线，也不一定就是一个好模型。</span></span>
<span id="cb267-365"><a href="#cb267-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-366"><a href="#cb267-366" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluation</span></span>
<span id="cb267-367"><a href="#cb267-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-368"><a href="#cb267-368" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-369"><a href="#cb267-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-370"><a href="#cb267-370" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-371"><a href="#cb267-371" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.rpart"</span>)</span>
<span id="cb267-372"><a href="#cb267-372" aria-hidden="true" tabindex="-1"></a>tsk_mtcars <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"mtcars"</span>)</span>
<span id="cb267-373"><a href="#cb267-373" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">=</span> <span class="fu">partition</span>(tsk_mtcars)</span>
<span id="cb267-374"><a href="#cb267-374" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(tsk_mtcars, splits<span class="sc">$</span>train)</span>
<span id="cb267-375"><a href="#cb267-375" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_rpart<span class="sc">$</span><span class="fu">predict</span>(tsk_mtcars, splits<span class="sc">$</span>test)</span>
<span id="cb267-376"><a href="#cb267-376" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-377"><a href="#cb267-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-378"><a href="#cb267-378" aria-hidden="true" tabindex="-1"></a><span class="fu">### Measures</span></span>
<span id="cb267-379"><a href="#cb267-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-380"><a href="#cb267-380" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-381"><a href="#cb267-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-382"><a href="#cb267-382" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-383"><a href="#cb267-383" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(<span class="fu">msr</span>())[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb267-384"><a href="#cb267-384" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-385"><a href="#cb267-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-386"><a href="#cb267-386" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-387"><a href="#cb267-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-388"><a href="#cb267-388" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-389"><a href="#cb267-389" aria-hidden="true" tabindex="-1"></a>measure <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"regr.mae"</span>)</span>
<span id="cb267-390"><a href="#cb267-390" aria-hidden="true" tabindex="-1"></a>measure</span>
<span id="cb267-391"><a href="#cb267-391" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-392"><a href="#cb267-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-393"><a href="#cb267-393" aria-hidden="true" tabindex="-1"></a><span class="fu">### Scoring Predictions</span></span>
<span id="cb267-394"><a href="#cb267-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-395"><a href="#cb267-395" aria-hidden="true" tabindex="-1"></a>Note that all task types have default measures that are used if the argument to <span class="in">`$score()`</span> is omitted, for regression this is the mean squared error (<span class="in">`msr("regr.mse")`</span>).</span>
<span id="cb267-396"><a href="#cb267-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-397"><a href="#cb267-397" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-398"><a href="#cb267-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-399"><a href="#cb267-399" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-400"><a href="#cb267-400" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>()</span>
<span id="cb267-401"><a href="#cb267-401" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(measure)</span>
<span id="cb267-402"><a href="#cb267-402" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"regr.mse"</span>, <span class="st">"regr.mae"</span>)))</span>
<span id="cb267-403"><a href="#cb267-403" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-404"><a href="#cb267-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-405"><a href="#cb267-405" aria-hidden="true" tabindex="-1"></a><span class="fu">### Technical Measures</span></span>
<span id="cb267-406"><a href="#cb267-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-407"><a href="#cb267-407" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3`</span> also provides measures that do not quantify the quality of the predictions of a model, but instead provide ‘meta’-information about the model. These include:</span>
<span id="cb267-408"><a href="#cb267-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-409"><a href="#cb267-409" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`msr("time_train")`</span>: The time taken to train a model.</span>
<span id="cb267-410"><a href="#cb267-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-411"><a href="#cb267-411" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`msr("time_predict")`</span>: The time taken for the model to make predictions.</span>
<span id="cb267-412"><a href="#cb267-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-413"><a href="#cb267-413" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`msr("time_both")`</span>: The total time taken to train the model and then make predictions.</span>
<span id="cb267-414"><a href="#cb267-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-415"><a href="#cb267-415" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`msr("selected_features")`</span>: The number of features selected by a model, which can only be used if the model has the “selected_features” property.</span>
<span id="cb267-416"><a href="#cb267-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-417"><a href="#cb267-417" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-418"><a href="#cb267-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-419"><a href="#cb267-419" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-420"><a href="#cb267-420" aria-hidden="true" tabindex="-1"></a>measures <span class="ot">=</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"time_train"</span>, <span class="st">"time_predict"</span>, <span class="st">"time_both"</span>))</span>
<span id="cb267-421"><a href="#cb267-421" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(measures, <span class="at">learner =</span> lrn_rpart)</span>
<span id="cb267-422"><a href="#cb267-422" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-423"><a href="#cb267-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-424"><a href="#cb267-424" aria-hidden="true" tabindex="-1"></a>These can be used after model training and predicting because we automatically store model run times whenever <span class="in">`$train()`</span> and <span class="in">`$predict()`</span> are called, so the measures above are equivalent to:</span>
<span id="cb267-425"><a href="#cb267-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-426"><a href="#cb267-426" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-427"><a href="#cb267-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-428"><a href="#cb267-428" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-429"><a href="#cb267-429" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(lrn_rpart<span class="sc">$</span>timings, <span class="at">both =</span> <span class="fu">sum</span>(lrn_rpart<span class="sc">$</span>timings))</span>
<span id="cb267-430"><a href="#cb267-430" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-431"><a href="#cb267-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-432"><a href="#cb267-432" aria-hidden="true" tabindex="-1"></a>The <span class="in">`selected_features`</span> measure calculates how many features were used in the fitted model.</span>
<span id="cb267-433"><a href="#cb267-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-434"><a href="#cb267-434" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-435"><a href="#cb267-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-436"><a href="#cb267-436" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-437"><a href="#cb267-437" aria-hidden="true" tabindex="-1"></a>msr_sf <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"selected_features"</span>)</span>
<span id="cb267-438"><a href="#cb267-438" aria-hidden="true" tabindex="-1"></a>msr_sf</span>
<span id="cb267-439"><a href="#cb267-439" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-440"><a href="#cb267-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-441"><a href="#cb267-441" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-442"><a href="#cb267-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-443"><a href="#cb267-443" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-444"><a href="#cb267-444" aria-hidden="true" tabindex="-1"></a><span class="co"># accessed hyperparameters with `$param_set`</span></span>
<span id="cb267-445"><a href="#cb267-445" aria-hidden="true" tabindex="-1"></a>msr_sf<span class="sc">$</span>param_set</span>
<span id="cb267-446"><a href="#cb267-446" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-447"><a href="#cb267-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-448"><a href="#cb267-448" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-449"><a href="#cb267-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-450"><a href="#cb267-450" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-451"><a href="#cb267-451" aria-hidden="true" tabindex="-1"></a>msr_sf<span class="sc">$</span>param_set<span class="sc">$</span>values<span class="sc">$</span>normalize <span class="ot">=</span> <span class="cn">TRUE</span></span>
<span id="cb267-452"><a href="#cb267-452" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(msr_sf, <span class="at">task =</span> tsk_mtcars, <span class="at">learner =</span> lrn_rpart)</span>
<span id="cb267-453"><a href="#cb267-453" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-454"><a href="#cb267-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-455"><a href="#cb267-455" aria-hidden="true" tabindex="-1"></a>Note that we passed the task and learner as the measure has the <span class="in">`requires_task`</span> and <span class="in">`requires_learner`</span> properties.</span>
<span id="cb267-456"><a href="#cb267-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-457"><a href="#cb267-457" aria-hidden="true" tabindex="-1"></a><span class="fu">## Our First Regression Experiment</span></span>
<span id="cb267-458"><a href="#cb267-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-459"><a href="#cb267-459" aria-hidden="true" tabindex="-1"></a>We have now seen how to train a model, make predictions and score them. What we have not yet attempted is to ascertain if our predictions are any ‘good’. So before look at how the building blocks of <span class="in">`mlr3`</span> extend to classification, we will take a brief pause to put together everything above in a short experiment to assess the quality of our predictions. We will do this by comparing the performance of a featureless regression learner to a decision tree with changed hyperparameters.</span>
<span id="cb267-460"><a href="#cb267-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-461"><a href="#cb267-461" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们已经了解了如何训练模型、进行预测并对其进行评分。但是，我们尚未尝试确定我们的预测是否“好”。因此，在深入研究 </span><span class="in">`mlr3`</span><span class="at"> 的构建模块如何扩展到分类之前，我们将简要停顿一下，通过一个简短的实验来评估我们预测的质量。我们将通过比较无特征的回归学习器与更改超参数的决策树的性能来进行评估。</span></span>
<span id="cb267-462"><a href="#cb267-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-463"><a href="#cb267-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-464"><a href="#cb267-464" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-465"><a href="#cb267-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-466"><a href="#cb267-466" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-467"><a href="#cb267-467" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">349</span>)</span>
<span id="cb267-468"><a href="#cb267-468" aria-hidden="true" tabindex="-1"></a>tsk_mtcars <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"mtcars"</span>)</span>
<span id="cb267-469"><a href="#cb267-469" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">=</span> <span class="fu">partition</span>(tsk_mtcars)</span>
<span id="cb267-470"><a href="#cb267-470" aria-hidden="true" tabindex="-1"></a>lrn_featureless <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.featureless"</span>)</span>
<span id="cb267-471"><a href="#cb267-471" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.rpart"</span>, <span class="at">cp =</span> .<span class="dv">2</span>, <span class="at">maxdepth =</span> <span class="dv">5</span>)</span>
<span id="cb267-472"><a href="#cb267-472" aria-hidden="true" tabindex="-1"></a>measures <span class="ot">=</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"regr.mse"</span>, <span class="st">"regr.mae"</span>))</span>
<span id="cb267-473"><a href="#cb267-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-474"><a href="#cb267-474" aria-hidden="true" tabindex="-1"></a><span class="co"># train learners</span></span>
<span id="cb267-475"><a href="#cb267-475" aria-hidden="true" tabindex="-1"></a>lrn_featureless<span class="sc">$</span><span class="fu">train</span>(tsk_mtcars, splits<span class="sc">$</span>train)</span>
<span id="cb267-476"><a href="#cb267-476" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(tsk_mtcars, splits<span class="sc">$</span>train)</span>
<span id="cb267-477"><a href="#cb267-477" aria-hidden="true" tabindex="-1"></a><span class="co"># make and score predictions</span></span>
<span id="cb267-478"><a href="#cb267-478" aria-hidden="true" tabindex="-1"></a>lrn_featureless<span class="sc">$</span><span class="fu">predict</span>(tsk_mtcars, splits<span class="sc">$</span>test)<span class="sc">$</span><span class="fu">score</span>(measures)</span>
<span id="cb267-479"><a href="#cb267-479" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">predict</span>(tsk_mtcars, splits<span class="sc">$</span>test)<span class="sc">$</span><span class="fu">score</span>(measures)</span>
<span id="cb267-480"><a href="#cb267-480" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-481"><a href="#cb267-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-482"><a href="#cb267-482" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classification</span></span>
<span id="cb267-483"><a href="#cb267-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-484"><a href="#cb267-484" aria-hidden="true" tabindex="-1"></a><span class="fu">### Our First Classification Experiment</span></span>
<span id="cb267-485"><a href="#cb267-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-486"><a href="#cb267-486" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-487"><a href="#cb267-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-488"><a href="#cb267-488" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-489"><a href="#cb267-489" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">349</span>)</span>
<span id="cb267-490"><a href="#cb267-490" aria-hidden="true" tabindex="-1"></a>tsk_penguins <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-491"><a href="#cb267-491" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">=</span> <span class="fu">partition</span>(tsk_penguins)</span>
<span id="cb267-492"><a href="#cb267-492" aria-hidden="true" tabindex="-1"></a>lrn_featureless <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.featureless"</span>)</span>
<span id="cb267-493"><a href="#cb267-493" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>, <span class="at">cp =</span> .<span class="dv">2</span>, <span class="at">maxdepth =</span> <span class="dv">5</span>)</span>
<span id="cb267-494"><a href="#cb267-494" aria-hidden="true" tabindex="-1"></a>measure <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"classif.acc"</span>)</span>
<span id="cb267-495"><a href="#cb267-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-496"><a href="#cb267-496" aria-hidden="true" tabindex="-1"></a><span class="co"># train learners</span></span>
<span id="cb267-497"><a href="#cb267-497" aria-hidden="true" tabindex="-1"></a>lrn_featureless<span class="sc">$</span><span class="fu">train</span>(tsk_penguins, splits<span class="sc">$</span>train)</span>
<span id="cb267-498"><a href="#cb267-498" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(tsk_penguins, splits<span class="sc">$</span>train)</span>
<span id="cb267-499"><a href="#cb267-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-500"><a href="#cb267-500" aria-hidden="true" tabindex="-1"></a><span class="co"># make and score predictions</span></span>
<span id="cb267-501"><a href="#cb267-501" aria-hidden="true" tabindex="-1"></a>lrn_featureless<span class="sc">$</span><span class="fu">predict</span>(tsk_penguins, splits<span class="sc">$</span>test)<span class="sc">$</span><span class="fu">score</span>(measure)</span>
<span id="cb267-502"><a href="#cb267-502" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">predict</span>(tsk_penguins, splits<span class="sc">$</span>test)<span class="sc">$</span><span class="fu">score</span>(measure)</span>
<span id="cb267-503"><a href="#cb267-503" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-504"><a href="#cb267-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-505"><a href="#cb267-505" aria-hidden="true" tabindex="-1"></a><span class="fu">### TaskClassif</span></span>
<span id="cb267-506"><a href="#cb267-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-507"><a href="#cb267-507" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-508"><a href="#cb267-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-509"><a href="#cb267-509" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-510"><a href="#cb267-510" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(<span class="fu">tsks</span>())[task_type <span class="sc">==</span> <span class="st">"classif"</span>]</span>
<span id="cb267-511"><a href="#cb267-511" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-512"><a href="#cb267-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-513"><a href="#cb267-513" aria-hidden="true" tabindex="-1"></a>The <span class="in">`sonar`</span> task is an example of a binary classification problem, as the target can only take two different values, in <span class="in">`mlr3`</span> terminology it has the “twoclass” property:</span>
<span id="cb267-514"><a href="#cb267-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-515"><a href="#cb267-515" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-516"><a href="#cb267-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-517"><a href="#cb267-517" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-518"><a href="#cb267-518" aria-hidden="true" tabindex="-1"></a>tsk_sonar <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"sonar"</span>)</span>
<span id="cb267-519"><a href="#cb267-519" aria-hidden="true" tabindex="-1"></a>tsk_sonar</span>
<span id="cb267-520"><a href="#cb267-520" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-521"><a href="#cb267-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-522"><a href="#cb267-522" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-523"><a href="#cb267-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-524"><a href="#cb267-524" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-525"><a href="#cb267-525" aria-hidden="true" tabindex="-1"></a>tsk_sonar<span class="sc">$</span>class_names</span>
<span id="cb267-526"><a href="#cb267-526" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-527"><a href="#cb267-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-528"><a href="#cb267-528" aria-hidden="true" tabindex="-1"></a>In contrast, <span class="in">`tsk("penguins")`</span> is a multiclass problem as there are more than two species of penguins; it has the “multiclass” property:</span>
<span id="cb267-529"><a href="#cb267-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-530"><a href="#cb267-530" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-531"><a href="#cb267-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-532"><a href="#cb267-532" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-533"><a href="#cb267-533" aria-hidden="true" tabindex="-1"></a>tsk_penguins <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-534"><a href="#cb267-534" aria-hidden="true" tabindex="-1"></a>tsk_penguins<span class="sc">$</span>properties</span>
<span id="cb267-535"><a href="#cb267-535" aria-hidden="true" tabindex="-1"></a>tsk_penguins<span class="sc">$</span>class_names</span>
<span id="cb267-536"><a href="#cb267-536" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-537"><a href="#cb267-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-538"><a href="#cb267-538" aria-hidden="true" tabindex="-1"></a>A further difference between these tasks is that binary classification tasks have an extra field called <span class="in">`$positive`</span>, which defines the ‘positive’ class. In binary classification, as there are only two possible class types, by convention one of these is known as the ‘positive’ class, and the other as the ‘negative’ class. It is arbitrary which is which, though often the more ‘important’ (and often smaller) class is set as the positive class. You can set the positive class during or after construction. If no positive class is specified then <span class="in">`mlr3`</span> assumes the first level in the <span class="in">`target`</span> column is the positive class, which can lead to misleading results.</span>
<span id="cb267-539"><a href="#cb267-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-540"><a href="#cb267-540" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 这两种任务之间的另一个区别是，二分类任务有一个额外的字段称为 </span><span class="in">`$positive`</span><span class="at">，它定义了“正类”（positive class）。在二分类问题中，由于只有两种可能的类别类型，按照惯例，其中一种被称为“正类”，另一种被称为“负类”。哪个是哪个是任意的，尽管通常更“重要”（通常更小）的类别被设置为正类。您可以在构建期间或之后设置正类。如果未指定正类，则 </span><span class="in">`mlr3`</span><span class="at"> 假定目标列中的第一个级别是正类，这可能导致误导性的结果。</span></span>
<span id="cb267-541"><a href="#cb267-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-542"><a href="#cb267-542" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-543"><a href="#cb267-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-544"><a href="#cb267-544" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-545"><a href="#cb267-545" aria-hidden="true" tabindex="-1"></a>Sonar <span class="ot">=</span> tsk_sonar<span class="sc">$</span><span class="fu">data</span>()</span>
<span id="cb267-546"><a href="#cb267-546" aria-hidden="true" tabindex="-1"></a>tsk_classif <span class="ot">=</span> <span class="fu">as_task_classif</span>(Sonar, <span class="at">target =</span> <span class="st">"Class"</span>, <span class="at">positive =</span> <span class="st">"R"</span>)</span>
<span id="cb267-547"><a href="#cb267-547" aria-hidden="true" tabindex="-1"></a>tsk_classif<span class="sc">$</span>positive</span>
<span id="cb267-548"><a href="#cb267-548" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-549"><a href="#cb267-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-550"><a href="#cb267-550" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-551"><a href="#cb267-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-552"><a href="#cb267-552" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-553"><a href="#cb267-553" aria-hidden="true" tabindex="-1"></a><span class="co"># changing after construction</span></span>
<span id="cb267-554"><a href="#cb267-554" aria-hidden="true" tabindex="-1"></a>tsk_classif<span class="sc">$</span>positive <span class="ot">=</span> <span class="st">"M"</span></span>
<span id="cb267-555"><a href="#cb267-555" aria-hidden="true" tabindex="-1"></a>tsk_classif<span class="sc">$</span>positive</span>
<span id="cb267-556"><a href="#cb267-556" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-557"><a href="#cb267-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-558"><a href="#cb267-558" aria-hidden="true" tabindex="-1"></a><span class="fu">### LearnerClassif and MeasureClassif</span></span>
<span id="cb267-559"><a href="#cb267-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-560"><a href="#cb267-560" aria-hidden="true" tabindex="-1"></a>Classification learners, which inherit from <span class="in">`LearnerClassif`</span>, have nearly the same interface as regression learners. However, a key difference is that the possible predictions in classification are either <span class="in">`"response"`</span> – predicting an observation’s class (a penguin’s species in our example, this is sometimes called “hard labeling”) – or <span class="in">`"prob"`</span> – predicting a vector of probabilities, also called “posterior probabilities”, of an observation belonging to each class. In classification, the latter can be more useful as it provides information about the confidence of the predictions:</span>
<span id="cb267-561"><a href="#cb267-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-562"><a href="#cb267-562" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 分类学习器（继承自 </span><span class="in">`LearnerClassif`</span><span class="at">）几乎具有与回归学习器相同的接口。然而，分类中的一个关键区别是，分类问题中可能的预测结果要么是 </span><span class="in">`"response"`</span><span class="at"> （预测观测的类别，例如我们示例中的企鹅物种，有时称为“硬标签”），要么是 </span><span class="in">`"prob"`</span><span class="at"> （预测属于每个类别的概率向量，也称为“后验概率”）。在分类中，后者可能更有用，因为它提供了有关预测的置信度信息：</span></span>
<span id="cb267-563"><a href="#cb267-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-564"><a href="#cb267-564" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-565"><a href="#cb267-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-566"><a href="#cb267-566" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-567"><a href="#cb267-567" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb267-568"><a href="#cb267-568" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(tsk_penguins, splits<span class="sc">$</span>train)</span>
<span id="cb267-569"><a href="#cb267-569" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_rpart<span class="sc">$</span><span class="fu">predict</span>(tsk_penguins, splits<span class="sc">$</span>test)</span>
<span id="cb267-570"><a href="#cb267-570" aria-hidden="true" tabindex="-1"></a>prediction</span>
<span id="cb267-571"><a href="#cb267-571" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-572"><a href="#cb267-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-573"><a href="#cb267-573" aria-hidden="true" tabindex="-1"></a>Also, the interface for classification measures, which are of class <span class="in">`MeasureClassif`</span>, is identical to regression measures. The key difference in usage is that you will need to ensure your selected measure evaluates the prediction type of interest. To evaluate "response" predictions, you will need measures with <span class="in">`predict_type = "response"`</span>, or to evaluate probability predictions you will need <span class="in">`predict_type = "prob"`</span>. The easiest way to find these measures is by filtering the <span class="in">`mlr_measures`</span> dictionary:</span>
<span id="cb267-574"><a href="#cb267-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-575"><a href="#cb267-575" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 此外，分类度量标准的接口，其类别为 </span><span class="in">`MeasureClassif`</span><span class="at">，与回归度量标准完全相同。在使用上的主要区别在于，您需要确保所选的度量标准评估感兴趣的预测类型。要评估 </span><span class="in">`“response”`</span><span class="at"> 预测，您需要使用 </span><span class="in">`predict_type = "response"`</span><span class="at"> 的度量标准，或者要评估概率预测，您需要使用 </span><span class="in">`predict_type = "prob"`</span><span class="at"> 的度量标准。查找这些度量标准的最简单方法是通过筛选 </span><span class="in">`mlr_measures`</span><span class="at"> 字典：</span></span>
<span id="cb267-576"><a href="#cb267-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-577"><a href="#cb267-577" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-578"><a href="#cb267-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-579"><a href="#cb267-579" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-580"><a href="#cb267-580" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(<span class="fu">msr</span>())[</span>
<span id="cb267-581"><a href="#cb267-581" aria-hidden="true" tabindex="-1"></a>  task_type <span class="sc">==</span> <span class="st">"classif"</span> <span class="sc">&amp;</span> predict_type <span class="sc">==</span> <span class="st">"prob"</span> <span class="sc">&amp;</span></span>
<span id="cb267-582"><a href="#cb267-582" aria-hidden="true" tabindex="-1"></a>  <span class="sc">!</span><span class="fu">sapply</span>(task_properties, \(x) <span class="st">"twoclass"</span> <span class="sc">%in%</span> x)</span>
<span id="cb267-583"><a href="#cb267-583" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb267-584"><a href="#cb267-584" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-585"><a href="#cb267-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-586"><a href="#cb267-586" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-587"><a href="#cb267-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-588"><a href="#cb267-588" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-589"><a href="#cb267-589" aria-hidden="true" tabindex="-1"></a>measures <span class="ot">=</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"classif.mbrier"</span>, <span class="st">"classif.logloss"</span>, <span class="st">"classif.acc"</span>))</span>
<span id="cb267-590"><a href="#cb267-590" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(measures)</span>
<span id="cb267-591"><a href="#cb267-591" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-592"><a href="#cb267-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-593"><a href="#cb267-593" aria-hidden="true" tabindex="-1"></a><span class="fu">### PredictionClassif, Confusion Matrix, and Thresholding</span></span>
<span id="cb267-594"><a href="#cb267-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-595"><a href="#cb267-595" aria-hidden="true" tabindex="-1"></a><span class="in">`PredictionClassif`</span> objects have two important differences from their regression analog. Firstly, the added field <span class="in">`$confusion`</span>, and secondly the added method <span class="in">`$set_threshold()`</span>.</span>
<span id="cb267-596"><a href="#cb267-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-597"><a href="#cb267-597" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`PredictionClassif`</span><span class="at"> 对象与其回归模型的预测对象有两个重要的区别。首先是新增的字段 </span><span class="in">`$confusion`</span><span class="at">，其次是新增的方法 </span><span class="in">`$set_threshold()`</span><span class="at">。</span></span>
<span id="cb267-598"><a href="#cb267-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-599"><a href="#cb267-599" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Confusion Matrix</span></span>
<span id="cb267-600"><a href="#cb267-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-601"><a href="#cb267-601" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-602"><a href="#cb267-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-603"><a href="#cb267-603" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-604"><a href="#cb267-604" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span>confusion</span>
<span id="cb267-605"><a href="#cb267-605" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-606"><a href="#cb267-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-607"><a href="#cb267-607" aria-hidden="true" tabindex="-1"></a>The rows in a confusion matrix are the predicted class and the columns are the true class. All off-diagonal entries are incorrectly classified observations, and all diagonal entries are correctly classified. In this case, the classifier does fairly well classifying all penguins, but we could have found that it only classifies the Adelie species well but often conflates Chinstrap and Gentoo, for example.</span>
<span id="cb267-608"><a href="#cb267-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-609"><a href="#cb267-609" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 混淆矩阵中的行表示预测的类别，列表示真实的类别。所有非对角线条目都是被错误分类的观测值，而所有对角线条目都是被正确分类的。在这种情况下，分类器在对所有企鹅进行分类时表现得相当不错，但我们也可能发现它只能很好地对 Adelie 物种进行分类，但经常将 Chinstrap 和 Gentoo 混为一谈。</span></span>
<span id="cb267-610"><a href="#cb267-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-611"><a href="#cb267-611" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-612"><a href="#cb267-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-613"><a href="#cb267-613" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-614"><a href="#cb267-614" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-confusion_matrix</span></span>
<span id="cb267-615"><a href="#cb267-615" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Counts of each class label in the ground truth data (left) and predictions (right)."</span></span>
<span id="cb267-616"><a href="#cb267-616" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(prediction)</span>
<span id="cb267-617"><a href="#cb267-617" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-618"><a href="#cb267-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-619"><a href="#cb267-619" aria-hidden="true" tabindex="-1"></a>In the binary classification case, the top left entry corresponds to true positives, the top right to false positives, the bottom left to false negatives and the bottom right to true negatives. Taking <span class="in">`tsk_sonar`</span> as an example with <span class="in">`M`</span> as the positive class:</span>
<span id="cb267-620"><a href="#cb267-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-621"><a href="#cb267-621" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在二分类情况下，左上角的条目对应于真正例（true positives），右上角对应于假正例（false positives），左下角对应于假负例（false negatives），右下角对应于真负例（true negatives）。以 </span><span class="in">`tsk_sonar`</span><span class="at"> 为例，</span><span class="in">`M`</span><span class="at"> 为正类：</span></span>
<span id="cb267-622"><a href="#cb267-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-623"><a href="#cb267-623" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-624"><a href="#cb267-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-625"><a href="#cb267-625" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-626"><a href="#cb267-626" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">=</span> <span class="fu">partition</span>(tsk_sonar)</span>
<span id="cb267-627"><a href="#cb267-627" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span></span>
<span id="cb267-628"><a href="#cb267-628" aria-hidden="true" tabindex="-1"></a>  <span class="fu">train</span>(tsk_sonar, splits<span class="sc">$</span>train)<span class="sc">$</span></span>
<span id="cb267-629"><a href="#cb267-629" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(tsk_sonar, splits<span class="sc">$</span>test)<span class="sc">$</span></span>
<span id="cb267-630"><a href="#cb267-630" aria-hidden="true" tabindex="-1"></a>  confusion</span>
<span id="cb267-631"><a href="#cb267-631" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-632"><a href="#cb267-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-633"><a href="#cb267-633" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Thresholding</span></span>
<span id="cb267-634"><a href="#cb267-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-635"><a href="#cb267-635" aria-hidden="true" tabindex="-1"></a>**阈值化**</span>
<span id="cb267-636"><a href="#cb267-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-637"><a href="#cb267-637" aria-hidden="true" tabindex="-1"></a>This 50% value is known as the threshold and it can be useful to change this threshold if there is class imbalance (when one class is over- or under-represented in a dataset), or if there are different costs associated with classes, or simply if there is a preference to ‘over’-predict one class. As an example, let us take <span class="in">`tsk("german_credit")`</span> in which 700 customers have good credit and 300 have bad. Now we could easily build a model with around “70%” accuracy simply by always predicting a customer will have good credit:</span>
<span id="cb267-638"><a href="#cb267-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-639"><a href="#cb267-639" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 这个 50% 的值被称为阈值，如果数据集中存在类别不平衡（即一个类别在数据集中过多或过少出现），或者不同的类别具有不同的成本，或者只是有一种“过度”预测一种类别的倾向，那么更改这个阈值可能会很有用。举个例子，让我们看看 </span><span class="in">`tsk("german_credit")`</span><span class="at">，其中有 700 个客户信用良好，300 个客户信用不良。现在，我们可以很容易地构建一个模型，总是预测客户会有良好的信用，从而获得 “70%” 左右的准确性：</span></span>
<span id="cb267-640"><a href="#cb267-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-641"><a href="#cb267-641" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-642"><a href="#cb267-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-643"><a href="#cb267-643" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-644"><a href="#cb267-644" aria-hidden="true" tabindex="-1"></a>task_credit <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"german_credit"</span>)</span>
<span id="cb267-645"><a href="#cb267-645" aria-hidden="true" tabindex="-1"></a>lrn_featureless <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.featureless"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb267-646"><a href="#cb267-646" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">=</span> <span class="fu">partition</span>(task_credit)</span>
<span id="cb267-647"><a href="#cb267-647" aria-hidden="true" tabindex="-1"></a>lrn_featureless<span class="sc">$</span><span class="fu">train</span>(task_credit, splits<span class="sc">$</span>train)</span>
<span id="cb267-648"><a href="#cb267-648" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_featureless<span class="sc">$</span><span class="fu">predict</span>(task_credit, splits<span class="sc">$</span>test)</span>
<span id="cb267-649"><a href="#cb267-649" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span>
<span id="cb267-650"><a href="#cb267-650" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-651"><a href="#cb267-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-652"><a href="#cb267-652" aria-hidden="true" tabindex="-1"></a>::: {.callout-caution}</span>
<span id="cb267-653"><a href="#cb267-653" aria-hidden="true" tabindex="-1"></a>TODO：等待后续添加交叉引用  13.1</span>
<span id="cb267-654"><a href="#cb267-654" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb267-655"><a href="#cb267-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-656"><a href="#cb267-656" aria-hidden="true" tabindex="-1"></a>While this model may appear to have good performance on the surface, in fact, it just ignores all ‘bad’ customers – this can create big problems in this finance example, as well as in healthcare tasks and other settings where false positives cost more than false negatives (see Section 13.1 for cost-sensitive classification).</span>
<span id="cb267-657"><a href="#cb267-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-658"><a href="#cb267-658" aria-hidden="true" tabindex="-1"></a>Thresholding allows classes to be selected with a different probability threshold, so instead of predicting that a customer has bad credit if P(good) &lt; 50%, we might predict bad credit if P(good) &lt; 70% – notice how we write this in terms of the positive class, which in this task is ‘good’. Let us see this in practice:</span>
<span id="cb267-659"><a href="#cb267-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-660"><a href="#cb267-660" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 虽然这个模型表面上看起来性能不错，但实际上它只是忽略了所有“不良”的客户 - 这在金融示例以及在医疗任务和其他一些情况下可能会带来很大问题，特别是在假阳性的成本高于假阴性的情况下（请参见第13.1节的成本敏感分类）。</span></span>
<span id="cb267-661"><a href="#cb267-661" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-662"><a href="#cb267-662" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 阈值化允许使用不同的概率阈值选择类别，因此，与其在P(好) &lt; 50%时预测客户信用不良，我们可以在P(好) &lt; 70%时预测客户信用不良。请注意，我们是根据正类别来表示这一点，而在这个任务中正类别是“好”。让我们看看实际应用中的情况：</span></span>
<span id="cb267-663"><a href="#cb267-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-664"><a href="#cb267-664" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-665"><a href="#cb267-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-666"><a href="#cb267-666" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-667"><a href="#cb267-667" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">set_threshold</span>(<span class="fl">0.7</span>)</span>
<span id="cb267-668"><a href="#cb267-668" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span>
<span id="cb267-669"><a href="#cb267-669" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-670"><a href="#cb267-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-671"><a href="#cb267-671" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-672"><a href="#cb267-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-673"><a href="#cb267-673" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-674"><a href="#cb267-674" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb267-675"><a href="#cb267-675" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(task_credit, splits<span class="sc">$</span>train)</span>
<span id="cb267-676"><a href="#cb267-676" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_rpart<span class="sc">$</span><span class="fu">predict</span>(task_credit, splits<span class="sc">$</span>test)</span>
<span id="cb267-677"><a href="#cb267-677" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span>
<span id="cb267-678"><a href="#cb267-678" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span>confusion</span>
<span id="cb267-679"><a href="#cb267-679" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-680"><a href="#cb267-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-681"><a href="#cb267-681" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-682"><a href="#cb267-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-683"><a href="#cb267-683" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-684"><a href="#cb267-684" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">set_threshold</span>(<span class="fl">0.7</span>)</span>
<span id="cb267-685"><a href="#cb267-685" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span>
<span id="cb267-686"><a href="#cb267-686" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span>confusion</span>
<span id="cb267-687"><a href="#cb267-687" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-688"><a href="#cb267-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-689"><a href="#cb267-689" aria-hidden="true" tabindex="-1"></a><span class="fu"># Evaluation and Benchmarking {#sec-performance}</span></span>
<span id="cb267-690"><a href="#cb267-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-691"><a href="#cb267-691" aria-hidden="true" tabindex="-1"></a>**Resampling Does Not Avoid Model Overfitting**: </span>
<span id="cb267-692"><a href="#cb267-692" aria-hidden="true" tabindex="-1"></a>A common **misunderstanding** is that holdout and other more advanced resampling strategies can prevent model overfitting. In fact, these methods just make overfitting visible as we can separately evaluate train/test performance. Resampling strategies also allow us to make (nearly) unbiased estimations of the generalization error.</span>
<span id="cb267-693"><a href="#cb267-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-694"><a href="#cb267-694" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **重采样不能避免模型过拟合**：一个常见的误解是，留出策略和其他更高级的重采样策略可以防止模型过拟合。实际上，这些方法只是使过拟合问题更加显而易见，因为我们可以单独评估训练/测试性能。重采样策略还允许我们对泛化误差进行（几乎）无偏估计。</span></span>
<span id="cb267-695"><a href="#cb267-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-696"><a href="#cb267-696" aria-hidden="true" tabindex="-1"></a><span class="fu">## Holdout and Scoring</span></span>
<span id="cb267-697"><a href="#cb267-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-698"><a href="#cb267-698" aria-hidden="true" tabindex="-1"></a>In practice, one would usually create an intermediate model, which is trained on a subset of the available data and then tested on the remainder of the data. The performance of this intermediate model, obtained by comparing the model predictions to the ground truth, is an estimate of the generalization performance of the final model, which is the model fitted on all data.</span>
<span id="cb267-699"><a href="#cb267-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-700"><a href="#cb267-700" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在实践中，通常会创建一个中间模型，该模型在可用数据的子集上进行训练，然后在剩余的数据上进行测试。通过将模型的预测与真实情况进行比较，中间模型的性能可以作为最终模型的泛化性能的估计。最终模型是在所有可用数据上训练的模型。</span></span>
<span id="cb267-701"><a href="#cb267-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-702"><a href="#cb267-702" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-703"><a href="#cb267-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-704"><a href="#cb267-704" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-705"><a href="#cb267-705" aria-hidden="true" tabindex="-1"></a>tsk_penguins <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-706"><a href="#cb267-706" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">=</span> <span class="fu">partition</span>(tsk_penguins)</span>
<span id="cb267-707"><a href="#cb267-707" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>)</span>
<span id="cb267-708"><a href="#cb267-708" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(tsk_penguins, splits<span class="sc">$</span>train)</span>
<span id="cb267-709"><a href="#cb267-709" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_rpart<span class="sc">$</span><span class="fu">predict</span>(tsk_penguins, splits<span class="sc">$</span>test)</span>
<span id="cb267-710"><a href="#cb267-710" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span>
<span id="cb267-711"><a href="#cb267-711" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-712"><a href="#cb267-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-713"><a href="#cb267-713" aria-hidden="true" tabindex="-1"></a><span class="fu">## Resampling</span></span>
<span id="cb267-714"><a href="#cb267-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-715"><a href="#cb267-715" aria-hidden="true" tabindex="-1"></a><span class="fu">### Constructing a Resampling Strategy</span></span>
<span id="cb267-716"><a href="#cb267-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-717"><a href="#cb267-717" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-718"><a href="#cb267-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-719"><a href="#cb267-719" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-720"><a href="#cb267-720" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(<span class="fu">rsmp</span>())</span>
<span id="cb267-721"><a href="#cb267-721" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-722"><a href="#cb267-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-723"><a href="#cb267-723" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-724"><a href="#cb267-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-725"><a href="#cb267-725" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-726"><a href="#cb267-726" aria-hidden="true" tabindex="-1"></a><span class="fu">rsmp</span>(<span class="st">"holdout"</span>, <span class="at">ratio =</span> .<span class="dv">8</span>)</span>
<span id="cb267-727"><a href="#cb267-727" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-728"><a href="#cb267-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-729"><a href="#cb267-729" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-730"><a href="#cb267-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-731"><a href="#cb267-731" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-732"><a href="#cb267-732" aria-hidden="true" tabindex="-1"></a><span class="co"># three-fold CV</span></span>
<span id="cb267-733"><a href="#cb267-733" aria-hidden="true" tabindex="-1"></a>cv3 <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>)</span>
<span id="cb267-734"><a href="#cb267-734" aria-hidden="true" tabindex="-1"></a><span class="co"># subsampling with 3 repeats and 9/10 ratio</span></span>
<span id="cb267-735"><a href="#cb267-735" aria-hidden="true" tabindex="-1"></a>ss390 <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"subsampling"</span>, <span class="at">repeats =</span> <span class="dv">3</span>, <span class="at">ratio =</span> .<span class="dv">9</span>)</span>
<span id="cb267-736"><a href="#cb267-736" aria-hidden="true" tabindex="-1"></a><span class="co"># 2-repeats 5-fold cv</span></span>
<span id="cb267-737"><a href="#cb267-737" aria-hidden="true" tabindex="-1"></a>rcv25 <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"repeated_cv"</span>, <span class="at">repeats =</span> <span class="dv">2</span>, <span class="at">folds =</span> <span class="dv">5</span>)</span>
<span id="cb267-738"><a href="#cb267-738" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-739"><a href="#cb267-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-740"><a href="#cb267-740" aria-hidden="true" tabindex="-1"></a>When a <span class="in">`"Resampling"`</span> object is constructed, it is simply a definition for how the data splitting process will be performed on the task when running the resampling strategy. However, it is possible to manually instantiate a resampling strategy, i.e., generate all train-test splits, by calling the <span class="in">`$instantiate()`</span> method on a given task.</span>
<span id="cb267-741"><a href="#cb267-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-742"><a href="#cb267-742" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 当构建一个 </span><span class="in">`"Resampling"`</span><span class="at"> 对象时，它只是对在运行重采样策略时如何执行数据拆分过程的定义。然而，可以通过在给定任务上调用 </span><span class="in">`$instantiate()`</span><span class="at"> 方法来手动实例化一个重采样策略，即生成所有的训练-测试拆分。</span></span>
<span id="cb267-743"><a href="#cb267-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-744"><a href="#cb267-744" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-745"><a href="#cb267-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-746"><a href="#cb267-746" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-747"><a href="#cb267-747" aria-hidden="true" tabindex="-1"></a>cv3<span class="sc">$</span><span class="fu">instantiate</span>(tsk_penguins)</span>
<span id="cb267-748"><a href="#cb267-748" aria-hidden="true" tabindex="-1"></a><span class="co"># first 5 observations in first traininng set</span></span>
<span id="cb267-749"><a href="#cb267-749" aria-hidden="true" tabindex="-1"></a>cv3<span class="sc">$</span><span class="fu">train_set</span>(<span class="dv">1</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb267-750"><a href="#cb267-750" aria-hidden="true" tabindex="-1"></a><span class="co"># fitst 5 observations in thirt test set</span></span>
<span id="cb267-751"><a href="#cb267-751" aria-hidden="true" tabindex="-1"></a>cv3<span class="sc">$</span><span class="fu">test_set</span>(<span class="dv">3</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb267-752"><a href="#cb267-752" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-753"><a href="#cb267-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-754"><a href="#cb267-754" aria-hidden="true" tabindex="-1"></a>When the aim is to fairly compare multiple learners, best practice dictates that all learners being compared use the same training data to build a model and that they use the same test data to evaluate the model performance. Resampling strategies are instantiated automatically for you when using the <span class="in">`resample()`</span> method. Therefore, manually instantiating resampling strategies is rarely required but might be useful for debugging or digging deeper into a model’s performance.</span>
<span id="cb267-755"><a href="#cb267-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-756"><a href="#cb267-756" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 当目标是公平比较多个学习器时，最佳实践要求所有进行比较的学习器都使用相同的训练数据来构建模型，并且它们使用相同的测试数据来评估模型性能。在使用 </span><span class="in">`resample()`</span><span class="at"> 方法时，重采样策略会自动为您实例化。因此，手动实例化重采样策略很少是必需的，但在调试或深入研究模型性能时可能会有用。</span></span>
<span id="cb267-757"><a href="#cb267-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-758"><a href="#cb267-758" aria-hidden="true" tabindex="-1"></a><span class="fu">### Resampling Experiments</span></span>
<span id="cb267-759"><a href="#cb267-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-760"><a href="#cb267-760" aria-hidden="true" tabindex="-1"></a>The <span class="in">`resample()`</span> function takes a given <span class="in">`Task`</span>, <span class="in">`Learner`</span>, and <span class="in">`Resampling`</span> object to run the given resampling strategy. <span class="in">`resample()`</span> repeatedly fits a model on training sets, makes predictions on the corresponding test sets and stores them in a <span class="in">`ResampleResult`</span> object, which contains all the information needed to estimate the generalization performance.</span>
<span id="cb267-761"><a href="#cb267-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-762"><a href="#cb267-762" aria-hidden="true" tabindex="-1"></a><span class="in">`resample()`</span> 函数接受给定的任务（<span class="in">`Task`</span>）、学习器（<span class="in">`Learner`</span>）和重采样（<span class="in">`Resampling`</span>）对象，以运行给定的重采样策略。<span class="in">`resample()`</span> 函数会在训练集上反复拟合模型，在相应的测试集上进行预测，并将预测结果存储在 <span class="in">`ResampleResult`</span> 对象中，该对象包含了估算泛化性能所需的所有信息。</span>
<span id="cb267-763"><a href="#cb267-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-764"><a href="#cb267-764" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-765"><a href="#cb267-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-766"><a href="#cb267-766" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-767"><a href="#cb267-767" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-768"><a href="#cb267-768" aria-hidden="true" tabindex="-1"></a>rr <span class="ot">=</span> <span class="fu">resample</span>(tsk_penguins, lrn_rpart, cv3)</span>
<span id="cb267-769"><a href="#cb267-769" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-770"><a href="#cb267-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-771"><a href="#cb267-771" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-772"><a href="#cb267-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-773"><a href="#cb267-773" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-774"><a href="#cb267-774" aria-hidden="true" tabindex="-1"></a>rr</span>
<span id="cb267-775"><a href="#cb267-775" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-776"><a href="#cb267-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-777"><a href="#cb267-777" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-778"><a href="#cb267-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-779"><a href="#cb267-779" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-780"><a href="#cb267-780" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the score for each iteration</span></span>
<span id="cb267-781"><a href="#cb267-781" aria-hidden="true" tabindex="-1"></a>acc <span class="ot">=</span> rr<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.ce"</span>))</span>
<span id="cb267-782"><a href="#cb267-782" aria-hidden="true" tabindex="-1"></a>acc[, .(iteration, classif.ce)]</span>
<span id="cb267-783"><a href="#cb267-783" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-784"><a href="#cb267-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-785"><a href="#cb267-785" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-786"><a href="#cb267-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-787"><a href="#cb267-787" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-788"><a href="#cb267-788" aria-hidden="true" tabindex="-1"></a><span class="co"># aggregated score across all resampling iterations</span></span>
<span id="cb267-789"><a href="#cb267-789" aria-hidden="true" tabindex="-1"></a>rr<span class="sc">$</span><span class="fu">aggregate</span>(<span class="fu">msr</span>(<span class="st">"classif.ce"</span>))</span>
<span id="cb267-790"><a href="#cb267-790" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-791"><a href="#cb267-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-792"><a href="#cb267-792" aria-hidden="true" tabindex="-1"></a>By default, the majority of measures will aggregate scores using a macro average, which first calculates the measure in each resampling iteration separately, and then averages these scores across all iterations. However, it is also possible to aggregate scores using a micro average, which pools predictions across resampling iterations into one <span class="in">`Prediction`</span> object and then computes the measure on this directly:</span>
<span id="cb267-793"><a href="#cb267-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-794"><a href="#cb267-794" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 默认情况下，大多数性能度量会使用宏平均（macro average）来汇总分数，它首先在每个重采样迭代中分别计算度量，然后在所有迭代中对这些分数进行平均。但也可以使用微平均（micro average）来汇总分数，它将重采样迭代中的预测汇总到一个 </span><span class="in">`Prediction`</span><span class="at"> 对象中，然后直接在该对象上计算度量：</span></span>
<span id="cb267-795"><a href="#cb267-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-796"><a href="#cb267-796" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-797"><a href="#cb267-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-798"><a href="#cb267-798" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-799"><a href="#cb267-799" aria-hidden="true" tabindex="-1"></a>rr<span class="sc">$</span><span class="fu">aggregate</span>(<span class="fu">msr</span>(<span class="st">"classif.ce"</span>, <span class="at">average =</span> <span class="st">"micro"</span>))</span>
<span id="cb267-800"><a href="#cb267-800" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-801"><a href="#cb267-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-802"><a href="#cb267-802" aria-hidden="true" tabindex="-1"></a>To visualize the resampling results, you can use the <span class="in">`autoplot.ResampleResult()`</span> function to plot scores across folds as boxplots or histograms (@fig-resamp-viz). Histograms can be useful to visually gauge the variance of the performance results across resampling iterations, whereas boxplots are often used when multiple learners are compared side-by-side (see @sec-benchmarking).</span>
<span id="cb267-803"><a href="#cb267-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-804"><a href="#cb267-804" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 要可视化重采样结果，您可以使用 </span><span class="in">`autoplot.ResampleResult()`</span><span class="at"> 函数绘制跨折叠的分数箱线图或直方图（@fig-resamp-viz）。直方图可以用于直观评估跨重采样迭代的性能结果方差，而箱线图通常用于比较多个学习器并排放置在一起时（请参阅 @sec-benchmarking）。</span></span>
<span id="cb267-805"><a href="#cb267-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-806"><a href="#cb267-806" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-807"><a href="#cb267-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-808"><a href="#cb267-808" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-809"><a href="#cb267-809" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-810"><a href="#cb267-810" aria-hidden="true" tabindex="-1"></a>rr <span class="ot">=</span> <span class="fu">resample</span>(tsk_penguins, lrn_rpart, <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">10</span>))</span>
<span id="cb267-811"><a href="#cb267-811" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-812"><a href="#cb267-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-813"><a href="#cb267-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-814"><a href="#cb267-814" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-815"><a href="#cb267-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-816"><a href="#cb267-816" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-817"><a href="#cb267-817" aria-hidden="true" tabindex="-1"></a><span class="co">#| layout-ncol: 2</span></span>
<span id="cb267-818"><a href="#cb267-818" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-resamp-viz</span></span>
<span id="cb267-819"><a href="#cb267-819" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-subcap: </span></span>
<span id="cb267-820"><a href="#cb267-820" aria-hidden="true" tabindex="-1"></a><span class="co">#|   - "Boxplot of accuracy scores."</span></span>
<span id="cb267-821"><a href="#cb267-821" aria-hidden="true" tabindex="-1"></a><span class="co">#|   - "Histogram of accuracy scores."</span></span>
<span id="cb267-822"><a href="#cb267-822" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Boxplot and Histogram of accuracy scores."</span></span>
<span id="cb267-823"><a href="#cb267-823" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Left: a boxplot ranging from 0.875 to 1.0 and the interquartile range between 0.925 and 0.7. Right: a histogram with five bars in a roughly normal distribution with mean 0.95, minimum 0.875 and maximum 1.0."</span></span>
<span id="cb267-824"><a href="#cb267-824" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb267-825"><a href="#cb267-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-826"><a href="#cb267-826" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(rr, <span class="at">measure =</span> <span class="fu">msr</span>(<span class="st">"classif.acc"</span>), <span class="at">type =</span> <span class="st">"boxplot"</span>)</span>
<span id="cb267-827"><a href="#cb267-827" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(rr, <span class="at">measure =</span> <span class="fu">msr</span>(<span class="st">"classif.acc"</span>), <span class="at">type =</span> <span class="st">"histogram"</span>)</span>
<span id="cb267-828"><a href="#cb267-828" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-829"><a href="#cb267-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-830"><a href="#cb267-830" aria-hidden="true" tabindex="-1"></a><span class="fu">### ResampleResult Objects</span></span>
<span id="cb267-831"><a href="#cb267-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-832"><a href="#cb267-832" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-833"><a href="#cb267-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-834"><a href="#cb267-834" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-835"><a href="#cb267-835" aria-hidden="true" tabindex="-1"></a><span class="co"># list of prediction objects</span></span>
<span id="cb267-836"><a href="#cb267-836" aria-hidden="true" tabindex="-1"></a>rrp <span class="ot">=</span> rr<span class="sc">$</span><span class="fu">predictions</span>()</span>
<span id="cb267-837"><a href="#cb267-837" aria-hidden="true" tabindex="-1"></a><span class="co"># print first two</span></span>
<span id="cb267-838"><a href="#cb267-838" aria-hidden="true" tabindex="-1"></a>rrp[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]</span>
<span id="cb267-839"><a href="#cb267-839" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-840"><a href="#cb267-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-841"><a href="#cb267-841" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-842"><a href="#cb267-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-843"><a href="#cb267-843" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-844"><a href="#cb267-844" aria-hidden="true" tabindex="-1"></a><span class="co"># macro averaged performance</span></span>
<span id="cb267-845"><a href="#cb267-845" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">sapply</span>(rrp, \(x) x<span class="sc">$</span><span class="fu">score</span>()))</span>
<span id="cb267-846"><a href="#cb267-846" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-847"><a href="#cb267-847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-848"><a href="#cb267-848" aria-hidden="true" tabindex="-1"></a>By default, the intermediate models produced at each resampling iteration are discarded after the prediction step to reduce memory consumption of the <span class="in">`ResampleResult`</span> object (only the predictions are required to calculate most performance measures). However, it can sometimes be useful to inspect, compare, or extract information from these intermediate models. We can configure the <span class="in">`resample()`</span> function to keep the fitted intermediate models by setting <span class="in">`store_models = TRUE`</span>. Each model trained in a specific resampling iteration can then be accessed via <span class="in">`$learners[[i]]$model`</span>, where <span class="in">`i`</span> refers to the <span class="in">`i`</span>-th resampling iteration:</span>
<span id="cb267-849"><a href="#cb267-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-850"><a href="#cb267-850" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 默认情况下，在进行预测步骤后，每个重新采样迭代产生的中间模型都会被丢弃，以降低 </span><span class="in">`ResampleResult`</span><span class="at"> 对象的内存消耗（大多数性能指标仅需要预测）。然而，有时候检查、比较或从这些中间模型中提取信息可能是有用的。我们可以通过设置 </span><span class="in">`store_models = TRUE`</span><span class="at"> 来配置 </span><span class="in">`resample()`</span><span class="at"> 函数以保留拟合的中间模型。然后，可以通过 </span><span class="in">`$learners[[i]]$model`</span><span class="at"> 来访问在特定重新采样迭代中训练的每个模型，其中 </span><span class="in">`i`</span><span class="at"> 指的是第 </span><span class="in">`i`</span><span class="at"> 个重新采样迭代：</span></span>
<span id="cb267-851"><a href="#cb267-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-852"><a href="#cb267-852" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-853"><a href="#cb267-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-854"><a href="#cb267-854" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-855"><a href="#cb267-855" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-856"><a href="#cb267-856" aria-hidden="true" tabindex="-1"></a>rr <span class="ot">=</span> <span class="fu">resample</span>(tsk_penguins, lrn_rpart, cv3, <span class="at">store_models =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-857"><a href="#cb267-857" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-858"><a href="#cb267-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-859"><a href="#cb267-859" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-860"><a href="#cb267-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-861"><a href="#cb267-861" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-862"><a href="#cb267-862" aria-hidden="true" tabindex="-1"></a><span class="co"># get the model from the first iteration</span></span>
<span id="cb267-863"><a href="#cb267-863" aria-hidden="true" tabindex="-1"></a>rr<span class="sc">$</span>learners[[<span class="dv">1</span>]]<span class="sc">$</span>model</span>
<span id="cb267-864"><a href="#cb267-864" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-865"><a href="#cb267-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-866"><a href="#cb267-866" aria-hidden="true" tabindex="-1"></a>In this example, we could then inspect the most important variables in each iteration to help us learn more about the respective fitted models:</span>
<span id="cb267-867"><a href="#cb267-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-868"><a href="#cb267-868" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-869"><a href="#cb267-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-870"><a href="#cb267-870" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-871"><a href="#cb267-871" aria-hidden="true" tabindex="-1"></a><span class="co"># print 2nd and 3rd iteration</span></span>
<span id="cb267-872"><a href="#cb267-872" aria-hidden="true" tabindex="-1"></a><span class="fu">lapply</span>(rr<span class="sc">$</span>learners[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>], \(x) x<span class="sc">$</span>model<span class="sc">$</span>variable.importance)</span>
<span id="cb267-873"><a href="#cb267-873" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-874"><a href="#cb267-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-875"><a href="#cb267-875" aria-hidden="true" tabindex="-1"></a><span class="fu">## Benchmarking {#sec-benchmarking}</span></span>
<span id="cb267-876"><a href="#cb267-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-877"><a href="#cb267-877" aria-hidden="true" tabindex="-1"></a><span class="fu">### benchmark()</span></span>
<span id="cb267-878"><a href="#cb267-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-879"><a href="#cb267-879" aria-hidden="true" tabindex="-1"></a>Benchmark experiments in <span class="in">`mlr3`</span> are conducted with <span class="in">`benchmark()`</span>, which simply runs <span class="in">`resample()`</span> on each task and learner separately, then collects the results. The provided resampling strategy is automatically instantiated on each task to ensure that all learners are compared against the same training and test data.</span>
<span id="cb267-880"><a href="#cb267-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-881"><a href="#cb267-881" aria-hidden="true" tabindex="-1"></a>To use the <span class="in">`benchmark()`</span> function we first call <span class="in">`benchmark_grid()`</span>, which constructs an exhaustive *design* to describe all combinations of the learners, tasks and resamplings to be used in a benchmark experiment, and instantiates the resampling strategies.</span>
<span id="cb267-882"><a href="#cb267-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-883"><a href="#cb267-883" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`mlr3`</span><span class="at"> 中的基准实验是使用 </span><span class="in">`benchmark()`</span><span class="at"> 函数进行的，该函数简单地在每个任务和学习器上分别运行 </span><span class="in">`resample()`</span><span class="at">，然后收集结果。提供的重新采样策略会自动在每个任务上进行实例化，以确保所有学习器都与相同的训练和测试数据进行比较。</span></span>
<span id="cb267-884"><a href="#cb267-884" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-885"><a href="#cb267-885" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 要使用 </span><span class="in">`benchmark()`</span><span class="at"> 函数，我们首先调用 </span><span class="in">`benchmark_grid()`</span><span class="at"> 函数，该函数构建一个详尽的设计来描述在基准实验中要使用的所有学习器、任务和重新采样的组合，并实例化重新采样策略。</span></span>
<span id="cb267-886"><a href="#cb267-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-887"><a href="#cb267-887" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-888"><a href="#cb267-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-889"><a href="#cb267-889" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-890"><a href="#cb267-890" aria-hidden="true" tabindex="-1"></a>tasks <span class="ot">=</span> <span class="fu">tsks</span>(<span class="fu">c</span>(<span class="st">"german_credit"</span>, <span class="st">"sonar"</span>))</span>
<span id="cb267-891"><a href="#cb267-891" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">lrns</span>(<span class="fu">c</span>(<span class="st">"classif.rpart"</span>, <span class="st">"classif.ranger"</span>, <span class="st">"classif.featureless"</span>),</span>
<span id="cb267-892"><a href="#cb267-892" aria-hidden="true" tabindex="-1"></a>                <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb267-893"><a href="#cb267-893" aria-hidden="true" tabindex="-1"></a>rsmp_cv5 <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>)</span>
<span id="cb267-894"><a href="#cb267-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-895"><a href="#cb267-895" aria-hidden="true" tabindex="-1"></a>design <span class="ot">=</span> <span class="fu">benchmark_grid</span>(tasks, learners, rsmp_cv5)</span>
<span id="cb267-896"><a href="#cb267-896" aria-hidden="true" tabindex="-1"></a>design</span>
<span id="cb267-897"><a href="#cb267-897" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-898"><a href="#cb267-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-899"><a href="#cb267-899" aria-hidden="true" tabindex="-1"></a>By default, <span class="in">`benchmark_grid()`</span> instantiates the resamplings on the tasks, which means that concrete train-test splits are generated. Since this process is stochastic, it is necessary to set a seed **before** calling <span class="in">`benchmark_grid()`</span> to ensure reproducibility of the data splits.</span>
<span id="cb267-900"><a href="#cb267-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-901"><a href="#cb267-901" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在默认情况下，</span><span class="in">`benchmark_grid()`</span><span class="at"> 会在任务上实例化重新采样，这意味着会生成具体的训练-测试拆分。由于这个过程是随机的，所以在调用 </span><span class="in">`benchmark_grid()`</span><span class="at"> 之前需要设置一个种子，以确保数据拆分的可重现性。</span></span>
<span id="cb267-902"><a href="#cb267-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-903"><a href="#cb267-903" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-904"><a href="#cb267-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-905"><a href="#cb267-905" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-906"><a href="#cb267-906" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-907"><a href="#cb267-907" aria-hidden="true" tabindex="-1"></a><span class="co"># pass design to benchmark()</span></span>
<span id="cb267-908"><a href="#cb267-908" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(design)</span>
<span id="cb267-909"><a href="#cb267-909" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-910"><a href="#cb267-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-911"><a href="#cb267-911" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-912"><a href="#cb267-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-913"><a href="#cb267-913" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-914"><a href="#cb267-914" aria-hidden="true" tabindex="-1"></a>bmr</span>
<span id="cb267-915"><a href="#cb267-915" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-916"><a href="#cb267-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-917"><a href="#cb267-917" aria-hidden="true" tabindex="-1"></a>As <span class="in">`benchmark()`</span> is just an extension of <span class="in">`resample()`</span>, we can once again use <span class="in">`$score()`</span>, or <span class="in">`$aggregate()`</span> depending on your use-case, though note that in this case <span class="in">`$score()`</span> will return results over each fold of each learner/task/resampling combination.</span>
<span id="cb267-918"><a href="#cb267-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-919"><a href="#cb267-919" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 由于 </span><span class="in">`benchmark()`</span><span class="at"> 只是 </span><span class="in">`resample()`</span><span class="at"> 的扩展，因此我们可以再次使用 </span><span class="in">`$score()`</span><span class="at"> 或 </span><span class="in">`$aggregate()`</span><span class="at">，具体取决于您的用例，但请注意，在这种情况下，</span><span class="in">`$score()`</span><span class="at"> 将返回每个学习器/任务/重新采样组合的每个折叠的结果。</span></span>
<span id="cb267-920"><a href="#cb267-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-921"><a href="#cb267-921" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-922"><a href="#cb267-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-923"><a href="#cb267-923" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-924"><a href="#cb267-924" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">score</span>()[<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">13</span>), .(iteration, task_id, learner_id, classif.ce)]</span>
<span id="cb267-925"><a href="#cb267-925" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-926"><a href="#cb267-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-927"><a href="#cb267-927" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-928"><a href="#cb267-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-929"><a href="#cb267-929" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-930"><a href="#cb267-930" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>()[, .(task_id, learner_id, classif.ce)]</span>
<span id="cb267-931"><a href="#cb267-931" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-932"><a href="#cb267-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-933"><a href="#cb267-933" aria-hidden="true" tabindex="-1"></a>::: {.callout-caution}</span>
<span id="cb267-934"><a href="#cb267-934" aria-hidden="true" tabindex="-1"></a>TODO：等待后续添加交叉引用  11.3</span>
<span id="cb267-935"><a href="#cb267-935" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb267-936"><a href="#cb267-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-937"><a href="#cb267-937" aria-hidden="true" tabindex="-1"></a>This would conclude a basic benchmark experiment where you can draw tentative conclusions about model performance, in this case we would possibly conclude that the random forest is the best of all three models on each task. We draw conclusions cautiously here as we have not run any statistical tests or included standard errors of measures, so we cannot definitively say if one model outperforms the other.</span>
<span id="cb267-938"><a href="#cb267-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-939"><a href="#cb267-939" aria-hidden="true" tabindex="-1"></a>As the results of <span class="in">`$score()`</span> and <span class="in">`$aggregate()`</span> are returned in a <span class="in">`data.table`</span>, you can post-process and analyze the results in any way you want. A common mistake is to average the learner performance across all tasks when the tasks vary significantly. This is a mistake as averaging the performance will miss out important insights into how learners compare on ‘easier’ or more ‘difficult’ predictive problems. A more robust alternative to compare the overall algorithm performance across multiple tasks is to compute the ranks of each learner on each task separately and then calculate the average ranks. This can provide a better comparison as task-specific ‘quirks’ are taken into account by comparing learners within tasks before comparing them across tasks. However, using ranks will lose information about the numerical differences between the calculated performance scores. Analysis of benchmark experiments, including statistical tests, is covered in more detail in Section 11.3.</span>
<span id="cb267-940"><a href="#cb267-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-941"><a href="#cb267-941" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 这将总结了一个基本的基准实验，您可以初步得出关于模型性能的结论，在这种情况下，我们可能会得出结论，随机森林在每个任务上都是三个模型中最好的。我们在这里谨慎地得出结论，因为我们没有进行任何统计测试，也没有包括性能度量的标准错误，因此我们不能明确地说一个模型是否优于另一个。</span></span>
<span id="cb267-942"><a href="#cb267-942" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-943"><a href="#cb267-943" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 由于 </span><span class="in">`$score()`</span><span class="at"> 和 </span><span class="in">`$aggregate()`</span><span class="at"> 的结果以 </span><span class="in">`data.table`</span><span class="at"> 返回，您可以以任何您想要的方式进行后处理和分析结果。一个常见的错误是在任务差异明显的情况下，对所有任务的学习器性能进行平均。这是一个错误，因为对性能进行平均将错过对学习器在“更容易”或“更困难”的预测问题上的比较重要的洞察。比较多个任务上的整体算法性能的更强大的替代方法是分别计算每个任务上每个学习器的排名，然后计算平均排名。这可以提供更好的比较，因为通过在比较任务之前在任务内部比较学习器，可以考虑到特定于任务的“怪癖”。然而，使用排名会丢失关于计算的性能分数之间的数值差异的信息。关于基准实验的分析，包括统计测试，在第11.3节中将更详细地介绍。</span></span>
<span id="cb267-944"><a href="#cb267-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-945"><a href="#cb267-945" aria-hidden="true" tabindex="-1"></a><span class="fu">### BenchmarkResult Objects</span></span>
<span id="cb267-946"><a href="#cb267-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-947"><a href="#cb267-947" aria-hidden="true" tabindex="-1"></a>A <span class="in">`BenchmarkResult`</span> object is a collection of multiple <span class="in">`ResampleResult`</span> objects.</span>
<span id="cb267-948"><a href="#cb267-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-949"><a href="#cb267-949" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-950"><a href="#cb267-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-951"><a href="#cb267-951" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-952"><a href="#cb267-952" aria-hidden="true" tabindex="-1"></a>bmrdt <span class="ot">=</span> <span class="fu">as.data.table</span>(bmr)</span>
<span id="cb267-953"><a href="#cb267-953" aria-hidden="true" tabindex="-1"></a>bmrdt[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, .(task, learner, resampling, iteration)]</span>
<span id="cb267-954"><a href="#cb267-954" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-955"><a href="#cb267-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-956"><a href="#cb267-956" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-957"><a href="#cb267-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-958"><a href="#cb267-958" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-959"><a href="#cb267-959" aria-hidden="true" tabindex="-1"></a>rr1 <span class="ot">=</span> bmr<span class="sc">$</span><span class="fu">resample_result</span>(<span class="dv">1</span>)</span>
<span id="cb267-960"><a href="#cb267-960" aria-hidden="true" tabindex="-1"></a>rr2 <span class="ot">=</span> bmr<span class="sc">$</span><span class="fu">resample_result</span>(<span class="dv">2</span>)</span>
<span id="cb267-961"><a href="#cb267-961" aria-hidden="true" tabindex="-1"></a>rr1</span>
<span id="cb267-962"><a href="#cb267-962" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-963"><a href="#cb267-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-964"><a href="#cb267-964" aria-hidden="true" tabindex="-1"></a>In addition, <span class="in">`as_benchmark_result()`</span> can be used to convert objects from <span class="in">`ResampleResult`</span> to <span class="in">`BenchmarkResult.`</span> The <span class="in">`c()`</span>-method can be used to combine multiple <span class="in">`BenchmarkResult`</span> objects, which can be useful when conducting experiments across multiple machines:</span>
<span id="cb267-965"><a href="#cb267-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-966"><a href="#cb267-966" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 此外，可以使用 </span><span class="in">`as_benchmark_result()`</span><span class="at"> 将 </span><span class="in">`ResampleResult`</span><span class="at"> 对象转换为 </span><span class="in">`BenchmarkResult`</span><span class="at">。</span><span class="in">`c()`</span><span class="at"> 方法可用于组合多个 </span><span class="in">`BenchmarkResult`</span><span class="at"> 对象，这在跨多台计算机进行实验时非常有用：</span></span>
<span id="cb267-967"><a href="#cb267-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-968"><a href="#cb267-968" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-969"><a href="#cb267-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-970"><a href="#cb267-970" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-971"><a href="#cb267-971" aria-hidden="true" tabindex="-1"></a>bmr1 <span class="ot">=</span> <span class="fu">as_benchmark_result</span>(rr1)</span>
<span id="cb267-972"><a href="#cb267-972" aria-hidden="true" tabindex="-1"></a>bmr2 <span class="ot">=</span> <span class="fu">as_benchmark_result</span>(rr2)</span>
<span id="cb267-973"><a href="#cb267-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-974"><a href="#cb267-974" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(bmr1, bmr2)</span>
<span id="cb267-975"><a href="#cb267-975" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-976"><a href="#cb267-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-977"><a href="#cb267-977" aria-hidden="true" tabindex="-1"></a>Boxplots are most commonly used to visualize benchmark experiments as they can intuitively summarize results across tasks and learners simultaneously.</span>
<span id="cb267-978"><a href="#cb267-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-979"><a href="#cb267-979" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 箱线图最常用于可视化基准实验，因为它们可以直观地同时总结任务和学习器之间的结果。</span></span>
<span id="cb267-980"><a href="#cb267-980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-981"><a href="#cb267-981" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-982"><a href="#cb267-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-983"><a href="#cb267-983" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-984"><a href="#cb267-984" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-benchmark-box</span></span>
<span id="cb267-985"><a href="#cb267-985" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Boxplots of accuracy scores for each learner across resampling iterations and the three tasks. Random forests (`lrn("classif.ranger")`) consistently outperforms the other learners.'</span></span>
<span id="cb267-986"><a href="#cb267-986" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(bmr, <span class="at">measure =</span> <span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span>
<span id="cb267-987"><a href="#cb267-987" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-988"><a href="#cb267-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-989"><a href="#cb267-989" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluation of Binary Classifiers</span></span>
<span id="cb267-990"><a href="#cb267-990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-991"><a href="#cb267-991" aria-hidden="true" tabindex="-1"></a><span class="fu">### Confusion Matrix</span></span>
<span id="cb267-992"><a href="#cb267-992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-993"><a href="#cb267-993" aria-hidden="true" tabindex="-1"></a>It is possible for a classifier to have a good classification accuracy but to overlook the nuances provided by a full confusion matrix, as in the following <span class="in">`tsk("german_credit")`</span> example:</span>
<span id="cb267-994"><a href="#cb267-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-995"><a href="#cb267-995" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-996"><a href="#cb267-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-997"><a href="#cb267-997" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-998"><a href="#cb267-998" aria-hidden="true" tabindex="-1"></a>tsk_german <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"german_credit"</span>)</span>
<span id="cb267-999"><a href="#cb267-999" aria-hidden="true" tabindex="-1"></a>lrn_ranger <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb267-1000"><a href="#cb267-1000" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">=</span> <span class="fu">partition</span>(tsk_german, <span class="at">ratio =</span> .<span class="dv">8</span>)</span>
<span id="cb267-1001"><a href="#cb267-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1002"><a href="#cb267-1002" aria-hidden="true" tabindex="-1"></a>lrn_ranger<span class="sc">$</span><span class="fu">train</span>(tsk_german, splits<span class="sc">$</span>train)</span>
<span id="cb267-1003"><a href="#cb267-1003" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_ranger<span class="sc">$</span><span class="fu">predict</span>(tsk_german, splits<span class="sc">$</span>test)</span>
<span id="cb267-1004"><a href="#cb267-1004" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span>
<span id="cb267-1005"><a href="#cb267-1005" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span>confusion</span>
<span id="cb267-1006"><a href="#cb267-1006" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1007"><a href="#cb267-1007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1008"><a href="#cb267-1008" aria-hidden="true" tabindex="-1"></a>On their own, the absolute numbers in a confusion matrix can be less useful when there is class imbalance. Instead, several normalized measures can be derived (@fig-confusion):</span>
<span id="cb267-1009"><a href="#cb267-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1010"><a href="#cb267-1010" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**True Positive Rate (TPR)**, **Sensitivity** or **Recall**: How many of the true positives did we predict as positive?</span>
<span id="cb267-1011"><a href="#cb267-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1012"><a href="#cb267-1012" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**True Negative Rate (TNR)** or **Specificity**: How many of the true negatives did we predict as negative?</span>
<span id="cb267-1013"><a href="#cb267-1013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1014"><a href="#cb267-1014" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**False Positive Rate (FPR)**, or $1 -$ **Specificity**: How many of the true negatives did we predict as positive?</span>
<span id="cb267-1015"><a href="#cb267-1015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1016"><a href="#cb267-1016" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Positive Predictive Value (PPV)** or **Precision**: If we predict positive how likely is it a true positive?</span>
<span id="cb267-1017"><a href="#cb267-1017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1018"><a href="#cb267-1018" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Negative Predictive Value (NPV)**: If we predict negative how likely is it a true negative?</span>
<span id="cb267-1019"><a href="#cb267-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1020"><a href="#cb267-1020" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Accuracy (ACC)**: The proportion of correctly classified instances out of the total number of instances.</span>
<span id="cb267-1021"><a href="#cb267-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1022"><a href="#cb267-1022" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**F1-score**: The harmonic mean of precision and recall, which balances the trade-off between precision and recall. It is calculated as $2 \times \frac{Precision \times Recall}{Precision + Recall}$.</span>
<span id="cb267-1023"><a href="#cb267-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1024"><a href="#cb267-1024" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1025"><a href="#cb267-1025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1026"><a href="#cb267-1026" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1027"><a href="#cb267-1027" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb267-1028"><a href="#cb267-1028" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-confusion</span></span>
<span id="cb267-1029"><a href="#cb267-1029" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Binary confusion matrix of ground truth class vs. predicted class."</span></span>
<span id="cb267-1030"><a href="#cb267-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1031"><a href="#cb267-1031" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"imgs/confusion_matrix.svg"</span>)</span>
<span id="cb267-1032"><a href="#cb267-1032" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1033"><a href="#cb267-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1034"><a href="#cb267-1034" aria-hidden="true" tabindex="-1"></a>The <span class="in">`mlr3measures`</span> package allows you to compute several common confusion matrix-based measures using the <span class="in">`confusion_matrix()`</span> function:</span>
<span id="cb267-1035"><a href="#cb267-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1036"><a href="#cb267-1036" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1037"><a href="#cb267-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1038"><a href="#cb267-1038" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1039"><a href="#cb267-1039" aria-hidden="true" tabindex="-1"></a>mlr3measures<span class="sc">::</span><span class="fu">confusion_matrix</span>(</span>
<span id="cb267-1040"><a href="#cb267-1040" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> prediction<span class="sc">$</span>truth,</span>
<span id="cb267-1041"><a href="#cb267-1041" aria-hidden="true" tabindex="-1"></a>  <span class="at">response =</span> prediction<span class="sc">$</span>response,</span>
<span id="cb267-1042"><a href="#cb267-1042" aria-hidden="true" tabindex="-1"></a>  <span class="at">positive =</span> tsk_german<span class="sc">$</span>positive</span>
<span id="cb267-1043"><a href="#cb267-1043" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1044"><a href="#cb267-1044" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1045"><a href="#cb267-1045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1046"><a href="#cb267-1046" aria-hidden="true" tabindex="-1"></a><span class="fu">### ROC Analysis</span></span>
<span id="cb267-1047"><a href="#cb267-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1048"><a href="#cb267-1048" aria-hidden="true" tabindex="-1"></a>The ROC curve is a line graph with TPR on the y-axis and the FPR on the x-axis. </span>
<span id="cb267-1049"><a href="#cb267-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1050"><a href="#cb267-1050" aria-hidden="true" tabindex="-1"></a>Consider classifiers that predict probabilities instead of discrete classes. Using different thresholds to cut off predicted probabilities and assign them to the positive and negative class will lead to different TPRs and FPRs and by plotting these values across different thresholds we can characterize the behavior of a binary classifier – this is the ROC curve.</span>
<span id="cb267-1051"><a href="#cb267-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1052"><a href="#cb267-1052" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 考虑预测概率而不是离散类别的分类器。使用不同的阈值来截断预测的概率并将其分配到正类别和负类别将导致不同的 TPR 和 FPR，并通过在不同的阈值上绘制这些值，我们可以表征二元分类器的行为 - 这就是 ROC 曲线。</span></span>
<span id="cb267-1053"><a href="#cb267-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1054"><a href="#cb267-1054" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1055"><a href="#cb267-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1056"><a href="#cb267-1056" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1057"><a href="#cb267-1057" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-basics-roc-ranger</span></span>
<span id="cb267-1058"><a href="#cb267-1058" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "ROC-curve based on the `german_credit` dataset and the `classif.ranger` random forest learner. Recall FPR = $1 -$ Specificity and TPR = Sensitivity."</span></span>
<span id="cb267-1059"><a href="#cb267-1059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1060"><a href="#cb267-1060" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(prediction, <span class="at">type =</span> <span class="st">"roc"</span>)</span>
<span id="cb267-1061"><a href="#cb267-1061" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1062"><a href="#cb267-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1063"><a href="#cb267-1063" aria-hidden="true" tabindex="-1"></a>A natural performance measure that can be derived from the ROC curve is the area under the curve (AUC), implemented in <span class="in">`msr("classif.auc")`</span>. The AUC can be interpreted as the probability that a randomly chosen positive instance has a higher predicted probability of belonging to the positive class than a randomly chosen negative instance. Therefore, higher values (closer to </span>
<span id="cb267-1064"><a href="#cb267-1064" aria-hidden="true" tabindex="-1"></a>) indicate better performance. Random classifiers (such as the featureless baseline) will always have an AUC of (approximately, when evaluated empirically) 0.5.</span>
<span id="cb267-1065"><a href="#cb267-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1066"><a href="#cb267-1066" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 从 ROC 曲线中可以导出的一个自然性能度量是曲线下面积（AUC），在 </span><span class="in">`msr("classif.auc")`</span><span class="at"> 中实现。AUC 可以解释为随机选择的正实例具有较高的预测概率，属于正类别，而不是随机选择的负实例的概率。因此，较高的值（越接近 1）表示更好的性能。随机分类器（例如没有特征的基线）的AUC总是为（在经验上评估时约为 0.5）。</span></span>
<span id="cb267-1067"><a href="#cb267-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1068"><a href="#cb267-1068" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1069"><a href="#cb267-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1070"><a href="#cb267-1070" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1071"><a href="#cb267-1071" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.auc"</span>))</span>
<span id="cb267-1072"><a href="#cb267-1072" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1073"><a href="#cb267-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1074"><a href="#cb267-1074" aria-hidden="true" tabindex="-1"></a>We can also plot the precision-recall curve (PRC) which visualizes the PPV/precision vs. TPR/recall. The main difference between ROC curves and PR curves is that the number of true-negatives are ignored in the latter. This can be useful in imbalanced populations where the positive class is rare, and where a classifier with high TPR may still not be very informative and have low PPV. See Davis and Goadrich (2006) for a detailed discussion about the relationship between the PRC and ROC curves.</span>
<span id="cb267-1075"><a href="#cb267-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1076"><a href="#cb267-1076" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们还可以绘制精确度-召回曲线（PRC），该曲线可视化了 PPV/精确度 与 TPR/召回 之间的关系。ROC曲线和PR曲线之间的主要区别在于后者忽略了真负例的数量。在不平衡的人群中，正类别很少见的情况下，具有高TPR的分类器可能仍然不太具有信息性，并且具有较低的PPV。有关PRC和ROC曲线之间关系的详细讨论，请参阅 Davis 和 Goadrich（2006）。</span></span>
<span id="cb267-1077"><a href="#cb267-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1078"><a href="#cb267-1078" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1079"><a href="#cb267-1079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1080"><a href="#cb267-1080" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1081"><a href="#cb267-1081" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Precision-Recall curve based on `tsk("german_credit")` and `lrn("classif.ranger")`.'</span></span>
<span id="cb267-1082"><a href="#cb267-1082" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-basics-prc-ranger</span></span>
<span id="cb267-1083"><a href="#cb267-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1084"><a href="#cb267-1084" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(prediction, <span class="at">type =</span> <span class="st">"prc"</span>)</span>
<span id="cb267-1085"><a href="#cb267-1085" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1086"><a href="#cb267-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1087"><a href="#cb267-1087" aria-hidden="true" tabindex="-1"></a>Finally, we can visualize ROC/PR curves for a <span class="in">`BenchmarkResult`</span> to compare multiple learners on the same <span class="in">`Task`</span>:</span>
<span id="cb267-1088"><a href="#cb267-1088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1089"><a href="#cb267-1089" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1090"><a href="#cb267-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1091"><a href="#cb267-1091" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1092"><a href="#cb267-1092" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-1093"><a href="#cb267-1093" aria-hidden="true" tabindex="-1"></a>design <span class="ot">=</span> <span class="fu">benchmark_grid</span>(</span>
<span id="cb267-1094"><a href="#cb267-1094" aria-hidden="true" tabindex="-1"></a>  <span class="at">tasks =</span> <span class="fu">tsk</span>(<span class="st">"german_credit"</span>),</span>
<span id="cb267-1095"><a href="#cb267-1095" aria-hidden="true" tabindex="-1"></a>  <span class="at">learners =</span> <span class="fu">lrns</span>(<span class="fu">c</span>(<span class="st">"classif.rpart"</span>, <span class="st">"classif.ranger"</span>),</span>
<span id="cb267-1096"><a href="#cb267-1096" aria-hidden="true" tabindex="-1"></a>                  <span class="at">predict_type =</span> <span class="st">"prob"</span>),</span>
<span id="cb267-1097"><a href="#cb267-1097" aria-hidden="true" tabindex="-1"></a>  <span class="at">resamplings =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>)</span>
<span id="cb267-1098"><a href="#cb267-1098" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1099"><a href="#cb267-1099" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(design)</span>
<span id="cb267-1100"><a href="#cb267-1100" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1101"><a href="#cb267-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1102"><a href="#cb267-1102" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1103"><a href="#cb267-1103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1104"><a href="#cb267-1104" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1105"><a href="#cb267-1105" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-basics-rocpr-bmr</span></span>
<span id="cb267-1106"><a href="#cb267-1106" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Comparing random forest (green) and decision tree (purple) using ROC and PR Curves.'</span></span>
<span id="cb267-1107"><a href="#cb267-1107" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(bmr, <span class="at">type =</span> <span class="st">"roc"</span>) <span class="sc">+</span></span>
<span id="cb267-1108"><a href="#cb267-1108" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(bmr, <span class="at">type =</span> <span class="st">"prc"</span>) <span class="sc">+</span></span>
<span id="cb267-1109"><a href="#cb267-1109" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot_layout</span>(<span class="at">guides =</span> <span class="st">"collect"</span>)</span>
<span id="cb267-1110"><a href="#cb267-1110" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1111"><a href="#cb267-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1112"><a href="#cb267-1112" aria-hidden="true" tabindex="-1"></a><span class="fu"># Tuning and Feature Selection {.unnumbered}</span></span>
<span id="cb267-1113"><a href="#cb267-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1114"><a href="#cb267-1114" aria-hidden="true" tabindex="-1"></a><span class="fu"># Hyperparameter Optimization {#sec-optimization}</span></span>
<span id="cb267-1115"><a href="#cb267-1115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1116"><a href="#cb267-1116" aria-hidden="true" tabindex="-1"></a>Hyperparameter optimization (HPO) closely relates to model evaluation (@sec-performance) as the objective is to find a hyperparameter configuration that optimizes the generalization performance. Broadly speaking, we could think of finding the optimal model configuration in the same way as selecting a model from a benchmark experiment, where in this case each model in the experiment is the same algorithm but with different hyperparameter configurations. For example, we could benchmark three support vector machines (SVMs) with three different <span class="in">`cost`</span> values.</span>
<span id="cb267-1117"><a href="#cb267-1117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1118"><a href="#cb267-1118" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; HPO与模型评估（@sec-performance）密切相关，因为目标是找到一个优化泛化性能的超参数配置。从广义上讲，我们可以将找到最佳模型配置视为从基准实验中选择模型的方式，其中在这种情况下，实验中的每个模型都是相同的算法，但具有不同的超参数配置。例如，我们可以使用三个不同 </span><span class="in">`cost`</span><span class="at"> 值来进行支持向量机（SVM）的基准测试。</span></span>
<span id="cb267-1119"><a href="#cb267-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1120"><a href="#cb267-1120" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Tuning</span></span>
<span id="cb267-1121"><a href="#cb267-1121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1122"><a href="#cb267-1122" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3tuning`</span> is the hyperparameter optimization package of the <span class="in">`mlr3`</span> ecosystem. At the heart of the package are the R6 classes</span>
<span id="cb267-1123"><a href="#cb267-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1124"><a href="#cb267-1124" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`TuningInstanceSingleCrit`</span>, a tuning ‘instance’ that describes the optimization problem and store the results; and</span>
<span id="cb267-1125"><a href="#cb267-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1126"><a href="#cb267-1126" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Tuner`</span> which is used to configure and run optimization algorithms.</span>
<span id="cb267-1127"><a href="#cb267-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1128"><a href="#cb267-1128" aria-hidden="true" tabindex="-1"></a><span class="fu">### Learner and Search Space</span></span>
<span id="cb267-1129"><a href="#cb267-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1130"><a href="#cb267-1130" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1131"><a href="#cb267-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1132"><a href="#cb267-1132" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1133"><a href="#cb267-1133" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(<span class="fu">lrn</span>(<span class="st">"classif.svm"</span>)<span class="sc">$</span>param_set)[,</span>
<span id="cb267-1134"><a href="#cb267-1134" aria-hidden="true" tabindex="-1"></a>                                      .(id, class, lower, upper, nlevels)]</span>
<span id="cb267-1135"><a href="#cb267-1135" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1136"><a href="#cb267-1136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1137"><a href="#cb267-1137" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1138"><a href="#cb267-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1139"><a href="#cb267-1139" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1140"><a href="#cb267-1140" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.svm"</span>,</span>
<span id="cb267-1141"><a href="#cb267-1141" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"C-classification"</span>,</span>
<span id="cb267-1142"><a href="#cb267-1142" aria-hidden="true" tabindex="-1"></a>    <span class="at">kernel =</span> <span class="st">"radial"</span>,</span>
<span id="cb267-1143"><a href="#cb267-1143" aria-hidden="true" tabindex="-1"></a>    <span class="at">cost =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="fl">1e5</span>),</span>
<span id="cb267-1144"><a href="#cb267-1144" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="dv">1</span>))</span>
<span id="cb267-1145"><a href="#cb267-1145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1146"><a href="#cb267-1146" aria-hidden="true" tabindex="-1"></a>learner</span>
<span id="cb267-1147"><a href="#cb267-1147" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1148"><a href="#cb267-1148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1149"><a href="#cb267-1149" aria-hidden="true" tabindex="-1"></a><span class="fu">### Terminator {#sec-terminator}</span></span>
<span id="cb267-1150"><a href="#cb267-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1151"><a href="#cb267-1151" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3tuning`</span> includes many methods to specify when to terminate an algorithm (@tbl-terms), which are implemented in <span class="in">`Terminator`</span> classes. Terminators are stored in the <span class="in">`mlr_terminators`</span> dictionary and are constructed with the sugar function <span class="in">`trm()`</span>.</span>
<span id="cb267-1152"><a href="#cb267-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1153"><a href="#cb267-1153" aria-hidden="true" tabindex="-1"></a>| Terminator            | Function call and default parameters                                    |</span>
<span id="cb267-1154"><a href="#cb267-1154" aria-hidden="true" tabindex="-1"></a>|-----------------------|-------------------------------------------------------------------------|</span>
<span id="cb267-1155"><a href="#cb267-1155" aria-hidden="true" tabindex="-1"></a>| Clock Time            | <span class="in">`trm("clock_time")`</span>              |</span>
<span id="cb267-1156"><a href="#cb267-1156" aria-hidden="true" tabindex="-1"></a>| Combo                 | <span class="in">`trm("combo", any = TRUE)`</span> |</span>
<span id="cb267-1157"><a href="#cb267-1157" aria-hidden="true" tabindex="-1"></a>| None                  | <span class="in">`trm("none")`</span>                                                           |</span>
<span id="cb267-1158"><a href="#cb267-1158" aria-hidden="true" tabindex="-1"></a>| Number of Evaluations | <span class="in">`trm("evals", n_evals = 100, k = 0)`</span>                                           |</span>
<span id="cb267-1159"><a href="#cb267-1159" aria-hidden="true" tabindex="-1"></a>| Performance Level     | <span class="in">`trm("perf_reached", level = 0.1)`</span>                                      |</span>
<span id="cb267-1160"><a href="#cb267-1160" aria-hidden="true" tabindex="-1"></a>| Run Time              | <span class="in">`trm("run_time", secs = 30)`</span>                                           |</span>
<span id="cb267-1161"><a href="#cb267-1161" aria-hidden="true" tabindex="-1"></a>| Stagnation            | <span class="in">`trm("stagnation", iters = 10, threshold = 0)`</span>                        |</span>
<span id="cb267-1162"><a href="#cb267-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1163"><a href="#cb267-1163" aria-hidden="true" tabindex="-1"></a>: Terminators available in <span class="in">`mlr3tuning`</span> at the time of publication, their function call and default parameters. A complete and up-to-date list can be found at <span class="ot">&lt;https://mlr-org.com/terminators.html&gt;</span>. {#tbl-terms}</span>
<span id="cb267-1164"><a href="#cb267-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1165"><a href="#cb267-1165" aria-hidden="true" tabindex="-1"></a>The most commonly used terminators are those that stop the tuning after a certain time (<span class="in">`trm("run_time")`</span>) or a given number of evaluations (<span class="in">`trm("evals")`</span>). Choosing a runtime is often based on practical considerations and intuition. Using a time limit can be important on compute clusters where a maximum runtime for a compute job may need to be specified. <span class="in">`trm("perf_reached")`</span> stops the tuning when a specified performance level is reached, which can be helpful if a certain performance is seen as sufficient for the practical use of the model, however, if this is set too optimistically the tuning may never terminate. <span class="in">`trm("stagnation")`</span> stops when no progress greater than the threshold has been made for a set number of iterations. The threshold can be difficult to select as the optimization could stop too soon for complex search spaces despite room for (possibly significant) improvement. <span class="in">`trm("none")`</span> is used for tuners that control termination themselves and so this terminator does nothing. Finally, any of these terminators can be freely combined by using <span class="in">`trm("combo")`</span>, which can be used to specify if HPO finishes when any (<span class="in">`any = TRUE`</span>) terminator is triggered or when all (<span class="in">`any = FALSE`</span>) are triggered.</span>
<span id="cb267-1166"><a href="#cb267-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1167"><a href="#cb267-1167" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 最常用的终止条件通常是那些在一定时间（</span><span class="in">`trm("run_time")`</span><span class="at">）或给定的评估次数（</span><span class="in">`trm("evals")`</span><span class="at">）之后停止调优的条件。选择运行时间通常基于实际考虑和直觉。在计算集群上使用时间限制可能很重要，因为可能需要为计算作业指定最大运行时间。</span><span class="in">`trm("perf_reached")`</span><span class="at">在达到指定性能水平时停止调优，这可以在某种性能被视为足够实际使用的情况下很有帮助，但如果设置得过于乐观，调优可能永远不会结束。</span><span class="in">`trm("stagnation")`</span><span class="at">在一定迭代次数内没有超过阈值的进展时停止，阈值的选择可能很困难，因为尽管可能有改进的空间（可能很大），但对于复杂的搜索空间，优化可能会过早停止。</span><span class="in">`trm("none")`</span><span class="at">用于控制自己终止的调谐器，因此该终止条件什么也不做。最后，任何这些终止条件都可以通过使用</span><span class="in">`trm("combo")`</span><span class="at">自由组合，可以用来指定HPO是否在任何（</span><span class="in">`any = TRUE`</span><span class="at">）终止条件触发时结束，或者在所有（</span><span class="in">`any = FALSE`</span><span class="at">）终止条件触发时结束。</span></span>
<span id="cb267-1168"><a href="#cb267-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1169"><a href="#cb267-1169" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning Instance with `ti`</span></span>
<span id="cb267-1170"><a href="#cb267-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1171"><a href="#cb267-1171" aria-hidden="true" tabindex="-1"></a>The tuning instance collects the tuner-agnostic information required to optimize a model, i.e., all information about the tuning process, except for the tuning algorithm itself. This includes the task to tune over, the learner to tune, the resampling method and measure used to analytically compare hyperparameter optimization configurations, and the terminator to determine when the measure has been optimized ‘enough’. This implicitly defines a “black box” objective function, mapping hyperparameter configurations to (stochastic) performance values, to be optimized. This concept will be revisited in @sec-optimization-advanced.</span>
<span id="cb267-1172"><a href="#cb267-1172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1173"><a href="#cb267-1173" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 调优实例收集了优化模型所需的与调谐器无关的信息，即所有与调优过程有关的信息，除了调谐算法本身。这包括要调优的任务、要调优的学习器、用于分析比较超参数优化配置的重抽样方法和度量，以及确定度量何时已经被优化到足够程度的终止条件。这隐式地定义了一个“黑盒”目标函数，将超参数配置映射到（随机的）性能值，以便进行优化。这个概念将在 @sec-optimization-advanced 中重新讨论。</span></span>
<span id="cb267-1174"><a href="#cb267-1174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1175"><a href="#cb267-1175" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1176"><a href="#cb267-1176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1177"><a href="#cb267-1177" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1178"><a href="#cb267-1178" aria-hidden="true" tabindex="-1"></a>tsk_sonar <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"sonar"</span>)</span>
<span id="cb267-1179"><a href="#cb267-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1180"><a href="#cb267-1180" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">ti</span>(</span>
<span id="cb267-1181"><a href="#cb267-1181" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> tsk_sonar,</span>
<span id="cb267-1182"><a href="#cb267-1182" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> learner,</span>
<span id="cb267-1183"><a href="#cb267-1183" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>),</span>
<span id="cb267-1184"><a href="#cb267-1184" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> <span class="fu">msr</span>(<span class="st">"classif.ce"</span>),</span>
<span id="cb267-1185"><a href="#cb267-1185" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"none"</span>)</span>
<span id="cb267-1186"><a href="#cb267-1186" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1187"><a href="#cb267-1187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1188"><a href="#cb267-1188" aria-hidden="true" tabindex="-1"></a>instance</span>
<span id="cb267-1189"><a href="#cb267-1189" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1190"><a href="#cb267-1190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1191"><a href="#cb267-1191" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuner</span></span>
<span id="cb267-1192"><a href="#cb267-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1193"><a href="#cb267-1193" aria-hidden="true" tabindex="-1"></a>With all the pieces of our tuning problem assembled, we can now decide how to tune our model. There are multiple <span class="in">`Tuner`</span> classes in <span class="in">`mlr3tuning`</span>, which implement different HPO (or more generally speaking black box optimization) algorithms (@tbl-tuners).</span>
<span id="cb267-1194"><a href="#cb267-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1195"><a href="#cb267-1195" aria-hidden="true" tabindex="-1"></a>| Tuner                           | Function call          | Package               |</span>
<span id="cb267-1196"><a href="#cb267-1196" aria-hidden="true" tabindex="-1"></a>|---------------------------------|------------------------|-----------------------|</span>
<span id="cb267-1197"><a href="#cb267-1197" aria-hidden="true" tabindex="-1"></a>| Random Search                   | <span class="in">`tnr("random_search")`</span> | <span class="in">`mlr3tuning`</span>        |</span>
<span id="cb267-1198"><a href="#cb267-1198" aria-hidden="true" tabindex="-1"></a>| Grid Search                     | <span class="in">`tnr("grid_search")`</span>   | <span class="in">`mlr3tuning`</span>        |</span>
<span id="cb267-1199"><a href="#cb267-1199" aria-hidden="true" tabindex="-1"></a>| Bayesian Optimization           | <span class="in">`tnr("mbo")`</span>           | <span class="in">`mlr3mbo`</span>           |</span>
<span id="cb267-1200"><a href="#cb267-1200" aria-hidden="true" tabindex="-1"></a>| CMA-ES                          | <span class="in">`tnr("cmaes")`</span>         | <span class="in">`adagio`</span> |</span>
<span id="cb267-1201"><a href="#cb267-1201" aria-hidden="true" tabindex="-1"></a>| Iterated Racing                | <span class="in">`tnr("irace")`</span>         | <span class="in">`irace`</span>  |</span>
<span id="cb267-1202"><a href="#cb267-1202" aria-hidden="true" tabindex="-1"></a>| Hyperband                       | <span class="in">`tnr("hyperband")`</span>     | <span class="in">`mlr3hyperband`</span>     |</span>
<span id="cb267-1203"><a href="#cb267-1203" aria-hidden="true" tabindex="-1"></a>| Generalized Simulated Annealing | <span class="in">`tnr("gensa")`</span>         | <span class="in">`GenSA`</span>  |</span>
<span id="cb267-1204"><a href="#cb267-1204" aria-hidden="true" tabindex="-1"></a>| Nonlinear Optimization          | <span class="in">`tnr("nloptr")`</span>        | <span class="in">`nloptr`</span> |</span>
<span id="cb267-1205"><a href="#cb267-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1206"><a href="#cb267-1206" aria-hidden="true" tabindex="-1"></a>: Tuning algorithms available in <span class="in">`mlr3tuning`</span>, their function call and the package in which the algorithm is implemented. A complete and up-to-date list can be found at <span class="ot">&lt;https://mlr-org.com/tuners.html&gt;</span>. {#tbl-tuners}</span>
<span id="cb267-1207"><a href="#cb267-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1208"><a href="#cb267-1208" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Search Strategies</span></span>
<span id="cb267-1209"><a href="#cb267-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1210"><a href="#cb267-1210" aria-hidden="true" tabindex="-1"></a>Grid search and random search (Bergstra and Bengio 2012) are the most basic algorithms and are often selected first in initial experiments. The idea of grid search is to exhaustively evaluate every possible combination of given hyperparameter values. Categorical hyperparameters are usually evaluated over all possible values they can take. Numeric and integer hyperparameter values are then spaced equidistantly in their box constraints (upper and lower bounds) according to a given resolution, which is the number of distinct values to try per hyperparameter. Random search involves randomly selecting values for each hyperparameter independently from a pre-specified distribution, usually uniform. Both methods are non-adaptive, which means each proposed configuration ignores the performance of previous configurations. Due to their simplicity, both grid search and random search can handle mixed search spaces (i.e., hyperparameters can be numeric, integer, or categorical) as well as hierarchical search spaces (@sec-defining-search-spaces).</span>
<span id="cb267-1211"><a href="#cb267-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1212"><a href="#cb267-1212" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 网格搜索和随机搜索（Bergstra和Bengio 2012）是最基本的算法，通常在初始实验中首选。网格搜索的思想是详尽地评估给定超参数值的每种可能组合。通常会对分类超参数评估它们可以取的所有可能值。然后，数值和整数超参数值将根据给定的分辨率均匀分布在它们的箱约束（上下界）中，分辨率是每个超参数要尝试的不同值的数量。随机搜索涉及从预先指定的分布（通常是均匀分布）中独立地随机选择每个超参数的值。这两种方法都是非自适应的，这意味着每个提出的配置都忽略了先前配置的性能。由于它们的简单性，网格搜索和随机搜索可以处理混合搜索空间（即，超参数可以是数值、整数或分类的）以及分层搜索空间（@sec-defining-search-spaces）。</span></span>
<span id="cb267-1213"><a href="#cb267-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1214"><a href="#cb267-1214" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Adaptive Algorithms</span></span>
<span id="cb267-1215"><a href="#cb267-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1216"><a href="#cb267-1216" aria-hidden="true" tabindex="-1"></a>Adaptive algorithms learn from previously evaluated configurations to find good configurations quickly, examples in <span class="in">`mlr3`</span> include Bayesian optimization (also called model-based optimization), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), Iterated Racing, and Hyperband.</span>
<span id="cb267-1217"><a href="#cb267-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1218"><a href="#cb267-1218" aria-hidden="true" tabindex="-1"></a>Bayesian optimization (e.g., Snoek, Larochelle, and Adams 2012) describes a family of iterative optimization algorithms that use a surrogate model to approximate the unknown function that is to be optimized – in HPO this would be the mapping from a hyperparameter configuration to the estimated generalization performance. If a suitable surrogate model is chosen, e.g. a random forest, Bayesian optimization can be quite flexible and even handle mixed and hierarchical search spaces. Bayesian optimization is discussed in full detail in @sec-bayesian-optimization.</span>
<span id="cb267-1219"><a href="#cb267-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1220"><a href="#cb267-1220" aria-hidden="true" tabindex="-1"></a>CMA-ES (Hansen and Auger 2011) is an evolutionary strategy that maintains a probability distribution over candidate points, with the distribution represented by a mean vector and covariance matrix. A new set of candidate points is generated by sampling from this distribution, with the probability of each candidate being proportional to its performance. The covariance matrix is adapted over time to reflect the performance landscape. Further evolutionary strategies are available in <span class="in">`mlr3`</span> via the <span class="in">`miesmuschel`</span> package, however, these will not be covered in this book.</span>
<span id="cb267-1221"><a href="#cb267-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1222"><a href="#cb267-1222" aria-hidden="true" tabindex="-1"></a>Racing algorithms work by iteratively discarding configurations that show poor performance, as determined by statistical tests. Iterated Racing (López-Ibáñez et al. 2016) starts by ‘racing’ down an initial population of randomly sampled configurations from a parameterized density and then uses the surviving configurations of the race to stochastically update the density of the subsequent race to focus on promising regions of the search space, and so on.</span>
<span id="cb267-1223"><a href="#cb267-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1224"><a href="#cb267-1224" aria-hidden="true" tabindex="-1"></a>Multi-fidelity HPO is an adaptive method that leverages the predictive power of computationally cheap lower fidelity evaluations (i.e., poorer quality predictions such as those arising from neural networks with a small number of epochs) to improve the overall optimization efficiency. This concept is used in Hyperband (Li et al. 2018), a popular multi-fidelity hyperparameter optimization algorithm that dynamically allocates increasingly more resources to promising configurations and terminates low-performing ones. Hyperband is discussed in full detail in @sec-hyperband.</span>
<span id="cb267-1225"><a href="#cb267-1225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1226"><a href="#cb267-1226" aria-hidden="true" tabindex="-1"></a>Other implemented algorithms for numeric search spaces are Generalized Simulated Annealing (Xiang et al. 2013; Tsallis and Stariolo 1996) and various nonlinear optimization algorithms.</span>
<span id="cb267-1227"><a href="#cb267-1227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1228"><a href="#cb267-1228" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 自适应算法通过学习先前评估的配置来快速找到良好的配置，</span><span class="in">`mlr3`</span><span class="at">中的示例包括贝叶斯优化（也称为基于模型的优化）、协方差矩阵自适应进化策略（CMA-ES）、迭代比赛和Hyperband。</span></span>
<span id="cb267-1229"><a href="#cb267-1229" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1230"><a href="#cb267-1230" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 贝叶斯优化（例如，Snoek、Larochelle和Adams 2012）描述了一族迭代优化算法，这些算法使用替代模型来近似待优化的未知函数——在HPO中，这将是从超参数配置到估计的泛化性能的映射。如果选择了合适的替代模型，例如随机森林，贝叶斯优化可以非常灵活，甚至可以处理混合和分层搜索空间。贝叶斯优化将在 @sec-bayesian-optimization 中详细讨论。</span></span>
<span id="cb267-1231"><a href="#cb267-1231" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1232"><a href="#cb267-1232" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; CMA-ES（Hansen和Auger 2011）是一种进化策略，它维护了候选点的概率分布，分布由均值向量和协方差矩阵表示。通过从该分布中抽样生成一组新的候选点，每个候选点的选择概率与其性能成正比。协方差矩阵会随着时间的推移而适应反映性能景观。通过</span><span class="in">`mlr3`</span><span class="at">中的</span><span class="in">`miesmuschel`</span><span class="at">包，还提供了其他进化策略，不过本书不会涵盖这些内容。</span></span>
<span id="cb267-1233"><a href="#cb267-1233" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1234"><a href="#cb267-1234" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 比赛算法通过迭代地丢弃显示性能较差的配置，这是通过统计测试确定的。迭代比赛（López-Ibáñez等人2016）首先通过从参数化密度中随机抽样生成的一组初始配置进行“比赛”，然后使用比赛的生存配置来随机更新后续比赛的密度，以便集中在搜索空间的有前途的区域，依此类推。</span></span>
<span id="cb267-1235"><a href="#cb267-1235" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1236"><a href="#cb267-1236" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 多保真度HPO是一种自适应方法，利用计算成本低的低保真度评估（即质量较差的预测，例如由具有较少周期的神经网络产生的预测）来提高整体优化效率。这个概念在Hyperband（Li等人2018）中得到了应用，这是一种流行的多保真度超参数优化算法，动态分配更多资源给有前途的配置并终止性能较低的配置。Hyperband将在 @sec-hyperband 中详细讨论。</span></span>
<span id="cb267-1237"><a href="#cb267-1237" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1238"><a href="#cb267-1238" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 对于数值搜索空间，其他已实现的算法包括广义模拟退火（Xiang等人2013；Tsallis和Stariolo 1996）和各种非线性优化算法。</span></span>
<span id="cb267-1239"><a href="#cb267-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1240"><a href="#cb267-1240" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Choosing Strategies</span></span>
<span id="cb267-1241"><a href="#cb267-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1242"><a href="#cb267-1242" aria-hidden="true" tabindex="-1"></a>As a rule of thumb, if the search space is small or does not have a complex structure, grid search may be able to exhaustively evaluate the entire search space in a reasonable time. However, grid search is generally not recommended due to the curse of dimensionality – the grid size ‘blows up’ very quickly as the number of parameters to tune increases – and insufficient coverage of numeric search spaces. By construction, grid search cannot evaluate a large number of unique values per hyperparameter, which is suboptimal when some hyperparameters have minimal impact on performance while others do. In such scenarios, random search is often a better choice as it considers more unique values per hyperparameter compared to grid search.</span>
<span id="cb267-1243"><a href="#cb267-1243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1244"><a href="#cb267-1244" aria-hidden="true" tabindex="-1"></a>For higher-dimensional search spaces or search spaces with more complex structure, more guided optimization algorithms such as evolutionary strategies or Bayesian optimization tend to perform better and are more likely to result in peak performance. When choosing between evolutionary strategies and Bayesian optimization, the cost of function evaluation is highly relevant. If hyperparameter configurations can be evaluated quickly, evolutionary strategies often work well. On the other hand, if model evaluations are time-consuming and the optimization budget is limited, Bayesian optimization is usually preferred, as it is quite sample efficient compared to other algorithms, i.e., less function evaluations are needed to find good configurations. Hence, Bayesian optimization is usually recommended for HPO. While the optimization overhead of Bayesian optimization is comparably large (e.g., in each iteration, training of the surrogate model and optimizing the acquisition function), this has less of an impact in the context of relatively costly function evaluations such as resampling of ML models.</span>
<span id="cb267-1245"><a href="#cb267-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1246"><a href="#cb267-1246" aria-hidden="true" tabindex="-1"></a>Finally, in cases where the hyperparameter optimization problem involves a meaningful fidelity parameter (e.g., number of epochs, number of trees, number of boosting rounds) and where the optimization budget needs to be spent efficiently, multi-fidelity hyperparameter optimization algorithms like Hyperband may be worth considering. For further details on different tuners and practical recommendations, we refer to Bischl et al. (2023).</span>
<span id="cb267-1247"><a href="#cb267-1247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1248"><a href="#cb267-1248" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 作为一个经验法则，如果搜索空间较小或没有复杂的结构，网格搜索可能能够在合理的时间内详尽地评估整个搜索空间。然而，通常不建议使用网格搜索，因为维度的诅咒问题——随着要调整的参数数量的增加，网格大小会迅速增加——以及对数值搜索空间的不足覆盖。从构造上来说，网格搜索不能评估每个超参数的大量唯一值，这在某些超参数对性能影响较小而其他超参数对性能有显著影响的情况下是不够优化的。在这种情况下，随机搜索通常是更好的选择，因为它考虑了每个超参数的更多唯一值，相对于网格搜索而言。</span></span>
<span id="cb267-1249"><a href="#cb267-1249" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1250"><a href="#cb267-1250" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 对于维度较高的搜索空间或搜索空间具有更复杂结构的情况，更有导向性的优化算法，如进化策略或贝叶斯优化，往往表现更好，并更有可能产生最佳性能。在选择进化策略和贝叶斯优化之间，函数评估成本非常重要。如果可以快速评估超参数配置，通常进化策略效果良好。另一方面，如果模型评估需要耗费时间，且优化预算有限，通常首选贝叶斯优化，因为与其他算法相比，它相对高效，即需要更少的函数评估来找到好的配置。因此，通常建议在HPO中使用贝叶斯优化。虽然贝叶斯优化的优化开销相对较大（例如，在每个迭代中，训练替代模型和优化获取函数），但在相对昂贵的函数评估环境中，例如ML模型的重新抽样，这影响较小。</span></span>
<span id="cb267-1251"><a href="#cb267-1251" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1252"><a href="#cb267-1252" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 最后，在超参数优化问题涉及有意义的保真度参数（例如，周期数、树数、提升轮数）且需要高效利用优化预算的情况下，可能值得考虑使用多保真度超参数优化算法，例如Hyperband。关于不同调谐器和实际建议的更多详细信息，请参阅Bischl等人（2023）。</span></span>
<span id="cb267-1253"><a href="#cb267-1253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1254"><a href="#cb267-1254" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1255"><a href="#cb267-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1256"><a href="#cb267-1256" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1257"><a href="#cb267-1257" aria-hidden="true" tabindex="-1"></a>tuner <span class="ot">=</span> <span class="fu">tnr</span>(<span class="st">"grid_search"</span>, <span class="at">resolution =</span> <span class="dv">5</span>, <span class="at">batch_size =</span> <span class="dv">10</span>)</span>
<span id="cb267-1258"><a href="#cb267-1258" aria-hidden="true" tabindex="-1"></a>tuner</span>
<span id="cb267-1259"><a href="#cb267-1259" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1260"><a href="#cb267-1260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1261"><a href="#cb267-1261" aria-hidden="true" tabindex="-1"></a>::: {.callout-caution}</span>
<span id="cb267-1262"><a href="#cb267-1262" aria-hidden="true" tabindex="-1"></a>TODO：等待后续添加交叉引用 10.1.3</span>
<span id="cb267-1263"><a href="#cb267-1263" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb267-1264"><a href="#cb267-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1265"><a href="#cb267-1265" aria-hidden="true" tabindex="-1"></a>For our SVM example, we will use a grid search with a resolution of five for runtime reasons here (in practice a larger resolution would be preferred). The resolution is the number of distinct values to try per hyperparameter, which means in our example the tuner will construct a 5x5 grid of 25 configurations of equally spaced points between the specified upper and lower bounds. All configurations will be tried by the tuner (in random order) until either all configurations are evaluated or the terminator (@sec-terminator) signals that the budget is exhausted. For grid and random search tuners, the <span class="in">`batch_size`</span> parameter controls how many configurations are evaluated at the same time when parallelization is enabled (see Section 10.1.3), and also determines how many configurations should be applied before the terminator should check if the termination criterion has been reached.</span>
<span id="cb267-1266"><a href="#cb267-1266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1267"><a href="#cb267-1267" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 对于我们的SVM示例，出于运行时的原因，我们将使用具有五个分辨率的网格搜索（在实践中，更大的分辨率将更可取）。分辨率是每个超参数要尝试的不同值的数量，这意味着在我们的示例中，调谐器将构建一个5x5的网格，其中包含25个在指定上限和下限之间等间距点的配置。调谐器将尝试所有配置（以随机顺序），直到所有配置都被评估或终止器（@sec-terminator）发出预算已用尽的信号。对于网格搜索和随机搜索调谐器，</span><span class="in">`batch_size`</span><span class="at"> 参数控制在启用并行化时同时评估多少个配置（请参阅第10.1.3节），并确定在终止器检查是否达到终止标准之前应用多少个配置。</span></span>
<span id="cb267-1268"><a href="#cb267-1268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1269"><a href="#cb267-1269" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1270"><a href="#cb267-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1271"><a href="#cb267-1271" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1272"><a href="#cb267-1272" aria-hidden="true" tabindex="-1"></a>tuner<span class="sc">$</span>param_set</span>
<span id="cb267-1273"><a href="#cb267-1273" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1274"><a href="#cb267-1274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1275"><a href="#cb267-1275" aria-hidden="true" tabindex="-1"></a>While changing the control parameters of the tuner can improve optimal performance, we have to take care that is likely the default settings will fit most needs. While it is not possible to cover all application cases, <span class="in">`mlr3tuning`</span>’s defaults were chosen to work well in most cases. However, some control parameters like <span class="in">`batch_size`</span> often interact with the parallelization setup (further described in Section 10.1.3) and may need to be adjusted accordingly.</span>
<span id="cb267-1276"><a href="#cb267-1276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1277"><a href="#cb267-1277" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 尽管更改调谐器的控制参数可以改善最优性能，但我们必须注意，通常情况下默认设置将适用于大多数需求。虽然不可能涵盖所有应用情况，但</span><span class="in">`mlr3tuning`</span><span class="at">的默认设置被选择为在大多数情况下表现良好。但是，一些控制参数，</span><span class="in">`如batch_size`</span><span class="at">，通常与并行化设置互动（在第10.1.3节中进一步描述），可能需要相应地进行调整。</span></span>
<span id="cb267-1278"><a href="#cb267-1278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1279"><a href="#cb267-1279" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Triggering the tuning process</span></span>
<span id="cb267-1280"><a href="#cb267-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1281"><a href="#cb267-1281" aria-hidden="true" tabindex="-1"></a>Now that we have introduced all our components, we can start the tuning process. To do this we simply pass the constructed TuningInstanceSingleCrit to the $optimize() method of the initialized Tuner.</span>
<span id="cb267-1282"><a href="#cb267-1282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1283"><a href="#cb267-1283" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1284"><a href="#cb267-1284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1285"><a href="#cb267-1285" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1286"><a href="#cb267-1286" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-1287"><a href="#cb267-1287" aria-hidden="true" tabindex="-1"></a>tuner<span class="sc">$</span><span class="fu">optimize</span>(instance)</span>
<span id="cb267-1288"><a href="#cb267-1288" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1289"><a href="#cb267-1289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1290"><a href="#cb267-1290" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1291"><a href="#cb267-1291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1292"><a href="#cb267-1292" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1293"><a href="#cb267-1293" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>result<span class="sc">$</span>learner_param_vals</span>
<span id="cb267-1294"><a href="#cb267-1294" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1295"><a href="#cb267-1295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1296"><a href="#cb267-1296" aria-hidden="true" tabindex="-1"></a><span class="fu">### Logarithmic Transformations</span></span>
<span id="cb267-1297"><a href="#cb267-1297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1298"><a href="#cb267-1298" aria-hidden="true" tabindex="-1"></a>To add this transformation to a hyperparameter we simply pass <span class="in">`logscale = TRUE`</span> to <span class="in">`to_tune()`</span>.</span>
<span id="cb267-1299"><a href="#cb267-1299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1300"><a href="#cb267-1300" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1301"><a href="#cb267-1301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1302"><a href="#cb267-1302" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1303"><a href="#cb267-1303" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-1304"><a href="#cb267-1304" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.svm"</span>, </span>
<span id="cb267-1305"><a href="#cb267-1305" aria-hidden="true" tabindex="-1"></a>    <span class="at">cost =</span> <span class="fu">to_tune</span>(<span class="fl">1e-5</span>, <span class="fl">1e5</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-1306"><a href="#cb267-1306" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma =</span> <span class="fu">to_tune</span>(<span class="fl">1e-5</span>, <span class="fl">1e5</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-1307"><a href="#cb267-1307" aria-hidden="true" tabindex="-1"></a>    <span class="at">kernel =</span> <span class="st">"radial"</span>,</span>
<span id="cb267-1308"><a href="#cb267-1308" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"C-classification"</span>)</span>
<span id="cb267-1309"><a href="#cb267-1309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1310"><a href="#cb267-1310" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">ti</span>(</span>
<span id="cb267-1311"><a href="#cb267-1311" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> tsk_sonar,</span>
<span id="cb267-1312"><a href="#cb267-1312" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> learner,</span>
<span id="cb267-1313"><a href="#cb267-1313" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>),</span>
<span id="cb267-1314"><a href="#cb267-1314" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> <span class="fu">msr</span>(<span class="st">"classif.ce"</span>),</span>
<span id="cb267-1315"><a href="#cb267-1315" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"none"</span>)</span>
<span id="cb267-1316"><a href="#cb267-1316" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1317"><a href="#cb267-1317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1318"><a href="#cb267-1318" aria-hidden="true" tabindex="-1"></a>tuner<span class="sc">$</span><span class="fu">optimize</span>(instance)</span>
<span id="cb267-1319"><a href="#cb267-1319" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1320"><a href="#cb267-1320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1321"><a href="#cb267-1321" aria-hidden="true" tabindex="-1"></a>Note that the fields <span class="in">`cost`</span> and <span class="in">`gamma`</span> show the optimal values before transformation, whereas <span class="in">`x_domain`</span> and <span class="in">`learner_param_vals`</span> contain optimal values *after* transformation, it is these latter fields you would take forward for future model use.</span>
<span id="cb267-1322"><a href="#cb267-1322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1323"><a href="#cb267-1323" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 请注意，</span><span class="in">`cost`</span><span class="at">和</span><span class="in">`gamma`</span><span class="at">字段显示了变换之前的最佳值，而</span><span class="in">`x_domain`</span><span class="at">和</span><span class="in">`learner_param_vals`</span><span class="at">包含了变换之后的最佳值，对于未来的模型使用，您应该使用后者的字段。</span></span>
<span id="cb267-1324"><a href="#cb267-1324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1325"><a href="#cb267-1325" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1326"><a href="#cb267-1326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1327"><a href="#cb267-1327" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1328"><a href="#cb267-1328" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>result<span class="sc">$</span>x_domain</span>
<span id="cb267-1329"><a href="#cb267-1329" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1330"><a href="#cb267-1330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1331"><a href="#cb267-1331" aria-hidden="true" tabindex="-1"></a><span class="fu">### Analyzing and Using the Result</span></span>
<span id="cb267-1332"><a href="#cb267-1332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1333"><a href="#cb267-1333" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1334"><a href="#cb267-1334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1335"><a href="#cb267-1335" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1336"><a href="#cb267-1336" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(instance<span class="sc">$</span>archive)[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, .(cost, gamma, classif.ce)]</span>
<span id="cb267-1337"><a href="#cb267-1337" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1338"><a href="#cb267-1338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1339"><a href="#cb267-1339" aria-hidden="true" tabindex="-1"></a>Another powerful feature of the instance is that we can score the internal <span class="in">`ResampleResults`</span> on a different performance measure, for example looking at false negative rate and false positive rate as well as classification error:</span>
<span id="cb267-1340"><a href="#cb267-1340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1341"><a href="#cb267-1341" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1342"><a href="#cb267-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1343"><a href="#cb267-1343" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1344"><a href="#cb267-1344" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(</span>
<span id="cb267-1345"><a href="#cb267-1345" aria-hidden="true" tabindex="-1"></a>  instance<span class="sc">$</span>archive,</span>
<span id="cb267-1346"><a href="#cb267-1346" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"classif.fpr"</span>, <span class="st">"classif.fnr"</span>))</span>
<span id="cb267-1347"><a href="#cb267-1347" aria-hidden="true" tabindex="-1"></a>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, .(cost, gamma, classif.ce, classif.fpr, classif.fnr)]</span>
<span id="cb267-1348"><a href="#cb267-1348" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1349"><a href="#cb267-1349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1350"><a href="#cb267-1350" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1351"><a href="#cb267-1351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1352"><a href="#cb267-1352" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1353"><a href="#cb267-1353" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-surface</span></span>
<span id="cb267-1354"><a href="#cb267-1354" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Model performance with different configurations for `cost` and `gamma`. Bright yellow regions represent the model performing worse and dark blue performing better. We can see that high `cost` values and low `gamma` values achieve the best performance. Note that we should not directly infer the performance of new unseen values from the heatmap since it is only an interpolation based on a surrogate model (`regr.ranger`). However, we can see the general interaction between the hyperparameters.</span></span>
<span id="cb267-1355"><a href="#cb267-1355" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(instance, <span class="at">type =</span> <span class="st">"surface"</span>)</span>
<span id="cb267-1356"><a href="#cb267-1356" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1357"><a href="#cb267-1357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1358"><a href="#cb267-1358" aria-hidden="true" tabindex="-1"></a>Once we found good hyperparameters for our learner through tuning, we can use them to train a final model on the whole data. To do this we simply construct a new learner with the same underlying algorithm and set the learner hyperparameters to the optimal configuration:</span>
<span id="cb267-1359"><a href="#cb267-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1360"><a href="#cb267-1360" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在通过调整找到学习器的良好超参数之后，我们可以使用它们在整个数据集上训练最终模型。为此，我们只需构建一个新的学习器，使用相同的底层算法，并将学习器的超参数设置为最佳配置：</span></span>
<span id="cb267-1361"><a href="#cb267-1361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1362"><a href="#cb267-1362" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1363"><a href="#cb267-1363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1364"><a href="#cb267-1364" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1365"><a href="#cb267-1365" aria-hidden="true" tabindex="-1"></a>lrn_svm_tuned <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.svm"</span>)</span>
<span id="cb267-1366"><a href="#cb267-1366" aria-hidden="true" tabindex="-1"></a>lrn_svm_tuned<span class="sc">$</span>param_set<span class="sc">$</span>values <span class="ot">=</span> instance<span class="sc">$</span>result_learner_param_vals</span>
<span id="cb267-1367"><a href="#cb267-1367" aria-hidden="true" tabindex="-1"></a>lrn_svm_tuned<span class="sc">$</span><span class="fu">train</span>(tsk_sonar)<span class="sc">$</span>model</span>
<span id="cb267-1368"><a href="#cb267-1368" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1369"><a href="#cb267-1369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1370"><a href="#cb267-1370" aria-hidden="true" tabindex="-1"></a><span class="fu">## Convenient Tuning with `tune` and `auto_tuner`</span></span>
<span id="cb267-1371"><a href="#cb267-1371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1372"><a href="#cb267-1372" aria-hidden="true" tabindex="-1"></a>In the previous section, we looked at constructing and manually putting together the components of HPO by creating a tuning instance using <span class="in">`ti()`</span>, passing this to the tuner, and then calling <span class="in">`$optimize()`</span> to start the tuning process. <span class="in">`mlr3tuning`</span> includes two helper methods to simplify this process further.</span>
<span id="cb267-1373"><a href="#cb267-1373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1374"><a href="#cb267-1374" aria-hidden="true" tabindex="-1"></a>The first helper function is <span class="in">`tune()`</span>, which creates the tuning instance and calls <span class="in">`$optimize()`</span> for you. You may prefer the manual method with <span class="in">`ti()`</span> if you want to view and make changes to the instance before tuning.</span>
<span id="cb267-1375"><a href="#cb267-1375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1376"><a href="#cb267-1376" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在上一节中，我们看到了通过使用</span><span class="in">`ti()`</span><span class="at">创建调整实例，将其传递给调整器，然后调用</span><span class="in">`$optimize()`</span><span class="at">来启动调整过程，来构建和手动组合HPO的组件。</span><span class="in">`mlr3tuning`</span><span class="at">包括两个辅助方法，以进一步简化这个过程。</span></span>
<span id="cb267-1377"><a href="#cb267-1377" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1378"><a href="#cb267-1378" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 第一个辅助函数是</span><span class="in">`tune()`</span><span class="at">，它创建调整实例并为您调用</span><span class="in">`$optimize()`</span><span class="at">。如果您想在调整之前查看并对实例进行更改，可能更喜欢使用</span><span class="in">`ti()`</span><span class="at">的手动方法。</span></span>
<span id="cb267-1379"><a href="#cb267-1379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1380"><a href="#cb267-1380" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1381"><a href="#cb267-1381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1382"><a href="#cb267-1382" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1383"><a href="#cb267-1383" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-1384"><a href="#cb267-1384" aria-hidden="true" tabindex="-1"></a>tnr_grid_search <span class="ot">=</span> <span class="fu">tnr</span>(<span class="st">"grid_search"</span>, <span class="at">resolution =</span> <span class="dv">5</span>, <span class="at">batch_size =</span> <span class="dv">5</span>)</span>
<span id="cb267-1385"><a href="#cb267-1385" aria-hidden="true" tabindex="-1"></a>lrn_svm <span class="ot">=</span> <span class="fu">lrn</span>(</span>
<span id="cb267-1386"><a href="#cb267-1386" aria-hidden="true" tabindex="-1"></a>  <span class="st">"classif.svm"</span>,</span>
<span id="cb267-1387"><a href="#cb267-1387" aria-hidden="true" tabindex="-1"></a>  <span class="at">cost =</span> <span class="fu">to_tune</span>(<span class="fl">1e-5</span>, <span class="fl">1e5</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-1388"><a href="#cb267-1388" aria-hidden="true" tabindex="-1"></a>  <span class="at">gamma =</span> <span class="fu">to_tune</span>(<span class="fl">1e-5</span>, <span class="fl">1e5</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-1389"><a href="#cb267-1389" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span> <span class="st">"radial"</span>,</span>
<span id="cb267-1390"><a href="#cb267-1390" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">"C-classification"</span></span>
<span id="cb267-1391"><a href="#cb267-1391" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1392"><a href="#cb267-1392" aria-hidden="true" tabindex="-1"></a>rsmp_cv3 <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>)</span>
<span id="cb267-1393"><a href="#cb267-1393" aria-hidden="true" tabindex="-1"></a>msr_ce <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"classif.ce"</span>)</span>
<span id="cb267-1394"><a href="#cb267-1394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1395"><a href="#cb267-1395" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">tune</span>(</span>
<span id="cb267-1396"><a href="#cb267-1396" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuner =</span> tnr_grid_search,</span>
<span id="cb267-1397"><a href="#cb267-1397" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> tsk_sonar,</span>
<span id="cb267-1398"><a href="#cb267-1398" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> lrn_svm,</span>
<span id="cb267-1399"><a href="#cb267-1399" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> rsmp_cv3,</span>
<span id="cb267-1400"><a href="#cb267-1400" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> msr_ce</span>
<span id="cb267-1401"><a href="#cb267-1401" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1402"><a href="#cb267-1402" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>result</span>
<span id="cb267-1403"><a href="#cb267-1403" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1404"><a href="#cb267-1404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1405"><a href="#cb267-1405" aria-hidden="true" tabindex="-1"></a>The other helper function is <span class="in">`auto_tuner`</span>, which creates an object of class <span class="in">`AutoTuner`</span>. The <span class="in">`AutoTuner`</span> inherits from the <span class="in">`Learner`</span> class and wraps all the information needed for tuning, which means you can treat a learner waiting to be optimized just like any other learner. Under the hood, the <span class="in">`AutoTuner`</span> essentially runs <span class="in">`tune()`</span> on the data that is passed to the model when <span class="in">`$train()`</span> is called and then sets the learner parameters to the optimal configuration.</span>
<span id="cb267-1406"><a href="#cb267-1406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1407"><a href="#cb267-1407" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 另一个辅助函数是</span><span class="in">`auto_tuner`</span><span class="at">，它创建一个</span><span class="in">`AutoTuner`</span><span class="at">类的对象。</span><span class="in">`AutoTuner`</span><span class="at">继承自</span><span class="in">`Learner`</span><span class="at">类，并包装了所有需要进行调整的信息，这意味着您可以像处理任何其他学习器一样处理等待优化的学习器。在底层，</span><span class="in">`AutoTuner`</span><span class="at">实际上在调用</span><span class="in">`$train()`</span><span class="at">时对传递给模型的数据上运行了</span><span class="in">`tune()`</span><span class="at">，然后将学习器参数设置为最佳配置。</span></span>
<span id="cb267-1408"><a href="#cb267-1408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1409"><a href="#cb267-1409" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1410"><a href="#cb267-1410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1411"><a href="#cb267-1411" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1412"><a href="#cb267-1412" aria-hidden="true" tabindex="-1"></a>at <span class="ot">=</span> <span class="fu">auto_tuner</span>(</span>
<span id="cb267-1413"><a href="#cb267-1413" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuner =</span> tnr_grid_search,</span>
<span id="cb267-1414"><a href="#cb267-1414" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> lrn_svm,</span>
<span id="cb267-1415"><a href="#cb267-1415" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> rsmp_cv3,</span>
<span id="cb267-1416"><a href="#cb267-1416" aria-hidden="true" tabindex="-1"></a>  <span class="at">measure =</span> msr_ce</span>
<span id="cb267-1417"><a href="#cb267-1417" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1418"><a href="#cb267-1418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1419"><a href="#cb267-1419" aria-hidden="true" tabindex="-1"></a>at</span>
<span id="cb267-1420"><a href="#cb267-1420" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1421"><a href="#cb267-1421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1422"><a href="#cb267-1422" aria-hidden="true" tabindex="-1"></a>And we can now call <span class="in">`$train()`</span>, which will first tune the hyperparameters in the search space listed above before fitting the optimal model.</span>
<span id="cb267-1423"><a href="#cb267-1423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1424"><a href="#cb267-1424" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1425"><a href="#cb267-1425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1426"><a href="#cb267-1426" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1427"><a href="#cb267-1427" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-1428"><a href="#cb267-1428" aria-hidden="true" tabindex="-1"></a>split <span class="ot">=</span> <span class="fu">partition</span>(tsk_sonar)</span>
<span id="cb267-1429"><a href="#cb267-1429" aria-hidden="true" tabindex="-1"></a>at<span class="sc">$</span><span class="fu">train</span>(tsk_sonar, <span class="at">row_ids =</span> split<span class="sc">$</span>train)</span>
<span id="cb267-1430"><a href="#cb267-1430" aria-hidden="true" tabindex="-1"></a>at<span class="sc">$</span><span class="fu">predict</span>(tsk_sonar, <span class="at">row_ids =</span> split<span class="sc">$</span>test)<span class="sc">$</span><span class="fu">score</span>()</span>
<span id="cb267-1431"><a href="#cb267-1431" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1432"><a href="#cb267-1432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1433"><a href="#cb267-1433" aria-hidden="true" tabindex="-1"></a>The <span class="in">`AutoTuner`</span> contains a tuning instance that can be analyzed like any other instance.</span>
<span id="cb267-1434"><a href="#cb267-1434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1435"><a href="#cb267-1435" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1436"><a href="#cb267-1436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1437"><a href="#cb267-1437" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1438"><a href="#cb267-1438" aria-hidden="true" tabindex="-1"></a>at<span class="sc">$</span>tuning_instance<span class="sc">$</span>result</span>
<span id="cb267-1439"><a href="#cb267-1439" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1440"><a href="#cb267-1440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1441"><a href="#cb267-1441" aria-hidden="true" tabindex="-1"></a>We could also pass the <span class="in">`AutoTuner`</span> to <span class="in">`resample()`</span> and <span class="in">`benchmark()`</span>, which would result in a nested resampling, discussed next.</span>
<span id="cb267-1442"><a href="#cb267-1442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1443"><a href="#cb267-1443" aria-hidden="true" tabindex="-1"></a><span class="fu">## Nested Resampling {#sec-nested-resampling}</span></span>
<span id="cb267-1444"><a href="#cb267-1444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1445"><a href="#cb267-1445" aria-hidden="true" tabindex="-1"></a>Nested resampling separates model optimization from the process of estimating the performance of the tuned model by adding an additional resampling, i.e., while model performance is estimated using a resampling method in the ‘usual way’, tuning is then performed by resampling the resampled data (@fig-nested-resampling).</span>
<span id="cb267-1446"><a href="#cb267-1446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1447"><a href="#cb267-1447" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 嵌套重抽样通过添加额外的重抽样来将模型优化与估计调整模型性能的过程分开，即在“通常方式”中使用重抽样方法来估计模型性能，然后通过对重抽样数据进行重抽样来进行调整（@fig-nested-resampling）。</span></span>
<span id="cb267-1448"><a href="#cb267-1448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1449"><a href="#cb267-1449" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1450"><a href="#cb267-1450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1451"><a href="#cb267-1451" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1452"><a href="#cb267-1452" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb267-1453"><a href="#cb267-1453" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-nested-resampling</span></span>
<span id="cb267-1454"><a href="#cb267-1454" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: An illustration of nested resampling. The large blocks represent three-fold CV for the outer resampling for model evaluation and the small blocks represent four-fold CV for the inner resampling for HPO. The light blue blocks are the training sets and the dark blue blocks are the test sets.</span></span>
<span id="cb267-1455"><a href="#cb267-1455" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: The image shows three rows of large blocks representing three-fold CV for the outer resampling. Below the blocks are four further rows of small blocks representing four-fold CV for the inner resampling. Text annotations highlight how tuned parameters from the inner resampling are passed to the outer resampling.</span></span>
<span id="cb267-1456"><a href="#cb267-1456" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"imgs/mlr3book_figures-11.svg"</span>)</span>
<span id="cb267-1457"><a href="#cb267-1457" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1458"><a href="#cb267-1458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1459"><a href="#cb267-1459" aria-hidden="true" tabindex="-1"></a>@fig-nested-resampling represents the following example of nested resampling:</span>
<span id="cb267-1460"><a href="#cb267-1460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1461"><a href="#cb267-1461" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Outer resampling start – Instantiate three-fold CV to create different testing and training datasets.</span>
<span id="cb267-1462"><a href="#cb267-1462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1463"><a href="#cb267-1463" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Inner resampling – Within the outer training data instantiate four-fold CV to create different inner testing and training datasets.</span>
<span id="cb267-1464"><a href="#cb267-1464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1465"><a href="#cb267-1465" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>HPO – Tune the hyperparameters on the outer training set (large, light blue blocks) using the inner data splits.</span>
<span id="cb267-1466"><a href="#cb267-1466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1467"><a href="#cb267-1467" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Training – Fit the learner on the outer training dataset using the optimal hyperparameter configuration obtained from the inner resampling (small blocks).</span>
<span id="cb267-1468"><a href="#cb267-1468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1469"><a href="#cb267-1469" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Evaluation – Evaluate the performance of the learner on the outer testing data (large, dark blue block).</span>
<span id="cb267-1470"><a href="#cb267-1470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1471"><a href="#cb267-1471" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Outer resampling repeats – Repeat (2)-(5) for each of the three outer folds.</span>
<span id="cb267-1472"><a href="#cb267-1472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1473"><a href="#cb267-1473" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Aggregation – Take the sample mean of the three performance values for an unbiased performance estimate.</span>
<span id="cb267-1474"><a href="#cb267-1474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1475"><a href="#cb267-1475" aria-hidden="true" tabindex="-1"></a>The inner resampling produces generalization performance estimates for each configuration and selects the optimal configuration to be evaluated on the outer resampling. The outer resampling then produces generalization estimates for these optimal configurations. The result from the outer resampling can be used for comparison to other models trained and tested on the same outer folds.</span>
<span id="cb267-1476"><a href="#cb267-1476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1477"><a href="#cb267-1477" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; @fig-nested-resampling 表示嵌套重抽样的以下示例：</span></span>
<span id="cb267-1478"><a href="#cb267-1478" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1479"><a href="#cb267-1479" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 1. 外部重抽样开始 - 实例化三折交叉验证以创建不同的测试和训练数据集。</span></span>
<span id="cb267-1480"><a href="#cb267-1480" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1481"><a href="#cb267-1481" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2. 内部重抽样 - 在外部训练数据中实例化四折交叉验证以创建不同的内部测试和训练数据集。</span></span>
<span id="cb267-1482"><a href="#cb267-1482" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1483"><a href="#cb267-1483" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3. HPO - 使用内部数据拆分在外部训练集（大的浅蓝色块）上调整超参数。</span></span>
<span id="cb267-1484"><a href="#cb267-1484" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1485"><a href="#cb267-1485" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 4. 训练 - 使用从内部重抽样获得的最佳超参数配置在外部训练数据集上拟合学习器（小块）。</span></span>
<span id="cb267-1486"><a href="#cb267-1486" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1487"><a href="#cb267-1487" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5. 评估 - 在外部测试数据上评估学习器的性能（大的深蓝色块）。</span></span>
<span id="cb267-1488"><a href="#cb267-1488" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1489"><a href="#cb267-1489" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 6. 外部重抽样重复 - 对三个外部折叠中的每一个重复步骤（2）-(5)。</span></span>
<span id="cb267-1490"><a href="#cb267-1490" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1491"><a href="#cb267-1491" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 7. 聚合 - 取三个性能值的样本均值以获得无偏性能估计。</span></span>
<span id="cb267-1492"><a href="#cb267-1492" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1493"><a href="#cb267-1493" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 内部重抽样为每个配置生成泛化性能估计，并选择要在外部重抽样中评估的最佳配置。然后，外部重抽样为这些最佳配置生成泛化估计。外部重抽样的结果可以用于与在相同外部折叠上训练和测试的其他模型进行比较。</span></span>
<span id="cb267-1494"><a href="#cb267-1494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1495"><a href="#cb267-1495" aria-hidden="true" tabindex="-1"></a>A common mistake is to think of nested resampling as a method to select optimal model configurations. Nested resampling is a method to compare models and to estimate the generalization performance of a tuned model, however, this is the performance based on multiple different configurations (one from each outer fold) and not performance based on a single configuration. If you are interested in identifying optimal configurations, then use <span class="in">`tune()`</span>/<span class="in">`ti()`</span> or <span class="in">`auto_tuner()`</span> with <span class="in">`$train()`</span> on the complete dataset.</span>
<span id="cb267-1496"><a href="#cb267-1496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1497"><a href="#cb267-1497" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 一个常见的错误是将嵌套重抽样视为选择最佳模型配置的方法。嵌套重抽样是一种用于比较模型和估计调整后模型的泛化性能的方法，但这是基于多种不同配置的性能（每个配置来自于外部折叠的一个），而不是基于单个配置的性能。如果您有兴趣确定最佳配置，那么请使用</span><span class="in">`tune()`</span><span class="at">/</span><span class="in">`ti()`</span><span class="at">或</span><span class="in">`auto_tuner()`</span><span class="at">与</span><span class="in">`$train()`</span><span class="at">在完整数据集上进行操作。</span></span>
<span id="cb267-1498"><a href="#cb267-1498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1499"><a href="#cb267-1499" aria-hidden="true" tabindex="-1"></a><span class="fu">### Nested Resampling with an `AutoTuner`</span></span>
<span id="cb267-1500"><a href="#cb267-1500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1501"><a href="#cb267-1501" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1502"><a href="#cb267-1502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1503"><a href="#cb267-1503" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1504"><a href="#cb267-1504" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-1505"><a href="#cb267-1505" aria-hidden="true" tabindex="-1"></a>at <span class="ot">=</span> <span class="fu">auto_tuner</span>(</span>
<span id="cb267-1506"><a href="#cb267-1506" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuner =</span> tnr_grid_search,</span>
<span id="cb267-1507"><a href="#cb267-1507" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> lrn_svm,</span>
<span id="cb267-1508"><a href="#cb267-1508" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">4</span>),</span>
<span id="cb267-1509"><a href="#cb267-1509" aria-hidden="true" tabindex="-1"></a>  <span class="at">measure =</span> msr_ce</span>
<span id="cb267-1510"><a href="#cb267-1510" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1511"><a href="#cb267-1511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1512"><a href="#cb267-1512" aria-hidden="true" tabindex="-1"></a>rr <span class="ot">=</span> <span class="fu">resample</span>(</span>
<span id="cb267-1513"><a href="#cb267-1513" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> tsk_sonar,</span>
<span id="cb267-1514"><a href="#cb267-1514" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> at,</span>
<span id="cb267-1515"><a href="#cb267-1515" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> rsmp_cv3,</span>
<span id="cb267-1516"><a href="#cb267-1516" aria-hidden="true" tabindex="-1"></a>  <span class="at">store_models =</span> <span class="cn">TRUE</span></span>
<span id="cb267-1517"><a href="#cb267-1517" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1518"><a href="#cb267-1518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1519"><a href="#cb267-1519" aria-hidden="true" tabindex="-1"></a>rr</span>
<span id="cb267-1520"><a href="#cb267-1520" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1521"><a href="#cb267-1521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1522"><a href="#cb267-1522" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1523"><a href="#cb267-1523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1524"><a href="#cb267-1524" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1525"><a href="#cb267-1525" aria-hidden="true" tabindex="-1"></a>rr<span class="sc">$</span><span class="fu">aggregate</span>()</span>
<span id="cb267-1526"><a href="#cb267-1526" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1527"><a href="#cb267-1527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1528"><a href="#cb267-1528" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1529"><a href="#cb267-1529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1530"><a href="#cb267-1530" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1531"><a href="#cb267-1531" aria-hidden="true" tabindex="-1"></a><span class="fu">extract_inner_tuning_results</span>(rr)[,</span>
<span id="cb267-1532"><a href="#cb267-1532" aria-hidden="true" tabindex="-1"></a>           .(iteration, cost, gamma, classif.ce)]</span>
<span id="cb267-1533"><a href="#cb267-1533" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1534"><a href="#cb267-1534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1535"><a href="#cb267-1535" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1536"><a href="#cb267-1536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1537"><a href="#cb267-1537" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1538"><a href="#cb267-1538" aria-hidden="true" tabindex="-1"></a><span class="fu">extract_inner_tuning_archives</span>(rr)[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,</span>
<span id="cb267-1539"><a href="#cb267-1539" aria-hidden="true" tabindex="-1"></a>              .(iteration, cost, gamma, classif.ce)]</span>
<span id="cb267-1540"><a href="#cb267-1540" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1541"><a href="#cb267-1541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1542"><a href="#cb267-1542" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Right (and Wrong) Way to Estimate Performance</span></span>
<span id="cb267-1543"><a href="#cb267-1543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1544"><a href="#cb267-1544" aria-hidden="true" tabindex="-1"></a>In this short section we will empirically demonstrate that directly reporting tuning performance without nested resampling results in optimistically biased performance estimates.</span>
<span id="cb267-1545"><a href="#cb267-1545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1546"><a href="#cb267-1546" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在这个简短的部分中，我们将通过实验证明，直接报告调优性能而不使用嵌套重抽样会导致性能估计存在乐观偏差。</span></span>
<span id="cb267-1547"><a href="#cb267-1547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1548"><a href="#cb267-1548" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1549"><a href="#cb267-1549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1550"><a href="#cb267-1550" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1551"><a href="#cb267-1551" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-1552"><a href="#cb267-1552" aria-hidden="true" tabindex="-1"></a>lrn_xgboost <span class="ot">=</span> <span class="fu">lrn</span>(</span>
<span id="cb267-1553"><a href="#cb267-1553" aria-hidden="true" tabindex="-1"></a>  <span class="st">"classif.xgboost"</span>,</span>
<span id="cb267-1554"><a href="#cb267-1554" aria-hidden="true" tabindex="-1"></a>  <span class="at">eta =</span> <span class="fu">to_tune</span>(<span class="fl">1e-4</span>, <span class="dv">1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-1555"><a href="#cb267-1555" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_depth =</span> <span class="fu">to_tune</span>(<span class="dv">1</span>, <span class="dv">20</span>),</span>
<span id="cb267-1556"><a href="#cb267-1556" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bytree =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="dv">1</span>),</span>
<span id="cb267-1557"><a href="#cb267-1557" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bylevel =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="dv">1</span>),</span>
<span id="cb267-1558"><a href="#cb267-1558" aria-hidden="true" tabindex="-1"></a>  <span class="at">lambda =</span> <span class="fu">to_tune</span>(<span class="fl">1e-3</span>, <span class="fl">1e3</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-1559"><a href="#cb267-1559" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fu">to_tune</span>(<span class="fl">1e-3</span>, <span class="fl">1e3</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-1560"><a href="#cb267-1560" aria-hidden="true" tabindex="-1"></a>  <span class="at">subsample =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="dv">1</span>)</span>
<span id="cb267-1561"><a href="#cb267-1561" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1562"><a href="#cb267-1562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1563"><a href="#cb267-1563" aria-hidden="true" tabindex="-1"></a>tsk_moons <span class="ot">=</span> <span class="fu">tgen</span>(<span class="st">"moons"</span>)</span>
<span id="cb267-1564"><a href="#cb267-1564" aria-hidden="true" tabindex="-1"></a>tsk_moons_train <span class="ot">=</span> tsk_moons<span class="sc">$</span><span class="fu">generate</span>(<span class="dv">100</span>)</span>
<span id="cb267-1565"><a href="#cb267-1565" aria-hidden="true" tabindex="-1"></a>tsk_moons_test <span class="ot">=</span> tsk_moons<span class="sc">$</span><span class="fu">generate</span>(<span class="fl">1e6</span>)</span>
<span id="cb267-1566"><a href="#cb267-1566" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1567"><a href="#cb267-1567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1568"><a href="#cb267-1568" aria-hidden="true" tabindex="-1"></a>Now we will tune the learner with respect to the classification error, using holdout resampling and random search with 700 evaluations. We then report the tuning performance without nested resampling.</span>
<span id="cb267-1569"><a href="#cb267-1569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1570"><a href="#cb267-1570" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1571"><a href="#cb267-1571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1572"><a href="#cb267-1572" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1573"><a href="#cb267-1573" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-1574"><a href="#cb267-1574" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-1575"><a href="#cb267-1575" aria-hidden="true" tabindex="-1"></a>tnr_random <span class="ot">=</span> <span class="fu">tnr</span>(<span class="st">"random_search"</span>)</span>
<span id="cb267-1576"><a href="#cb267-1576" aria-hidden="true" tabindex="-1"></a>rsmp_holdout <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"holdout"</span>)</span>
<span id="cb267-1577"><a href="#cb267-1577" aria-hidden="true" tabindex="-1"></a>trm_evals700 <span class="ot">=</span> <span class="fu">trm</span>(<span class="st">"evals"</span>, <span class="at">n_evals =</span> <span class="dv">700</span>)</span>
<span id="cb267-1578"><a href="#cb267-1578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1579"><a href="#cb267-1579" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">tune</span>(</span>
<span id="cb267-1580"><a href="#cb267-1580" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuner =</span> tnr_random,</span>
<span id="cb267-1581"><a href="#cb267-1581" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> tsk_moons_train,</span>
<span id="cb267-1582"><a href="#cb267-1582" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> lrn_xgboost,</span>
<span id="cb267-1583"><a href="#cb267-1583" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> rsmp_holdout,</span>
<span id="cb267-1584"><a href="#cb267-1584" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> msr_ce,</span>
<span id="cb267-1585"><a href="#cb267-1585" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> trm_evals700</span>
<span id="cb267-1586"><a href="#cb267-1586" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1587"><a href="#cb267-1587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1588"><a href="#cb267-1588" aria-hidden="true" tabindex="-1"></a>insample <span class="ot">=</span> instance<span class="sc">$</span>result_y</span>
<span id="cb267-1589"><a href="#cb267-1589" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1590"><a href="#cb267-1590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1591"><a href="#cb267-1591" aria-hidden="true" tabindex="-1"></a>Next, we estimate generalization error by nested resampling (below we use an outer five-fold CV), using an <span class="in">`AutoTuner`</span>:</span>
<span id="cb267-1592"><a href="#cb267-1592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1593"><a href="#cb267-1593" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1594"><a href="#cb267-1594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1595"><a href="#cb267-1595" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1596"><a href="#cb267-1596" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-1597"><a href="#cb267-1597" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-1598"><a href="#cb267-1598" aria-hidden="true" tabindex="-1"></a><span class="co"># same setup as above</span></span>
<span id="cb267-1599"><a href="#cb267-1599" aria-hidden="true" tabindex="-1"></a>at <span class="ot">=</span> <span class="fu">auto_tuner</span>(</span>
<span id="cb267-1600"><a href="#cb267-1600" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuner =</span> tnr_random,</span>
<span id="cb267-1601"><a href="#cb267-1601" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> lrn_xgboost,</span>
<span id="cb267-1602"><a href="#cb267-1602" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> rsmp_holdout,</span>
<span id="cb267-1603"><a href="#cb267-1603" aria-hidden="true" tabindex="-1"></a>  <span class="at">measure =</span> msr_ce,</span>
<span id="cb267-1604"><a href="#cb267-1604" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> trm_evals700</span>
<span id="cb267-1605"><a href="#cb267-1605" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1606"><a href="#cb267-1606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1607"><a href="#cb267-1607" aria-hidden="true" tabindex="-1"></a>rsmp_cv5 <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>)</span>
<span id="cb267-1608"><a href="#cb267-1608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1609"><a href="#cb267-1609" aria-hidden="true" tabindex="-1"></a>outsample <span class="ot">=</span> <span class="fu">resample</span>(tsk_moons_train, at, rsmp_cv5)<span class="sc">$</span><span class="fu">aggregate</span>()</span>
<span id="cb267-1610"><a href="#cb267-1610" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1611"><a href="#cb267-1611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1612"><a href="#cb267-1612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1613"><a href="#cb267-1613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1614"><a href="#cb267-1614" aria-hidden="true" tabindex="-1"></a>And finally, we estimate the generalization error by training the tuned learner (i.e., using the values from the <span class="in">`instance`</span> above) on the full training data again and predicting on the test data.</span>
<span id="cb267-1615"><a href="#cb267-1615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1616"><a href="#cb267-1616" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1617"><a href="#cb267-1617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1618"><a href="#cb267-1618" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1619"><a href="#cb267-1619" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-1620"><a href="#cb267-1620" aria-hidden="true" tabindex="-1"></a>lrn_xgboost_tuned <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.xgboost"</span>)</span>
<span id="cb267-1621"><a href="#cb267-1621" aria-hidden="true" tabindex="-1"></a>lrn_xgboost_tuned<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">set_values</span>(</span>
<span id="cb267-1622"><a href="#cb267-1622" aria-hidden="true" tabindex="-1"></a>  <span class="at">.values =</span> instance<span class="sc">$</span>result_learner_param_vals)</span>
<span id="cb267-1623"><a href="#cb267-1623" aria-hidden="true" tabindex="-1"></a>generalization <span class="ot">=</span> lrn_xgboost_tuned<span class="sc">$</span><span class="fu">train</span>(tsk_moons_train)<span class="sc">$</span></span>
<span id="cb267-1624"><a href="#cb267-1624" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(tsk_moons_test)<span class="sc">$</span></span>
<span id="cb267-1625"><a href="#cb267-1625" aria-hidden="true" tabindex="-1"></a>  <span class="fu">score</span>()</span>
<span id="cb267-1626"><a href="#cb267-1626" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1627"><a href="#cb267-1627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1628"><a href="#cb267-1628" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1629"><a href="#cb267-1629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1630"><a href="#cb267-1630" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1631"><a href="#cb267-1631" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb267-1632"><a href="#cb267-1632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1633"><a href="#cb267-1633" aria-hidden="true" tabindex="-1"></a><span class="co"># save(insample, outsample, generalization,</span></span>
<span id="cb267-1634"><a href="#cb267-1634" aria-hidden="true" tabindex="-1"></a><span class="co">#      file = "result/sec-resample-overfitting.RData")</span></span>
<span id="cb267-1635"><a href="#cb267-1635" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"result/sec-resample-overfitting.RData"</span>)</span>
<span id="cb267-1636"><a href="#cb267-1636" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1637"><a href="#cb267-1637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1638"><a href="#cb267-1638" aria-hidden="true" tabindex="-1"></a>Now we can compare these three values:</span>
<span id="cb267-1639"><a href="#cb267-1639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1640"><a href="#cb267-1640" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1641"><a href="#cb267-1641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1642"><a href="#cb267-1642" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1643"><a href="#cb267-1643" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(</span>
<span id="cb267-1644"><a href="#cb267-1644" aria-hidden="true" tabindex="-1"></a>  <span class="at">true_generalization =</span> <span class="fu">as.numeric</span>(generalization),</span>
<span id="cb267-1645"><a href="#cb267-1645" aria-hidden="true" tabindex="-1"></a>  <span class="at">without_nested_resampling =</span> <span class="fu">as.numeric</span>(insample),</span>
<span id="cb267-1646"><a href="#cb267-1646" aria-hidden="true" tabindex="-1"></a>  <span class="at">with_nest_resampling =</span> <span class="fu">as.numeric</span>(outsample)</span>
<span id="cb267-1647"><a href="#cb267-1647" aria-hidden="true" tabindex="-1"></a>), <span class="dv">2</span>)</span>
<span id="cb267-1648"><a href="#cb267-1648" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1649"><a href="#cb267-1649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1650"><a href="#cb267-1650" aria-hidden="true" tabindex="-1"></a>We find that the performance estimate from unnested tuning optimistically overestimates the true performance (which could indicate ‘meta-overfitting’ to the specific inner holdout-splits), while the outer estimate from nested resampling works much better.</span>
<span id="cb267-1651"><a href="#cb267-1651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1652"><a href="#cb267-1652" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们发现，未经嵌套重抽样的调优性能估计会乐观地高估真实性能（这可能表明对特定内部保留集的‘元过拟合’），而来自嵌套重抽样的外部估计效果要好得多。</span></span>
<span id="cb267-1653"><a href="#cb267-1653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1654"><a href="#cb267-1654" aria-hidden="true" tabindex="-1"></a><span class="fu">## More Advanced Search Spaces {#sec-defining-search-spaces}</span></span>
<span id="cb267-1655"><a href="#cb267-1655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1656"><a href="#cb267-1656" aria-hidden="true" tabindex="-1"></a><span class="fu">### Scalar Parameter Tuning</span></span>
<span id="cb267-1657"><a href="#cb267-1657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1658"><a href="#cb267-1658" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1659"><a href="#cb267-1659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1660"><a href="#cb267-1660" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1661"><a href="#cb267-1661" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(</span>
<span id="cb267-1662"><a href="#cb267-1662" aria-hidden="true" tabindex="-1"></a>  <span class="st">"classif.svm"</span>,</span>
<span id="cb267-1663"><a href="#cb267-1663" aria-hidden="true" tabindex="-1"></a>  <span class="at">cost =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="fl">1e5</span>),</span>
<span id="cb267-1664"><a href="#cb267-1664" aria-hidden="true" tabindex="-1"></a>  <span class="at">gamma =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="dv">1</span>),</span>
<span id="cb267-1665"><a href="#cb267-1665" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span> <span class="st">"radial"</span>,</span>
<span id="cb267-1666"><a href="#cb267-1666" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">"C-classification"</span></span>
<span id="cb267-1667"><a href="#cb267-1667" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1668"><a href="#cb267-1668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1669"><a href="#cb267-1669" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">search_space</span>()</span>
<span id="cb267-1670"><a href="#cb267-1670" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1671"><a href="#cb267-1671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1672"><a href="#cb267-1672" aria-hidden="true" tabindex="-1"></a>In this example, we can see that <span class="in">`gamma`</span> hyperparameter has class <span class="in">`ParamDbl`</span>, with <span class="in">`lower = 0.1`</span> and <span class="in">`upper = 1`</span>, which was automatically created by <span class="in">`to_tune()`</span> as we passed two numeric values to this function. If we wanted to tune over a non-numeric hyperparameter, we can still use <span class="in">`to_tune()`</span>, which will infer the correct class to construct in the resulting parameter set. For example, say we wanted to tune the numeric <span class="in">`cost`</span>, factor <span class="in">`kernel`</span>, and logical <span class="in">`scale`</span> hyperparameter in our SVM:</span>
<span id="cb267-1673"><a href="#cb267-1673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1674"><a href="#cb267-1674" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1675"><a href="#cb267-1675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1676"><a href="#cb267-1676" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1677"><a href="#cb267-1677" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(</span>
<span id="cb267-1678"><a href="#cb267-1678" aria-hidden="true" tabindex="-1"></a>  <span class="st">"classif.svm"</span>,</span>
<span id="cb267-1679"><a href="#cb267-1679" aria-hidden="true" tabindex="-1"></a>  <span class="at">cost =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="fl">1e5</span>),</span>
<span id="cb267-1680"><a href="#cb267-1680" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(<span class="st">"radial"</span>, <span class="st">"linear"</span>)),</span>
<span id="cb267-1681"><a href="#cb267-1681" aria-hidden="true" tabindex="-1"></a>  <span class="at">shrinking =</span> <span class="fu">to_tune</span>(),</span>
<span id="cb267-1682"><a href="#cb267-1682" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">"C-classification"</span></span>
<span id="cb267-1683"><a href="#cb267-1683" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1684"><a href="#cb267-1684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1685"><a href="#cb267-1685" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">search_space</span>()</span>
<span id="cb267-1686"><a href="#cb267-1686" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1687"><a href="#cb267-1687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1688"><a href="#cb267-1688" aria-hidden="true" tabindex="-1"></a>Here the <span class="in">`kernel`</span> hyperparameter is a factor, so we simply pass in a vector corresponding to the levels we want to tune over. The <span class="in">`shrinking`</span> hyperparameter is a logical, there are only two possible values this could take so we do not need to pass anything to <span class="in">`to_tune()`</span>, it will automatically recognize this is a logical from <span class="in">`learner$param_set`</span> and passes this detail to <span class="in">`learner$param_set$search_space()`</span>. Similarly, for factor parameters, we could also use <span class="in">`to_tune()`</span> without any arguments if we want to tune over all possible values. Finally, we can use <span class="in">`to_tune()`</span> to treat numeric parameters as factors if we want to discretize them over a small subset of possible values, for example, if we wanted to find the optimal number of trees in a random forest we might only consider three scenarios: 100, 200, or 400 trees:</span>
<span id="cb267-1689"><a href="#cb267-1689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1690"><a href="#cb267-1690" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在这里，</span><span class="in">`kernel`</span><span class="at"> 超参数是一个因子，因此我们只需传入一个与我们要调整的级别相对应的向量。</span><span class="in">`shrinking`</span><span class="at"> 超参数是一个逻辑型的，它只有两个可能的取值，所以我们不需要传递任何参数给 </span><span class="in">`to_tune()`</span><span class="at">，它会自动识别这是一个逻辑型，然后将这个细节传递给 </span><span class="in">`learner$param_set$search_space()`</span><span class="at">。类似地，对于因子参数，如果我们想要调整所有可能的值，我们也可以使用 </span><span class="in">`to_tune()`</span><span class="at"> 而不带任何参数。最后，如果我们想要将数值参数视为因子，并希望将其离散化为可能值的一小部分，例如，如果我们想要找到随机森林中最佳的树的数量，我们可能只考虑三种情况：100、200 或 400 棵树：</span></span>
<span id="cb267-1691"><a href="#cb267-1691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1692"><a href="#cb267-1692" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1693"><a href="#cb267-1693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1694"><a href="#cb267-1694" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1695"><a href="#cb267-1695" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-1696"><a href="#cb267-1696" aria-hidden="true" tabindex="-1"></a><span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>, <span class="at">num.trees =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">400</span>)))</span>
<span id="cb267-1697"><a href="#cb267-1697" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1698"><a href="#cb267-1698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1699"><a href="#cb267-1699" aria-hidden="true" tabindex="-1"></a><span class="fu">### Defining Search Spaces with `ps`</span></span>
<span id="cb267-1700"><a href="#cb267-1700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1701"><a href="#cb267-1701" aria-hidden="true" tabindex="-1"></a>As a simple example, let us look at how to create a search space to tune <span class="in">`cost`</span> and <span class="in">`gamma`</span> again:</span>
<span id="cb267-1702"><a href="#cb267-1702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1703"><a href="#cb267-1703" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1704"><a href="#cb267-1704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1705"><a href="#cb267-1705" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1706"><a href="#cb267-1706" aria-hidden="true" tabindex="-1"></a>search_space <span class="ot">=</span> <span class="fu">ps</span>(</span>
<span id="cb267-1707"><a href="#cb267-1707" aria-hidden="true" tabindex="-1"></a>  <span class="at">cost =</span> <span class="fu">p_dbl</span>(<span class="at">lower =</span> <span class="fl">1e-1</span>, <span class="at">upper =</span> <span class="fl">1e5</span>),</span>
<span id="cb267-1708"><a href="#cb267-1708" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span> <span class="fu">p_fct</span>(<span class="fu">c</span>(<span class="st">"radial"</span>, <span class="st">"linear"</span>)),</span>
<span id="cb267-1709"><a href="#cb267-1709" aria-hidden="true" tabindex="-1"></a>  <span class="at">shrinking =</span> <span class="fu">p_lgl</span>()</span>
<span id="cb267-1710"><a href="#cb267-1710" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1711"><a href="#cb267-1711" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1712"><a href="#cb267-1712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1713"><a href="#cb267-1713" aria-hidden="true" tabindex="-1"></a>This search space would then be passed to the <span class="in">`search_space`</span> argument in <span class="in">`auto_tuner()`</span>:</span>
<span id="cb267-1714"><a href="#cb267-1714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1715"><a href="#cb267-1715" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1716"><a href="#cb267-1716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1717"><a href="#cb267-1717" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1718"><a href="#cb267-1718" aria-hidden="true" tabindex="-1"></a><span class="fu">ti</span>(</span>
<span id="cb267-1719"><a href="#cb267-1719" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> tsk_sonar,</span>
<span id="cb267-1720"><a href="#cb267-1720" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> <span class="fu">lrn</span>(<span class="st">"classif.svm"</span>, <span class="at">type =</span> <span class="st">"C-classification"</span>),</span>
<span id="cb267-1721"><a href="#cb267-1721" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> rsmp_cv3,</span>
<span id="cb267-1722"><a href="#cb267-1722" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> msr_ce,</span>
<span id="cb267-1723"><a href="#cb267-1723" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"none"</span>),</span>
<span id="cb267-1724"><a href="#cb267-1724" aria-hidden="true" tabindex="-1"></a>  <span class="at">search_space =</span> search_space</span>
<span id="cb267-1725"><a href="#cb267-1725" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1726"><a href="#cb267-1726" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1727"><a href="#cb267-1727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1728"><a href="#cb267-1728" aria-hidden="true" tabindex="-1"></a><span class="fu">### Transformations and Tuning Over Vectors</span></span>
<span id="cb267-1729"><a href="#cb267-1729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1730"><a href="#cb267-1730" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1731"><a href="#cb267-1731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1732"><a href="#cb267-1732" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1733"><a href="#cb267-1733" aria-hidden="true" tabindex="-1"></a><span class="fu">lrn</span>(<span class="st">"classif.svm"</span>, <span class="at">cost =</span> <span class="fu">to_tune</span>(<span class="fl">1e-5</span>, <span class="fl">1e5</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>))<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">search_space</span>()</span>
<span id="cb267-1734"><a href="#cb267-1734" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1735"><a href="#cb267-1735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1736"><a href="#cb267-1736" aria-hidden="true" tabindex="-1"></a>Notice that now the <span class="in">`lower`</span> and <span class="in">`upper`</span> fields correspond to the transformed bounds, i.e. $<span class="co">[</span><span class="ot">\log(1e-5), \log(1e5)</span><span class="co">]</span>$.</span>
<span id="cb267-1737"><a href="#cb267-1737" aria-hidden="true" tabindex="-1"></a>To manually create the same transformation, we can pass the transformation to the <span class="in">`trafo`</span> argument in <span class="in">`p_dbl()`</span> and set the bounds:</span>
<span id="cb267-1738"><a href="#cb267-1738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1739"><a href="#cb267-1739" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 请注意，现在</span><span class="in">`lower`</span><span class="at">和</span><span class="in">`upper`</span><span class="at">字段对应于经过变换的界限，即$</span><span class="co">[</span><span class="ot">\log(1e-5), \log(1e5)</span><span class="co">]</span><span class="at">$。要手动创建相同的变换，我们可以将变换传递给</span><span class="in">`p_dbl()`</span><span class="at">中的</span><span class="in">`trafo`</span><span class="at">参数，并设置界限：</span></span>
<span id="cb267-1740"><a href="#cb267-1740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1741"><a href="#cb267-1741" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1742"><a href="#cb267-1742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1743"><a href="#cb267-1743" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1744"><a href="#cb267-1744" aria-hidden="true" tabindex="-1"></a>search_space <span class="ot">=</span> <span class="fu">ps</span>(<span class="at">cost =</span> <span class="fu">p_dbl</span>(<span class="fu">log</span>(<span class="fl">1e-5</span>), <span class="fu">log</span>(<span class="fl">1e5</span>),</span>
<span id="cb267-1745"><a href="#cb267-1745" aria-hidden="true" tabindex="-1"></a>                               <span class="at">trafo =</span> \(x) <span class="fu">exp</span>(x)))</span>
<span id="cb267-1746"><a href="#cb267-1746" aria-hidden="true" tabindex="-1"></a>search_space</span>
<span id="cb267-1747"><a href="#cb267-1747" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1748"><a href="#cb267-1748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1749"><a href="#cb267-1749" aria-hidden="true" tabindex="-1"></a>We can confirm it is correctly set by making use of the <span class="in">`$trafo()`</span> method, which takes a named list and applies the specified transformations</span>
<span id="cb267-1750"><a href="#cb267-1750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1751"><a href="#cb267-1751" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们可以通过使用</span><span class="in">`$trafo()`</span><span class="at">方法来确认它是否设置正确，该方法接受一个命名的列表并应用指定的转换。</span></span>
<span id="cb267-1752"><a href="#cb267-1752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1753"><a href="#cb267-1753" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1754"><a href="#cb267-1754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1755"><a href="#cb267-1755" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1756"><a href="#cb267-1756" aria-hidden="true" tabindex="-1"></a>search_space<span class="sc">$</span><span class="fu">trafo</span>(<span class="fu">list</span>(<span class="at">cost =</span> <span class="dv">1</span>))</span>
<span id="cb267-1757"><a href="#cb267-1757" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1758"><a href="#cb267-1758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1759"><a href="#cb267-1759" aria-hidden="true" tabindex="-1"></a>Where transformations become the most powerful is in the ability to pass arbitrary functions that can act on single parameters or even the entire parameter set. As an example, consider a simple transformation to add ‘2’ to our range:</span>
<span id="cb267-1760"><a href="#cb267-1760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1761"><a href="#cb267-1761" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1762"><a href="#cb267-1762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1763"><a href="#cb267-1763" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1764"><a href="#cb267-1764" aria-hidden="true" tabindex="-1"></a>search_space <span class="ot">=</span> <span class="fu">ps</span>(<span class="at">cost =</span> <span class="fu">p_dbl</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="at">trafo =</span> \(x) x <span class="sc">+</span> <span class="dv">2</span>))</span>
<span id="cb267-1765"><a href="#cb267-1765" aria-hidden="true" tabindex="-1"></a>search_space<span class="sc">$</span><span class="fu">trafo</span>(<span class="fu">list</span>(<span class="at">cost =</span> <span class="dv">1</span>))</span>
<span id="cb267-1766"><a href="#cb267-1766" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1767"><a href="#cb267-1767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1768"><a href="#cb267-1768" aria-hidden="true" tabindex="-1"></a>Simple transformations such as this can even be added directly to a learner by passing a <span class="in">`Param`</span> object to <span class="in">`to_tune()`</span>:</span>
<span id="cb267-1769"><a href="#cb267-1769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1770"><a href="#cb267-1770" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1771"><a href="#cb267-1771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1772"><a href="#cb267-1772" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1773"><a href="#cb267-1773" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-1774"><a href="#cb267-1774" aria-hidden="true" tabindex="-1"></a><span class="fu">lrn</span>(<span class="st">"classif.svm"</span>,</span>
<span id="cb267-1775"><a href="#cb267-1775" aria-hidden="true" tabindex="-1"></a>    <span class="at">cost =</span> <span class="fu">to_tune</span>(<span class="fu">p_dbl</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="at">trafo =</span> \(x) x <span class="sc">+</span> <span class="dv">2</span>)))</span>
<span id="cb267-1776"><a href="#cb267-1776" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1777"><a href="#cb267-1777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1778"><a href="#cb267-1778" aria-hidden="true" tabindex="-1"></a>More complex transformations that require multiple arguments should be passed to the <span class="in">`.extra_trafo`</span> parameter in <span class="in">`ps()`</span>. <span class="in">`.extra_trafo`</span> takes a function with parameters <span class="in">`x`</span> and <span class="in">`param_set`</span> where, during tuning, <span class="in">`x`</span> will be a list containing the configuration being tested, and <span class="in">`param_set`</span> is the whole parameter set. Below we first exponentiate the value of <span class="in">`cost`</span> and then add ‘2’ if the <span class="in">`kernel`</span> is <span class="in">`"polynomial"`</span>.</span>
<span id="cb267-1779"><a href="#cb267-1779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1780"><a href="#cb267-1780" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 需要多个参数的更复杂的转换应该通过 </span><span class="in">`ps()`</span><span class="at"> 中的 </span><span class="in">`.extra_trafo`</span><span class="at"> 参数传递。</span><span class="in">`.extra_trafo`</span><span class="at"> 接受一个带有参数 </span><span class="in">`x`</span><span class="at"> 和 </span><span class="in">`param_set`</span><span class="at"> 的函数，在调整过程中，</span><span class="in">`x`</span><span class="at"> 将是一个包含正在测试的配置的列表，而 </span><span class="in">`param_set`</span><span class="at"> 则是整个参数集。在下面的示例中，我们首先将 </span><span class="in">`cost`</span><span class="at"> 的值取幂，然后如果 </span><span class="in">`kernel`</span><span class="at"> 是 "polynomial"，就加上 '2'。</span></span>
<span id="cb267-1781"><a href="#cb267-1781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1782"><a href="#cb267-1782" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1783"><a href="#cb267-1783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1784"><a href="#cb267-1784" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1785"><a href="#cb267-1785" aria-hidden="true" tabindex="-1"></a>search_space <span class="ot">=</span> <span class="fu">ps</span>(</span>
<span id="cb267-1786"><a href="#cb267-1786" aria-hidden="true" tabindex="-1"></a>  <span class="at">cost =</span> <span class="fu">p_dbl</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">trafo =</span> \(x) <span class="fu">exp</span>(x)),</span>
<span id="cb267-1787"><a href="#cb267-1787" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span> <span class="fu">p_fct</span>(<span class="fu">c</span>(<span class="st">"polynomial"</span>, <span class="st">"radial"</span>)),</span>
<span id="cb267-1788"><a href="#cb267-1788" aria-hidden="true" tabindex="-1"></a>  <span class="at">.extra_trafo =</span> \(x, param_set) {</span>
<span id="cb267-1789"><a href="#cb267-1789" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (x<span class="sc">$</span>kernel <span class="sc">==</span> <span class="st">"polynomial"</span>) {</span>
<span id="cb267-1790"><a href="#cb267-1790" aria-hidden="true" tabindex="-1"></a>      x<span class="sc">$</span>cost <span class="ot">=</span> x<span class="sc">$</span>cost <span class="sc">+</span> <span class="dv">2</span></span>
<span id="cb267-1791"><a href="#cb267-1791" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb267-1792"><a href="#cb267-1792" aria-hidden="true" tabindex="-1"></a>    x</span>
<span id="cb267-1793"><a href="#cb267-1793" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb267-1794"><a href="#cb267-1794" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1795"><a href="#cb267-1795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1796"><a href="#cb267-1796" aria-hidden="true" tabindex="-1"></a>search_space<span class="sc">$</span><span class="fu">trafo</span>(<span class="fu">list</span>(<span class="at">cost =</span> <span class="dv">1</span>, <span class="at">kernel =</span> <span class="st">"radial"</span>))</span>
<span id="cb267-1797"><a href="#cb267-1797" aria-hidden="true" tabindex="-1"></a>search_space<span class="sc">$</span><span class="fu">trafo</span>(<span class="fu">list</span>(<span class="at">cost =</span> <span class="dv">1</span>, <span class="at">kernel =</span> <span class="st">"polynomial"</span>))</span>
<span id="cb267-1798"><a href="#cb267-1798" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1799"><a href="#cb267-1799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1800"><a href="#cb267-1800" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hyperparameter Dependencies</span></span>
<span id="cb267-1801"><a href="#cb267-1801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1802"><a href="#cb267-1802" aria-hidden="true" tabindex="-1"></a>Hyperparameter dependencies occur when a hyperparameter should only be set if another hyperparameter has a particular value. For example, the <span class="in">`degree`</span> parameter in SVM is only valid when <span class="in">`kernel`</span> is <span class="in">`"polynomial"`</span>. In the <span class="in">`ps()`</span> function, we specify this using the depends argument, which takes a named argument of the form <span class="in">`&lt;param&gt; == value`</span> or <span class="in">`&lt;param&gt; %in% &lt;vector&gt;`</span>:</span>
<span id="cb267-1803"><a href="#cb267-1803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1804"><a href="#cb267-1804" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1805"><a href="#cb267-1805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1806"><a href="#cb267-1806" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1807"><a href="#cb267-1807" aria-hidden="true" tabindex="-1"></a><span class="fu">ps</span>(</span>
<span id="cb267-1808"><a href="#cb267-1808" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span> <span class="fu">p_fct</span>(<span class="fu">c</span>(<span class="st">"polynomial"</span>, <span class="st">"radial"</span>)),</span>
<span id="cb267-1809"><a href="#cb267-1809" aria-hidden="true" tabindex="-1"></a>  <span class="at">degree =</span> <span class="fu">p_int</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="at">depends =</span> (kernel <span class="sc">==</span> <span class="st">"polynomial"</span>)),</span>
<span id="cb267-1810"><a href="#cb267-1810" aria-hidden="true" tabindex="-1"></a>  <span class="at">gamma =</span> <span class="fu">p_dbl</span>(<span class="fl">1e-5</span>, <span class="fl">1e5</span>,</span>
<span id="cb267-1811"><a href="#cb267-1811" aria-hidden="true" tabindex="-1"></a>                <span class="at">depends =</span> (kernel <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"polynomial"</span>, <span class="st">"radial"</span>)))</span>
<span id="cb267-1812"><a href="#cb267-1812" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1813"><a href="#cb267-1813" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1814"><a href="#cb267-1814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1815"><a href="#cb267-1815" aria-hidden="true" tabindex="-1"></a>Above we have said that <span class="in">`degree`</span> should only be set if <span class="in">`kernel`</span> is (<span class="in">`==`</span>) <span class="in">`"polynomial"`</span>, and <span class="in">`gamma`</span> should only be set if <span class="in">`kernel`</span> is one of (<span class="in">`%in%`</span>) <span class="in">`"polynomial"`</span> or  <span class="in">`"radial"`</span>.</span>
<span id="cb267-1816"><a href="#cb267-1816" aria-hidden="true" tabindex="-1"></a>In practice, some underlying implementations ignore unused parameters and others throw errors, either way, this is problematic during tuning if, for example, we were wasting time trying to tune <span class="in">`degree`</span> when the kernel was not polynomial.</span>
<span id="cb267-1817"><a href="#cb267-1817" aria-hidden="true" tabindex="-1"></a>Hence setting the dependency tells the tuning process to tune <span class="in">`degree`</span> if <span class="in">`kernel`</span> is <span class="in">`"polynomial"`</span> and to ignore it otherwise.</span>
<span id="cb267-1818"><a href="#cb267-1818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1819"><a href="#cb267-1819" aria-hidden="true" tabindex="-1"></a>Dependencies can also be passed straight into a learner using <span class="in">`to_tune()`</span>:</span>
<span id="cb267-1820"><a href="#cb267-1820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1821"><a href="#cb267-1821" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在上面的示例中，我们说过</span><span class="in">`degree`</span><span class="at">只有在</span><span class="in">`kernel`</span><span class="at">为(</span><span class="in">`==`</span><span class="at">) </span><span class="in">`"polynomial"`</span><span class="at">时才应设置，而</span><span class="in">`gamma`</span><span class="at">只有在</span><span class="in">`kernel`</span><span class="at">是(</span><span class="in">`%in%`</span><span class="at">) </span><span class="in">`"polynomial"`</span><span class="at">或</span><span class="in">`"radial"`</span><span class="at">之一时才应设置。</span>  </span>
<span id="cb267-1822"><a href="#cb267-1822" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 实际上，一些底层实现会忽略未使用的参数，而其他一些则会引发错误，无论哪种情况，在调优过程中都会造成问题，例如，当内核不是多项式时，浪费时间尝试调整</span><span class="in">`degree`</span><span class="at">。</span>  </span>
<span id="cb267-1823"><a href="#cb267-1823" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 因此，设置依赖关系告诉调整过程，如果</span><span class="in">`kernel`</span><span class="at">是</span><span class="in">`"polynomial"`</span><span class="at">，则调整</span><span class="in">`degree`</span><span class="at">，否则忽略它。</span></span>
<span id="cb267-1824"><a href="#cb267-1824" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1825"><a href="#cb267-1825" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 依赖关系也可以直接传递给学习器，使用 </span><span class="in">`to_tune()`</span><span class="at">：</span></span>
<span id="cb267-1826"><a href="#cb267-1826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1827"><a href="#cb267-1827" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1828"><a href="#cb267-1828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1829"><a href="#cb267-1829" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1830"><a href="#cb267-1830" aria-hidden="true" tabindex="-1"></a><span class="fu">lrn</span>(</span>
<span id="cb267-1831"><a href="#cb267-1831" aria-hidden="true" tabindex="-1"></a>  <span class="st">"classif.svm"</span>,</span>
<span id="cb267-1832"><a href="#cb267-1832" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(<span class="st">"polynomial"</span>, <span class="st">"radial"</span>)),</span>
<span id="cb267-1833"><a href="#cb267-1833" aria-hidden="true" tabindex="-1"></a>  <span class="at">degree =</span> <span class="fu">to_tune</span>(<span class="fu">p_int</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="at">depends =</span> (kernel <span class="sc">==</span> <span class="st">"polynomial"</span>)))</span>
<span id="cb267-1834"><a href="#cb267-1834" aria-hidden="true" tabindex="-1"></a>)<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">search_space</span>()</span>
<span id="cb267-1835"><a href="#cb267-1835" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1836"><a href="#cb267-1836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1837"><a href="#cb267-1837" aria-hidden="true" tabindex="-1"></a><span class="fu">### Recommended Search Spaces with `mlrtuningspaces`</span></span>
<span id="cb267-1838"><a href="#cb267-1838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1839"><a href="#cb267-1839" aria-hidden="true" tabindex="-1"></a>Selected search spaces can require a lot of background knowledge or expertise. The package <span class="in">`mlr3tuningspaces`</span> tries to make HPO more accessible by providing implementations of published search spaces for many popular machine learning algorithms, the hope is that these search spaces are applicable to a wide range of datasets. The search spaces are stored in the dictionary <span class="in">`mlr_tuning_spaces`</span>.</span>
<span id="cb267-1840"><a href="#cb267-1840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1841"><a href="#cb267-1841" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 所选的搜索空间可能需要大量的背景知识或专业知识。包</span><span class="in">`mlr3tuningspaces`</span><span class="at">试图通过提供许多流行的机器学习算法的已发表搜索空间的实现来使HPO更加可访问，希望这些搜索空间适用于各种各样的数据集。这些搜索空间存储在</span><span class="in">`mlr_tuning_spaces`</span><span class="at">字典中。</span></span>
<span id="cb267-1842"><a href="#cb267-1842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1843"><a href="#cb267-1843" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1844"><a href="#cb267-1844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1845"><a href="#cb267-1845" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1846"><a href="#cb267-1846" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb267-1847"><a href="#cb267-1847" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3tuningspaces)</span>
<span id="cb267-1848"><a href="#cb267-1848" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(mlr_tuning_spaces)[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, .(key, label)]</span>
<span id="cb267-1849"><a href="#cb267-1849" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1850"><a href="#cb267-1850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1851"><a href="#cb267-1851" aria-hidden="true" tabindex="-1"></a>The tuning spaces are named according to the scheme <span class="in">`{learner-id}.{tuning-space-id}`</span>. The <span class="in">`default`</span> tuning spaces are published in Bischl et al. (2023), other tuning spaces are part of the random bot experiments <span class="in">`rbv1`</span> and <span class="in">`rbv2`</span> published in Kuehn et al. (2018) and Binder, Pfisterer, and Bischl (2020). The sugar function <span class="in">`lts()`</span> (learner tuning space) is used to retrieve a <span class="in">`TuningSpace.`</span></span>
<span id="cb267-1852"><a href="#cb267-1852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1853"><a href="#cb267-1853" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1854"><a href="#cb267-1854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1855"><a href="#cb267-1855" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1856"><a href="#cb267-1856" aria-hidden="true" tabindex="-1"></a>lts_rpart <span class="ot">=</span> <span class="fu">lts</span>(<span class="st">"classif.rpart.default"</span>)</span>
<span id="cb267-1857"><a href="#cb267-1857" aria-hidden="true" tabindex="-1"></a>lts_rpart</span>
<span id="cb267-1858"><a href="#cb267-1858" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1859"><a href="#cb267-1859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1860"><a href="#cb267-1860" aria-hidden="true" tabindex="-1"></a>A tuning space can be passed to <span class="in">`ti()`</span> or <span class="in">`auto_tuner()`</span> as the <span class="in">`search_space.`</span></span>
<span id="cb267-1861"><a href="#cb267-1861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1862"><a href="#cb267-1862" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1863"><a href="#cb267-1863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1864"><a href="#cb267-1864" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1865"><a href="#cb267-1865" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">ti</span>(</span>
<span id="cb267-1866"><a href="#cb267-1866" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> tsk_sonar,</span>
<span id="cb267-1867"><a href="#cb267-1867" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>),</span>
<span id="cb267-1868"><a href="#cb267-1868" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>),</span>
<span id="cb267-1869"><a href="#cb267-1869" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> <span class="fu">msr</span>(<span class="st">"classif.ce"</span>),</span>
<span id="cb267-1870"><a href="#cb267-1870" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"evals"</span>, <span class="at">n_evals =</span> <span class="dv">20</span>),</span>
<span id="cb267-1871"><a href="#cb267-1871" aria-hidden="true" tabindex="-1"></a>  <span class="at">search_space =</span> lts_rpart</span>
<span id="cb267-1872"><a href="#cb267-1872" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1873"><a href="#cb267-1873" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1874"><a href="#cb267-1874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1875"><a href="#cb267-1875" aria-hidden="true" tabindex="-1"></a>Alternatively, as loaded search spaces are just a collection of tune tokens, we could also pass these straight to a learner:</span>
<span id="cb267-1876"><a href="#cb267-1876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1877"><a href="#cb267-1877" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 或者，由于加载的搜索空间只是一组调整令牌，我们还可以将它们直接传递给学习器：</span></span>
<span id="cb267-1878"><a href="#cb267-1878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1879"><a href="#cb267-1879" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1880"><a href="#cb267-1880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1881"><a href="#cb267-1881" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1882"><a href="#cb267-1882" aria-hidden="true" tabindex="-1"></a>vals <span class="ot">=</span> lts_rpart<span class="sc">$</span>values</span>
<span id="cb267-1883"><a href="#cb267-1883" aria-hidden="true" tabindex="-1"></a>vals</span>
<span id="cb267-1884"><a href="#cb267-1884" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>)</span>
<span id="cb267-1885"><a href="#cb267-1885" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">set_values</span>(<span class="at">.values =</span> vals)</span>
<span id="cb267-1886"><a href="#cb267-1886" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span>param_set</span>
<span id="cb267-1887"><a href="#cb267-1887" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1888"><a href="#cb267-1888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1889"><a href="#cb267-1889" aria-hidden="true" tabindex="-1"></a>We could also apply the default search spaces from Bischl et al. (2023) by passing the learner to <span class="in">`lts()`</span>:</span>
<span id="cb267-1890"><a href="#cb267-1890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1891"><a href="#cb267-1891" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1892"><a href="#cb267-1892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1893"><a href="#cb267-1893" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1894"><a href="#cb267-1894" aria-hidden="true" tabindex="-1"></a><span class="fu">lts</span>(<span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>))</span>
<span id="cb267-1895"><a href="#cb267-1895" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1896"><a href="#cb267-1896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1897"><a href="#cb267-1897" aria-hidden="true" tabindex="-1"></a>Finally, it is possible to overwrite a predefined tuning space in construction, for example, changing the range of the <span class="in">`maxdepth`</span> hyperparameter in a decision tree:</span>
<span id="cb267-1898"><a href="#cb267-1898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1899"><a href="#cb267-1899" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1900"><a href="#cb267-1900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1901"><a href="#cb267-1901" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1902"><a href="#cb267-1902" aria-hidden="true" tabindex="-1"></a><span class="fu">lts</span>(<span class="st">"classif.rpart.rbv2"</span>, <span class="at">maxdepth =</span> <span class="fu">to_tune</span>(<span class="dv">1</span>, <span class="dv">20</span>))</span>
<span id="cb267-1903"><a href="#cb267-1903" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1904"><a href="#cb267-1904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1905"><a href="#cb267-1905" aria-hidden="true" tabindex="-1"></a><span class="fu"># Advanced Tuning Methods and Black Box Optimization {#sec-optimization-advanced}</span></span>
<span id="cb267-1906"><a href="#cb267-1906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1907"><a href="#cb267-1907" aria-hidden="true" tabindex="-1"></a><span class="fu">## Error Handling and Memory Management</span></span>
<span id="cb267-1908"><a href="#cb267-1908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1909"><a href="#cb267-1909" aria-hidden="true" tabindex="-1"></a><span class="fu">### Encapsulation and Fallback Learner</span></span>
<span id="cb267-1910"><a href="#cb267-1910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1911"><a href="#cb267-1911" aria-hidden="true" tabindex="-1"></a>Even in simple machine learning problems, there is a lot of potential for things to go wrong. For example, when learners do not converge, run out of memory, or terminate with an error due to issues in the underlying data. As a common issue, learners can fail if there are factor levels present in the test data that were not in the training data, models fail in this case as there have been no weights/coefficients trained for these new factor levels:</span>
<span id="cb267-1912"><a href="#cb267-1912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1913"><a href="#cb267-1913" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 即使在简单的机器学习问题中，出现问题的可能性也很大。例如，当学习器不收敛、耗尽内存或由于底层数据问题而出现错误终止时。作为一个常见问题，如果测试数据中存在训练数据中没有的因子水平，那么学习器可能会失败，因为针对这些新的因子水平没有进行权重/系数的训练：</span></span>
<span id="cb267-1914"><a href="#cb267-1914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1915"><a href="#cb267-1915" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1916"><a href="#cb267-1916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1917"><a href="#cb267-1917" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1918"><a href="#cb267-1918" aria-hidden="true" tabindex="-1"></a><span class="co">#| error: true</span></span>
<span id="cb267-1919"><a href="#cb267-1919" aria-hidden="true" tabindex="-1"></a>tsk_pen <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-1920"><a href="#cb267-1920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1921"><a href="#cb267-1921" aria-hidden="true" tabindex="-1"></a><span class="co"># remove rows with missing values</span></span>
<span id="cb267-1922"><a href="#cb267-1922" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span><span class="fu">filter</span>(tsk_pen<span class="sc">$</span>row_ids[<span class="fu">complete.cases</span>(tsk_pen<span class="sc">$</span><span class="fu">data</span>())])</span>
<span id="cb267-1923"><a href="#cb267-1923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1924"><a href="#cb267-1924" aria-hidden="true" tabindex="-1"></a>rsmp_custom <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"custom"</span>)</span>
<span id="cb267-1925"><a href="#cb267-1925" aria-hidden="true" tabindex="-1"></a>rsmp_custom<span class="sc">$</span><span class="fu">instantiate</span>(</span>
<span id="cb267-1926"><a href="#cb267-1926" aria-hidden="true" tabindex="-1"></a>  tsk_pen,</span>
<span id="cb267-1927"><a href="#cb267-1927" aria-hidden="true" tabindex="-1"></a>  <span class="at">train_sets =</span> <span class="fu">list</span>(tsk_pen<span class="sc">$</span>row_ids[tsk_pen<span class="sc">$</span><span class="fu">data</span>()<span class="sc">$</span>island <span class="sc">!=</span> <span class="st">"Torgersen"</span>]),</span>
<span id="cb267-1928"><a href="#cb267-1928" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_sets =</span> <span class="fu">list</span>(tsk_pen<span class="sc">$</span>row_ids[tsk_pen<span class="sc">$</span><span class="fu">data</span>()<span class="sc">$</span>island <span class="sc">==</span> <span class="st">"Torgersen"</span>])</span>
<span id="cb267-1929"><a href="#cb267-1929" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-1930"><a href="#cb267-1930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1931"><a href="#cb267-1931" aria-hidden="true" tabindex="-1"></a>msr_ce <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"classif.ce"</span>)</span>
<span id="cb267-1932"><a href="#cb267-1932" aria-hidden="true" tabindex="-1"></a>tnr_random <span class="ot">=</span> <span class="fu">tnr</span>(<span class="st">"random_search"</span>)</span>
<span id="cb267-1933"><a href="#cb267-1933" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.lda"</span>, <span class="at">method =</span> <span class="st">"t"</span>, <span class="at">nu =</span> <span class="fu">to_tune</span>(<span class="dv">3</span>, <span class="dv">10</span>))</span>
<span id="cb267-1934"><a href="#cb267-1934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1935"><a href="#cb267-1935" aria-hidden="true" tabindex="-1"></a><span class="fu">tune</span>(tnr_random, tsk_pen, learner, rsmp_custom, msr_ce, <span class="dv">10</span>)</span>
<span id="cb267-1936"><a href="#cb267-1936" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1937"><a href="#cb267-1937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1938"><a href="#cb267-1938" aria-hidden="true" tabindex="-1"></a>::: {.callout-caution}</span>
<span id="cb267-1939"><a href="#cb267-1939" aria-hidden="true" tabindex="-1"></a>TODO：等待后续添加交叉引用  10.2.1</span>
<span id="cb267-1940"><a href="#cb267-1940" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb267-1941"><a href="#cb267-1941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1942"><a href="#cb267-1942" aria-hidden="true" tabindex="-1"></a>In the above example, we can see the tuning process breaks and we lose all information about the hyperparameter optimization process. This is even worse in nested resampling or benchmarking when errors could cause us to lose all progress across multiple configurations or even learners and tasks.</span>
<span id="cb267-1943"><a href="#cb267-1943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1944"><a href="#cb267-1944" aria-hidden="true" tabindex="-1"></a>Encapsulation (Section 10.2.1) allows errors to be isolated and handled, without disrupting the tuning process. We can tell a learner to encapsulate an error by setting the <span class="in">`$encapsulate`</span> field as follows:</span>
<span id="cb267-1945"><a href="#cb267-1945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1946"><a href="#cb267-1946" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在上述示例中，我们可以看到调优过程中断，我们失去了有关超参数优化过程的所有信息。在嵌套重抽样或基准测试中，当错误可能导致我们失去跨多个配置甚至学习器和任务的所有进展时，情况会变得更糟。</span></span>
<span id="cb267-1947"><a href="#cb267-1947" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1948"><a href="#cb267-1948" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 封装（第10.2.1节）允许隔离和处理错误，而不会干扰调优过程。我们可以通过设置</span><span class="in">`$encapsulate`</span><span class="at">字段来告诉学习器封装错误，如下所示：</span></span>
<span id="cb267-1949"><a href="#cb267-1949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1950"><a href="#cb267-1950" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1951"><a href="#cb267-1951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1952"><a href="#cb267-1952" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1953"><a href="#cb267-1953" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span>encapsulate <span class="ot">=</span> <span class="fu">c</span>(<span class="at">train =</span> <span class="st">"evaluate"</span>, <span class="at">predict =</span> <span class="st">"evaluate"</span>)</span>
<span id="cb267-1954"><a href="#cb267-1954" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1955"><a href="#cb267-1955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1956"><a href="#cb267-1956" aria-hidden="true" tabindex="-1"></a>Note by passing <span class="in">`"evaluate"`</span> to both <span class="in">`train`</span> and <span class="in">`predict`</span>, we are telling the learner to set up encapsulation in both the training and prediction stages (see Section 10.2 for other encapsulation options).</span>
<span id="cb267-1957"><a href="#cb267-1957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1958"><a href="#cb267-1958" aria-hidden="true" tabindex="-1"></a>Another common issue that cannot be easily solved during HPO is learners not converging and the process running indefinitely. We can prevent this from happening by setting the <span class="in">`timeout`</span> field in a learner, which signals the learner to stop if it has been running for that much time (in seconds), again this can be set for training and prediction individually:</span>
<span id="cb267-1959"><a href="#cb267-1959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1960"><a href="#cb267-1960" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 请注意，通过在</span><span class="in">`train`</span><span class="at">和</span><span class="in">`predict`</span><span class="at">中都传递</span><span class="in">`"evaluate"`</span><span class="at">，我们告诉学习器在训练和预测阶段都设置封装（有关其他封装选项，请参见第10.2节）。</span></span>
<span id="cb267-1961"><a href="#cb267-1961" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1962"><a href="#cb267-1962" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 另一个在HPO期间难以轻松解决的常见问题是学习器不收敛，进程无限运行。我们可以通过在学习器中设置</span><span class="in">`timeout`</span><span class="at">字段来防止这种情况发生，该字段表示如果学习器运行了这么长时间（以秒为单位），则应停止运行。同样，这可以分别为训练和预测设置：</span></span>
<span id="cb267-1963"><a href="#cb267-1963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1964"><a href="#cb267-1964" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1965"><a href="#cb267-1965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1966"><a href="#cb267-1966" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1967"><a href="#cb267-1967" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span>timeout <span class="ot">=</span> <span class="fu">c</span>(<span class="at">train =</span> <span class="dv">30</span>, <span class="at">predict =</span> <span class="dv">30</span>)</span>
<span id="cb267-1968"><a href="#cb267-1968" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1969"><a href="#cb267-1969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1970"><a href="#cb267-1970" aria-hidden="true" tabindex="-1"></a>Now if either an error occurs, or the model timeout threshold is reached, then instead of breaking, the learner will simply not make predictions when errors are found and the result is <span class="in">`NA`</span> for resampling iterations with errors. When this happens, our hyperparameter optimization experiment will fail as we cannot aggregate results across resampling iterations. Therefore it is essential to select a fallback learner (Section 10.2.2), which is a learner that will be fitted if the learner of interest fails.</span>
<span id="cb267-1971"><a href="#cb267-1971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1972"><a href="#cb267-1972" aria-hidden="true" tabindex="-1"></a>A common approach is to use a featureless baseline (<span class="in">`lrn("regr.featureless"`</span>) or <span class="in">`lrn("classif.featureless"))`</span>. Below we set <span class="in">`lrn("classif.featureless")`</span>, which always predicts the majority class, by passing this learner to the <span class="in">`$fallback`</span> field.</span>
<span id="cb267-1973"><a href="#cb267-1973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1974"><a href="#cb267-1974" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 如果出现错误或达到模型超时阈值，那么学习器将不会中断，而是在发现错误时不进行预测，对于出现错误的重抽样迭代，结果将是</span><span class="in">`NA`</span><span class="at">。当发生这种情况时，我们的超参数优化实验将失败，因为我们无法在重抽样迭代之间聚合结果。因此，选择一个回退学习器（第10.2.2节）非常重要，这是一种在感兴趣的学习器失败时将要训练的备用学习器。</span></span>
<span id="cb267-1975"><a href="#cb267-1975" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-1976"><a href="#cb267-1976" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 一个常见的方法是使用一个没有特征的基线学习器（</span><span class="in">`lrn("regr.featureless"`</span><span class="at">或</span><span class="in">`lrn("classif.featureless")`</span><span class="at">）。下面我们设置了</span><span class="in">`lrn("classif.featureless")`</span><span class="at">，它总是预测多数类别，通过将这个学习器传递给</span><span class="in">`$fallback`</span><span class="at">字段来实现。</span></span>
<span id="cb267-1977"><a href="#cb267-1977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1978"><a href="#cb267-1978" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1979"><a href="#cb267-1979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1980"><a href="#cb267-1980" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1981"><a href="#cb267-1981" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span>fallback <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.featureless"</span>)</span>
<span id="cb267-1982"><a href="#cb267-1982" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1983"><a href="#cb267-1983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1984"><a href="#cb267-1984" aria-hidden="true" tabindex="-1"></a>We can now run our experiment and see errors that occurred during tuning in the archive.</span>
<span id="cb267-1985"><a href="#cb267-1985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1986"><a href="#cb267-1986" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1987"><a href="#cb267-1987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1988"><a href="#cb267-1988" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1989"><a href="#cb267-1989" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-1990"><a href="#cb267-1990" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">tune</span>(tnr_random, tsk_pen, learner, rsmp_custom, msr_ce, <span class="dv">10</span>)</span>
<span id="cb267-1991"><a href="#cb267-1991" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-1992"><a href="#cb267-1992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1993"><a href="#cb267-1993" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-1994"><a href="#cb267-1994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1995"><a href="#cb267-1995" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-1996"><a href="#cb267-1996" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(instance<span class="sc">$</span>archive)[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, .(df, classif.ce, errors)]</span>
<span id="cb267-1997"><a href="#cb267-1997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-1998"><a href="#cb267-1998" aria-hidden="true" tabindex="-1"></a><span class="co"># reading the error in the first resample result</span></span>
<span id="cb267-1999"><a href="#cb267-1999" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>archive<span class="sc">$</span><span class="fu">resample_result</span>(<span class="dv">1</span>)<span class="sc">$</span>errors</span>
<span id="cb267-2000"><a href="#cb267-2000" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2001"><a href="#cb267-2001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2002"><a href="#cb267-2002" aria-hidden="true" tabindex="-1"></a>The learner was tuned without breaking because the errors were encapsulated and logged before the fallback learners were used for fitting and predicting:</span>
<span id="cb267-2003"><a href="#cb267-2003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2004"><a href="#cb267-2004" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 由于错误被封装并在使用回退学习器进行拟合和预测之前进行了记录，学习器在没有中断的情况下进行了调优：</span></span>
<span id="cb267-2005"><a href="#cb267-2005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2006"><a href="#cb267-2006" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2007"><a href="#cb267-2007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2008"><a href="#cb267-2008" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2009"><a href="#cb267-2009" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>result</span>
<span id="cb267-2010"><a href="#cb267-2010" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2011"><a href="#cb267-2011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2012"><a href="#cb267-2012" aria-hidden="true" tabindex="-1"></a><span class="fu">### Memory Management</span></span>
<span id="cb267-2013"><a href="#cb267-2013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2014"><a href="#cb267-2014" aria-hidden="true" tabindex="-1"></a>Running a large tuning experiment can use a lot of memory, especially when using nested resampling. Most of the memory is consumed by the models since each resampling iteration creates one new model. Storing the models is therefore disabled by default and in most cases is not required. The option <span class="in">`store_models`</span> in the functions <span class="in">`ti()`</span> and <span class="in">`auto_tuner()`</span> allows us to enable the storage of the models.</span>
<span id="cb267-2015"><a href="#cb267-2015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2016"><a href="#cb267-2016" aria-hidden="true" tabindex="-1"></a>The archive stores a <span class="in">`ResampleResult`</span> for each evaluated hyperparameter configuration. The contained <span class="in">`Prediction`</span> objects can also take up a lot of memory, especially with large datasets and many resampling iterations. We can disable the storage of the resample results by setting <span class="in">`store_benchmark_result = FALSE`</span> in the functions <span class="in">`ti()`</span> and <span class="in">`auto_tuner()`</span>. Note that without the resample results, it is no longer possible to score the configurations with another measure.</span>
<span id="cb267-2017"><a href="#cb267-2017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2018"><a href="#cb267-2018" aria-hidden="true" tabindex="-1"></a>When we run nested resampling with many outer resampling iterations, additional memory can be saved if we set <span class="in">`store_tuning_instance = FALSE`</span> in the <span class="in">`auto_tuner()`</span> function. However, the functions <span class="in">`extract_inner_tuning_results()`</span> and <span class="in">`extract_inner_tuning_archives()`</span> will then no longer work.</span>
<span id="cb267-2019"><a href="#cb267-2019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2020"><a href="#cb267-2020" aria-hidden="true" tabindex="-1"></a>The option <span class="in">`store_models = TRUE`</span> sets <span class="in">`store_benchmark_result`</span> and <span class="in">`store_tuning_instance`</span> to <span class="in">`TRUE`</span> because the models are stored in the benchmark results which in turn is part of the instance. This also means that <span class="in">`store_benchmark_result = TRUE`</span> sets <span class="in">`store_tuning_instance`</span> to <span class="in">`TRUE.`</span></span>
<span id="cb267-2021"><a href="#cb267-2021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2022"><a href="#cb267-2022" aria-hidden="true" tabindex="-1"></a>Finally, we can set <span class="in">`store_models = FALSE`</span> in the <span class="in">`resample()`</span> or <span class="in">`benchmark()`</span> functions to disable the storage of the auto tuners when running nested resampling. This way we can still access the aggregated performance (<span class="in">`rr$aggregate()`</span>) but lose information about the inner resampling.</span>
<span id="cb267-2023"><a href="#cb267-2023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2024"><a href="#cb267-2024" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 运行大型调优实验可能会使用大量内存，特别是在使用嵌套重抽样时。大多数内存被模型消耗，因为每个重抽样迭代都会创建一个新模型。默认情况下禁用存储模型，而在大多数情况下也不需要存储模型。在函数</span><span class="in">`ti()`</span><span class="at">和</span><span class="in">`auto_tuner()`</span><span class="at">中，选项</span><span class="in">`store_models`</span><span class="at">允许我们启用模型的存储。</span></span>
<span id="cb267-2025"><a href="#cb267-2025" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2026"><a href="#cb267-2026" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 归档存储了每个评估的超参数配置的</span><span class="in">`ResampleResult`</span><span class="at">。包含的</span><span class="in">`Prediction`</span><span class="at">对象在大型数据集和许多重抽样迭代时可能占用大量内存。我们可以通过在函数</span><span class="in">`ti()`</span><span class="at">和</span><span class="in">`auto_tuner()`</span><span class="at">中设置</span><span class="in">`store_benchmark_result = FALSE`</span><span class="at">来禁用重抽样结果的存储。请注意，如果没有重抽样结果，就不再可能使用另一个度量来评分配置。</span></span>
<span id="cb267-2027"><a href="#cb267-2027" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2028"><a href="#cb267-2028" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 当我们运行具有许多外部重抽样迭代的嵌套重抽样时，如果在</span><span class="in">`auto_tuner()`</span><span class="at">函数中设置</span><span class="in">`store_tuning_instance = FALSE`</span><span class="at">，还可以节省额外的内存。然而，</span><span class="in">`extract_inner_tuning_results()`</span><span class="at">和</span><span class="in">`extract_inner_tuning_archives()`</span><span class="at">函数将不再起作用。</span></span>
<span id="cb267-2029"><a href="#cb267-2029" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2030"><a href="#cb267-2030" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 选项</span><span class="in">`store_models = TRUE`</span><span class="at">会将</span><span class="in">`store_benchmark_result`</span><span class="at">和</span><span class="in">`store_tuning_instance`</span><span class="at">设置为</span><span class="in">`TRUE`</span><span class="at">，因为模型存储在基准结果中，而基准结果又是实例的一部分。这也意味着</span><span class="in">`store_benchmark_result = TRUE`</span><span class="at">会将</span><span class="in">`store_tuning_instance`</span><span class="at">设置为</span><span class="in">`TRUE`</span><span class="at">。</span></span>
<span id="cb267-2031"><a href="#cb267-2031" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2032"><a href="#cb267-2032" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 最后，在运行嵌套重抽样时，可以在</span><span class="in">`resample()`</span><span class="at">或</span><span class="in">`benchmark()`</span><span class="at">函数中设置</span><span class="in">`store_models = FALSE`</span><span class="at">以禁用自动调整器的存储。这样我们仍然可以访问聚合性能（</span><span class="in">`rr$aggregate()`</span><span class="at">），但会失去有关内部重抽样的信息。</span></span>
<span id="cb267-2033"><a href="#cb267-2033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2034"><a href="#cb267-2034" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multi-Objective Tuning</span></span>
<span id="cb267-2035"><a href="#cb267-2035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2036"><a href="#cb267-2036" aria-hidden="true" tabindex="-1"></a>So far we have considered optimizing a model with respect to one metric, but multi-criteria, or multi-objective optimization, is also possible. A simple example of multi-objective optimization might be optimizing a classifier to simultaneously maximize true positive predictions and minimize false negative predictions. In another example, consider the single-objective problem of tuning a neural network to minimize classification error. The best-performing model is likely to be quite complex, possibly with many layers that will have drawbacks like being harder to deploy on devices with limited resources. In this case, we might want to simultaneously minimize the classification error and model complexity.</span>
<span id="cb267-2037"><a href="#cb267-2037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2038"><a href="#cb267-2038" aria-hidden="true" tabindex="-1"></a>By definition, optimization of multiple metrics means these will be in competition (otherwise we would only optimize one of them) and therefore in general no single configuration exists that optimizes all metrics. Therefore, we instead focus on the concept of Pareto optimality. One hyperparameter configuration is said to Pareto-dominate another if the resulting model is equal or better in all metrics and strictly better in at least one metric.</span>
<span id="cb267-2039"><a href="#cb267-2039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2040"><a href="#cb267-2040" aria-hidden="true" tabindex="-1"></a>The goal of multi-objective hyperparameter optimization is to find a set of non-dominated solutions so that their corresponding metric values approximate the Pareto front.</span>
<span id="cb267-2041"><a href="#cb267-2041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2042"><a href="#cb267-2042" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 到目前为止，我们考虑了根据一个度量来优化模型，但多标准或多目标优化也是可能的。多目标优化的一个简单示例可能是优化分类器，同时最大化真正例预测和最小化假负例预测。在另一个示例中，考虑单一目标问题，即调整神经网络以最小化分类错误。性能最佳的模型可能相当复杂，可能具有许多层，具有诸如在资源有限的设备上部署更困难等缺点。在这种情况下，我们可能希望同时最小化分类错误和模型复杂性。</span></span>
<span id="cb267-2043"><a href="#cb267-2043" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2044"><a href="#cb267-2044" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 根据定义，多个度量的优化意味着它们将竞争（否则我们只会优化其中一个），因此通常不存在单个配置可以优化所有度量。因此，我们转而关注帕累托最优的概念。如果得到的模型在所有度量上相等或更好，且至少在一个度量上严格更好，则一个超参数配置被认为帕累托优于另一个。</span></span>
<span id="cb267-2045"><a href="#cb267-2045" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2046"><a href="#cb267-2046" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 多目标超参数优化的目标是找到一组非支配解，以便它们对应的度量值近似于帕累托前沿。</span></span>
<span id="cb267-2047"><a href="#cb267-2047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2048"><a href="#cb267-2048" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2049"><a href="#cb267-2049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2050"><a href="#cb267-2050" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2051"><a href="#cb267-2051" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>, <span class="at">cp =</span> <span class="fu">to_tune</span>(<span class="fl">1e-04</span>, <span class="fl">1e-1</span>),</span>
<span id="cb267-2052"><a href="#cb267-2052" aria-hidden="true" tabindex="-1"></a>              <span class="at">minsplit =</span> <span class="fu">to_tune</span>(<span class="dv">2</span>, <span class="dv">64</span>), <span class="at">maxdepth =</span> <span class="fu">to_tune</span>(<span class="dv">1</span>, <span class="dv">30</span>))</span>
<span id="cb267-2053"><a href="#cb267-2053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2054"><a href="#cb267-2054" aria-hidden="true" tabindex="-1"></a>measures <span class="ot">=</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"classif.ce"</span>, <span class="st">"selected_features"</span>))</span>
<span id="cb267-2055"><a href="#cb267-2055" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2056"><a href="#cb267-2056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2057"><a href="#cb267-2057" aria-hidden="true" tabindex="-1"></a>As we are tuning with respect to multiple measures, the function <span class="in">`ti()`</span> automatically creates a <span class="in">`TuningInstanceMultiCrit`</span> instead of a <span class="in">`TuningInstanceSingleCrit.`</span> Below we set <span class="in">`store_models = TRUE`</span> as this is required by the selected features measure.</span>
<span id="cb267-2058"><a href="#cb267-2058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2059"><a href="#cb267-2059" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2060"><a href="#cb267-2060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2061"><a href="#cb267-2061" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2062"><a href="#cb267-2062" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">ti</span>(</span>
<span id="cb267-2063"><a href="#cb267-2063" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> <span class="fu">tsk</span>(<span class="st">"sonar"</span>),</span>
<span id="cb267-2064"><a href="#cb267-2064" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> learner,</span>
<span id="cb267-2065"><a href="#cb267-2065" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>),</span>
<span id="cb267-2066"><a href="#cb267-2066" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> measures,</span>
<span id="cb267-2067"><a href="#cb267-2067" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"evals"</span>, <span class="at">n_evals =</span> <span class="dv">30</span>),</span>
<span id="cb267-2068"><a href="#cb267-2068" aria-hidden="true" tabindex="-1"></a>  <span class="at">store_models =</span> <span class="cn">TRUE</span></span>
<span id="cb267-2069"><a href="#cb267-2069" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-2070"><a href="#cb267-2070" aria-hidden="true" tabindex="-1"></a>instance</span>
<span id="cb267-2071"><a href="#cb267-2071" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2072"><a href="#cb267-2072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2073"><a href="#cb267-2073" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2074"><a href="#cb267-2074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2075"><a href="#cb267-2075" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2076"><a href="#cb267-2076" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-2077"><a href="#cb267-2077" aria-hidden="true" tabindex="-1"></a>tuner <span class="ot">=</span> <span class="fu">tnr</span>(<span class="st">"random_search"</span>)</span>
<span id="cb267-2078"><a href="#cb267-2078" aria-hidden="true" tabindex="-1"></a>tuner<span class="sc">$</span><span class="fu">optimize</span>(instance)</span>
<span id="cb267-2079"><a href="#cb267-2079" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2080"><a href="#cb267-2080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2081"><a href="#cb267-2081" aria-hidden="true" tabindex="-1"></a>Finally, we inspect the best-performing configurations, i.e., the Pareto set. Note that the <span class="in">`selected_features`</span> measure is averaged across the folds, so the values in the archive may not always be integers.</span>
<span id="cb267-2082"><a href="#cb267-2082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2083"><a href="#cb267-2083" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 最后，我们检查性能最佳的配置，即帕累托集。请注意，所选择的特征度量是在交叉验证折叠上进行平均的，因此归档中的值可能不总是整数。</span></span>
<span id="cb267-2084"><a href="#cb267-2084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2085"><a href="#cb267-2085" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2086"><a href="#cb267-2086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2087"><a href="#cb267-2087" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2088"><a href="#cb267-2088" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>archive<span class="sc">$</span><span class="fu">best</span>()[, .(cp, minsplit, maxdepth, classif.ce, selected_features)]</span>
<span id="cb267-2089"><a href="#cb267-2089" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2090"><a href="#cb267-2090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2091"><a href="#cb267-2091" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multi-Fidelity Tuning via Hyperband {#sec-hyperband}</span></span>
<span id="cb267-2092"><a href="#cb267-2092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2093"><a href="#cb267-2093" aria-hidden="true" tabindex="-1"></a>Increasingly large datasets and search spaces and increasingly complex models make hyperparameter optimization a time-consuming and computationally expensive task. To tackle this, some HPO methods make use of evaluating a configuration at multiple fidelity levels. Multi-fidelity HPO is motivated by the idea that the performance of a lower-fidelity model is indicative of the full-fidelity model, which can be used to make HPO more efficient (as we will soon see with Hyperband).</span>
<span id="cb267-2094"><a href="#cb267-2094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2095"><a href="#cb267-2095" aria-hidden="true" tabindex="-1"></a>To unpack what these terms mean and to motivate multi-fidelity tuning, say that we think a gradient boosting algorithm with up to 1000 rounds will be a very good fit to our training data. However, we are concerned this model will take too long to tune and train. Therefore, we want to gauge the performance of this model using a similar model that is quicker to train by setting a smaller number of rounds. In this example, the hyperparameter controlling the number of rounds is a fidelity parameter, as it controls the tradeoff between model performance and speed. The different configurations of this parameter are known as fidelity levels. We refer to the model with 1000 rounds as the model at full-fidelity and we want to approximate this model’s performance using models at different fidelity levels. Lower fidelity levels result in low-fidelity models that are quicker to train but may poorly predict the full-fidelity model’s performance. On the other hand, higher fidelity levels result in high-fidelity models that are slower to train but may better indicate the full-fidelity model’s performance.</span>
<span id="cb267-2096"><a href="#cb267-2096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2097"><a href="#cb267-2097" aria-hidden="true" tabindex="-1"></a>Other common models that have natural fidelity parameters include neural networks (number of epochs) and random forests (number of trees). The proportion of data to subsample before running any algorithm can also be viewed as a model-agnostic fidelity parameter, we will return to this in @sec-hyperband-example-svm.</span>
<span id="cb267-2098"><a href="#cb267-2098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2099"><a href="#cb267-2099" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 随着数据集和搜索空间的不断增大，以及模型的日益复杂，超参数优化变成了一项耗时且计算成本高昂的任务。为了解决这个问题，一些超参数优化方法利用多个保真度水平（fidelity levels）对配置进行评估。多保真度（Multi-fidelity）超参数优化的动机在于，较低保真度模型的性能可作为完全保真度模型的指示，从而提高超参数优化的效率（正如我们即将看到的 Hyperband 算法）。</span></span>
<span id="cb267-2100"><a href="#cb267-2100" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2101"><a href="#cb267-2101" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 为了解释这些术语的含义并推动多保真度调整的动机，假设我们认为一个带有最多1000轮的梯度提升算法将非常适合我们的训练数据。然而，我们担心这个模型调优和训练的时间会太长。因此，我们希望使用一个训练时间更短的类似模型来评估这个模型的性能，方法是设置较少的轮数。在这个例子中，控制轮数的超参数被称为保真度参数，因为它控制了模型性能和速度之间的权衡。该参数的不同配置被称为保真度水平。我们将拥有1000轮的模型称为全保真度模型，我们希望使用不同保真度水平的模型来近似该模型的性能。较低的保真度水平会产生训练速度更快但可能较差的低保真度模型，而较高的保真度水平则会产生训练速度较慢但可能更好地指示全保真度模型性能的高保真度模型。</span></span>
<span id="cb267-2102"><a href="#cb267-2102" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2103"><a href="#cb267-2103" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 其他常见的自然带有保真度参数的模型包括神经网络（轮数）和随机森林（树的数量）。在运行任何算法之前对数据进行子采样的比例也可以看作是一种不依赖于特定模型的保真度参数，我们将在第 @sec-hyperband-example-svm 中详细讨论此点。</span></span>
<span id="cb267-2104"><a href="#cb267-2104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2105"><a href="#cb267-2105" aria-hidden="true" tabindex="-1"></a>The Successive Halving and Hyperband algorithms are implemented in <span class="in">`mlr3hyperband`</span> as <span class="in">`tnr("successive_halving")`</span> and <span class="in">`tnr("hyperband")`</span> respectively; in this section, we will only showcase the Hyperband method.</span>
<span id="cb267-2106"><a href="#cb267-2106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2107"><a href="#cb267-2107" aria-hidden="true" tabindex="-1"></a>By example, we will optimize <span class="in">`lrn("classif.xgboost")`</span> on <span class="in">`tsk("sonar")`</span> and use the number of boosting iterations (<span class="in">`nrounds`</span>) as the fidelity parameter, this is a suitable choice as increasing iterations increases model training time but generally also improves performance. Hyperband will allocate increasingly more boosting iterations to well-performing hyperparameter configurations.</span>
<span id="cb267-2108"><a href="#cb267-2108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2109"><a href="#cb267-2109" aria-hidden="true" tabindex="-1"></a>We will load the learner and define the search space. We specify a range from 16 ($r_{min}$</span>
<span id="cb267-2110"><a href="#cb267-2110" aria-hidden="true" tabindex="-1"></a>) to 128 ($<span class="in">`r_{max}`</span>$) boosting iterations and tag the parameter with <span class="in">`"budget"`</span> to identify it as a fidelity parameter. For the other hyperparameters, we take the search space for XGBoost from Bischl et al. (2023), which usually works well for a wide range of datasets.</span>
<span id="cb267-2111"><a href="#cb267-2111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2112"><a href="#cb267-2112" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在</span><span class="in">`mlr3hyperband`</span><span class="at">中，连续加倍算法和Hyperband算法分别被实现为</span><span class="in">`tuner("successive_halving")`</span><span class="at">和</span><span class="in">`tuner("hyperband")`</span><span class="at">。在本节中，我们将仅展示Hyperband方法的使用。</span></span>
<span id="cb267-2113"><a href="#cb267-2113" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2114"><a href="#cb267-2114" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 举例来说，我们将在</span><span class="in">`tsk("sonar")`</span><span class="at">上优化</span><span class="in">`lrn("classif.xgboost")`</span><span class="at">，并使用提升迭代次数（</span><span class="in">`nrounds`</span><span class="at">）作为保真度参数。这是一个合适的选择，因为增加迭代次数会增加模型训练时间，但通常也会提高性能。Hyperband将为性能良好的超参数配置分配越来越多的提升迭代次数。</span></span>
<span id="cb267-2115"><a href="#cb267-2115" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2116"><a href="#cb267-2116" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们将加载学习器并定义搜索空间。我们指定了从16（最小值）到128（最大值）的提升迭代次数范围，并将该参数标记为</span><span class="in">`"budget"`</span><span class="at">，以识别它为保真度参数。对于其他超参数，我们采用了来自Bischl等人（2023年）的XGBoost搜索空间，通常适用于各种数据集。</span></span>
<span id="cb267-2117"><a href="#cb267-2117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2118"><a href="#cb267-2118" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2119"><a href="#cb267-2119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2120"><a href="#cb267-2120" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2121"><a href="#cb267-2121" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.xgboost"</span>)</span>
<span id="cb267-2122"><a href="#cb267-2122" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">set_values</span>(</span>
<span id="cb267-2123"><a href="#cb267-2123" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrounds           =</span> <span class="fu">to_tune</span>(<span class="fu">p_int</span>(<span class="dv">16</span>, <span class="dv">128</span>, <span class="at">tags =</span> <span class="st">"budget"</span>)),</span>
<span id="cb267-2124"><a href="#cb267-2124" aria-hidden="true" tabindex="-1"></a>  <span class="at">eta               =</span> <span class="fu">to_tune</span>(<span class="fl">1e-4</span>, <span class="dv">1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-2125"><a href="#cb267-2125" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_depth         =</span> <span class="fu">to_tune</span>(<span class="dv">1</span>, <span class="dv">20</span>),</span>
<span id="cb267-2126"><a href="#cb267-2126" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bytree  =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="dv">1</span>),</span>
<span id="cb267-2127"><a href="#cb267-2127" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bylevel =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="dv">1</span>),</span>
<span id="cb267-2128"><a href="#cb267-2128" aria-hidden="true" tabindex="-1"></a>  <span class="at">lambda            =</span> <span class="fu">to_tune</span>(<span class="fl">1e-3</span>, <span class="fl">1e3</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-2129"><a href="#cb267-2129" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha             =</span> <span class="fu">to_tune</span>(<span class="fl">1e-3</span>, <span class="fl">1e3</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-2130"><a href="#cb267-2130" aria-hidden="true" tabindex="-1"></a>  <span class="at">subsample         =</span> <span class="fu">to_tune</span>(<span class="fl">1e-1</span>, <span class="dv">1</span>)</span>
<span id="cb267-2131"><a href="#cb267-2131" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-2132"><a href="#cb267-2132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2133"><a href="#cb267-2133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2134"><a href="#cb267-2134" aria-hidden="true" tabindex="-1"></a>We now construct the tuning instance and a hyperband tuner with <span class="in">`eta = 2`</span>. We use <span class="in">`trm("none")`</span> and set the <span class="in">`repetitions`</span> control parameter to <span class="in">`1`</span> so that Hyperband can terminate itself after all brackets have been evaluated a single time. Note that setting <span class="in">`repetition = Inf`</span> can be useful if you want a terminator to stop the optimization, for example, based on runtime. The <span class="in">`hyperband_schedule()`</span> function can be used to display the schedule across the given fidelity levels and budget increase factor.</span>
<span id="cb267-2135"><a href="#cb267-2135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2136"><a href="#cb267-2136" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 现在，我们构建调优实例和一个</span><span class="in">`eta = 2`</span><span class="at">的Hyperband调优器。我们使用</span><span class="in">`tuner("none")`</span><span class="at">并将</span><span class="in">`repetitions`</span><span class="at">控制参数设置为</span><span class="in">`1`</span><span class="at">，以便Hyperband在所有档次都被评估一次后自动终止。请注意，如果你希望终止器根据运行时间等因素停止优化，将</span><span class="in">`repetition = Inf`</span><span class="at">设置为无穷大可能会更有用。</span><span class="in">`hyperband_schedule()`</span><span class="at">函数可以用来显示在给定的保真度水平和预算增加因子下的调度计划。</span></span>
<span id="cb267-2137"><a href="#cb267-2137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2138"><a href="#cb267-2138" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2139"><a href="#cb267-2139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2140"><a href="#cb267-2140" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2141"><a href="#cb267-2141" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">ti</span>(</span>
<span id="cb267-2142"><a href="#cb267-2142" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> <span class="fu">tsk</span>(<span class="st">"sonar"</span>),</span>
<span id="cb267-2143"><a href="#cb267-2143" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> learner,</span>
<span id="cb267-2144"><a href="#cb267-2144" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"holdout"</span>),</span>
<span id="cb267-2145"><a href="#cb267-2145" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> <span class="fu">msr</span>(<span class="st">"classif.ce"</span>),</span>
<span id="cb267-2146"><a href="#cb267-2146" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"none"</span>)</span>
<span id="cb267-2147"><a href="#cb267-2147" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-2148"><a href="#cb267-2148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2149"><a href="#cb267-2149" aria-hidden="true" tabindex="-1"></a>tuner <span class="ot">=</span> <span class="fu">tnr</span>(<span class="st">"hyperband"</span>, <span class="at">eta =</span> <span class="dv">2</span>, <span class="at">repetitions =</span> <span class="dv">1</span>)</span>
<span id="cb267-2150"><a href="#cb267-2150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2151"><a href="#cb267-2151" aria-hidden="true" tabindex="-1"></a><span class="fu">hyperband_schedule</span>(<span class="at">r_min =</span> <span class="dv">16</span>, <span class="at">r_max =</span> <span class="dv">128</span>, <span class="at">eta =</span> <span class="dv">2</span>)</span>
<span id="cb267-2152"><a href="#cb267-2152" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2153"><a href="#cb267-2153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2154"><a href="#cb267-2154" aria-hidden="true" tabindex="-1"></a>Finally, we can tune as normal and print the result and archive. Note that the archive resulting from a Hyperband run contains the additional columns <span class="in">`bracket`</span> and <span class="in">`stage`</span> which break down the results by the corresponding bracket and stage.</span>
<span id="cb267-2155"><a href="#cb267-2155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2156"><a href="#cb267-2156" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2157"><a href="#cb267-2157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2158"><a href="#cb267-2158" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2159"><a href="#cb267-2159" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-2160"><a href="#cb267-2160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2161"><a href="#cb267-2161" aria-hidden="true" tabindex="-1"></a>tuner<span class="sc">$</span><span class="fu">optimize</span>(instance)</span>
<span id="cb267-2162"><a href="#cb267-2162" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2163"><a href="#cb267-2163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2164"><a href="#cb267-2164" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2165"><a href="#cb267-2165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2166"><a href="#cb267-2166" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2167"><a href="#cb267-2167" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>result[, .(classif.ce, nrounds)]</span>
<span id="cb267-2168"><a href="#cb267-2168" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(instance<span class="sc">$</span>archive)[,</span>
<span id="cb267-2169"><a href="#cb267-2169" aria-hidden="true" tabindex="-1"></a>      .(bracket, stage, classif.ce, eta, max_depth, colsample_bytree)]</span>
<span id="cb267-2170"><a href="#cb267-2170" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2171"><a href="#cb267-2171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2172"><a href="#cb267-2172" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bayesian Optimization {#sec-bayesian-optimization}</span></span>
<span id="cb267-2173"><a href="#cb267-2173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2174"><a href="#cb267-2174" aria-hidden="true" tabindex="-1"></a>In hyperparameter optimization (@sec-optimization), learners are passed a hyperparameter configuration and evaluated on a given task via a resampling technique to estimate its generalization performance with the goal to find the optimal hyperparameter configuration. In general, no analytical description for the mapping from hyperparameter configuration to performance exists and gradient information is also not available. HPO is, therefore, a prime example for black box optimization, which considers the optimization of a function whose mathematical structure and analytical description is unknown or unexploitable. As a result, the only observable information is the output value (i.e., generalization performance) of the function given an input value (i.e., hyperparameter configuration). In fact, as evaluating the performance of a learner can take a substantial amount of time, HPO is quite an expensive black box optimization problem. Black box optimization problems occur in the real-world, for example they are encountered quite often in engineering such as in modeling experiments like crash tests or chemical reactions.</span>
<span id="cb267-2175"><a href="#cb267-2175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2176"><a href="#cb267-2176" aria-hidden="true" tabindex="-1"></a>Many optimization algorithm classes exist that can be used for black box optimization, which differ in how they tackle this problem; for example we saw in @sec-optimization methods including grid/random search and briefly discussed evolutionary strategies. Bayesian optimization refers to a class of sample-efficient iterative global black box optimization algorithms that rely on a ‘surrogate model’ trained on observed data to model the black box function. This surrogate model is typically a non-linear regression model that tries to capture the unknown function using limited observed data. During each iteration, BO algorithms employ an ‘acquisition function’ to determine the next candidate point for evaluation. This function measures the expected ‘utility’ of each point within the search space based on the prediction of the surrogate model. The algorithm then selects the candidate point with the best acquisition function value and evaluates the black box function at that point to then update the surrogate model. This iterative process continues until a termination criterion is met, such as reaching a pre-specified maximum number of evaluations or achieving a desired level of performance. BO is a powerful method that often results in good optimization performance, especially if the cost of the black box evaluation becomes expensive and the optimization budget is tight.</span>
<span id="cb267-2177"><a href="#cb267-2177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2178"><a href="#cb267-2178" aria-hidden="true" tabindex="-1"></a>As a running example throughout this section, we will optimize the sinusoidal function $f: <span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span> \rightarrow \mathbb{R}, x \mapsto 2x + \sin(14x)$ (@fig-bayesian-optimization-sinusoidal), which is characterized by two local minima and one global minimum.</span>
<span id="cb267-2179"><a href="#cb267-2179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2180"><a href="#cb267-2180" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在超参数优化（@sec-optimization）中，学习器会接收一个超参数配置，并通过重新采样技术在给定任务上进行评估，以估算其泛化性能，目标是找到最优的超参数配置。通常情况下，超参数配置到性能的映射没有解析描述，也无法获得梯度信息。因此，HPO是黑盒优化的一个典型例子，它考虑的是一种函数的优化，该函数的数学结构和解析描述是未知的或无法利用的。因此，唯一可观察到的信息是在给定输入值（即，超参数配置）的情况下，函数的输出值（即，泛化性能）。实际上，由于评估学习器的性能可能需要大量时间，HPO是一个非常昂贵的黑盒优化问题。黑盒优化问题在现实世界中经常出现，例如在工程领域，例如在建模实验中，如碰撞测试或化学反应。</span></span>
<span id="cb267-2181"><a href="#cb267-2181" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2182"><a href="#cb267-2182" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 存在许多可用于黑盒优化的优化算法类别，它们在解决这个问题时的方式各不相同；例如，在 @sec-optimization 中我们介绍了一些方法，包括网格/随机搜索，并简要讨论了进化策略。贝叶斯优化是指一类基于样本高效迭代的全局黑盒优化算法，它依赖于在观察到的数据上训练的“代理模型”来对黑盒函数进行建模。这个代理模型通常是一个非线性回归模型，它试图使用有限的观察数据来捕捉未知函数。在每次迭代中，BO算法使用一个“采集函数”来确定下一个待评估的候选点。该函数基于代理模型的预测，测量搜索空间内每个点的预期“效用”。然后，算法选择具有最佳采集函数值的候选点，并在该点处评估黑盒函数，然后更新代理模型。这个迭代过程会持续进行，直到满足终止准则，例如达到预先指定的最大评估次数或达到所需的性能水平。BO是一种强大的方法，通常在性能评估的成本昂贵且优化预算有限的情况下表现良好。</span></span>
<span id="cb267-2183"><a href="#cb267-2183" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2184"><a href="#cb267-2184" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在本节的整个过程中，我们将优化正弦函数 $f: </span><span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span><span class="at"> \rightarrow \mathbb{R}, x \mapsto 2x + \sin(14x)$ （@fig-bayesian-optimization-sinusoidal），该函数具有两个局部最小值和一个全局最小值，作为一个运行示例。</span></span>
<span id="cb267-2185"><a href="#cb267-2185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2186"><a href="#cb267-2186" aria-hidden="true" tabindex="-1"></a><span class="fu">### Black Box Optimization</span></span>
<span id="cb267-2187"><a href="#cb267-2187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2188"><a href="#cb267-2188" aria-hidden="true" tabindex="-1"></a>To start translating our problem to code we will use the <span class="in">`ObjectiveRFun`</span> class to take a single configuration as input. The <span class="in">`Objective`</span> requires specification of the function to optimize its domain and codomain. By tagging the codomain with <span class="in">`"minimize"`</span> or <span class="in">`"maximize"`</span> we specify the optimization direction. Note how below our optimization function takes a <span class="in">`list`</span> as an input with one element called <span class="in">`x`</span>.</span>
<span id="cb267-2189"><a href="#cb267-2189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2190"><a href="#cb267-2190" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 为了开始将我们的问题转化为代码，我们将使用</span><span class="in">`ObjectiveRFun`</span><span class="at">类以单个配置作为输入。</span><span class="in">`Objective`</span><span class="at">函数需要指定优化其定义域和共域的函数。通过将共域标记为</span><span class="in">`"minimize"`</span><span class="at">或</span><span class="in">`"maximize"`</span><span class="at">，我们可以指定优化的方向。请注意，在下面的例子中，我们的优化函数以一个名为x的元素的列表作为输入。</span></span>
<span id="cb267-2191"><a href="#cb267-2191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2192"><a href="#cb267-2192" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2193"><a href="#cb267-2193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2194"><a href="#cb267-2194" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2195"><a href="#cb267-2195" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bbotk)</span>
<span id="cb267-2196"><a href="#cb267-2196" aria-hidden="true" tabindex="-1"></a>sinus_1D <span class="ot">=</span> \(xs) <span class="dv">2</span> <span class="sc">*</span> xs<span class="sc">$</span>x <span class="sc">*</span> <span class="fu">sin</span>(<span class="dv">14</span> <span class="sc">*</span> xs<span class="sc">$</span>x)</span>
<span id="cb267-2197"><a href="#cb267-2197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2198"><a href="#cb267-2198" aria-hidden="true" tabindex="-1"></a>domain <span class="ot">=</span> <span class="fu">ps</span>(<span class="at">x =</span> <span class="fu">p_dbl</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb267-2199"><a href="#cb267-2199" aria-hidden="true" tabindex="-1"></a>codomain <span class="ot">=</span> <span class="fu">ps</span>(<span class="at">y =</span> <span class="fu">p_dbl</span>(<span class="at">tags =</span> <span class="st">"minimize"</span>))</span>
<span id="cb267-2200"><a href="#cb267-2200" aria-hidden="true" tabindex="-1"></a>objective <span class="ot">=</span> ObjectiveRFun<span class="sc">$</span><span class="fu">new</span>(sinus_1D, <span class="at">domain =</span> domain, <span class="at">codomain =</span> codomain)</span>
<span id="cb267-2201"><a href="#cb267-2201" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2202"><a href="#cb267-2202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2203"><a href="#cb267-2203" aria-hidden="true" tabindex="-1"></a>We can visualize our objective by generating a grid of points on which we evaluate the function (@fig-bayesian-optimization-sinusoidal), this will help us identify its local minima and global minimum.</span>
<span id="cb267-2204"><a href="#cb267-2204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2205"><a href="#cb267-2205" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2206"><a href="#cb267-2206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2207"><a href="#cb267-2207" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2208"><a href="#cb267-2208" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-bayesian-optimization-sinusoidal</span></span>
<span id="cb267-2209"><a href="#cb267-2209" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Visualization of the sinusoidal function. Local minima in triangles and global minimum in the circle.</span></span>
<span id="cb267-2210"><a href="#cb267-2210" aria-hidden="true" tabindex="-1"></a>xydt <span class="ot">=</span> <span class="fu">generate_design_grid</span>(domain, <span class="at">resolution =</span> <span class="dv">1001</span>)<span class="sc">$</span>data</span>
<span id="cb267-2211"><a href="#cb267-2211" aria-hidden="true" tabindex="-1"></a>xydt[, y <span class="sc">:</span><span class="er">=</span> objective<span class="sc">$</span><span class="fu">eval_dt</span>(xydt)<span class="sc">$</span>y]</span>
<span id="cb267-2212"><a href="#cb267-2212" aria-hidden="true" tabindex="-1"></a>optima <span class="ot">=</span> <span class="fu">data.table</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.3509406</span>, <span class="fl">0.7918238</span>))</span>
<span id="cb267-2213"><a href="#cb267-2213" aria-hidden="true" tabindex="-1"></a>optima[, y <span class="sc">:</span><span class="er">=</span> objective<span class="sc">$</span><span class="fu">eval_dt</span>(optima)<span class="sc">$</span>y]</span>
<span id="cb267-2214"><a href="#cb267-2214" aria-hidden="true" tabindex="-1"></a>optima[, type <span class="sc">:</span><span class="er">=</span> <span class="fu">c</span>(<span class="st">"local"</span>, <span class="st">"local"</span>, <span class="st">"global"</span>)]</span>
<span id="cb267-2215"><a href="#cb267-2215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2216"><a href="#cb267-2216" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(xydt, <span class="fu">aes</span>(x, y)) <span class="sc">+</span></span>
<span id="cb267-2217"><a href="#cb267-2217" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb267-2218"><a href="#cb267-2218" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> optima, <span class="fu">aes</span>(<span class="at">pch =</span> type),</span>
<span id="cb267-2219"><a href="#cb267-2219" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb267-2220"><a href="#cb267-2220" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb267-2221"><a href="#cb267-2221" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb267-2222"><a href="#cb267-2222" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2223"><a href="#cb267-2223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2224"><a href="#cb267-2224" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2225"><a href="#cb267-2225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2226"><a href="#cb267-2226" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2227"><a href="#cb267-2227" aria-hidden="true" tabindex="-1"></a>xydt[y <span class="sc">==</span> <span class="fu">min</span>(y), ]</span>
<span id="cb267-2228"><a href="#cb267-2228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2229"><a href="#cb267-2229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2230"><a href="#cb267-2230" aria-hidden="true" tabindex="-1"></a>With the objective function defined, we can proceed to optimize it using <span class="in">`OptimInstanceSingleCrit`</span>. This class allows us to wrap the objective function and explicitly specify a search space. The search space defines the set of input values we want to optimize over, and it is typically a subset or transformation of the domain, though by default the entire domain is taken as the search space. In black box optimization, it is common for the domain, and hence also the search space, to have finite box constraints. Similarly to HPO, transformations can sometimes be used to more efficiently search the space.</span>
<span id="cb267-2231"><a href="#cb267-2231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2232"><a href="#cb267-2232" aria-hidden="true" tabindex="-1"></a>In the following, we use a simple random search to optimize the sinusoidal function over the whole domain and inspect the result from the instance in the usual way. Analogously to tuners, Optimizers in bbotk are stored in the mlr_optimizers dictionary and can be constructed with opt().</span>
<span id="cb267-2233"><a href="#cb267-2233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2234"><a href="#cb267-2234" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 有了目标函数的定义，我们可以使用</span><span class="in">`OptimInstanceSingleCrit`</span><span class="at">来进行优化。这个类允许我们封装目标函数并显式地指定一个搜索空间。搜索空间定义了我们想要在其上进行优化的输入值集合，通常它是域的一个子集或变换，尽管默认情况下整个域被视为搜索空间。在黑盒优化中，域，因此也是搜索空间，通常具有有限的区间约束。类似于HPO，有时可以使用变换来更有效地搜索空间。</span></span>
<span id="cb267-2235"><a href="#cb267-2235" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2236"><a href="#cb267-2236" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在接下来的例子中，我们使用简单的随机搜索来在整个域上优化正弦函数，并以通常的方式检查实例的结果。与调优器类似，在</span><span class="in">`bbotk`</span><span class="at">中，优化器存储在</span><span class="in">`mlr_optimizers`</span><span class="at">字典中，可以使用</span><span class="in">`opt()`</span><span class="at">构建。</span></span>
<span id="cb267-2237"><a href="#cb267-2237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2238"><a href="#cb267-2238" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2239"><a href="#cb267-2239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2240"><a href="#cb267-2240" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2241"><a href="#cb267-2241" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-2242"><a href="#cb267-2242" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> OptimInstanceSingleCrit<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb267-2243"><a href="#cb267-2243" aria-hidden="true" tabindex="-1"></a>  objective,</span>
<span id="cb267-2244"><a href="#cb267-2244" aria-hidden="true" tabindex="-1"></a>  <span class="at">search_space =</span> domain,</span>
<span id="cb267-2245"><a href="#cb267-2245" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"evals"</span>, <span class="at">n_evals =</span> <span class="dv">20</span>)</span>
<span id="cb267-2246"><a href="#cb267-2246" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-2247"><a href="#cb267-2247" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> <span class="fu">opt</span>(<span class="st">"random_search"</span>, <span class="at">batch_size =</span> <span class="dv">20</span>)</span>
<span id="cb267-2248"><a href="#cb267-2248" aria-hidden="true" tabindex="-1"></a>optimizer<span class="sc">$</span><span class="fu">optimize</span>(instance)</span>
<span id="cb267-2249"><a href="#cb267-2249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2250"><a href="#cb267-2250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2251"><a href="#cb267-2251" aria-hidden="true" tabindex="-1"></a>Similarly to how we can use <span class="in">`tune()`</span> to construct a tuning instance, here we can use <span class="in">`bb_optimize()`</span>, which returns a list with elements <span class="in">`"par"`</span> (best found parameters), <span class="in">`"val"`</span> (optimal outcome), and "instance" (the optimization instance); the values given as <span class="in">`"par"`</span> and <span class="in">`"val"`</span> are the same as the values found in <span class="in">`instance$result`</span>:</span>
<span id="cb267-2252"><a href="#cb267-2252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2253"><a href="#cb267-2253" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2254"><a href="#cb267-2254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2255"><a href="#cb267-2255" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2256"><a href="#cb267-2256" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-2257"><a href="#cb267-2257" aria-hidden="true" tabindex="-1"></a>optimal <span class="ot">=</span> <span class="fu">bb_optimize</span>(objective, <span class="at">method =</span> <span class="st">"random_search"</span>, <span class="at">max_evals =</span> <span class="dv">20</span>)</span>
<span id="cb267-2258"><a href="#cb267-2258" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2259"><a href="#cb267-2259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2260"><a href="#cb267-2260" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2261"><a href="#cb267-2261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2262"><a href="#cb267-2262" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2263"><a href="#cb267-2263" aria-hidden="true" tabindex="-1"></a>optimal<span class="sc">$</span>instance<span class="sc">$</span>result</span>
<span id="cb267-2264"><a href="#cb267-2264" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2265"><a href="#cb267-2265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2266"><a href="#cb267-2266" aria-hidden="true" tabindex="-1"></a>Now we have introduced the basic black box optimization setup, we can introduce the building blocks of any Bayesian optimization algorithm.</span>
<span id="cb267-2267"><a href="#cb267-2267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2268"><a href="#cb267-2268" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb267-2269"><a href="#cb267-2269" aria-hidden="true" tabindex="-1"></a>跳过了贝叶斯优化部分。</span>
<span id="cb267-2270"><a href="#cb267-2270" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb267-2271"><a href="#cb267-2271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2272"><a href="#cb267-2272" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> Bayesian Optimization for HPO --&gt;</span></span>
<span id="cb267-2273"><a href="#cb267-2273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2274"><a href="#cb267-2274" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- `mlr3mbo` can be used for HPO by making use of `TunerMbo`, which is a wrapper around `OptimizerMbo` and works in the exact same way. --&gt;</span></span>
<span id="cb267-2275"><a href="#cb267-2275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2276"><a href="#cb267-2276" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb267-2277"><a href="#cb267-2277" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- bayesopt_ego = mlr_loop_functions$get("bayesopt_ego") --&gt;</span></span>
<span id="cb267-2278"><a href="#cb267-2278" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- surrogate = srlrn(lrn("regr.km", covtype = "matern5_2", --&gt;</span></span>
<span id="cb267-2279"><a href="#cb267-2279" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   optim.method = "BFGS", control = list(trace = FALSE))) --&gt;</span></span>
<span id="cb267-2280"><a href="#cb267-2280" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- acq_function = acqf("ei") --&gt;</span></span>
<span id="cb267-2281"><a href="#cb267-2281" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- acq_optimizer = acqo(opt("nloptr", algorithm = "NLOPT_GN_ORIG_DIRECT"), --&gt;</span></span>
<span id="cb267-2282"><a href="#cb267-2282" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   terminator = trm("stagnation", iters = 100, threshold = 1e-5)) --&gt;</span></span>
<span id="cb267-2283"><a href="#cb267-2283" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb267-2284"><a href="#cb267-2284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2285"><a href="#cb267-2285" aria-hidden="true" tabindex="-1"></a><span class="fu"># Feature Selection</span></span>
<span id="cb267-2286"><a href="#cb267-2286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2287"><a href="#cb267-2287" aria-hidden="true" tabindex="-1"></a>Feature selection, also known as variable or descriptor selection, is the process of finding a subset of features to use with a given task and learner. Using an optimal set of features can have several benefits:</span>
<span id="cb267-2288"><a href="#cb267-2288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2289"><a href="#cb267-2289" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>improved predictive performance, since we reduce overfitting on irrelevant features,</span>
<span id="cb267-2290"><a href="#cb267-2290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2291"><a href="#cb267-2291" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>robust models that do not rely on noisy features,</span>
<span id="cb267-2292"><a href="#cb267-2292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2293"><a href="#cb267-2293" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>simpler models that are easier to interpret,</span>
<span id="cb267-2294"><a href="#cb267-2294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2295"><a href="#cb267-2295" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>faster model fitting, e.g. for model updates,</span>
<span id="cb267-2296"><a href="#cb267-2296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2297"><a href="#cb267-2297" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>faster prediction, and</span>
<span id="cb267-2298"><a href="#cb267-2298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2299"><a href="#cb267-2299" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>no need to collect potentially expensive features.</span>
<span id="cb267-2300"><a href="#cb267-2300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2301"><a href="#cb267-2301" aria-hidden="true" tabindex="-1"></a>However, these objectives will not necessarily be optimized by the same set of features and thus feature selection can be seen as a multi-objective optimization problem. In this chapter, we mostly focus on feature selection as a means of improving predictive performance, but also briefly cover the optimization of multiple criteria (@sec-multicrit-featsel).</span>
<span id="cb267-2302"><a href="#cb267-2302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2303"><a href="#cb267-2303" aria-hidden="true" tabindex="-1"></a>Reducing the number of features can improve models across many scenarios, but it can be especially helpful in datasets that have a high number of features in comparison to the number of data points. Many learners perform implicit, also called embedded, feature selection, e.g. via the choice of variables used for splitting in a decision tree. Most other feature selection methods are model agnostic, i.e. they can be used together with any learner.</span>
<span id="cb267-2304"><a href="#cb267-2304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2305"><a href="#cb267-2305" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 特征选择，也称为变量或描述符选择，是找到适用于给定任务和学习器的特征子集的过程。使用最优特征集合可以带来几个好处：</span></span>
<span id="cb267-2306"><a href="#cb267-2306" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2307"><a href="#cb267-2307" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 1. 提高预测性能，因为我们减少了对无关特征的过拟合。</span></span>
<span id="cb267-2308"><a href="#cb267-2308" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2309"><a href="#cb267-2309" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2. 构建不依赖噪声特征的稳健模型。</span></span>
<span id="cb267-2310"><a href="#cb267-2310" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2311"><a href="#cb267-2311" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3. 创建更容易解释的简单模型。</span></span>
<span id="cb267-2312"><a href="#cb267-2312" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2313"><a href="#cb267-2313" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 4. 更快的模型拟合，例如用于模型更新。</span></span>
<span id="cb267-2314"><a href="#cb267-2314" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2315"><a href="#cb267-2315" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5. 更快的预测速度。</span></span>
<span id="cb267-2316"><a href="#cb267-2316" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2317"><a href="#cb267-2317" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 6. 无需收集可能昂贵的特征。</span></span>
<span id="cb267-2318"><a href="#cb267-2318" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2319"><a href="#cb267-2319" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 然而，这些目标不一定会被相同的特征集合最优化，因此特征选择可以被看作是一个多目标优化问题。在本章中，我们主要关注特征选择作为提高预测性能的手段，但也简要介绍了多标准优化的方法（请参见 @sec-multicrit-featsel）。</span></span>
<span id="cb267-2320"><a href="#cb267-2320" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2321"><a href="#cb267-2321" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在许多情况下，减少特征数量可以提高模型性能，但在与数据点数量相比特征数量较多的数据集中，特别有帮助。许多学习器通过隐式的、也称为嵌入式的特征选择方法，例如在决策树中用于分割的变量选择中执行特征选择。大多数其他特征选择方法是与模型无关的，即它们可以与任何学习器一起使用。在识别相关特征的许多不同方法中，我们将重点放在两个通用概念上，它们在下面详细描述：过滤方法和包装方法。</span></span>
<span id="cb267-2322"><a href="#cb267-2322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2323"><a href="#cb267-2323" aria-hidden="true" tabindex="-1"></a><span class="fu">## Filters</span></span>
<span id="cb267-2324"><a href="#cb267-2324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2325"><a href="#cb267-2325" aria-hidden="true" tabindex="-1"></a>Filter algorithms select features by assigning numeric scores to each feature, e.g. correlation between features and target variable, use these to rank the features and select a feature subset based on the ranking. Features that are assigned lower scores are then omitted in subsequent modeling steps.</span>
<span id="cb267-2326"><a href="#cb267-2326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2327"><a href="#cb267-2327" aria-hidden="true" tabindex="-1"></a>The learner used in a feature importance or embedded filter is independent of learners used in subsequent modeling steps. For example, one might use feature importance of a random forest for feature selection and train a neural network on the reduced feature set.</span>
<span id="cb267-2328"><a href="#cb267-2328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2329"><a href="#cb267-2329" aria-hidden="true" tabindex="-1"></a>Most of the filter methods have some limitations, for example, the correlation filter can only be calculated for regression tasks with numeric features. For a full list of all implemented filter methods, we refer the reader to <span class="ot">&lt;https://mlr3filters.mlr-org.com&gt;</span>, which also shows the supported task and features types. A benchmark of filter methods was performed by Bommert et al. (2020), who recommend not to rely on a single filter method but to try several ones if the available computational resources allow. If only a single filter method is to be used, the authors recommend to use a feature importance filter using random forest permutation importance (see @sec-fs-var-imp-filters), similar to the permutation method described above, but also the JMIM and AUC filters performed well in their comparison.</span>
<span id="cb267-2330"><a href="#cb267-2330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2331"><a href="#cb267-2331" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 过滤算法通过为每个特征分配数值分数（例如，特征与目标变量之间的相关性）来选择特征，然后使用这些分数对特征进行排序，并基于排名选择一个特征子集。分配较低分数的特征将在后续建模步骤中被省略。</span></span>
<span id="cb267-2332"><a href="#cb267-2332" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2333"><a href="#cb267-2333" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在特征重要性或嵌入式过滤器中使用的学习器与后续建模步骤中使用的学习器是相互独立的。例如，可以使用随机森林的特征重要性进行特征选择，然后在减少后的特征集上训练神经网络。</span></span>
<span id="cb267-2334"><a href="#cb267-2334" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2335"><a href="#cb267-2335" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 大多数过滤方法都有一些限制，例如，相关性过滤只能用于具有数值特征的回归任务。有关所有已实现的过滤方法的完整列表，我们建议读者访问</span><span class="ot">&lt;https://mlr3filters.mlr-org.com&gt;</span><span class="at">，该网站还显示了支持的任务和特征类型。Bommert等人（2020年）进行了一项过滤方法的基准测试，他们建议不要仅依赖于单个过滤方法，而是在计算资源允许的情况下尝试多种方法。如果只想使用单个过滤方法，作者建议使用基于随机森林排列重要性的特征重要性过滤器（参见 @sec-fs-var-imp-filters ），类似于上述描述的排列方法，但JMIM和AUC过滤器在他们的比较中也表现良好。</span></span>
<span id="cb267-2336"><a href="#cb267-2336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2337"><a href="#cb267-2337" aria-hidden="true" tabindex="-1"></a><span class="fu">### Calculating Filter Value</span></span>
<span id="cb267-2338"><a href="#cb267-2338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2339"><a href="#cb267-2339" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2340"><a href="#cb267-2340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2341"><a href="#cb267-2341" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2342"><a href="#cb267-2342" aria-hidden="true" tabindex="-1"></a>flt_gain <span class="ot">=</span> <span class="fu">flt</span>(<span class="st">"information_gain"</span>)</span>
<span id="cb267-2343"><a href="#cb267-2343" aria-hidden="true" tabindex="-1"></a>tsk_pen <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-2344"><a href="#cb267-2344" aria-hidden="true" tabindex="-1"></a>flt_gain<span class="sc">$</span><span class="fu">calculate</span>(tsk_pen)</span>
<span id="cb267-2345"><a href="#cb267-2345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2346"><a href="#cb267-2346" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(flt_gain)</span>
<span id="cb267-2347"><a href="#cb267-2347" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2348"><a href="#cb267-2348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2349"><a href="#cb267-2349" aria-hidden="true" tabindex="-1"></a>This shows that the flipper and bill measurements are the most informative features for predicting the species of a penguin in this dataset, whereas sex and year are the least informative. Some filters have hyperparameters that can be changed in the same way as <span class="in">`Learner`</span> hyperparameters. For example, to calculate <span class="in">`"spearman"`</span> instead of <span class="in">`"pearson"`</span> correlation with the correlation filter:</span>
<span id="cb267-2350"><a href="#cb267-2350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2351"><a href="#cb267-2351" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 这显示了在这个数据集中，翅膀和嘴巴的测量是预测企鹅物种最具信息量的特征，而性别和年份则是最不具信息量的特征。一些过滤器具有可以像</span><span class="in">`Learner`</span><span class="at">超参数一样更改的超参数。例如，要使用相关性过滤器计算</span><span class="in">`"Spearman"`</span><span class="at">相关性而不是</span><span class="in">`"Pearson"`</span><span class="at">相关性：</span></span>
<span id="cb267-2352"><a href="#cb267-2352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2353"><a href="#cb267-2353" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2354"><a href="#cb267-2354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2355"><a href="#cb267-2355" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2356"><a href="#cb267-2356" aria-hidden="true" tabindex="-1"></a>flt_cor <span class="ot">=</span> <span class="fu">flt</span>(<span class="st">"correlation"</span>, <span class="at">method =</span> <span class="st">"spearman"</span>)</span>
<span id="cb267-2357"><a href="#cb267-2357" aria-hidden="true" tabindex="-1"></a>flt_cor<span class="sc">$</span>param_set</span>
<span id="cb267-2358"><a href="#cb267-2358" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2359"><a href="#cb267-2359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2360"><a href="#cb267-2360" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feature Importance Filters {#sec-fs-var-imp-filters}</span></span>
<span id="cb267-2361"><a href="#cb267-2361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2362"><a href="#cb267-2362" aria-hidden="true" tabindex="-1"></a>To use feature importance filters, we can use a learner with with an <span class="in">`$importance()`</span> method that reports feature importance. All learners with the property “importance” have this functionality. A list of all learners with this property can be found with</span>
<span id="cb267-2363"><a href="#cb267-2363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2364"><a href="#cb267-2364" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2365"><a href="#cb267-2365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2366"><a href="#cb267-2366" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2367"><a href="#cb267-2367" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-2368"><a href="#cb267-2368" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(mlr_learners)[<span class="fu">sapply</span>(properties, \(x) <span class="st">"importance"</span> <span class="sc">%in%</span> x)]</span>
<span id="cb267-2369"><a href="#cb267-2369" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2370"><a href="#cb267-2370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2371"><a href="#cb267-2371" aria-hidden="true" tabindex="-1"></a>For some learners, the desired filter method needs to be set as a hyperparameter. For example, <span class="in">`lrn("classif.ranger")`</span> comes with multiple integrated methods, which can be selected during construction: To use the feature importance method <span class="in">`"impurity"`</span>, select it during learner construction:</span>
<span id="cb267-2372"><a href="#cb267-2372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2373"><a href="#cb267-2373" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2374"><a href="#cb267-2374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2375"><a href="#cb267-2375" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2376"><a href="#cb267-2376" aria-hidden="true" tabindex="-1"></a><span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>)<span class="sc">$</span>param_set<span class="sc">$</span>levels<span class="sc">$</span>importance</span>
<span id="cb267-2377"><a href="#cb267-2377" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2378"><a href="#cb267-2378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2379"><a href="#cb267-2379" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2380"><a href="#cb267-2380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2381"><a href="#cb267-2381" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2382"><a href="#cb267-2382" aria-hidden="true" tabindex="-1"></a>lrn_ranger <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>)</span>
<span id="cb267-2383"><a href="#cb267-2383" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2384"><a href="#cb267-2384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2385"><a href="#cb267-2385" aria-hidden="true" tabindex="-1"></a>We first have to remove missing data because the learner cannot handle missing data, i.e. it does not have the property “missing”. Note we use the <span class="in">`$filter()`</span> method to remove rows; the “filter” name is unrelated to feature filtering, however.</span>
<span id="cb267-2386"><a href="#cb267-2386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2387"><a href="#cb267-2387" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2388"><a href="#cb267-2388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2389"><a href="#cb267-2389" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2390"><a href="#cb267-2390" aria-hidden="true" tabindex="-1"></a>tsk_pen <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-2391"><a href="#cb267-2391" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span><span class="fu">filter</span>(tsk_pen<span class="sc">$</span>row_ids[<span class="fu">complete.cases</span>(tsk_pen<span class="sc">$</span><span class="fu">data</span>())])</span>
<span id="cb267-2392"><a href="#cb267-2392" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2393"><a href="#cb267-2393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2394"><a href="#cb267-2394" aria-hidden="true" tabindex="-1"></a>Now we can use <span class="in">`flt("importance")`</span> to calculate importance values:</span>
<span id="cb267-2395"><a href="#cb267-2395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2396"><a href="#cb267-2396" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2397"><a href="#cb267-2397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2398"><a href="#cb267-2398" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2399"><a href="#cb267-2399" aria-hidden="true" tabindex="-1"></a>flt_importance <span class="ot">=</span> <span class="fu">flt</span>(<span class="st">"importance"</span>, <span class="at">learner =</span> lrn_ranger)</span>
<span id="cb267-2400"><a href="#cb267-2400" aria-hidden="true" tabindex="-1"></a>flt_importance<span class="sc">$</span><span class="fu">calculate</span>(tsk_pen)</span>
<span id="cb267-2401"><a href="#cb267-2401" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(flt_importance)</span>
<span id="cb267-2402"><a href="#cb267-2402" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2403"><a href="#cb267-2403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2404"><a href="#cb267-2404" aria-hidden="true" tabindex="-1"></a><span class="fu">### Embedded Methods</span></span>
<span id="cb267-2405"><a href="#cb267-2405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2406"><a href="#cb267-2406" aria-hidden="true" tabindex="-1"></a>Many learners internally select a subset of the features which they find helpful for prediction, but ignore other features. For example, a decision tree might never select some features for splitting. These subsets can be used for feature selection, which we call embedded methods because the feature selection is embedded in the learner. The selected features (and those not selected) can be queried if the learner has the <span class="in">`"selected_features"`</span> property. As above, we can find those learners with</span>
<span id="cb267-2407"><a href="#cb267-2407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2408"><a href="#cb267-2408" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 许多学习器在内部选择对预测有帮助的特征子集，但忽略其他特征。例如，决策树可能永远不会选择某些特征进行分割。这些子集可以用于特征选择，我们称之为嵌入方法，因为特征选择嵌入在学习器中。如果学习器具有</span><span class="in">`"selected_features"`</span><span class="at">属性，那么可以查询所选特征（以及未被选择的特征）。与上述类似，我们可以找到那些带有该属性的学习器：</span></span>
<span id="cb267-2409"><a href="#cb267-2409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2410"><a href="#cb267-2410" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2411"><a href="#cb267-2411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2412"><a href="#cb267-2412" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2413"><a href="#cb267-2413" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-2414"><a href="#cb267-2414" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(mlr_learners)[<span class="fu">sapply</span>(properties, \(x) <span class="st">"selected_features"</span> <span class="sc">%in%</span> x)]</span>
<span id="cb267-2415"><a href="#cb267-2415" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2416"><a href="#cb267-2416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2417"><a href="#cb267-2417" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2418"><a href="#cb267-2418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2419"><a href="#cb267-2419" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2420"><a href="#cb267-2420" aria-hidden="true" tabindex="-1"></a>tsk_pen <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-2421"><a href="#cb267-2421" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>)</span>
<span id="cb267-2422"><a href="#cb267-2422" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(tsk_pen)</span>
<span id="cb267-2423"><a href="#cb267-2423" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">selected_features</span>()</span>
<span id="cb267-2424"><a href="#cb267-2424" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2425"><a href="#cb267-2425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2426"><a href="#cb267-2426" aria-hidden="true" tabindex="-1"></a>The features selected by the model can be extracted by a <span class="in">`Filter`</span> object, where <span class="in">`$calculate()`</span> corresponds to training the learner on the given task:</span>
<span id="cb267-2427"><a href="#cb267-2427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2428"><a href="#cb267-2428" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2429"><a href="#cb267-2429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2430"><a href="#cb267-2430" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2431"><a href="#cb267-2431" aria-hidden="true" tabindex="-1"></a>flt_selected <span class="ot">=</span> <span class="fu">flt</span>(<span class="st">"selected_features"</span>, <span class="at">learner =</span> lrn_rpart)</span>
<span id="cb267-2432"><a href="#cb267-2432" aria-hidden="true" tabindex="-1"></a>flt_selected<span class="sc">$</span><span class="fu">calculate</span>(tsk_pen)</span>
<span id="cb267-2433"><a href="#cb267-2433" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(flt_selected)</span>
<span id="cb267-2434"><a href="#cb267-2434" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2435"><a href="#cb267-2435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2436"><a href="#cb267-2436" aria-hidden="true" tabindex="-1"></a>Contrary to other filter methods, embedded methods just return values of <span class="in">`1`</span> (selected features) and <span class="in">`0`</span> (dropped feature).</span>
<span id="cb267-2437"><a href="#cb267-2437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2438"><a href="#cb267-2438" aria-hidden="true" tabindex="-1"></a><span class="fu">### Filter-Based Feature Selection</span></span>
<span id="cb267-2439"><a href="#cb267-2439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2440"><a href="#cb267-2440" aria-hidden="true" tabindex="-1"></a>After calculating a score for each feature, one has to select the features to be kept or those to be dropped from further modeling steps. For the <span class="in">`"selected_features"`</span> filter described in embedded methods, this step is straight-forward since the methods assign either a value of 1 for a feature to be kept or 0 for a feature to be dropped. Below, we find the names of features with a value of 1 and select those features with <span class="in">`task$select()`</span>. At first glance it may appear a bit convoluted to have a filter assign scores based on the feature names returned by <span class="in">`$selected_features()`</span>, only to turn these scores back into the names of the features to be kept. However, this approach allows us to use the same interface for all filter methods, which is especially useful when we want to automate the feature selection process in pipelines, as we will see in @sec-pipelines-featsel.</span>
<span id="cb267-2441"><a href="#cb267-2441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2442"><a href="#cb267-2442" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在为每个特征计算分数之后，需要选择要保留的特征或要在进一步建模步骤中舍弃的特征。对于嵌入方法中描述的</span><span class="in">`"selected_features"`</span><span class="at">筛选器来说，这一步骤非常直接，因为该方法为要保留的特征分配值1，为要舍弃的特征分配值0。在下面的代码中，我们查找值为1的特征的名称，并使用</span><span class="in">`task$select()`</span><span class="at">选择这些特征。乍一看，这似乎有点繁琐，因为我们让一个筛选器基于</span><span class="in">`$selected_features()`</span><span class="at">返回的特征名称分配分数，然后再将这些分数转换回要保留的特征的名称。然而，这种方法使我们能够为所有筛选方法使用相同的接口，尤其在我们想要在管道中自动化特征选择过程时特别有用，正如我们将在 @sec-pipelines-featsel 中看到的那样。</span></span>
<span id="cb267-2443"><a href="#cb267-2443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2444"><a href="#cb267-2444" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2445"><a href="#cb267-2445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2446"><a href="#cb267-2446" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2447"><a href="#cb267-2447" aria-hidden="true" tabindex="-1"></a>flt_selected<span class="sc">$</span><span class="fu">calculate</span>(tsk_pen)</span>
<span id="cb267-2448"><a href="#cb267-2448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2449"><a href="#cb267-2449" aria-hidden="true" tabindex="-1"></a><span class="co"># select all features used by rpart</span></span>
<span id="cb267-2450"><a href="#cb267-2450" aria-hidden="true" tabindex="-1"></a>keep <span class="ot">=</span> <span class="fu">names</span>(<span class="fu">which</span>(flt_selected<span class="sc">$</span>scores <span class="sc">==</span> <span class="dv">1</span>))</span>
<span id="cb267-2451"><a href="#cb267-2451" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span><span class="fu">select</span>(keep)</span>
<span id="cb267-2452"><a href="#cb267-2452" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span>feature_names</span>
<span id="cb267-2453"><a href="#cb267-2453" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2454"><a href="#cb267-2454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2455"><a href="#cb267-2455" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2456"><a href="#cb267-2456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2457"><a href="#cb267-2457" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2458"><a href="#cb267-2458" aria-hidden="true" tabindex="-1"></a><span class="co"># select the top k(= 3) features</span></span>
<span id="cb267-2459"><a href="#cb267-2459" aria-hidden="true" tabindex="-1"></a>tsk_pen <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-2460"><a href="#cb267-2460" aria-hidden="true" tabindex="-1"></a>flt_gain <span class="ot">=</span> <span class="fu">flt</span>(<span class="st">"information_gain"</span>)</span>
<span id="cb267-2461"><a href="#cb267-2461" aria-hidden="true" tabindex="-1"></a>flt_gain<span class="sc">$</span><span class="fu">calculate</span>(tsk_pen)</span>
<span id="cb267-2462"><a href="#cb267-2462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2463"><a href="#cb267-2463" aria-hidden="true" tabindex="-1"></a>keep <span class="ot">=</span> <span class="fu">names</span>(<span class="fu">head</span>(flt_gain<span class="sc">$</span>scores, <span class="dv">3</span>))</span>
<span id="cb267-2464"><a href="#cb267-2464" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span><span class="fu">select</span>(keep)</span>
<span id="cb267-2465"><a href="#cb267-2465" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span>feature_names</span>
<span id="cb267-2466"><a href="#cb267-2466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2467"><a href="#cb267-2467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2468"><a href="#cb267-2468" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2469"><a href="#cb267-2469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2470"><a href="#cb267-2470" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2471"><a href="#cb267-2471" aria-hidden="true" tabindex="-1"></a><span class="co"># Select all features with a score (&gt; 0.5)</span></span>
<span id="cb267-2472"><a href="#cb267-2472" aria-hidden="true" tabindex="-1"></a>tsk_pen <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-2473"><a href="#cb267-2473" aria-hidden="true" tabindex="-1"></a>flt_gain <span class="ot">=</span> <span class="fu">flt</span>(<span class="st">"information_gain"</span>)</span>
<span id="cb267-2474"><a href="#cb267-2474" aria-hidden="true" tabindex="-1"></a>flt_gain<span class="sc">$</span><span class="fu">calculate</span>(tsk_pen)</span>
<span id="cb267-2475"><a href="#cb267-2475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2476"><a href="#cb267-2476" aria-hidden="true" tabindex="-1"></a>keep <span class="ot">=</span> <span class="fu">names</span>(<span class="fu">which</span>(flt_gain<span class="sc">$</span>scores <span class="sc">&gt;</span> <span class="fl">0.5</span>))</span>
<span id="cb267-2477"><a href="#cb267-2477" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span><span class="fu">select</span>(keep)</span>
<span id="cb267-2478"><a href="#cb267-2478" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span>feature_names</span>
<span id="cb267-2479"><a href="#cb267-2479" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2480"><a href="#cb267-2480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2481"><a href="#cb267-2481" aria-hidden="true" tabindex="-1"></a><span class="fu">## Wrapper Methods</span></span>
<span id="cb267-2482"><a href="#cb267-2482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2483"><a href="#cb267-2483" aria-hidden="true" tabindex="-1"></a>Wrapper methods work by fitting models on selected feature subsets and evaluating their performance (Kohavi and John 1997). This can be done in a sequential fashion, e.g. by iteratively adding features to the model in sequential forward selection, or in a parallel fashion, e.g. by evaluating random feature subsets in a random search. Below, we describe these simple approaches in a common framework along with more advanced methods such as genetic search. We further show how to select features by optimizing multiple performance measures and how to wrap a learner with feature selection to use it in pipelines or benchmarks.</span>
<span id="cb267-2484"><a href="#cb267-2484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2485"><a href="#cb267-2485" aria-hidden="true" tabindex="-1"></a>In more detail, wrapper methods iteratively evaluate subsets of features by resampling a learner restricted to this feature subset and with a chosen performance metric (with holdout or a more expensive CV), and using the resulting performance to guide the search. The specific search strategy iteration is defined by a <span class="in">`FSelector`</span> object. A simple example is the sequential forward selection that starts with computing each single-feature model, selects the best one, and then iteratively always adds the feature that leads to the largest performance improvement.</span>
<span id="cb267-2486"><a href="#cb267-2486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2487"><a href="#cb267-2487" aria-hidden="true" tabindex="-1"></a>Wrapper methods can be used with any learner, but need to train or even resample the learner potentially many times, leading to a computationally intensive method. All wrapper methods are implemented via the package <span class="in">`mlr3fselect`</span>.</span>
<span id="cb267-2488"><a href="#cb267-2488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2489"><a href="#cb267-2489" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 包装方法通过在选择的特征子集上拟合模型并评估其性能来工作（Kohavi和John，1997年）。这可以以顺序方式进行，例如通过在顺序前向选择中迭代地将特征添加到模型中，也可以以并行方式进行，例如通过在随机搜索中评估随机特征子集。在下面，我们描述了这些简单方法，以及更高级的方法，比如遗传搜索，都在一个共同的框架下。我们还展示了如何通过优化多个性能指标来选择特征，以及如何用特征选择包装一个学习器，使其可以在管道或基准测试中使用。</span></span>
<span id="cb267-2490"><a href="#cb267-2490" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2491"><a href="#cb267-2491" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 更详细地说，包装方法通过对特征子集进行迭代评估，方法是通过对一个受限于该特征子集的学习器进行重抽样，选择一个选定的性能指标（使用留出法或更昂贵的交叉验证），并使用得到的性能来引导搜索。具体的搜索策略迭代是由一个</span><span class="in">`FSelector`</span><span class="at">对象定义的。一个简单的例子是顺序前向选择，它从计算每个单特征模型开始，选择最好的模型，然后迭代地添加导致性能提升最大的特征。</span></span>
<span id="cb267-2492"><a href="#cb267-2492" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2493"><a href="#cb267-2493" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 包装方法可以与任何学习器一起使用，但可能需要多次训练甚至重抽样学习器，因此是一种计算密集型的方法。所有的包装方法都是通过</span><span class="in">`mlr3fselect`</span><span class="at">包实现的。</span></span>
<span id="cb267-2494"><a href="#cb267-2494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2495"><a href="#cb267-2495" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simple Forward Selection Example</span></span>
<span id="cb267-2496"><a href="#cb267-2496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2497"><a href="#cb267-2497" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2498"><a href="#cb267-2498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2499"><a href="#cb267-2499" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2500"><a href="#cb267-2500" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-2501"><a href="#cb267-2501" aria-hidden="true" tabindex="-1"></a>tsk_pen <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-2502"><a href="#cb267-2502" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span><span class="fu">select</span>(<span class="fu">c</span>(<span class="st">"bill_depth"</span>, <span class="st">"bill_length"</span>, <span class="st">"body_mass"</span>, <span class="st">"flipper_length"</span>))</span>
<span id="cb267-2503"><a href="#cb267-2503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2504"><a href="#cb267-2504" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">fselect</span>(</span>
<span id="cb267-2505"><a href="#cb267-2505" aria-hidden="true" tabindex="-1"></a>  <span class="at">fselector =</span> <span class="fu">fs</span>(<span class="st">"sequential"</span>),</span>
<span id="cb267-2506"><a href="#cb267-2506" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> tsk_pen,</span>
<span id="cb267-2507"><a href="#cb267-2507" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> lrn_rpart,</span>
<span id="cb267-2508"><a href="#cb267-2508" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>),</span>
<span id="cb267-2509"><a href="#cb267-2509" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> <span class="fu">msr</span>(<span class="st">"classif.acc"</span>)</span>
<span id="cb267-2510"><a href="#cb267-2510" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-2511"><a href="#cb267-2511" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2512"><a href="#cb267-2512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2513"><a href="#cb267-2513" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2514"><a href="#cb267-2514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2515"><a href="#cb267-2515" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2516"><a href="#cb267-2516" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">=</span> <span class="fu">as.data.table</span>(instance<span class="sc">$</span>archive)</span>
<span id="cb267-2517"><a href="#cb267-2517" aria-hidden="true" tabindex="-1"></a>dt[batch_nr <span class="sc">==</span> <span class="dv">1</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb267-2518"><a href="#cb267-2518" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2519"><a href="#cb267-2519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2520"><a href="#cb267-2520" aria-hidden="true" tabindex="-1"></a>We see that the feature <span class="in">`flipper_length`</span> achieved the highest prediction performance in the first iteration and is thus selected. We plot the performance over the iterations:</span>
<span id="cb267-2521"><a href="#cb267-2521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2522"><a href="#cb267-2522" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2523"><a href="#cb267-2523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2524"><a href="#cb267-2524" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2525"><a href="#cb267-2525" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(instance, <span class="at">type =</span> <span class="st">"performance"</span>)</span>
<span id="cb267-2526"><a href="#cb267-2526" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2527"><a href="#cb267-2527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2528"><a href="#cb267-2528" aria-hidden="true" tabindex="-1"></a>In the plot, we can see that adding a second feature further improves the performance to over 90%. To see which feature was added, we can go back to the archive and look at the second iteration:</span>
<span id="cb267-2529"><a href="#cb267-2529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2530"><a href="#cb267-2530" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2531"><a href="#cb267-2531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2532"><a href="#cb267-2532" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2533"><a href="#cb267-2533" aria-hidden="true" tabindex="-1"></a>dt[batch_nr <span class="sc">==</span> <span class="dv">2</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb267-2534"><a href="#cb267-2534" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2535"><a href="#cb267-2535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2536"><a href="#cb267-2536" aria-hidden="true" tabindex="-1"></a>The improvement in batch three is small so we may even prefer to select a marginally worse model with two features to reduce data size.</span>
<span id="cb267-2537"><a href="#cb267-2537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2538"><a href="#cb267-2538" aria-hidden="true" tabindex="-1"></a>To directly show the best feature set, we can use <span class="in">`$result_feature_set`</span> which returns the features in alphabetical order (not order selected):</span>
<span id="cb267-2539"><a href="#cb267-2539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2540"><a href="#cb267-2540" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在第三次迭代中的改进很小，因此我们甚至可能更愿意选择一个带有两个特征的性能稍差一点的模型，以减小数据集的大小。</span></span>
<span id="cb267-2541"><a href="#cb267-2541" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2542"><a href="#cb267-2542" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 要直接显示最佳特征集，我们可以使用</span><span class="in">`$result_feature_set`</span><span class="at">，该属性返回按字母顺序排列的特征（而不是选择的顺序）：</span></span>
<span id="cb267-2543"><a href="#cb267-2543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2544"><a href="#cb267-2544" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2545"><a href="#cb267-2545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2546"><a href="#cb267-2546" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2547"><a href="#cb267-2547" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>result_feature_set</span>
<span id="cb267-2548"><a href="#cb267-2548" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2549"><a href="#cb267-2549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2550"><a href="#cb267-2550" aria-hidden="true" tabindex="-1"></a><span class="fu">### The FSelectInstance Class</span></span>
<span id="cb267-2551"><a href="#cb267-2551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2552"><a href="#cb267-2552" aria-hidden="true" tabindex="-1"></a>To create an <span class="in">`FSelectInstanceSingleCrit`</span> object, we use the sugar function <span class="in">`fsi()`</span>:</span>
<span id="cb267-2553"><a href="#cb267-2553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2554"><a href="#cb267-2554" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2555"><a href="#cb267-2555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2556"><a href="#cb267-2556" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2557"><a href="#cb267-2557" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">fsi</span>(</span>
<span id="cb267-2558"><a href="#cb267-2558" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> tsk_pen,</span>
<span id="cb267-2559"><a href="#cb267-2559" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> lrn_rpart,</span>
<span id="cb267-2560"><a href="#cb267-2560" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>),</span>
<span id="cb267-2561"><a href="#cb267-2561" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> <span class="fu">msr</span>(<span class="st">"classif.acc"</span>),</span>
<span id="cb267-2562"><a href="#cb267-2562" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"evals"</span>, <span class="at">n_evals =</span> <span class="dv">20</span>)</span>
<span id="cb267-2563"><a href="#cb267-2563" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-2564"><a href="#cb267-2564" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2565"><a href="#cb267-2565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2566"><a href="#cb267-2566" aria-hidden="true" tabindex="-1"></a><span class="fu">### The FSelector Class</span></span>
<span id="cb267-2567"><a href="#cb267-2567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2568"><a href="#cb267-2568" aria-hidden="true" tabindex="-1"></a>The <span class="in">`FSelector`</span> class is the base class for different feature selection algorithms. The following algorithms are currently implemented in <span class="in">`mlr3fselect`</span>:</span>
<span id="cb267-2569"><a href="#cb267-2569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2570"><a href="#cb267-2570" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Random search, trying random feature subsets until termination (<span class="in">`fs("random_search")`</span>)</span>
<span id="cb267-2571"><a href="#cb267-2571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2572"><a href="#cb267-2572" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Exhaustive search, trying all possible feature subsets (<span class="in">`fs("exhaustive_search")`</span>)</span>
<span id="cb267-2573"><a href="#cb267-2573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2574"><a href="#cb267-2574" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sequential search, i.e. sequential forward or backward selection (<span class="in">`fs("sequential")`</span>)</span>
<span id="cb267-2575"><a href="#cb267-2575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2576"><a href="#cb267-2576" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Recursive feature elimination, which uses a learner’s importance scores to iteratively remove features with low feature importance (<span class="in">`fs("rfe")`</span>)</span>
<span id="cb267-2577"><a href="#cb267-2577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2578"><a href="#cb267-2578" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Design points, trying all user-supplied feature sets (<span class="in">`fs("design_points")`</span>)</span>
<span id="cb267-2579"><a href="#cb267-2579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2580"><a href="#cb267-2580" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Genetic search, implementing a genetic algorithm which treats the features as a binary sequence and tries to find the best subset with mutations (<span class="in">`fs("genetic_search")`</span>)</span>
<span id="cb267-2581"><a href="#cb267-2581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2582"><a href="#cb267-2582" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Shadow variable search, which adds permuted copies of all features (shadow variables), performs forward selection, and stops when a shadow variable is selected (<span class="in">`fs("shadow_variable_search")`</span>)</span>
<span id="cb267-2583"><a href="#cb267-2583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2584"><a href="#cb267-2584" aria-hidden="true" tabindex="-1"></a>Note that all these methods can be stopped (early) with a terminator, e.g. an exhaustive search can be stopped after a given number of evaluations. In this example, we will use a simple random search and retrieve it from the <span class="in">`mlr_fselectors`</span> dictionary with <span class="in">`fs()`</span>.</span>
<span id="cb267-2585"><a href="#cb267-2585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2586"><a href="#cb267-2586" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`FSelector`</span><span class="at">类是不同特征选择算法的基类。目前在</span><span class="in">`mlr3fselect`</span><span class="at">中实现了以下算法：</span></span>
<span id="cb267-2587"><a href="#cb267-2587" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2588"><a href="#cb267-2588" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; - 随机搜索，直到满足终止条件为止尝试随机特征子集 (</span><span class="in">`fs("random_search")`</span><span class="at">)</span></span>
<span id="cb267-2589"><a href="#cb267-2589" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2590"><a href="#cb267-2590" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; - 穷举搜索，尝试所有可能的特征子集 (</span><span class="in">`fs("exhaustive_search")`</span><span class="at">)</span></span>
<span id="cb267-2591"><a href="#cb267-2591" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2592"><a href="#cb267-2592" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; - 顺序搜索，即顺序前向或顺序后向选择 (</span><span class="in">`fs("sequential")`</span><span class="at">)</span></span>
<span id="cb267-2593"><a href="#cb267-2593" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2594"><a href="#cb267-2594" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; - 递归特征消除，它使用学习器的重要性分数，迭代地删除具有较低重要性的特征 (</span><span class="in">`fs("rfe")`</span><span class="at">)</span></span>
<span id="cb267-2595"><a href="#cb267-2595" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2596"><a href="#cb267-2596" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; - 设计点，尝试所有用户提供的特征集 (</span><span class="in">`fs("design_points")`</span><span class="at">)</span></span>
<span id="cb267-2597"><a href="#cb267-2597" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2598"><a href="#cb267-2598" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; - 遗传搜索，实现将特征视为二进制序列的遗传算法，并尝试通过突变找到最佳子集 (</span><span class="in">`fs("genetic_search")`</span><span class="at">)</span></span>
<span id="cb267-2599"><a href="#cb267-2599" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2600"><a href="#cb267-2600" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; - 影子变量搜索，它将所有特征的排列副本（影子变量）添加到特征集中，执行前向选择，并在选择了影子变量时停止 (</span><span class="in">`fs("shadow_variable_search")`</span><span class="at">)</span></span>
<span id="cb267-2601"><a href="#cb267-2601" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2602"><a href="#cb267-2602" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 请注意，所有这些方法都可以（提前）通过终止条件停止，例如，穷举搜索可以在给定数量的评估后停止。在本例中，我们将使用简单的随机搜索，并使用</span><span class="in">`fs()`</span><span class="at">函数从</span><span class="in">`mlr_fselectors`</span><span class="at">字典中检索它。</span></span>
<span id="cb267-2603"><a href="#cb267-2603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2604"><a href="#cb267-2604" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2605"><a href="#cb267-2605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2606"><a href="#cb267-2606" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2607"><a href="#cb267-2607" aria-hidden="true" tabindex="-1"></a>fselector <span class="ot">=</span> <span class="fu">fs</span>(<span class="st">"random_search"</span>)</span>
<span id="cb267-2608"><a href="#cb267-2608" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2609"><a href="#cb267-2609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2610"><a href="#cb267-2610" aria-hidden="true" tabindex="-1"></a><span class="fu">### Starting the Feature Selection</span></span>
<span id="cb267-2611"><a href="#cb267-2611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2612"><a href="#cb267-2612" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2613"><a href="#cb267-2613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2614"><a href="#cb267-2614" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2615"><a href="#cb267-2615" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-2616"><a href="#cb267-2616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2617"><a href="#cb267-2617" aria-hidden="true" tabindex="-1"></a>fselector<span class="sc">$</span><span class="fu">optimize</span>(instance)</span>
<span id="cb267-2618"><a href="#cb267-2618" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2619"><a href="#cb267-2619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2620"><a href="#cb267-2620" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2621"><a href="#cb267-2621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2622"><a href="#cb267-2622" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2623"><a href="#cb267-2623" aria-hidden="true" tabindex="-1"></a><span class="co"># access the best feature subset and the corresponding measured performance</span></span>
<span id="cb267-2624"><a href="#cb267-2624" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(instance<span class="sc">$</span>result)[, .(features, classif.acc)]</span>
<span id="cb267-2625"><a href="#cb267-2625" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2626"><a href="#cb267-2626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2627"><a href="#cb267-2627" aria-hidden="true" tabindex="-1"></a>Now the optimized feature subset can be used to subset the task and fit the model on all observations:</span>
<span id="cb267-2628"><a href="#cb267-2628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2629"><a href="#cb267-2629" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2630"><a href="#cb267-2630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2631"><a href="#cb267-2631" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2632"><a href="#cb267-2632" aria-hidden="true" tabindex="-1"></a>tsk_pen <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-2633"><a href="#cb267-2633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2634"><a href="#cb267-2634" aria-hidden="true" tabindex="-1"></a>tsk_pen<span class="sc">$</span><span class="fu">select</span>(instance<span class="sc">$</span>result_feature_set)</span>
<span id="cb267-2635"><a href="#cb267-2635" aria-hidden="true" tabindex="-1"></a>lrn_rpart<span class="sc">$</span><span class="fu">train</span>(tsk_pen)</span>
<span id="cb267-2636"><a href="#cb267-2636" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2637"><a href="#cb267-2637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2638"><a href="#cb267-2638" aria-hidden="true" tabindex="-1"></a><span class="fu">### Optimizing Multiple Performance Measures {#sec-multicrit-featsel}</span></span>
<span id="cb267-2639"><a href="#cb267-2639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2640"><a href="#cb267-2640" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2641"><a href="#cb267-2641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2642"><a href="#cb267-2642" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2643"><a href="#cb267-2643" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">fsi</span>(</span>
<span id="cb267-2644"><a href="#cb267-2644" aria-hidden="true" tabindex="-1"></a>  <span class="at">task =</span> <span class="fu">tsk</span>(<span class="st">"sonar"</span>),</span>
<span id="cb267-2645"><a href="#cb267-2645" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> lrn_rpart,</span>
<span id="cb267-2646"><a href="#cb267-2646" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"holdout"</span>),</span>
<span id="cb267-2647"><a href="#cb267-2647" aria-hidden="true" tabindex="-1"></a>  <span class="at">measures =</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"classif.tpr"</span>, <span class="st">"classif.tnr"</span>)),</span>
<span id="cb267-2648"><a href="#cb267-2648" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"evals"</span>, <span class="at">n_evals =</span> <span class="dv">20</span>)</span>
<span id="cb267-2649"><a href="#cb267-2649" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-2650"><a href="#cb267-2650" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2651"><a href="#cb267-2651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2652"><a href="#cb267-2652" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2653"><a href="#cb267-2653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2654"><a href="#cb267-2654" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2655"><a href="#cb267-2655" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-2656"><a href="#cb267-2656" aria-hidden="true" tabindex="-1"></a>fselector <span class="ot">=</span> <span class="fu">fs</span>(<span class="st">"random_search"</span>)</span>
<span id="cb267-2657"><a href="#cb267-2657" aria-hidden="true" tabindex="-1"></a>fselector<span class="sc">$</span><span class="fu">optimize</span>(instance)</span>
<span id="cb267-2658"><a href="#cb267-2658" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2659"><a href="#cb267-2659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2660"><a href="#cb267-2660" aria-hidden="true" tabindex="-1"></a>Note that these two measures cannot both be optimal at the same time (except for the perfect classifier) and we expect several Pareto-optimal solutions.</span>
<span id="cb267-2661"><a href="#cb267-2661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2662"><a href="#cb267-2662" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 请注意，这两个指标在同一时间不能都达到最优（除了完美的分类器），我们期望会有多个帕累托最优解。</span></span>
<span id="cb267-2663"><a href="#cb267-2663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2664"><a href="#cb267-2664" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2665"><a href="#cb267-2665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2666"><a href="#cb267-2666" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2667"><a href="#cb267-2667" aria-hidden="true" tabindex="-1"></a><span class="co"># access the best feature subsets</span></span>
<span id="cb267-2668"><a href="#cb267-2668" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(instance<span class="sc">$</span>result)[, .(features, classif.tpr, classif.tnr)]</span>
<span id="cb267-2669"><a href="#cb267-2669" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2670"><a href="#cb267-2670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2671"><a href="#cb267-2671" aria-hidden="true" tabindex="-1"></a>We see different tradeoffs of sensitivity and specificity but no feature subset is dominated by another, i.e. has worse sensitivity and specificity than any other subset.</span>
<span id="cb267-2672"><a href="#cb267-2672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2673"><a href="#cb267-2673" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们看到了不同灵敏度和特异性的权衡，但没有任何特征子集被另一个支配，即没有任何子集的灵敏度和特异性都比其他子集差。</span></span>
<span id="cb267-2674"><a href="#cb267-2674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2675"><a href="#cb267-2675" aria-hidden="true" tabindex="-1"></a><span class="fu">### Nested Resampling</span></span>
<span id="cb267-2676"><a href="#cb267-2676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2677"><a href="#cb267-2677" aria-hidden="true" tabindex="-1"></a>As in tuning, the performance estimate of the finally selected feature subset is usually optimistically biased. To obtain unbiased performance estimates, nested resampling is required and can be set up analogously to HPO (see @sec-nested-resampling). We now show this as an example on the <span class="in">`sonar`</span> task. The <span class="in">`AutoFSelector`</span> class wraps a learner and augments it with automatic feature selection. Because the <span class="in">`AutoFSelector`</span> itself inherits from the <span class="in">`Learner`</span> base class, it can be used like any other learner. In the example below, a logistic regression learner is created. This learner is then wrapped in a random search feature selector that uses holdout (inner) resampling for performance evaluation. The sugar function <span class="in">`auto_fselector`</span> can be used to create an instance of <span class="in">`AutoFSelector`</span>:</span>
<span id="cb267-2678"><a href="#cb267-2678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2679"><a href="#cb267-2679" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 与调优中一样，最终选择的特征子集的性能估计通常是乐观偏倚的。为了获得无偏的性能估计，需要进行嵌套重抽样，并且可以类似于HPO进行设置（请参见 @sec-nested-resampling）。下面的例子中，我们展示了在声纳任务上使用嵌套重抽样的示例。</span><span class="in">`AutoFSelector`</span><span class="at">类将学习器封装，并增加了自动特征选择功能。因为</span><span class="in">`AutoFSelector`</span><span class="at">本身继承自</span><span class="in">`Learner`</span><span class="at">基类，所以它可以像其他学习器一样使用。在下面的例子中，我们创建了一个逻辑回归学习器。然后，将该学习器包装在一个使用留出法（内部）重抽样进行性能评估的随机搜索特征选择器中。</span><span class="in">`auto_fselector`</span><span class="at">函数可以用来创建</span><span class="in">`AutoFSelector`</span><span class="at">的实例：</span></span>
<span id="cb267-2680"><a href="#cb267-2680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2681"><a href="#cb267-2681" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2682"><a href="#cb267-2682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2683"><a href="#cb267-2683" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2684"><a href="#cb267-2684" aria-hidden="true" tabindex="-1"></a>afs <span class="ot">=</span> <span class="fu">auto_fselector</span>(</span>
<span id="cb267-2685"><a href="#cb267-2685" aria-hidden="true" tabindex="-1"></a>  <span class="at">fselector =</span> <span class="fu">fs</span>(<span class="st">"random_search"</span>),</span>
<span id="cb267-2686"><a href="#cb267-2686" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> <span class="fu">lrn</span>(<span class="st">"classif.log_reg"</span>),</span>
<span id="cb267-2687"><a href="#cb267-2687" aria-hidden="true" tabindex="-1"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"holdout"</span>),</span>
<span id="cb267-2688"><a href="#cb267-2688" aria-hidden="true" tabindex="-1"></a>  <span class="at">measure =</span> <span class="fu">msr</span>(<span class="st">"classif.acc"</span>),</span>
<span id="cb267-2689"><a href="#cb267-2689" aria-hidden="true" tabindex="-1"></a>  <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"evals"</span>, <span class="at">n_evals =</span> <span class="dv">10</span>)</span>
<span id="cb267-2690"><a href="#cb267-2690" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-2691"><a href="#cb267-2691" aria-hidden="true" tabindex="-1"></a>afs</span>
<span id="cb267-2692"><a href="#cb267-2692" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2693"><a href="#cb267-2693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2694"><a href="#cb267-2694" aria-hidden="true" tabindex="-1"></a>The <span class="in">`AutoFSelector`</span> can then be passed to <span class="in">`benchmark()`</span> or <span class="in">`resample()`</span> for nested resampling (@sec-nested-resampling). Below we compare our wrapped learner <span class="in">`afs`</span> with a normal logistic regression <span class="in">`lrn("classif.log_reg")`</span>.</span>
<span id="cb267-2695"><a href="#cb267-2695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2696"><a href="#cb267-2696" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2697"><a href="#cb267-2697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2698"><a href="#cb267-2698" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2699"><a href="#cb267-2699" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-2700"><a href="#cb267-2700" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb267-2701"><a href="#cb267-2701" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">=</span> <span class="fu">benchmark_grid</span>(<span class="fu">tsk</span>(<span class="st">"sonar"</span>), <span class="fu">list</span>(afs, <span class="fu">lrn</span>(<span class="st">"classif.log_reg"</span>)),</span>
<span id="cb267-2702"><a href="#cb267-2702" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>))</span>
<span id="cb267-2703"><a href="#cb267-2703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2704"><a href="#cb267-2704" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(grid)<span class="sc">$</span><span class="fu">aggregate</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span>
<span id="cb267-2705"><a href="#cb267-2705" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2706"><a href="#cb267-2706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2707"><a href="#cb267-2707" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2708"><a href="#cb267-2708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2709"><a href="#cb267-2709" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2710"><a href="#cb267-2710" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(bmr)[, .(learner_id, classif.acc)]</span>
<span id="cb267-2711"><a href="#cb267-2711" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2712"><a href="#cb267-2712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2713"><a href="#cb267-2713" aria-hidden="true" tabindex="-1"></a>We can see that, in this example, the feature selection improves prediction performance.</span>
<span id="cb267-2714"><a href="#cb267-2714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2715"><a href="#cb267-2715" aria-hidden="true" tabindex="-1"></a><span class="fu"># Pipelines and Preprocessing {-}</span></span>
<span id="cb267-2716"><a href="#cb267-2716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2717"><a href="#cb267-2717" aria-hidden="true" tabindex="-1"></a><span class="fu"># Sequential Pipelines</span></span>
<span id="cb267-2718"><a href="#cb267-2718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2719"><a href="#cb267-2719" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3`</span> aims to provide a layer of abstraction for ML practitioners, allowing users to quickly swap one algorithm for another without needing expert knowledge of the underlying implementation. A unified interface for <span class="in">`Task`</span>, <span class="in">`Learner`</span>, and <span class="in">`Measure`</span> objects means that complex benchmark and tuning experiments can be run in just a few lines of code for any off-the-shelf model, i.e., if you just want to run an experiment using the basic implementation from the underlying algorithm, we hope we have made this easy for you to do.</span>
<span id="cb267-2720"><a href="#cb267-2720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2721"><a href="#cb267-2721" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3pipelines`</span> (Binder et al. 2021) takes this modularity one step further, extending it to workflows that may also include data preprocessing (@sec-preprocessing), building ensemble-models, or even more complicated meta-models. mlr3pipelines makes it possible to build individual steps within a <span class="in">`Learner`</span> out of building blocks, which inherit from the <span class="in">`PipeOp`</span> class. <span class="in">`PipeOps`</span> can be connected using directed edges to form a <span class="in">`Graph`</span> or ‘pipeline’, which represent the flow of data between operations. During model training, the <span class="in">`PipeOps`</span> in a <span class="in">`Graph`</span> transform a given Task and subsequent <span class="in">`PipeOps`</span> receive the transformed <span class="in">`Task`</span> as input. As well as transforming data, <span class="in">`PipeOps`</span> generate a state, which is used to inform the <span class="in">`PipeOps`</span> operation during prediction, similar to how learners learn and store model parameters/weights during training that go on to inform model prediction.</span>
<span id="cb267-2722"><a href="#cb267-2722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2723"><a href="#cb267-2723" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`mlr3`</span><span class="at">旨在为机器学习从业者提供一个抽象层，使用户能够快速替换一个算法为另一个算法，而无需了解底层实现的专业知识。统一的</span><span class="in">`Task`</span><span class="at">（任务）、</span><span class="in">`Learner`</span><span class="at">（学习器）和</span><span class="in">`Measure`</span><span class="at">（度量）对象接口意味着，可以使用极少的代码行数运行任何现成模型的复杂基准和调优实验，即，如果你只想使用底层算法的基本实现来运行一个实验，我们希望我们已经让这变得容易了。</span></span>
<span id="cb267-2724"><a href="#cb267-2724" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2725"><a href="#cb267-2725" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`mlr3pipelines`</span><span class="at">（Binder等人，2021年）将这种模块化推进了一步，将其扩展到可能还包括数据预处理（@sec-preprocessing）、构建集成模型，甚至更复杂的元模型的工作流中。</span><span class="in">`mlr3pipelines`</span><span class="at">使得可以用继承自</span><span class="in">`PipeOp`</span><span class="at">类的构建块构建</span><span class="in">`Learner`</span><span class="at">内部的各个步骤。</span><span class="in">`PipeOps`</span><span class="at">可以使用有向边连接，形成一个</span><span class="in">`Graph`</span><span class="at">（图）或“管道”，它表示操作之间的数据流。在模型训练期间，</span><span class="in">`Graph`</span><span class="at">中的</span><span class="in">`PipeOps`</span><span class="at">会转换给定的</span><span class="in">`Task`</span><span class="at">，随后的</span><span class="in">`PipeOps`</span><span class="at">以转换后的</span><span class="in">`Task`</span><span class="at">作为输入。除了转换数据外，</span><span class="in">`PipeOps`</span><span class="at">还生成一个状态，用于在预测期间通知</span><span class="in">`PipeOps`</span><span class="at">的操作，类似于学习器在训练期间学习和存储模型参数/权重，然后用于模型预测。</span></span>
<span id="cb267-2726"><a href="#cb267-2726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2727"><a href="#cb267-2727" aria-hidden="true" tabindex="-1"></a><span class="fu">## PipeOp: Pipeline Operators</span></span>
<span id="cb267-2728"><a href="#cb267-2728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2729"><a href="#cb267-2729" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2730"><a href="#cb267-2730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2731"><a href="#cb267-2731" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2732"><a href="#cb267-2732" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(<span class="fu">po</span>())[<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]</span>
<span id="cb267-2733"><a href="#cb267-2733" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2734"><a href="#cb267-2734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2735"><a href="#cb267-2735" aria-hidden="true" tabindex="-1"></a>Let us now take a look at a <span class="in">`PipeOp`</span> in practice using principal component analysis (PCA) as an example, which is implemented in <span class="in">`PipeOpPCA`</span>. Below we construct the <span class="in">`PipeOp`</span> using its ID <span class="in">`"pca"`</span> and inspect it.</span>
<span id="cb267-2736"><a href="#cb267-2736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2737"><a href="#cb267-2737" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2738"><a href="#cb267-2738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2739"><a href="#cb267-2739" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2740"><a href="#cb267-2740" aria-hidden="true" tabindex="-1"></a>po_pca <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"pca"</span>, <span class="at">center =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-2741"><a href="#cb267-2741" aria-hidden="true" tabindex="-1"></a>po_pca</span>
<span id="cb267-2742"><a href="#cb267-2742" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2743"><a href="#cb267-2743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2744"><a href="#cb267-2744" aria-hidden="true" tabindex="-1"></a>A <span class="in">`PipeOp`</span> can be trained using <span class="in">`$train()`</span>, which can have multiple inputs and outputs. Both inputs and outputs are passed as elements in a single <span class="in">`list`</span>. The <span class="in">`"pca"`</span> <span class="in">`PipeOp`</span> takes as input the original task and after training returns the task with features replaced by their principal components.</span>
<span id="cb267-2745"><a href="#cb267-2745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2746"><a href="#cb267-2746" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2747"><a href="#cb267-2747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2748"><a href="#cb267-2748" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2749"><a href="#cb267-2749" aria-hidden="true" tabindex="-1"></a>tsk_small <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins_simple"</span>)<span class="sc">$</span><span class="fu">select</span>(<span class="fu">c</span>(<span class="st">"bill_depth"</span>, <span class="st">"bill_length"</span>))</span>
<span id="cb267-2750"><a href="#cb267-2750" aria-hidden="true" tabindex="-1"></a>poin <span class="ot">=</span> <span class="fu">list</span>(tsk_small<span class="sc">$</span><span class="fu">clone</span>()<span class="sc">$</span><span class="fu">filter</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>))</span>
<span id="cb267-2751"><a href="#cb267-2751" aria-hidden="true" tabindex="-1"></a>poout <span class="ot">=</span> po_pca<span class="sc">$</span><span class="fu">train</span>(poin)  <span class="co"># poin: Task in a list</span></span>
<span id="cb267-2752"><a href="#cb267-2752" aria-hidden="true" tabindex="-1"></a>poout  <span class="co"># list with a single element 'output'</span></span>
<span id="cb267-2753"><a href="#cb267-2753" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2754"><a href="#cb267-2754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2755"><a href="#cb267-2755" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2756"><a href="#cb267-2756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2757"><a href="#cb267-2757" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2758"><a href="#cb267-2758" aria-hidden="true" tabindex="-1"></a>poout[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">head</span>()</span>
<span id="cb267-2759"><a href="#cb267-2759" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2760"><a href="#cb267-2760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2761"><a href="#cb267-2761" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2762"><a href="#cb267-2762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2763"><a href="#cb267-2763" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2764"><a href="#cb267-2764" aria-hidden="true" tabindex="-1"></a>po_pca<span class="sc">$</span>state</span>
<span id="cb267-2765"><a href="#cb267-2765" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2766"><a href="#cb267-2766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2767"><a href="#cb267-2767" aria-hidden="true" tabindex="-1"></a>Once trained, the <span class="in">`$predict()`</span> function can then access the saved state to operate on the test data, which again is passed as a <span class="in">`list`</span>:</span>
<span id="cb267-2768"><a href="#cb267-2768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2769"><a href="#cb267-2769" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2770"><a href="#cb267-2770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2771"><a href="#cb267-2771" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2772"><a href="#cb267-2772" aria-hidden="true" tabindex="-1"></a>tsk_onepenguin <span class="ot">=</span> tsk_small<span class="sc">$</span><span class="fu">clone</span>()<span class="sc">$</span><span class="fu">filter</span>(<span class="dv">42</span>)</span>
<span id="cb267-2773"><a href="#cb267-2773" aria-hidden="true" tabindex="-1"></a>poin <span class="ot">=</span> <span class="fu">list</span>(tsk_onepenguin)</span>
<span id="cb267-2774"><a href="#cb267-2774" aria-hidden="true" tabindex="-1"></a>poout <span class="ot">=</span> po_pca<span class="sc">$</span><span class="fu">predict</span>(poin)</span>
<span id="cb267-2775"><a href="#cb267-2775" aria-hidden="true" tabindex="-1"></a>poout[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">data</span>()</span>
<span id="cb267-2776"><a href="#cb267-2776" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2777"><a href="#cb267-2777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2778"><a href="#cb267-2778" aria-hidden="true" tabindex="-1"></a><span class="fu">## Graph: Networks of PopeOps</span></span>
<span id="cb267-2779"><a href="#cb267-2779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2780"><a href="#cb267-2780" aria-hidden="true" tabindex="-1"></a><span class="in">`PipeOps`</span> represent individual computational steps in machine learning pipelines. These pipelines themselves are defined by <span class="in">`Graph`</span> objects. A <span class="in">`Graph`</span> is a collection of <span class="in">`PipeOps`</span> with “edges” that guide the flow of data.</span>
<span id="cb267-2781"><a href="#cb267-2781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2782"><a href="#cb267-2782" aria-hidden="true" tabindex="-1"></a>The most convenient way of building a <span class="in">`Graph`</span> is to connect a sequence of <span class="in">`PipeOps`</span> using the <span class="in">`%&gt;&gt;%`</span>-operator (read “double-arrow”) operator. When given two <span class="in">`PipeOp`</span>s, this operator creates a <span class="in">`Graph`</span> that first executes the left-hand <span class="in">`PipeOp`</span>, followed by the right-hand one. It can also be used to connect a <span class="in">`Graph`</span> with a <span class="in">`PipeOp`</span>, or with another Graph. The following example uses <span class="in">`po("mutate")`</span> to add a new feature to the task, and <span class="in">`po("scale")`</span> to then scale and center all numeric features.</span>
<span id="cb267-2783"><a href="#cb267-2783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2784"><a href="#cb267-2784" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`PipeOps`</span><span class="at">代表机器学习管道中的单个计算步骤。这些管道本身由</span><span class="in">`Graph`</span><span class="at">对象定义。</span><span class="in">`Graph`</span><span class="at">是一个包含</span><span class="in">`PipeOps`</span><span class="at">的集合，其“边”指导着数据的流动。</span></span>
<span id="cb267-2785"><a href="#cb267-2785" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-2786"><a href="#cb267-2786" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 构建</span><span class="in">`Graph`</span><span class="at">的最方便的方法是使用</span><span class="in">`%&gt;&gt;%`</span><span class="at">（读作“双箭头”）操作符连接一系列</span><span class="in">`PipeOps`</span><span class="at">。当给定两个</span><span class="in">`PipeOp`</span><span class="at">时，此操作符创建一个</span><span class="in">`Graph`</span><span class="at">，首先执行左侧的</span><span class="in">`PipeOp`</span><span class="at">，然后执行右侧的。它也可以用于将</span><span class="in">`Graph`</span><span class="at">与</span><span class="in">`PipeOp`</span><span class="at">或另一个</span><span class="in">`Graph`</span><span class="at">连接。以下示例使用</span><span class="in">`po("mutate")`</span><span class="at">将一个新特征添加到任务，然后使用</span><span class="in">`po("scale")`</span><span class="at">对所有数值特征进行缩放和居中处理。</span></span>
<span id="cb267-2787"><a href="#cb267-2787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2788"><a href="#cb267-2788" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2789"><a href="#cb267-2789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2790"><a href="#cb267-2790" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2791"><a href="#cb267-2791" aria-hidden="true" tabindex="-1"></a>po_mutate <span class="ot">=</span> <span class="fu">po</span>(</span>
<span id="cb267-2792"><a href="#cb267-2792" aria-hidden="true" tabindex="-1"></a>  <span class="st">"mutate"</span>,</span>
<span id="cb267-2793"><a href="#cb267-2793" aria-hidden="true" tabindex="-1"></a>  <span class="at">mutation =</span> <span class="fu">list</span>(<span class="at">bill_ratio =</span> <span class="sc">~</span> bill_length <span class="sc">/</span> bill_depth)</span>
<span id="cb267-2794"><a href="#cb267-2794" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-2795"><a href="#cb267-2795" aria-hidden="true" tabindex="-1"></a>po_scale <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"scale"</span>)</span>
<span id="cb267-2796"><a href="#cb267-2796" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> po_mutate <span class="sc">%&gt;&gt;%</span> po_scale</span>
<span id="cb267-2797"><a href="#cb267-2797" aria-hidden="true" tabindex="-1"></a>graph</span>
<span id="cb267-2798"><a href="#cb267-2798" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2799"><a href="#cb267-2799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2800"><a href="#cb267-2800" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2801"><a href="#cb267-2801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2802"><a href="#cb267-2802" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2803"><a href="#cb267-2803" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span><span class="fu">plot</span>(<span class="at">horizontal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-2804"><a href="#cb267-2804" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2805"><a href="#cb267-2805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2806"><a href="#cb267-2806" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2807"><a href="#cb267-2807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2808"><a href="#cb267-2808" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2809"><a href="#cb267-2809" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span>pipeops</span>
<span id="cb267-2810"><a href="#cb267-2810" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2811"><a href="#cb267-2811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2812"><a href="#cb267-2812" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2813"><a href="#cb267-2813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2814"><a href="#cb267-2814" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2815"><a href="#cb267-2815" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span>edges</span>
<span id="cb267-2816"><a href="#cb267-2816" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2817"><a href="#cb267-2817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2818"><a href="#cb267-2818" aria-hidden="true" tabindex="-1"></a>Instead of using <span class="in">`%&gt;&gt;%`</span>, you can also create a <span class="in">`Graph`</span> explicitly using the <span class="in">`$add_pipeop()`</span> and <span class="in">`$add_edge()`</span> methods to create <span class="in">`PipeOps`</span> and the edges connecting them:</span>
<span id="cb267-2819"><a href="#cb267-2819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2820"><a href="#cb267-2820" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2821"><a href="#cb267-2821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2822"><a href="#cb267-2822" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2823"><a href="#cb267-2823" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> Graph<span class="sc">$</span><span class="fu">new</span>()<span class="sc">$</span></span>
<span id="cb267-2824"><a href="#cb267-2824" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_pipeop</span>(po_mutate)<span class="sc">$</span></span>
<span id="cb267-2825"><a href="#cb267-2825" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_pipeop</span>(po_scale)<span class="sc">$</span></span>
<span id="cb267-2826"><a href="#cb267-2826" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_edge</span>(<span class="st">"mutate"</span>, <span class="st">"scale"</span>)</span>
<span id="cb267-2827"><a href="#cb267-2827" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2828"><a href="#cb267-2828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2829"><a href="#cb267-2829" aria-hidden="true" tabindex="-1"></a>Once built, a <span class="in">`Graph`</span> can be used by calling <span class="in">`$train()`</span> and <span class="in">`$predict()`</span> as if it were a <span class="in">`Learner`</span> (though it still outputs a <span class="in">`list`</span> during training and prediction):</span>
<span id="cb267-2830"><a href="#cb267-2830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2831"><a href="#cb267-2831" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2832"><a href="#cb267-2832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2833"><a href="#cb267-2833" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2834"><a href="#cb267-2834" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> graph<span class="sc">$</span><span class="fu">train</span>(tsk_small)</span>
<span id="cb267-2835"><a href="#cb267-2835" aria-hidden="true" tabindex="-1"></a>result</span>
<span id="cb267-2836"><a href="#cb267-2836" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2837"><a href="#cb267-2837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2838"><a href="#cb267-2838" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2839"><a href="#cb267-2839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2840"><a href="#cb267-2840" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2841"><a href="#cb267-2841" aria-hidden="true" tabindex="-1"></a>result[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">data</span>()[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb267-2842"><a href="#cb267-2842" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2843"><a href="#cb267-2843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2844"><a href="#cb267-2844" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2845"><a href="#cb267-2845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2846"><a href="#cb267-2846" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2847"><a href="#cb267-2847" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> graph<span class="sc">$</span><span class="fu">predict</span>(tsk_onepenguin)</span>
<span id="cb267-2848"><a href="#cb267-2848" aria-hidden="true" tabindex="-1"></a>result[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">head</span>()</span>
<span id="cb267-2849"><a href="#cb267-2849" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2850"><a href="#cb267-2850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2851"><a href="#cb267-2851" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sequential Learner-Pipelines</span></span>
<span id="cb267-2852"><a href="#cb267-2852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2853"><a href="#cb267-2853" aria-hidden="true" tabindex="-1"></a>Possibly the most common application for <span class="in">`mlr3pipelines`</span> is to use it to perform preprocessing tasks, such as missing value imputation or factor encoding, and to then feed the resulting data into a <span class="in">`Learner`</span> – we will see more of this in practice in @sec-preprocessing. A <span class="in">`Graph`</span> representing this workflow manipulates data and fits a <span class="in">`Learner`</span>-model during training, ensuring that the data is processed the same way during the prediction stage. Conceptually, the process may look as shown in Figure 7.3.</span>
<span id="cb267-2854"><a href="#cb267-2854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2855"><a href="#cb267-2855" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`mlr3pipelines`</span><span class="at">可能最常见的应用之一是用它来执行预处理任务，比如缺失值填充或因子编码，然后将处理后的数据输入到一个学习器中 - 我们将在 @sec-preprocessing 的实践中更多地了解到这方面的内容。代表这种工作流程的图形在训练期间操作数据并拟合学习器模型，确保数据在预测阶段以相同的方式被处理。</span></span>
<span id="cb267-2856"><a href="#cb267-2856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2857"><a href="#cb267-2857" aria-hidden="true" tabindex="-1"></a><span class="fu">### Learners as PipeOps and Graphs as Learners</span></span>
<span id="cb267-2858"><a href="#cb267-2858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2859"><a href="#cb267-2859" aria-hidden="true" tabindex="-1"></a><span class="in">`Learner`</span> objects can be converted to <span class="in">`PipeOps`</span> with <span class="in">`as_pipeop()`</span>, however, this is only necessary if you choose to manually create a graph instead of using <span class="in">`%&gt;&gt;%`</span>. With either method, internally Learners are passed to <span class="in">`po("learner")`</span>. The following code creates a <span class="in">`Graph`</span> that uses <span class="in">`po("imputesample")`</span> to impute missing values by sampling from observed values (@sec-preprocessing-missing) then fits a logistic regression on the transformed task.</span>
<span id="cb267-2860"><a href="#cb267-2860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2861"><a href="#cb267-2861" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2862"><a href="#cb267-2862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2863"><a href="#cb267-2863" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2864"><a href="#cb267-2864" aria-hidden="true" tabindex="-1"></a>lrn_logreg <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.log_reg"</span>)</span>
<span id="cb267-2865"><a href="#cb267-2865" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"imputesample"</span>) <span class="sc">%&gt;&gt;%</span> lrn_logreg</span>
<span id="cb267-2866"><a href="#cb267-2866" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span><span class="fu">plot</span>(<span class="at">horizontal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-2867"><a href="#cb267-2867" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2868"><a href="#cb267-2868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2869"><a href="#cb267-2869" aria-hidden="true" tabindex="-1"></a>We have seen how training and predicting <span class="in">`Graphs`</span> is possible but has a slightly different design to <span class="in">`Learner`</span> objects, i.e., inputs and outputs during both training and predicting are <span class="in">`list`</span> objects. To use a <span class="in">`Graph`</span> as a <span class="in">`Learner`</span> with an identical interface, it can be wrapped in a <span class="in">`GraphLearner`</span> object with <span class="in">`as_learner()`</span>. The <span class="in">`Graph`</span> can then be used like any other <span class="in">`Learner`</span>, so now we can benchmark our pipeline to decide if we should impute by sampling or with the mode of observed values (<span class="in">`po("imputemode")`</span>):</span>
<span id="cb267-2870"><a href="#cb267-2870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2871"><a href="#cb267-2871" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们已经看到，训练和预测</span><span class="in">`图（Graphs）`</span><span class="at">是可能的，但与</span><span class="in">`学习器（Learner）`</span><span class="at">对象相比，设计略有不同，即在训练和预测过程中，输入和输出都是</span><span class="in">`列表（list）`</span><span class="at">对象。要将</span><span class="in">`图（Graph）`</span><span class="at">作为具有相同接口的</span><span class="in">`学习器（Learner）`</span><span class="at">使用，可以使用</span><span class="in">`as_learner()`</span><span class="at">将其封装为</span><span class="in">`图学习器（GraphLearner）`</span><span class="at">对象。然后，该</span><span class="in">`图（Graph）`</span><span class="at">就可以像任何其他</span><span class="in">`学习器（Learner）`</span><span class="at">一样使用，因此现在我们可以对我们的管道进行基准测试，以决定是使用从观察到的值中抽样填补还是使用观察到的值的模式进行填补（</span><span class="in">`po("imputemode")`</span><span class="at">）：</span></span>
<span id="cb267-2872"><a href="#cb267-2872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2873"><a href="#cb267-2873" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2874"><a href="#cb267-2874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2875"><a href="#cb267-2875" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2876"><a href="#cb267-2876" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-2877"><a href="#cb267-2877" aria-hidden="true" tabindex="-1"></a>glrn_sample <span class="ot">=</span> <span class="fu">as_learner</span>(graph)</span>
<span id="cb267-2878"><a href="#cb267-2878" aria-hidden="true" tabindex="-1"></a>glrn_mode <span class="ot">=</span> <span class="fu">as_learner</span>(<span class="fu">po</span>(<span class="st">"imputemode"</span>) <span class="sc">%&gt;&gt;%</span> lrn_logreg)</span>
<span id="cb267-2879"><a href="#cb267-2879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2880"><a href="#cb267-2880" aria-hidden="true" tabindex="-1"></a>design <span class="ot">=</span> <span class="fu">benchmark_grid</span>(<span class="fu">tsk</span>(<span class="st">"pima"</span>), <span class="fu">list</span>(glrn_sample, glrn_mode),</span>
<span id="cb267-2881"><a href="#cb267-2881" aria-hidden="true" tabindex="-1"></a>                        <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>))</span>
<span id="cb267-2882"><a href="#cb267-2882" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(design)</span>
<span id="cb267-2883"><a href="#cb267-2883" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2884"><a href="#cb267-2884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2885"><a href="#cb267-2885" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2886"><a href="#cb267-2886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2887"><a href="#cb267-2887" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2888"><a href="#cb267-2888" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>()[, .(learner_id, classif.ce)]</span>
<span id="cb267-2889"><a href="#cb267-2889" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2890"><a href="#cb267-2890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2891"><a href="#cb267-2891" aria-hidden="true" tabindex="-1"></a><span class="fu">### Inspecting Graphs</span></span>
<span id="cb267-2892"><a href="#cb267-2892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2893"><a href="#cb267-2893" aria-hidden="true" tabindex="-1"></a>You may want to inspect pipelines and the flow of data to learn more about your pipeline or to debug them. We first need to set the <span class="in">`$keep_results`</span> flag to be <span class="in">`TRUE`</span> so that intermediate results are retained, which is turned off by default to save memory.</span>
<span id="cb267-2894"><a href="#cb267-2894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2895"><a href="#cb267-2895" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2896"><a href="#cb267-2896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2897"><a href="#cb267-2897" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2898"><a href="#cb267-2898" aria-hidden="true" tabindex="-1"></a>glrn_sample<span class="sc">$</span>graph_model<span class="sc">$</span>keep_results <span class="ot">=</span> <span class="cn">TRUE</span></span>
<span id="cb267-2899"><a href="#cb267-2899" aria-hidden="true" tabindex="-1"></a>glrn_sample<span class="sc">$</span><span class="fu">train</span>(<span class="fu">tsk</span>(<span class="st">"pima"</span>))</span>
<span id="cb267-2900"><a href="#cb267-2900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2901"><a href="#cb267-2901" aria-hidden="true" tabindex="-1"></a>imputesample_output <span class="ot">=</span> glrn_sample<span class="sc">$</span>graph_model<span class="sc">$</span>pipeops<span class="sc">$</span>imputesample<span class="sc">$</span>.result</span>
<span id="cb267-2902"><a href="#cb267-2902" aria-hidden="true" tabindex="-1"></a>imputesample_output[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">missings</span>()</span>
<span id="cb267-2903"><a href="#cb267-2903" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2904"><a href="#cb267-2904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2905"><a href="#cb267-2905" aria-hidden="true" tabindex="-1"></a><span class="fu">### Configuring Pipeline Hyperparameters</span></span>
<span id="cb267-2906"><a href="#cb267-2906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2907"><a href="#cb267-2907" aria-hidden="true" tabindex="-1"></a><span class="in">`PipeOp`</span> hyperparameters are collected together in the <span class="in">`$param_set`</span> of a graph and prefixed with the ID of the <span class="in">`PipeOp`</span> to avoid parameter name clashes. Below we use the same <span class="in">`PipeOp`</span> twice but set the <span class="in">`id`</span> to ensure their IDs are unique.</span>
<span id="cb267-2908"><a href="#cb267-2908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2909"><a href="#cb267-2909" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 管道操作（PipeOp）的超参数被集中存储在图的</span><span class="in">`$param_set`</span><span class="at">中，并且在名称前加上管道操作的ID，以避免参数名称冲突。在下面的例子中，我们使用相同的管道操作两次，但设置了ID以确保它们的ID是唯一的。</span></span>
<span id="cb267-2910"><a href="#cb267-2910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2911"><a href="#cb267-2911" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2912"><a href="#cb267-2912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2913"><a href="#cb267-2913" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2914"><a href="#cb267-2914" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"scale"</span>, <span class="at">center =</span> <span class="cn">FALSE</span>, <span class="at">scale =</span> <span class="cn">TRUE</span>, <span class="at">id =</span> <span class="st">"scale"</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-2915"><a href="#cb267-2915" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"scale"</span>, <span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale =</span> <span class="cn">FALSE</span>, <span class="at">id =</span> <span class="st">"center"</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-2916"><a href="#cb267-2916" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>, <span class="at">cp =</span> <span class="dv">1</span>)</span>
<span id="cb267-2917"><a href="#cb267-2917" aria-hidden="true" tabindex="-1"></a><span class="fu">unlist</span>(graph<span class="sc">$</span>param_set<span class="sc">$</span>values)</span>
<span id="cb267-2918"><a href="#cb267-2918" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2919"><a href="#cb267-2919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2920"><a href="#cb267-2920" aria-hidden="true" tabindex="-1"></a>Whether a pipeline is treated as a <span class="in">`Graph`</span> or <span class="in">`GraphLearner`</span>, hyperparameters are updated and accessed in the same way.</span>
<span id="cb267-2921"><a href="#cb267-2921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2922"><a href="#cb267-2922" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2923"><a href="#cb267-2923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2924"><a href="#cb267-2924" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2925"><a href="#cb267-2925" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span>param_set<span class="sc">$</span>values<span class="sc">$</span>classif.rpart.maxdepth <span class="ot">=</span> <span class="dv">5</span></span>
<span id="cb267-2926"><a href="#cb267-2926" aria-hidden="true" tabindex="-1"></a>graph_learner <span class="ot">=</span> <span class="fu">as_learner</span>(graph)</span>
<span id="cb267-2927"><a href="#cb267-2927" aria-hidden="true" tabindex="-1"></a>graph_learner<span class="sc">$</span>param_set<span class="sc">$</span>values<span class="sc">$</span>classif.rpart.minsplit <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb267-2928"><a href="#cb267-2928" aria-hidden="true" tabindex="-1"></a><span class="fu">unlist</span>(graph_learner<span class="sc">$</span>param_set<span class="sc">$</span>values)</span>
<span id="cb267-2929"><a href="#cb267-2929" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2930"><a href="#cb267-2930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2931"><a href="#cb267-2931" aria-hidden="true" tabindex="-1"></a><span class="fu"># Non-sequential Pipelines and Tuning</span></span>
<span id="cb267-2932"><a href="#cb267-2932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2933"><a href="#cb267-2933" aria-hidden="true" tabindex="-1"></a>By using the <span class="in">`gunion()`</span> function, we can instead combine multiple <span class="in">`PipeOps`</span>, <span class="in">`Graphs`</span>, or a mixture of both, into a parallel <span class="in">`Graph`</span>.</span>
<span id="cb267-2934"><a href="#cb267-2934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2935"><a href="#cb267-2935" aria-hidden="true" tabindex="-1"></a>In the following example, we create a <span class="in">`Graph`</span> that centers its inputs (<span class="in">`po("scale")`</span>) and then copies the centered data to two parallel streams: one replaces the data with columns that indicate whether data is missing (<span class="in">`po("missind")`</span>), and the other imputes missing data using the median (<span class="in">`po("imputemedian")`</span>), which we will return to in @sec-preprocessing-missing. The outputs of both streams are then combined into a single dataset using <span class="in">`po("featureunion")`</span>.</span>
<span id="cb267-2936"><a href="#cb267-2936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2937"><a href="#cb267-2937" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2938"><a href="#cb267-2938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2939"><a href="#cb267-2939" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2940"><a href="#cb267-2940" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"scale"</span>, <span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-2941"><a href="#cb267-2941" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gunion</span>(<span class="fu">list</span>(</span>
<span id="cb267-2942"><a href="#cb267-2942" aria-hidden="true" tabindex="-1"></a>    <span class="fu">po</span>(<span class="st">"missind"</span>),</span>
<span id="cb267-2943"><a href="#cb267-2943" aria-hidden="true" tabindex="-1"></a>    <span class="fu">po</span>(<span class="st">"imputemedian"</span>)</span>
<span id="cb267-2944"><a href="#cb267-2944" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-2945"><a href="#cb267-2945" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"featureunion"</span>)</span>
<span id="cb267-2946"><a href="#cb267-2946" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span></span>
<span id="cb267-2947"><a href="#cb267-2947" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span><span class="fu">plot</span>(<span class="at">horizontal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-2948"><a href="#cb267-2948" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2949"><a href="#cb267-2949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2950"><a href="#cb267-2950" aria-hidden="true" tabindex="-1"></a>When applied to the first three rows of the <span class="in">`"pima"`</span> task we can see how this imputes missing data and adds a column indicating where values were missing.</span>
<span id="cb267-2951"><a href="#cb267-2951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2952"><a href="#cb267-2952" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2953"><a href="#cb267-2953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2954"><a href="#cb267-2954" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2955"><a href="#cb267-2955" aria-hidden="true" tabindex="-1"></a>tsk_pima_head <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"pima"</span>)<span class="sc">$</span><span class="fu">filter</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span>
<span id="cb267-2956"><a href="#cb267-2956" aria-hidden="true" tabindex="-1"></a>tsk_pima_head<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> <span class="fu">c</span>(<span class="st">"diabetes"</span>, <span class="st">"insulin"</span>, <span class="st">"triceps"</span>))</span>
<span id="cb267-2957"><a href="#cb267-2957" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> graph<span class="sc">$</span><span class="fu">train</span>(tsk_pima_head)[[<span class="dv">1</span>]]</span>
<span id="cb267-2958"><a href="#cb267-2958" aria-hidden="true" tabindex="-1"></a>result<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> <span class="fu">c</span>(<span class="st">"diabetes"</span>, <span class="st">"insulin"</span>, <span class="st">"missing_insulin"</span>, <span class="st">"triceps"</span>, <span class="st">"missing_triceps"</span>))</span>
<span id="cb267-2959"><a href="#cb267-2959" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2960"><a href="#cb267-2960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2961"><a href="#cb267-2961" aria-hidden="true" tabindex="-1"></a><span class="fu">## Selectors and Parallel Pipelines</span></span>
<span id="cb267-2962"><a href="#cb267-2962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2963"><a href="#cb267-2963" aria-hidden="true" tabindex="-1"></a>It is common in <span class="in">`Graphs`</span> for an operation to be applied to a subset of features. In <span class="in">`mlr3pipelines`</span> this can be achieved in two ways: either by passing the column subset to the <span class="in">`affect_columns`</span> hyperparameter of a <span class="in">`PipeOp`</span> (assuming it has that hyperparameter), which controls which columns should be affected by the <span class="in">`PipeOp`</span>; or, one can use the <span class="in">`PipeOpSelect`</span> operator to create operations in parallel on specified feature subsets, and then unite the result using <span class="in">`PipeOpFeatureUnion`</span>.</span>
<span id="cb267-2964"><a href="#cb267-2964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2965"><a href="#cb267-2965" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在</span><span class="in">`图（Graphs）`</span><span class="at">中，常常会对特征的子集应用操作。在</span><span class="in">`mlr3pipelines`</span><span class="at">中，可以通过两种方式实现这一点：一种方式是将列子集传递给</span><span class="in">`PipeOp`</span><span class="at">的</span><span class="in">`affect_columns`</span><span class="at">超参数（假设该超参数存在），它控制哪些列应该受到</span><span class="in">`PipeOp`</span><span class="at">的影响；另一种方式是使用</span><span class="in">`PipeOpSelect`</span><span class="at">运算符，针对指定的特征子集并行创建操作，然后使用</span><span class="in">`PipeOpFeatureUnion`</span><span class="at">将结果合并。</span></span>
<span id="cb267-2966"><a href="#cb267-2966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2967"><a href="#cb267-2967" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2968"><a href="#cb267-2968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2969"><a href="#cb267-2969" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2970"><a href="#cb267-2970" aria-hidden="true" tabindex="-1"></a>sel_bill <span class="ot">=</span> <span class="fu">selector_grep</span>(<span class="st">"^bill"</span>)</span>
<span id="cb267-2971"><a href="#cb267-2971" aria-hidden="true" tabindex="-1"></a>sel_not_bill <span class="ot">=</span> <span class="fu">selector_invert</span>(sel_bill)</span>
<span id="cb267-2972"><a href="#cb267-2972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2973"><a href="#cb267-2973" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"scale"</span>, <span class="at">affect_columns =</span> sel_not_bill) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-2974"><a href="#cb267-2974" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"pca"</span>, <span class="at">affect_columns =</span> sel_bill)</span>
<span id="cb267-2975"><a href="#cb267-2975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2976"><a href="#cb267-2976" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> graph<span class="sc">$</span><span class="fu">train</span>(<span class="fu">tsk</span>(<span class="st">"penguins_simple"</span>))</span>
<span id="cb267-2977"><a href="#cb267-2977" aria-hidden="true" tabindex="-1"></a>result[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">data</span>()[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb267-2978"><a href="#cb267-2978" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2979"><a href="#cb267-2979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2980"><a href="#cb267-2980" aria-hidden="true" tabindex="-1"></a>The biggest advantage of this method is that it creates a very simple, sequential <span class="in">`Graph`</span>. However, one disadvantage of the <span class="in">`affect_columns`</span> method is that it is relatively easy to have unexpected results if the ordering of <span class="in">`PipeOps`</span> is mixed up. For example, if we had reversed the order of <span class="in">`po("pca")`</span> and <span class="in">`po("scale")`</span> above then we would have first created columns <span class="in">`"PC1"`</span> and <span class="in">`"PC2"`</span> and then erroneously scaled these, since their names do not start with “bill” and they are therefore matched by <span class="in">`sel_not_bill`</span>. Creating parallel paths with <span class="in">`po("select")`</span> can help mitigate such errors by selecting features given by the Selector and creating independent data processing streams with the given feature subset. Below we pass the parallel pipelines to <span class="in">`gunion()`</span> as a list to ensure they receive the same input, and then combine the outputs with <span class="in">`po("featureunion")`</span>.</span>
<span id="cb267-2981"><a href="#cb267-2981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2982"><a href="#cb267-2982" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 这种方法的最大优势在于它创建了一个非常简单、顺序的图形结构。然而，</span><span class="in">`affect_columns`</span><span class="at"> 方法的一个缺点是，如果 PipeOps 的顺序混乱，很容易产生意外的结果。例如，如果我们在上述例子中颠倒了 </span><span class="in">`po("pca")`</span><span class="at"> 和 </span><span class="in">`po("scale")`</span><span class="at"> 的顺序，那么我们首先会创建 </span><span class="in">`"PC1"`</span><span class="at"> 和 </span><span class="in">`"PC2"`</span><span class="at"> 这两列，然后错误地对它们进行了缩放，因为它们的列名不以 "bill" 开头，所以被 </span><span class="in">`sel_not_bill`</span><span class="at"> 匹配到了。使用 </span><span class="in">`po("select")`</span><span class="at"> 创建并行路径可以帮助减轻此类错误，它根据选择器给定的特征选择功能，并使用给定的特征子集创建独立的数据处理流。在下面的例子中，我们将并行流程以列表形式传递给 </span><span class="in">`gunion()`</span><span class="at"> 以确保它们接收相同的输入，然后使用 </span><span class="in">`po("featureunion")`</span><span class="at"> 组合它们的输出结果。</span></span>
<span id="cb267-2983"><a href="#cb267-2983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2984"><a href="#cb267-2984" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-2985"><a href="#cb267-2985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2986"><a href="#cb267-2986" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-2987"><a href="#cb267-2987" aria-hidden="true" tabindex="-1"></a>po_select_bill <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"select"</span>, <span class="at">id =</span> <span class="st">"s_bill"</span>, <span class="at">selector =</span> sel_bill)</span>
<span id="cb267-2988"><a href="#cb267-2988" aria-hidden="true" tabindex="-1"></a>po_select_not_bill <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"select"</span>, <span class="at">id =</span> <span class="st">"s_notbill"</span>, <span class="at">selector =</span> sel_not_bill)</span>
<span id="cb267-2989"><a href="#cb267-2989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2990"><a href="#cb267-2990" aria-hidden="true" tabindex="-1"></a>path_pca <span class="ot">=</span> po_select_bill <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"pca"</span>)</span>
<span id="cb267-2991"><a href="#cb267-2991" aria-hidden="true" tabindex="-1"></a>path_scale <span class="ot">=</span> po_select_not_bill <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"scale"</span>)</span>
<span id="cb267-2992"><a href="#cb267-2992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2993"><a href="#cb267-2993" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> <span class="fu">gunion</span>(<span class="fu">list</span>(path_pca, path_scale)) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"featureunion"</span>)</span>
<span id="cb267-2994"><a href="#cb267-2994" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span><span class="fu">plot</span>(<span class="at">horizontal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-2995"><a href="#cb267-2995" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-2996"><a href="#cb267-2996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2997"><a href="#cb267-2997" aria-hidden="true" tabindex="-1"></a>The <span class="in">`po("select")`</span> method also has the significant advantage that it allows the same set of features to be used in multiple operations simultaneously, or to both transform features and keep their untransformed versions (by using <span class="in">`po("nop")`</span> in one path). <span class="in">`PipeOpNOP`</span> performs no operation on its inputs and is thus useful when you only want to perform a transformation on a subset of features and leave the others untouched:</span>
<span id="cb267-2998"><a href="#cb267-2998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-2999"><a href="#cb267-2999" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`po("select")`</span><span class="at"> 方法的另一个重要优势是，它允许同时在多个操作中使用相同的特征集，或者在进行特征转换的同时保留它们的未转换版本（通过在其中一个路径中使用 </span><span class="in">`po("nop")`</span><span class="at">）。</span><span class="in">`PipeOpNOP`</span><span class="at"> 在其输入上不执行任何操作，因此当你只想对某些特征子集进行转换而保持其他特征不变时，它非常有用：</span></span>
<span id="cb267-3000"><a href="#cb267-3000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3001"><a href="#cb267-3001" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3002"><a href="#cb267-3002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3003"><a href="#cb267-3003" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3004"><a href="#cb267-3004" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> <span class="fu">gunion</span>(<span class="fu">list</span>(</span>
<span id="cb267-3005"><a href="#cb267-3005" aria-hidden="true" tabindex="-1"></a>  po_select_bill <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"scale"</span>),</span>
<span id="cb267-3006"><a href="#cb267-3006" aria-hidden="true" tabindex="-1"></a>  po_select_not_bill <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"nop"</span>)</span>
<span id="cb267-3007"><a href="#cb267-3007" aria-hidden="true" tabindex="-1"></a>)) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"featureunion"</span>)</span>
<span id="cb267-3008"><a href="#cb267-3008" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span><span class="fu">plot</span>(<span class="at">horizontal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-3009"><a href="#cb267-3009" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3010"><a href="#cb267-3010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3011"><a href="#cb267-3011" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3012"><a href="#cb267-3012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3013"><a href="#cb267-3013" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3014"><a href="#cb267-3014" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span><span class="fu">train</span>(<span class="fu">tsk</span>(<span class="st">"penguins_simple"</span>))[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">data</span>()[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb267-3015"><a href="#cb267-3015" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3016"><a href="#cb267-3016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3017"><a href="#cb267-3017" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practical Pipelines by Example</span></span>
<span id="cb267-3018"><a href="#cb267-3018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3019"><a href="#cb267-3019" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bagging with “greplicate” and “subsample”</span></span>
<span id="cb267-3020"><a href="#cb267-3020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3021"><a href="#cb267-3021" aria-hidden="true" tabindex="-1"></a>The basic idea of bagging (from **b**ootstrapp **agg**regat**ing**), introduced by Breiman (1996), is to aggregate multiple predictors into a single, more powerful predictor. Predictions are usually aggregated by the arithmetic mean for regression tasks or majority vote for classification. The underlying intuition behind bagging is that averaging a set of unstable and diverse (i.e., only weakly correlated) predictors can reduce the variance of the overall prediction. Each learner is trained on a different random sample of the original data.</span>
<span id="cb267-3022"><a href="#cb267-3022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3023"><a href="#cb267-3023" aria-hidden="true" tabindex="-1"></a>Although we have already seen that a pre-constructed bagging pipeline is available with <span class="in">`ppl("bagging")`</span>, in this section we will build our own pipeline from scratch to showcase how to construct a complex Graph, which will look something like @fig-pipelines-bagging.</span>
<span id="cb267-3024"><a href="#cb267-3024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3025"><a href="#cb267-3025" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 装袋（bagging）的基本思想（来自**b**ootstrapp **agg**regat**ing**，由Breiman（1996）引入）是将多个预测器聚合成一个更强大的预测器。在回归任务中，通常通过算术平均值来聚合预测结果，而在分类任务中则采用多数投票法。装袋背后的基本直觉是，将一组不稳定且多样化的（即仅弱相关的）预测器进行平均，可以减小整体预测的方差。每个学习器都是在原始数据的不同随机样本上训练得到的。</span></span>
<span id="cb267-3026"><a href="#cb267-3026" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3027"><a href="#cb267-3027" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 尽管我们已经看到在</span><span class="in">`ppl("bagging")`</span><span class="at">中提供了一个预先构建的装袋管道，但在本节中，我们将从零开始构建我们自己的管道，以展示如何构建一个复杂的图形，类似于 @fig-pipelines-bagging 所示。</span></span>
<span id="cb267-3028"><a href="#cb267-3028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3029"><a href="#cb267-3029" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3030"><a href="#cb267-3030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3031"><a href="#cb267-3031" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3032"><a href="#cb267-3032" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb267-3033"><a href="#cb267-3033" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-pipelines-bagging</span></span>
<span id="cb267-3034"><a href="#cb267-3034" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Graph that performs Bagging by independently subsampling data and fitting individual decision tree learners. The resulting predictions are aggregated by a majority vote `PipeOp`."</span></span>
<span id="cb267-3035"><a href="#cb267-3035" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: 'Graph shows "Dtrain" with arrows to four separate po("subsample") boxes that each have a separate arrow to four more po("classif.rpart") boxes that each have an arrow to the same one po("classif.avg") box.'</span></span>
<span id="cb267-3036"><a href="#cb267-3036" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"imgs/mlr3book_figures-26.svg"</span>)</span>
<span id="cb267-3037"><a href="#cb267-3037" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3038"><a href="#cb267-3038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3039"><a href="#cb267-3039" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3040"><a href="#cb267-3040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3041"><a href="#cb267-3041" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3042"><a href="#cb267-3042" aria-hidden="true" tabindex="-1"></a>gr_single_pred <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"subsample"</span>, <span class="at">frac =</span> .<span class="dv">7</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>)</span>
<span id="cb267-3043"><a href="#cb267-3043" aria-hidden="true" tabindex="-1"></a>gr_pred_set <span class="ot">=</span> <span class="fu">ppl</span>(<span class="st">"greplicate"</span>, <span class="at">graph =</span> gr_single_pred, <span class="at">n =</span> <span class="dv">10</span>)</span>
<span id="cb267-3044"><a href="#cb267-3044" aria-hidden="true" tabindex="-1"></a>gr_bagging <span class="ot">=</span> gr_pred_set <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"classifavg"</span>, <span class="at">innum =</span> <span class="dv">10</span>)</span>
<span id="cb267-3045"><a href="#cb267-3045" aria-hidden="true" tabindex="-1"></a>gr_bagging<span class="sc">$</span><span class="fu">plot</span>()</span>
<span id="cb267-3046"><a href="#cb267-3046" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3047"><a href="#cb267-3047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3048"><a href="#cb267-3048" aria-hidden="true" tabindex="-1"></a>Now let us see how well our bagging pipeline compares to the single decision tree and a random forest when benchmarked against <span class="in">`tsk("sonar")`</span>.</span>
<span id="cb267-3049"><a href="#cb267-3049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3050"><a href="#cb267-3050" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3051"><a href="#cb267-3051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3052"><a href="#cb267-3052" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3053"><a href="#cb267-3053" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3054"><a href="#cb267-3054" aria-hidden="true" tabindex="-1"></a>glrn_bagging <span class="ot">=</span> <span class="fu">as_learner</span>(gr_bagging)</span>
<span id="cb267-3055"><a href="#cb267-3055" aria-hidden="true" tabindex="-1"></a>glrn_bagging<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"bagging"</span></span>
<span id="cb267-3056"><a href="#cb267-3056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3057"><a href="#cb267-3057" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">c</span>(glrn_bagging, <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>), <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>))</span>
<span id="cb267-3058"><a href="#cb267-3058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3059"><a href="#cb267-3059" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(<span class="fu">tsk</span>(<span class="st">"sonar"</span>), learners,</span>
<span id="cb267-3060"><a href="#cb267-3060" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>)))</span>
<span id="cb267-3061"><a href="#cb267-3061" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3062"><a href="#cb267-3062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3063"><a href="#cb267-3063" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3064"><a href="#cb267-3064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3065"><a href="#cb267-3065" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3066"><a href="#cb267-3066" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>()[, .(learner_id, classif.ce)]</span>
<span id="cb267-3067"><a href="#cb267-3067" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3068"><a href="#cb267-3068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3069"><a href="#cb267-3069" aria-hidden="true" tabindex="-1"></a>To automatically recreate this pipeline, you can construct <span class="in">`ppl("bagging")`</span> by specifying the learner to ‘bag’, the number of iterations, the fraction of data to sample, and the <span class="in">`PipeOp`</span> to average the predictions, as shown in the code below. Note we set <span class="in">`collect_multiplicity = TRUE`</span> which collects the predictions across paths, that technically use the <span class="in">`Multiplicity`</span> method, which we will not discuss here but refer the reader to the documentation.</span>
<span id="cb267-3070"><a href="#cb267-3070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3071"><a href="#cb267-3071" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 要自动重新创建这个管道，您可以通过在代码中指定学习器为‘bag’、迭代次数、采样的数据比例以及用于平均预测的</span><span class="in">`PipeOp`</span><span class="at">来构建</span><span class="in">`ppl("bagging")`</span><span class="at">，如下所示。请注意，我们设置了</span><span class="in">`collect_multiplicity = TRUE`</span><span class="at">，这样可以在路径间收集预测结果，这实际上使用了</span><span class="in">`Multiplicity`</span><span class="at">方法，但我们在这里不会讨论详细内容，读者可以参考文档了解更多信息。</span></span>
<span id="cb267-3072"><a href="#cb267-3072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3073"><a href="#cb267-3073" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3074"><a href="#cb267-3074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3075"><a href="#cb267-3075" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3076"><a href="#cb267-3076" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-3077"><a href="#cb267-3077" aria-hidden="true" tabindex="-1"></a><span class="fu">ppl</span>(<span class="st">"bagging"</span>, <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>), <span class="at">iterations =</span> <span class="dv">10</span>, <span class="at">frac =</span> <span class="fl">0.7</span>,</span>
<span id="cb267-3078"><a href="#cb267-3078" aria-hidden="true" tabindex="-1"></a>    <span class="at">averager =</span> <span class="fu">po</span>(<span class="st">"classifavg"</span>, <span class="at">collect_multiplicity =</span> <span class="cn">TRUE</span>))</span>
<span id="cb267-3079"><a href="#cb267-3079" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3080"><a href="#cb267-3080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3081"><a href="#cb267-3081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3082"><a href="#cb267-3082" aria-hidden="true" tabindex="-1"></a>The main difference between our pipeline and a random forest is that the latter also performs feature subsampling, where only a random subset of available features is considered at each split point. While we cannot implement this directly with <span class="in">`mlr3pipelines`</span>, we can use a custom <span class="in">`Selector`</span> method to approximate this method. We will create this <span class="in">`Selector`</span> by passing a function that takes as input the task and returns a sample of the features, we sample the square root of the number of features to mimic the implementation in <span class="in">`ranger`</span>. For efficiency, we will now use <span class="in">`ppl("bagging")`</span> to recreate the steps above:</span>
<span id="cb267-3083"><a href="#cb267-3083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3084"><a href="#cb267-3084" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们的管道与随机森林之间的主要区别在于，后者还执行特征子抽样，即在每个分裂点只考虑可用特征的一个随机子集。虽然我们无法直接在</span><span class="in">`mlr3pipelines`</span><span class="at">中实现这一点，但我们可以使用自定义的选择器方法来近似这个方法。我们将通过传递一个接受任务作为输入并返回特征样本的函数来创建这个选择器。我们将对特征进行采样，采样数量为特征数量的平方根，以模仿</span><span class="in">`ranger`</span><span class="at">中的实现。为了提高效率，我们现在将使用</span><span class="in">`ppl("bagging")`</span><span class="at">来重新创建上述步骤：</span></span>
<span id="cb267-3085"><a href="#cb267-3085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3086"><a href="#cb267-3086" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3087"><a href="#cb267-3087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3088"><a href="#cb267-3088" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3089"><a href="#cb267-3089" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3090"><a href="#cb267-3090" aria-hidden="true" tabindex="-1"></a><span class="co"># custom selector</span></span>
<span id="cb267-3091"><a href="#cb267-3091" aria-hidden="true" tabindex="-1"></a>selector_subsample <span class="ot">=</span> <span class="cf">function</span>(task) {</span>
<span id="cb267-3092"><a href="#cb267-3092" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample</span>(task<span class="sc">$</span>feature_names, <span class="fu">sqrt</span>(<span class="fu">length</span>(task<span class="sc">$</span>feature_names)))</span>
<span id="cb267-3093"><a href="#cb267-3093" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb267-3094"><a href="#cb267-3094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3095"><a href="#cb267-3095" aria-hidden="true" tabindex="-1"></a><span class="co"># bagging pipeline with out selector</span></span>
<span id="cb267-3096"><a href="#cb267-3096" aria-hidden="true" tabindex="-1"></a>gr_bagging_quasi_rf <span class="ot">=</span> <span class="fu">ppl</span>(</span>
<span id="cb267-3097"><a href="#cb267-3097" aria-hidden="true" tabindex="-1"></a>  <span class="st">"bagging"</span>,</span>
<span id="cb267-3098"><a href="#cb267-3098" aria-hidden="true" tabindex="-1"></a>  <span class="at">graph =</span> <span class="fu">po</span>(<span class="st">"select"</span>, <span class="at">selector =</span> selector_subsample) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3099"><a href="#cb267-3099" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>, <span class="at">minsplit =</span> <span class="dv">1</span>),</span>
<span id="cb267-3100"><a href="#cb267-3100" aria-hidden="true" tabindex="-1"></a>  <span class="at">iterations =</span> <span class="dv">100</span>,</span>
<span id="cb267-3101"><a href="#cb267-3101" aria-hidden="true" tabindex="-1"></a>  <span class="at">averager =</span> <span class="fu">po</span>(<span class="st">"classifavg"</span>, <span class="at">collect_multiplicity =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-3102"><a href="#cb267-3102" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-3103"><a href="#cb267-3103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3104"><a href="#cb267-3104" aria-hidden="true" tabindex="-1"></a><span class="co"># bootstrap resampling</span></span>
<span id="cb267-3105"><a href="#cb267-3105" aria-hidden="true" tabindex="-1"></a>gr_bagging_quasi_rf<span class="sc">$</span>param_set<span class="sc">$</span>values<span class="sc">$</span>subsample.replace <span class="ot">=</span> <span class="cn">TRUE</span></span>
<span id="cb267-3106"><a href="#cb267-3106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3107"><a href="#cb267-3107" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to learner</span></span>
<span id="cb267-3108"><a href="#cb267-3108" aria-hidden="true" tabindex="-1"></a>glrn_quasi_rf <span class="ot">=</span> <span class="fu">as_learner</span>(gr_bagging_quasi_rf)</span>
<span id="cb267-3109"><a href="#cb267-3109" aria-hidden="true" tabindex="-1"></a>glrn_quasi_rf<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"quasi.rf"</span></span>
<span id="cb267-3110"><a href="#cb267-3110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3111"><a href="#cb267-3111" aria-hidden="true" tabindex="-1"></a><span class="co"># benchmark</span></span>
<span id="cb267-3112"><a href="#cb267-3112" aria-hidden="true" tabindex="-1"></a>design <span class="ot">=</span> <span class="fu">benchmark_grid</span>(</span>
<span id="cb267-3113"><a href="#cb267-3113" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tsks</span>(<span class="st">"sonar"</span>),</span>
<span id="cb267-3114"><a href="#cb267-3114" aria-hidden="true" tabindex="-1"></a>  <span class="at">learners =</span> <span class="fu">list</span>(glrn_quasi_rf, <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>, <span class="at">num.trees =</span> <span class="dv">100</span>)),</span>
<span id="cb267-3115"><a href="#cb267-3115" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>)</span>
<span id="cb267-3116"><a href="#cb267-3116" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-3117"><a href="#cb267-3117" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(design)</span>
<span id="cb267-3118"><a href="#cb267-3118" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3119"><a href="#cb267-3119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3120"><a href="#cb267-3120" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3121"><a href="#cb267-3121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3122"><a href="#cb267-3122" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3123"><a href="#cb267-3123" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>()[, .(learner_id, classif.ce)]</span>
<span id="cb267-3124"><a href="#cb267-3124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3125"><a href="#cb267-3125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3126"><a href="#cb267-3126" aria-hidden="true" tabindex="-1"></a>In only a few lines of code, we took a weaker learner and turned it into a powerful model that we can see is comparable to the implementation in <span class="in">`ranger::ranger`</span>.</span>
<span id="cb267-3127"><a href="#cb267-3127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3128"><a href="#cb267-3128" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stacking with `po(“learner_cv”)`</span></span>
<span id="cb267-3129"><a href="#cb267-3129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3130"><a href="#cb267-3130" aria-hidden="true" tabindex="-1"></a>Stacking (Wolpert 1992) is another very popular ensembling technique that can significantly improve predictive performance.</span>
<span id="cb267-3131"><a href="#cb267-3131" aria-hidden="true" tabindex="-1"></a>The basic idea behind stacking is to use predictions from multiple models (usually referred to as level 0 models) as features for a subsequent model (the level 1 model) which in turn combines these predictions (@fig-pipelines-stacking).</span>
<span id="cb267-3132"><a href="#cb267-3132" aria-hidden="true" tabindex="-1"></a>A simple combination can be a linear model (possibly regularized if you have many level 0 models), since a weighted sum of level 0 models is often plausible and good enough.</span>
<span id="cb267-3133"><a href="#cb267-3133" aria-hidden="true" tabindex="-1"></a>Though, non-linear level 1 models can also be used, and it is also possible for the level 1 model to access the input features as well as the level 0 predictions.</span>
<span id="cb267-3134"><a href="#cb267-3134" aria-hidden="true" tabindex="-1"></a>Stacking can be built with more than two levels (both conceptually, and in <span class="in">`mlr3`</span>) but we limit ourselves to this simpler setup here, which often also performs well in practice.</span>
<span id="cb267-3135"><a href="#cb267-3135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3136"><a href="#cb267-3136" aria-hidden="true" tabindex="-1"></a>As with bagging, we will demonstrate how to create a stacking pipeline manually, although a pre-constructed pipeline is available with <span class="in">`ppl("stacking")`</span>.</span>
<span id="cb267-3137"><a href="#cb267-3137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3138"><a href="#cb267-3138" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 堆叠（Stacking）（Wolpert 1992）是另一种非常流行的集成技术，可以显著提高预测性能。堆叠背后的基本思想是使用来自多个模型的预测（通常称为第0级模型）作为后续模型（第1级模型）的特征，后者再结合这些预测（ @fig-pipelines-stacking ）。简单的组合可以是一个线性模型（如果你有很多第0级模型，可能需要正则化），因为第0级模型的加权和通常是合理且足够好的。当然，也可以使用非线性的第1级模型，并且第1级模型还可以访问输入特征以及第0级的预测。堆叠可以建立多个级别（在概念上和在</span><span class="in">`mlr`</span><span class="at">3中都可以），但在这里我们限制自己使用这种较简单的设置，因为在实践中它通常也表现得很好。</span></span>
<span id="cb267-3139"><a href="#cb267-3139" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3140"><a href="#cb267-3140" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 与装袋类似，我们将演示如何手动创建一个堆叠管道，尽管</span><span class="in">`ppl("stacking")`</span><span class="at">中也提供了一个预先构建的管道。</span></span>
<span id="cb267-3141"><a href="#cb267-3141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3142"><a href="#cb267-3142" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3143"><a href="#cb267-3143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3144"><a href="#cb267-3144" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3145"><a href="#cb267-3145" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb267-3146"><a href="#cb267-3146" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-pipelines-stacking</span></span>
<span id="cb267-3147"><a href="#cb267-3147" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Graph that performs Stacking by fitting three models and using their outputs as features for another model after combining with `PipeOpFeatureUnion`."</span></span>
<span id="cb267-3148"><a href="#cb267-3148" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: 'Graph shows "Dtrain" with arrows to three boxes: "Decision Tree", "KNN", and "Lasso Regression". Each of these points to the same "Feature Union -&gt; Logistic Regression".'</span></span>
<span id="cb267-3149"><a href="#cb267-3149" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"imgs/mlr3book_figures-27.svg"</span>)</span>
<span id="cb267-3150"><a href="#cb267-3150" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3151"><a href="#cb267-3151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3152"><a href="#cb267-3152" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3153"><a href="#cb267-3153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3154"><a href="#cb267-3154" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3155"><a href="#cb267-3155" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb267-3156"><a href="#cb267-3156" aria-hidden="true" tabindex="-1"></a>po_rparv_cv <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"learner_cv"</span>, <span class="at">learner =</span> lrn_rpart,</span>
<span id="cb267-3157"><a href="#cb267-3157" aria-hidden="true" tabindex="-1"></a>                 <span class="at">resampling.folds =</span> <span class="dv">2</span>, <span class="at">id =</span> <span class="st">"rpart_cv"</span>)</span>
<span id="cb267-3158"><a href="#cb267-3158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3159"><a href="#cb267-3159" aria-hidden="true" tabindex="-1"></a>lrn_knn <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.kknn"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb267-3160"><a href="#cb267-3160" aria-hidden="true" tabindex="-1"></a>po_knn_cv <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"learner_cv"</span>, <span class="at">learner =</span> lrn_knn,</span>
<span id="cb267-3161"><a href="#cb267-3161" aria-hidden="true" tabindex="-1"></a>               <span class="at">resampling.folds =</span> <span class="dv">2</span>, <span class="at">id =</span> <span class="st">"knn_cv"</span>)</span>
<span id="cb267-3162"><a href="#cb267-3162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3163"><a href="#cb267-3163" aria-hidden="true" tabindex="-1"></a>lrn_glmnet <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.glmnet"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb267-3164"><a href="#cb267-3164" aria-hidden="true" tabindex="-1"></a>po_glmnet_cv <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"learner_cv"</span>, <span class="at">learner =</span> lrn_glmnet,</span>
<span id="cb267-3165"><a href="#cb267-3165" aria-hidden="true" tabindex="-1"></a>                  <span class="at">resampling.folds =</span> <span class="dv">2</span>, <span class="at">id =</span> <span class="st">"glmnet_cv"</span>)</span>
<span id="cb267-3166"><a href="#cb267-3166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3167"><a href="#cb267-3167" aria-hidden="true" tabindex="-1"></a>gr_level_0 <span class="ot">=</span> <span class="fu">gunion</span>(<span class="fu">list</span>(po_rparv_cv, po_knn_cv, po_glmnet_cv))</span>
<span id="cb267-3168"><a href="#cb267-3168" aria-hidden="true" tabindex="-1"></a>gr_combined <span class="ot">=</span> gr_level_0 <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"featureunion"</span>)</span>
<span id="cb267-3169"><a href="#cb267-3169" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3170"><a href="#cb267-3170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3171"><a href="#cb267-3171" aria-hidden="true" tabindex="-1"></a>The resulting task contains the predicted probabilities for both classes made from each of the level 0 learners. However, as the probabilities always add up to </span>
<span id="cb267-3172"><a href="#cb267-3172" aria-hidden="true" tabindex="-1"></a>, we only need the predictions for one of the classes (as this is a binary classification task), so we can use <span class="in">`po("select")`</span> to only keep predictions for one class (we choose <span class="in">`"M"`</span> in this example).</span>
<span id="cb267-3173"><a href="#cb267-3173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3174"><a href="#cb267-3174" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 生成的任务包含了从第0级学习器中得到的两个类别的预测概率。然而，由于这些概率总是加起来等于1，我们只需要其中一个类别的预测结果（因为这是一个二元分类任务），所以我们可以使用</span><span class="in">`po("select")`</span><span class="at">来仅保留其中一个类别的预测（在这个示例中我们选择了</span><span class="in">`"M"`</span><span class="at">类别）。</span></span>
<span id="cb267-3175"><a href="#cb267-3175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3176"><a href="#cb267-3176" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3177"><a href="#cb267-3177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3178"><a href="#cb267-3178" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3179"><a href="#cb267-3179" aria-hidden="true" tabindex="-1"></a>gr_stack <span class="ot">=</span> gr_combined <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3180"><a href="#cb267-3180" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"select"</span>, <span class="at">selector =</span> <span class="fu">selector_grep</span>(<span class="st">"</span><span class="sc">\\</span><span class="st">.M$"</span>))</span>
<span id="cb267-3181"><a href="#cb267-3181" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3182"><a href="#cb267-3182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3183"><a href="#cb267-3183" aria-hidden="true" tabindex="-1"></a>Finally, we can combine our pipeline with the final model that will take these predictions as its input. Below we use logistic regression, which combines the level 0 predictions in a weighted linear sum.</span>
<span id="cb267-3184"><a href="#cb267-3184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3185"><a href="#cb267-3185" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3186"><a href="#cb267-3186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3187"><a href="#cb267-3187" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3188"><a href="#cb267-3188" aria-hidden="true" tabindex="-1"></a>gr_stack <span class="ot">=</span> gr_stack <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"learner"</span>, <span class="fu">lrn</span>(<span class="st">"classif.log_reg"</span>))</span>
<span id="cb267-3189"><a href="#cb267-3189" aria-hidden="true" tabindex="-1"></a>gr_stack<span class="sc">$</span><span class="fu">plot</span>(<span class="at">horizontal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-3190"><a href="#cb267-3190" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3191"><a href="#cb267-3191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3192"><a href="#cb267-3192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3193"><a href="#cb267-3193" aria-hidden="true" tabindex="-1"></a>As our final model was an interpretable logistic regression, we can inspect the weights of the level 0 learners by looking at the final trained model:</span>
<span id="cb267-3194"><a href="#cb267-3194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3195"><a href="#cb267-3195" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 由于我们的最终模型是一个可解释的逻辑回归模型，我们可以通过查看最终训练好的模型来检查第0级学习器的权重。</span></span>
<span id="cb267-3196"><a href="#cb267-3196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3197"><a href="#cb267-3197" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3198"><a href="#cb267-3198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3199"><a href="#cb267-3199" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3200"><a href="#cb267-3200" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3201"><a href="#cb267-3201" aria-hidden="true" tabindex="-1"></a>glrn_stack <span class="ot">=</span> <span class="fu">as_learner</span>(gr_stack)</span>
<span id="cb267-3202"><a href="#cb267-3202" aria-hidden="true" tabindex="-1"></a>glrn_stack<span class="sc">$</span><span class="fu">train</span>(<span class="fu">tsk</span>(<span class="st">"sonar"</span>))</span>
<span id="cb267-3203"><a href="#cb267-3203" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3204"><a href="#cb267-3204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3205"><a href="#cb267-3205" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3206"><a href="#cb267-3206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3207"><a href="#cb267-3207" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3208"><a href="#cb267-3208" aria-hidden="true" tabindex="-1"></a>glrn_stack<span class="sc">$</span><span class="fu">base_learner</span>()<span class="sc">$</span>model</span>
<span id="cb267-3209"><a href="#cb267-3209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3210"><a href="#cb267-3210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3211"><a href="#cb267-3211" aria-hidden="true" tabindex="-1"></a>The model weights suggest that knn influences the predictions the most with the largest coefficient. To confirm this we can benchmark the individual models alongside the stacking pipeline.</span>
<span id="cb267-3212"><a href="#cb267-3212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3213"><a href="#cb267-3213" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 模型的权重表明，knn的影响最大，其系数最大。为了确认这一点，我们可以将单独的模型与堆叠管道进行基准测试。</span></span>
<span id="cb267-3214"><a href="#cb267-3214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3215"><a href="#cb267-3215" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3216"><a href="#cb267-3216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3217"><a href="#cb267-3217" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3218"><a href="#cb267-3218" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3219"><a href="#cb267-3219" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb267-3220"><a href="#cb267-3220" aria-hidden="true" tabindex="-1"></a>glrn_stack<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"stacking"</span></span>
<span id="cb267-3221"><a href="#cb267-3221" aria-hidden="true" tabindex="-1"></a>design <span class="ot">=</span> <span class="fu">benchmark_grid</span>(</span>
<span id="cb267-3222"><a href="#cb267-3222" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tsk</span>(<span class="st">"sonar"</span>),</span>
<span id="cb267-3223"><a href="#cb267-3223" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(lrn_rpart, lrn_knn, lrn_glmnet, glrn_stack),</span>
<span id="cb267-3224"><a href="#cb267-3224" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rsmp</span>(<span class="st">"repeated_cv"</span>)</span>
<span id="cb267-3225"><a href="#cb267-3225" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-3226"><a href="#cb267-3226" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(design)</span>
<span id="cb267-3227"><a href="#cb267-3227" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>()[, .(learner_id, classif.ce)]</span>
<span id="cb267-3228"><a href="#cb267-3228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3229"><a href="#cb267-3229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3230"><a href="#cb267-3230" aria-hidden="true" tabindex="-1"></a>This experiment confirms that of the individual models, the KNN learner performs the best, however, our stacking pipeline outperforms them all. Now that we have seen the inner workings of this pipeline, next time you might want to more efficiently create it using <span class="in">`ppl("stacking")`</span>, to copy the example above you would run:</span>
<span id="cb267-3231"><a href="#cb267-3231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3232"><a href="#cb267-3232" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 这个实验证实了在单独的模型中，KNN学习器表现最好，但我们的堆叠管道的性能超过了它们所有。现在我们已经了解了这个管道的内部工作原理，下次您可能希望更高效地使用</span><span class="in">`ppl("stacking")`</span><span class="at">来创建它。如果要复制上述示例，您可以运行：</span></span>
<span id="cb267-3233"><a href="#cb267-3233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3234"><a href="#cb267-3234" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3235"><a href="#cb267-3235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3236"><a href="#cb267-3236" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3237"><a href="#cb267-3237" aria-hidden="true" tabindex="-1"></a><span class="fu">ppl</span>(<span class="st">"stacking"</span>,</span>
<span id="cb267-3238"><a href="#cb267-3238" aria-hidden="true" tabindex="-1"></a>    <span class="at">base_learners =</span> <span class="fu">lrns</span>(<span class="fu">c</span>(<span class="st">"classif.rpart"</span>, <span class="st">"classif.kknn"</span>, <span class="st">"classif.glmnet"</span>)),</span>
<span id="cb267-3239"><a href="#cb267-3239" aria-hidden="true" tabindex="-1"></a>    <span class="at">super_learner =</span> <span class="fu">lrn</span>(<span class="st">"classif.log_reg"</span>))</span>
<span id="cb267-3240"><a href="#cb267-3240" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3241"><a href="#cb267-3241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3242"><a href="#cb267-3242" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tuning Graphs</span></span>
<span id="cb267-3243"><a href="#cb267-3243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3244"><a href="#cb267-3244" aria-hidden="true" tabindex="-1"></a>By wrapping a pipeline inside a <span class="in">`GraphLearner`</span>, we can tune it at two levels of complexity using <span class="in">`mlr3tuning`</span>:</span>
<span id="cb267-3245"><a href="#cb267-3245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3246"><a href="#cb267-3246" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Tuning of a fixed, usually sequential pipeline, where preprocessing is combined with a given learner. This simply means the joint tuning of any subset of selected hyperparameters of operations in the pipeline. Conceptually and also technically in <span class="in">`mlr3`</span>, this is not much different from tuning a learner that is not part of a pipeline.</span>
<span id="cb267-3247"><a href="#cb267-3247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3248"><a href="#cb267-3248" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Tuning not only the hyperparameters of a pipeline, whose structure is not completely fixed in terms of its included operations, but also which concrete <span class="in">`PipeOps`</span> should be applied to data. This allows us to select these operations (e.g. which learner to use, which preprocessing to perform) in a data-driven manner known as “Combined Algorithm Selection and Hyperparameter optimization” (Thornton et al. 2013). As we will soon see, we can do this in <span class="in">`mlr3pipelines`</span> by using the powerful branching and proxy meta operators. Through this, we can conveniently create our own “mini AutoML systems” (Hutter, Kotthoff, and Vanschoren 2019) in <span class="in">`mlr3`</span>, which can even be geared for specific tasks.</span>
<span id="cb267-3249"><a href="#cb267-3249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3250"><a href="#cb267-3250" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 通过将一个管道包装在</span><span class="in">`GraphLearner`</span><span class="at">内部，我们可以使用</span><span class="in">`mlr3tuning`</span><span class="at">在两个复杂度级别上进行调整：</span></span>
<span id="cb267-3251"><a href="#cb267-3251" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3252"><a href="#cb267-3252" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 1. 对于一个固定的、通常是顺序执行的管道进行调整，其中预处理与指定的学习器结合在一起。这意味着对管道中操作的任意子集的超参数进行联合调整。从概念上讲，在</span><span class="in">`mlr3`</span><span class="at">中，这与调整不是管道一部分的学习器没有太大区别，技术上也是如此。</span></span>
<span id="cb267-3253"><a href="#cb267-3253" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3254"><a href="#cb267-3254" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2. 不仅调整管道的超参数，而且调整管道的结构在其包含的操作方面并不完全固定，还可以确定应该将哪些具体的PipeOps应用于数据。这使我们能够以一种数据驱动的方式选择这些操作（例如使用哪个学习器，进行哪种预处理），这被称为“联合算法选择和超参数优化”（Thornton等人，2013）。正如我们将很快看到的，我们可以通过使用强大的分支和代理元操作符在</span><span class="in">`mlr3pipelines`</span><span class="at">中实现这一点。通过这种方式，我们可以方便地在</span><span class="in">`mlr`</span><span class="at">3中创建我们自己的“小型AutoML系统”（Hutter、Kotthoff和Vanschoren，2019），甚至可以针对特定任务进行调整。</span></span>
<span id="cb267-3255"><a href="#cb267-3255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3256"><a href="#cb267-3256" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning Graph Hyperparameters</span></span>
<span id="cb267-3257"><a href="#cb267-3257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3258"><a href="#cb267-3258" aria-hidden="true" tabindex="-1"></a>The optimal setting of the <span class="in">`rank.`</span> hyperparameter of our PCA <span class="in">`PipeOp`</span> may realistically depend on the value of the <span class="in">`k`</span> hyperparameter of the KNN model so jointly tuning them is reasonable.</span>
<span id="cb267-3259"><a href="#cb267-3259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3260"><a href="#cb267-3260" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们PCA </span><span class="in">`PipeOp`</span><span class="at">的</span><span class="in">`rank.`</span><span class="at">超参数的最佳设置可能实际上依赖于KNN模型的</span><span class="in">`k`</span><span class="at">超参数的值，因此联合调整它们是合理的。</span></span>
<span id="cb267-3261"><a href="#cb267-3261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3262"><a href="#cb267-3262" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3263"><a href="#cb267-3263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3264"><a href="#cb267-3264" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3265"><a href="#cb267-3265" aria-hidden="true" tabindex="-1"></a>lrn_knn <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.kknn"</span>, <span class="at">k =</span> <span class="fu">to_tune</span>(<span class="dv">1</span>, <span class="dv">32</span>))</span>
<span id="cb267-3266"><a href="#cb267-3266" aria-hidden="true" tabindex="-1"></a>po_pca <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"pca"</span>, <span class="at">rank. =</span> <span class="fu">to_tune</span>(<span class="dv">2</span>, <span class="dv">20</span>))</span>
<span id="cb267-3267"><a href="#cb267-3267" aria-hidden="true" tabindex="-1"></a>graph_learner <span class="ot">=</span> <span class="fu">as_learner</span>(po_pca <span class="sc">%&gt;&gt;%</span> lrn_knn)</span>
<span id="cb267-3268"><a href="#cb267-3268" aria-hidden="true" tabindex="-1"></a>graph_learner<span class="sc">$</span>param_set<span class="sc">$</span>values</span>
<span id="cb267-3269"><a href="#cb267-3269" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3270"><a href="#cb267-3270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3271"><a href="#cb267-3271" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3272"><a href="#cb267-3272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3273"><a href="#cb267-3273" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3274"><a href="#cb267-3274" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3275"><a href="#cb267-3275" aria-hidden="true" tabindex="-1"></a>glrn_tuned <span class="ot">=</span> <span class="fu">auto_tuner</span>(<span class="fu">tnr</span>(<span class="st">"random_search"</span>), graph_learner,</span>
<span id="cb267-3276"><a href="#cb267-3276" aria-hidden="true" tabindex="-1"></a>                        <span class="fu">rsmp</span>(<span class="st">"holdout"</span>), <span class="at">term_evals =</span> <span class="dv">10</span>)</span>
<span id="cb267-3277"><a href="#cb267-3277" aria-hidden="true" tabindex="-1"></a>glrn_untuned <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"pca"</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">lrn</span>(<span class="st">"classif.kknn"</span>)</span>
<span id="cb267-3278"><a href="#cb267-3278" aria-hidden="true" tabindex="-1"></a>design <span class="ot">=</span> <span class="fu">benchmark_grid</span>(<span class="fu">tsk</span>(<span class="st">"sonar"</span>), <span class="fu">list</span>(glrn_tuned, glrn_untuned),</span>
<span id="cb267-3279"><a href="#cb267-3279" aria-hidden="true" tabindex="-1"></a>                        <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>))</span>
<span id="cb267-3280"><a href="#cb267-3280" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(design)</span>
<span id="cb267-3281"><a href="#cb267-3281" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3282"><a href="#cb267-3282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3283"><a href="#cb267-3283" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3284"><a href="#cb267-3284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3285"><a href="#cb267-3285" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3286"><a href="#cb267-3286" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>()[, .(learner_id, classif.ce)]</span>
<span id="cb267-3287"><a href="#cb267-3287" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3288"><a href="#cb267-3288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3289"><a href="#cb267-3289" aria-hidden="true" tabindex="-1"></a>Tuning pipelines will usually take longer than tuning individual learners as training steps are often more complex and the search space will be larger. Therefore, parallelization is often appropriate (Section 10.1) and/or more efficient tuning methods for searching large tuning spaces such as Bayesian optimization.</span>
<span id="cb267-3290"><a href="#cb267-3290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3291"><a href="#cb267-3291" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 通常，调整整个管道的时间通常比调整单个学习器的时间长，因为训练步骤通常更加复杂，搜索空间也更大。因此，通常情况下，可以考虑使用并行化（第10.1节）或者更高效的调优方法，比如搜索大型调优空间的贝叶斯优化。</span></span>
<span id="cb267-3292"><a href="#cb267-3292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3293"><a href="#cb267-3293" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning Alternative Paths with po(“branch”)</span></span>
<span id="cb267-3294"><a href="#cb267-3294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3295"><a href="#cb267-3295" aria-hidden="true" tabindex="-1"></a>We will answer that question by making use of <span class="in">`PipeOpBranch`</span> and <span class="in">`PipeOpUnbranch`</span>, which make it possible to specify multiple alternative paths in a pipeline. <span class="in">`po("branch")`</span> creates multiple paths such that data can only flow through one of these as determined by the <span class="in">`selection`</span> hyperparameter (@fig-pipelines-branching). This concept makes it possible to use tuning to decide which <span class="in">`PipeOps`</span> and <span class="in">`Learners`</span> to include in the pipeline, while also allowing all options in every path to be tuned.</span>
<span id="cb267-3296"><a href="#cb267-3296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3297"><a href="#cb267-3297" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们将利用</span><span class="in">`PipeOpBranch`</span><span class="at">和</span><span class="in">`PipeOpUnbranch`</span><span class="at">来回答这个问题，它们使得在管道中指定多个备选路径成为可能。</span><span class="in">`po("branch")`</span><span class="at">创建多个路径，数据只能流经其中一个，由选择超参数决定（@fig-pipelines-branching）。这个概念使得我们能够使用调优来决定在管道中包括哪些</span><span class="in">`PipeOps`</span><span class="at">和学习器，同时也允许在每个路径中调整所有选项。</span></span>
<span id="cb267-3298"><a href="#cb267-3298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3299"><a href="#cb267-3299" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3300"><a href="#cb267-3300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3301"><a href="#cb267-3301" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3302"><a href="#cb267-3302" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb267-3303"><a href="#cb267-3303" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-pipelines-branching</span></span>
<span id="cb267-3304"><a href="#cb267-3304" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Figure demonstrates the `po("branch")` and `po("unbranch")` operators where three separate branches are created and data only flows through the PCA, which is specified with the argument to `selection`.'</span></span>
<span id="cb267-3305"><a href="#cb267-3305" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: 'Graph with "Dtrain" on the left with an arrow to `po("branch", selection = "pca")` which then has a dark shaded arrow to a box that says "PCA". Above this box is a transparent box that says "PipeOpNOP" and below the "PCA" box is another transparent box that says "YeoJohnson", the implication is that only the "PCA" box is active. The "PCA" box then has an arrow to `po("unbranch")` -&gt; po("branch", selection = "XGBoost")` which has three arrows to another three boxes with "XGBoost" highlighted and "Random Forest" and "Decision Tree" transparent again. These finally have arrows to the same `po("unbranch")`.'</span></span>
<span id="cb267-3306"><a href="#cb267-3306" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"imgs/mlr3book_figures-24.svg"</span>)</span>
<span id="cb267-3307"><a href="#cb267-3307" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3308"><a href="#cb267-3308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3309"><a href="#cb267-3309" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3310"><a href="#cb267-3310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3311"><a href="#cb267-3311" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3312"><a href="#cb267-3312" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3313"><a href="#cb267-3313" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3oml)</span>
<span id="cb267-3314"><a href="#cb267-3314" aria-hidden="true" tabindex="-1"></a>otsk_mnist <span class="ot">=</span> <span class="fu">otsk</span>(<span class="at">id =</span> <span class="dv">3573</span>)</span>
<span id="cb267-3315"><a href="#cb267-3315" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb267-3316"><a href="#cb267-3316" aria-hidden="true" tabindex="-1"></a>tsk_mnist <span class="ot">=</span> <span class="fu">as_task</span>(otsk_mnist)<span class="sc">$</span></span>
<span id="cb267-3317"><a href="#cb267-3317" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">sample</span>(<span class="dv">70000</span>, <span class="dv">1000</span>))<span class="sc">$</span></span>
<span id="cb267-3318"><a href="#cb267-3318" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(otsk_mnist<span class="sc">$</span>feature_names[<span class="fu">sample</span>(<span class="dv">700</span>, <span class="dv">100</span>)])</span>
<span id="cb267-3319"><a href="#cb267-3319" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3320"><a href="#cb267-3320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3321"><a href="#cb267-3321" aria-hidden="true" tabindex="-1"></a><span class="in">`po("branch")`</span> is initialized either with the number of branches or with a <span class="in">`character`</span>-vector indicating the names of the branches, the latter makes the <span class="in">`selection`</span> hyperparameter (discussed below) more readable.</span>
<span id="cb267-3322"><a href="#cb267-3322" aria-hidden="true" tabindex="-1"></a>Below we create three branches: do nothing (<span class="in">`po("nop")`</span>), apply PCA (<span class="in">`po("pca")`</span>), remove constant features (<span class="in">`po("removeconstants")`</span>) then apply the Yeo-Johnson transform (<span class="in">`po("yeojohnson")`</span>). It is important to use <span class="in">`po("unbranch")`</span> (with the same arguments as <span class="in">`"branch"`</span>) to ensure that the outputs are merged into one result object.</span>
<span id="cb267-3323"><a href="#cb267-3323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3324"><a href="#cb267-3324" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3325"><a href="#cb267-3325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3326"><a href="#cb267-3326" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3327"><a href="#cb267-3327" aria-hidden="true" tabindex="-1"></a>paths <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"nop"</span>, <span class="st">"pca"</span>, <span class="st">"yeojohnson"</span>)</span>
<span id="cb267-3328"><a href="#cb267-3328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3329"><a href="#cb267-3329" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"branch"</span>, paths, <span class="at">id =</span> <span class="st">"branchP0"</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3330"><a href="#cb267-3330" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gunion</span>(<span class="fu">list</span>(</span>
<span id="cb267-3331"><a href="#cb267-3331" aria-hidden="true" tabindex="-1"></a>    <span class="fu">po</span>(<span class="st">"nop"</span>),</span>
<span id="cb267-3332"><a href="#cb267-3332" aria-hidden="true" tabindex="-1"></a>    <span class="fu">po</span>(<span class="st">"pca"</span>),</span>
<span id="cb267-3333"><a href="#cb267-3333" aria-hidden="true" tabindex="-1"></a>    <span class="fu">po</span>(<span class="st">"removeconstants"</span>, <span class="at">id =</span> <span class="st">"rm_const"</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3334"><a href="#cb267-3334" aria-hidden="true" tabindex="-1"></a>      <span class="fu">po</span>(<span class="st">"yeojohnson"</span>, <span class="at">id =</span> <span class="st">"YJ"</span>)</span>
<span id="cb267-3335"><a href="#cb267-3335" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3336"><a href="#cb267-3336" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"unbranch"</span>, paths, <span class="at">id =</span> <span class="st">"unbranchP0"</span>)</span>
<span id="cb267-3337"><a href="#cb267-3337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3338"><a href="#cb267-3338" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span><span class="fu">plot</span>(<span class="at">horizontal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-3339"><a href="#cb267-3339" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3340"><a href="#cb267-3340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3341"><a href="#cb267-3341" aria-hidden="true" tabindex="-1"></a>We can see how the output of this <span class="in">`Graph`</span> depends on the setting of the <span class="in">`branch.selection`</span> hyperparameter:</span>
<span id="cb267-3342"><a href="#cb267-3342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3343"><a href="#cb267-3343" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3344"><a href="#cb267-3344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3345"><a href="#cb267-3345" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3346"><a href="#cb267-3346" aria-hidden="true" tabindex="-1"></a><span class="co"># use the "PCA" path</span></span>
<span id="cb267-3347"><a href="#cb267-3347" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span>param_set<span class="sc">$</span>values<span class="sc">$</span>branchP0.selection <span class="ot">=</span> <span class="st">"pca"</span></span>
<span id="cb267-3348"><a href="#cb267-3348" aria-hidden="true" tabindex="-1"></a><span class="co"># new PCA columns</span></span>
<span id="cb267-3349"><a href="#cb267-3349" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(graph<span class="sc">$</span><span class="fu">train</span>(tsk_mnist)[[<span class="dv">1</span>]]<span class="sc">$</span>feature_names)</span>
<span id="cb267-3350"><a href="#cb267-3350" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3351"><a href="#cb267-3351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3352"><a href="#cb267-3352" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3353"><a href="#cb267-3353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3354"><a href="#cb267-3354" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3355"><a href="#cb267-3355" aria-hidden="true" tabindex="-1"></a><span class="co"># use the "Np-Op" path</span></span>
<span id="cb267-3356"><a href="#cb267-3356" aria-hidden="true" tabindex="-1"></a>graph<span class="sc">$</span>param_set<span class="sc">$</span>values<span class="sc">$</span>branchP0.selection <span class="ot">=</span> <span class="st">"nop"</span></span>
<span id="cb267-3357"><a href="#cb267-3357" aria-hidden="true" tabindex="-1"></a><span class="co"># same features</span></span>
<span id="cb267-3358"><a href="#cb267-3358" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(graph<span class="sc">$</span><span class="fu">train</span>(tsk_mnist)[[<span class="dv">1</span>]]<span class="sc">$</span>feature_names)</span>
<span id="cb267-3359"><a href="#cb267-3359" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3360"><a href="#cb267-3360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3361"><a href="#cb267-3361" aria-hidden="true" tabindex="-1"></a>Branching can even be used to tune which of several learners is most appropriate for a given dataset. We extend our example further and add the choice between a decision tree and KKNN:</span>
<span id="cb267-3362"><a href="#cb267-3362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3363"><a href="#cb267-3363" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3364"><a href="#cb267-3364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3365"><a href="#cb267-3365" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3366"><a href="#cb267-3366" aria-hidden="true" tabindex="-1"></a>graph_learner <span class="ot">=</span> graph <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3367"><a href="#cb267-3367" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ppl</span>(<span class="st">"branch"</span>, <span class="fu">lrns</span>(<span class="fu">c</span>(<span class="st">"classif.rpart"</span>, <span class="st">"classif.kknn"</span>)))</span>
<span id="cb267-3368"><a href="#cb267-3368" aria-hidden="true" tabindex="-1"></a>graph_learner<span class="sc">$</span><span class="fu">plot</span>(<span class="at">horizontal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-3369"><a href="#cb267-3369" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3370"><a href="#cb267-3370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3371"><a href="#cb267-3371" aria-hidden="true" tabindex="-1"></a>Tuning the selection hyperparameters can help determine which of the possible options work best in combination. We additionally tune the k hyperparameter of the KNN learner, as it may depend on the type of preprocessing performed. As this hyperparameter is only active when the "classif.kknn" path is chosen we will set a dependency:</span>
<span id="cb267-3372"><a href="#cb267-3372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3373"><a href="#cb267-3373" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3374"><a href="#cb267-3374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3375"><a href="#cb267-3375" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3376"><a href="#cb267-3376" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3377"><a href="#cb267-3377" aria-hidden="true" tabindex="-1"></a>graph_learner <span class="ot">=</span> <span class="fu">as_learner</span>(graph_learner)</span>
<span id="cb267-3378"><a href="#cb267-3378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3379"><a href="#cb267-3379" aria-hidden="true" tabindex="-1"></a>graph_learner<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">set_values</span>(</span>
<span id="cb267-3380"><a href="#cb267-3380" aria-hidden="true" tabindex="-1"></a>  <span class="at">branchP0.selection =</span> <span class="fu">to_tune</span>(paths),</span>
<span id="cb267-3381"><a href="#cb267-3381" aria-hidden="true" tabindex="-1"></a>  <span class="at">branch.selection =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(<span class="st">"classif.rpart"</span>, <span class="st">"classif.kknn"</span>)),</span>
<span id="cb267-3382"><a href="#cb267-3382" aria-hidden="true" tabindex="-1"></a>  <span class="at">classif.kknn.k =</span> <span class="fu">to_tune</span>(<span class="fu">p_int</span>(<span class="dv">1</span>, <span class="dv">32</span>, </span>
<span id="cb267-3383"><a href="#cb267-3383" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">depends =</span> branch.selection <span class="sc">==</span> <span class="st">"classif.kknn"</span>))</span>
<span id="cb267-3384"><a href="#cb267-3384" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-3385"><a href="#cb267-3385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3386"><a href="#cb267-3386" aria-hidden="true" tabindex="-1"></a><span class="co"># 实际应使用网格搜索</span></span>
<span id="cb267-3387"><a href="#cb267-3387" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">tune</span>(<span class="fu">tnr</span>(<span class="st">"random_search"</span>), tsk_mnist, graph_learner,</span>
<span id="cb267-3388"><a href="#cb267-3388" aria-hidden="true" tabindex="-1"></a>                <span class="fu">rsmp</span>(<span class="st">"repeated_cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>, <span class="at">repeats =</span> <span class="dv">3</span>),</span>
<span id="cb267-3389"><a href="#cb267-3389" aria-hidden="true" tabindex="-1"></a>                <span class="fu">msr</span>(<span class="st">"classif.ce"</span>), <span class="at">term_evals =</span> <span class="dv">20</span>)  </span>
<span id="cb267-3390"><a href="#cb267-3390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3391"><a href="#cb267-3391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3392"><a href="#cb267-3392" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3393"><a href="#cb267-3393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3394"><a href="#cb267-3394" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3395"><a href="#cb267-3395" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>archive<span class="sc">$</span>data[<span class="fu">order</span>(classif.ce)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>],</span>
<span id="cb267-3396"><a href="#cb267-3396" aria-hidden="true" tabindex="-1"></a>          .(branchP0.selection, classif.kknn.k, branch.selection, classif.ce)]</span>
<span id="cb267-3397"><a href="#cb267-3397" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3398"><a href="#cb267-3398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3399"><a href="#cb267-3399" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3400"><a href="#cb267-3400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3401"><a href="#cb267-3401" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3402"><a href="#cb267-3402" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(instance)</span>
<span id="cb267-3403"><a href="#cb267-3403" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3404"><a href="#cb267-3404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3405"><a href="#cb267-3405" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hyperband with Subsampling {#sec-hyperband-example-svm}</span></span>
<span id="cb267-3406"><a href="#cb267-3406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3407"><a href="#cb267-3407" aria-hidden="true" tabindex="-1"></a>We previously saw how some learners have hyperparameters that can act naturally as fidelity parameters, such as the number of trees in a random forest. However, using pipelines, we can now create a fidelity parameter for any model using <span class="in">`po("subsample")`</span>. The <span class="in">`frac`</span> parameter of <span class="in">`po("subsample")`</span> controls the amount of data fed into the subsequent <span class="in">`Learner`</span>. In general, feeding less data to a <span class="in">`Learner`</span> results in quicker model training but poorer quality predictions compared to when more training data is supplied. Resampling with less data will still give us some information about the relative performance of different model configurations, thus making the fraction of data to subsample the perfect candidate for a fidelity parameter.</span>
<span id="cb267-3408"><a href="#cb267-3408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3409"><a href="#cb267-3409" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 我们之前看到，一些学习器具有可以自然充当保真度参数的超参数，例如随机森林中的树的数量。然而，使用管道，我们现在可以使用</span><span class="in">`po("subsample")`</span><span class="at">为任何模型创建一个保真度参数。</span><span class="in">`po("subsample")`</span><span class="at">的</span><span class="in">`frac`</span><span class="at">参数控制了传递到后续学习器的数据量。通常情况下，向学习器提供更少的数据会导致模型训练更快，但与提供更多训练数据相比，预测质量较差。使用较少的数据重新采样仍然可以为我们提供有关不同模型配置相对性能的一些信息，因此将数据子采样的比例作为保真度参数是一个完美的选择。</span></span>
<span id="cb267-3410"><a href="#cb267-3410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3411"><a href="#cb267-3411" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3412"><a href="#cb267-3412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3413"><a href="#cb267-3413" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3414"><a href="#cb267-3414" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.svm"</span>, <span class="at">id =</span> <span class="st">"svm"</span>, <span class="at">type =</span> <span class="st">"C-classification"</span>,</span>
<span id="cb267-3415"><a href="#cb267-3415" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel =</span> <span class="st">"radial"</span>, <span class="at">cost =</span> <span class="fu">to_tune</span>(<span class="fl">1e-5</span>, <span class="fl">1e5</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb267-3416"><a href="#cb267-3416" aria-hidden="true" tabindex="-1"></a>              <span class="at">gamma =</span> <span class="fu">to_tune</span>(<span class="fl">1e-5</span>, <span class="fl">1e5</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>))</span>
<span id="cb267-3417"><a href="#cb267-3417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3418"><a href="#cb267-3418" aria-hidden="true" tabindex="-1"></a>graph_learner <span class="ot">=</span> <span class="fu">as_learner</span>(</span>
<span id="cb267-3419"><a href="#cb267-3419" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"subsample"</span>, <span class="at">frac =</span> <span class="fu">to_tune</span>(<span class="fu">p_dbl</span>(<span class="dv">3</span><span class="sc">^-</span><span class="dv">3</span>, <span class="dv">1</span>, <span class="at">tags =</span> <span class="st">"budget"</span>))) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3420"><a href="#cb267-3420" aria-hidden="true" tabindex="-1"></a>    learner</span>
<span id="cb267-3421"><a href="#cb267-3421" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-3422"><a href="#cb267-3422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3423"><a href="#cb267-3423" aria-hidden="true" tabindex="-1"></a>graph_learner<span class="sc">$</span>encapsulate <span class="ot">=</span> <span class="fu">c</span>(<span class="at">train =</span> <span class="st">"evaluate"</span>, <span class="at">predict =</span> <span class="st">"evaluate"</span>)</span>
<span id="cb267-3424"><a href="#cb267-3424" aria-hidden="true" tabindex="-1"></a>graph_learner<span class="sc">$</span>timeout <span class="ot">=</span> <span class="fu">c</span>(<span class="at">train =</span> <span class="dv">30</span>, <span class="at">predict =</span> <span class="dv">30</span>)</span>
<span id="cb267-3425"><a href="#cb267-3425" aria-hidden="true" tabindex="-1"></a>graph_learner<span class="sc">$</span>fallback <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.featureless"</span>)</span>
<span id="cb267-3426"><a href="#cb267-3426" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3427"><a href="#cb267-3427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3428"><a href="#cb267-3428" aria-hidden="true" tabindex="-1"></a>Now we can tune our SVM by tuning our <span class="in">`GraphLearner`</span> as normal, below we set <span class="in">`eta = 3`</span> for Hyperband.</span>
<span id="cb267-3429"><a href="#cb267-3429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3430"><a href="#cb267-3430" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3431"><a href="#cb267-3431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3432"><a href="#cb267-3432" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3433"><a href="#cb267-3433" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3434"><a href="#cb267-3434" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">tune</span>(<span class="fu">tnr</span>(<span class="st">"hyperband"</span>, <span class="at">eta =</span> <span class="dv">3</span>), <span class="fu">tsk</span>(<span class="st">"sonar"</span>), graph_learner,</span>
<span id="cb267-3435"><a href="#cb267-3435" aria-hidden="true" tabindex="-1"></a>                <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>), <span class="fu">msr</span>(<span class="st">"classif.ce"</span>))</span>
<span id="cb267-3436"><a href="#cb267-3436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3437"><a href="#cb267-3437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3438"><a href="#cb267-3438" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3439"><a href="#cb267-3439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3440"><a href="#cb267-3440" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3441"><a href="#cb267-3441" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>result_x_domain</span>
<span id="cb267-3442"><a href="#cb267-3442" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3443"><a href="#cb267-3443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3444"><a href="#cb267-3444" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feature Selection with Filter Pipelines {#sec-pipelines-featsel}</span></span>
<span id="cb267-3445"><a href="#cb267-3445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3446"><a href="#cb267-3446" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3447"><a href="#cb267-3447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3448"><a href="#cb267-3448" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3449"><a href="#cb267-3449" aria-hidden="true" tabindex="-1"></a>task_pen <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"penguins"</span>)</span>
<span id="cb267-3450"><a href="#cb267-3450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3451"><a href="#cb267-3451" aria-hidden="true" tabindex="-1"></a><span class="co"># combine filter (keep top 3 features) with learner</span></span>
<span id="cb267-3452"><a href="#cb267-3452" aria-hidden="true" tabindex="-1"></a>po_flt <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"filter"</span>, <span class="at">filter =</span> <span class="fu">flt</span>(<span class="st">"information_gain"</span>), <span class="at">filter.nfeat =</span> <span class="dv">3</span>)</span>
<span id="cb267-3453"><a href="#cb267-3453" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> po_flt <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"learner"</span>, <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>))</span>
<span id="cb267-3454"><a href="#cb267-3454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3455"><a href="#cb267-3455" aria-hidden="true" tabindex="-1"></a><span class="fu">po</span>(<span class="st">"filter"</span>, <span class="at">filter =</span> <span class="fu">flt</span>(<span class="st">"information_gain"</span>), <span class="at">filter.nfeat =</span> <span class="dv">3</span>)<span class="sc">$</span></span>
<span id="cb267-3456"><a href="#cb267-3456" aria-hidden="true" tabindex="-1"></a>  <span class="fu">train</span>(<span class="fu">list</span>(task_pen))[[<span class="dv">1</span>]]<span class="sc">$</span>feature_names</span>
<span id="cb267-3457"><a href="#cb267-3457" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3458"><a href="#cb267-3458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3459"><a href="#cb267-3459" aria-hidden="true" tabindex="-1"></a>Choosing <span class="in">`3`</span> as the cutoff was fairly arbitrary but by tuning a graph we can optimize this cutoff:</span>
<span id="cb267-3460"><a href="#cb267-3460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3461"><a href="#cb267-3461" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 选择</span><span class="in">`3`</span><span class="at">作为截止值是相当任意的，但通过调整一个图表，我们可以优化这个截止值：</span></span>
<span id="cb267-3462"><a href="#cb267-3462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3463"><a href="#cb267-3463" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3464"><a href="#cb267-3464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3465"><a href="#cb267-3465" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3466"><a href="#cb267-3466" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3467"><a href="#cb267-3467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3468"><a href="#cb267-3468" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb267-3469"><a href="#cb267-3469" aria-hidden="true" tabindex="-1"></a><span class="co"># tune between 1 and total number of features</span></span>
<span id="cb267-3470"><a href="#cb267-3470" aria-hidden="true" tabindex="-1"></a>po_filter <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"filter"</span>, <span class="at">filter =</span> <span class="fu">flt</span>(<span class="st">"information_gain"</span>),</span>
<span id="cb267-3471"><a href="#cb267-3471" aria-hidden="true" tabindex="-1"></a>               <span class="at">filter.nfeat =</span> <span class="fu">to_tune</span>(<span class="dv">1</span>, task_pen<span class="sc">$</span>ncol))</span>
<span id="cb267-3472"><a href="#cb267-3472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3473"><a href="#cb267-3473" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span> <span class="fu">as_learner</span>(po_filter <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"learner"</span>, <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>)))</span>
<span id="cb267-3474"><a href="#cb267-3474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3475"><a href="#cb267-3475" aria-hidden="true" tabindex="-1"></a>instance <span class="ot">=</span> <span class="fu">tune</span>(<span class="fu">tnr</span>(<span class="st">"random_search"</span>), task_pen, graph,</span>
<span id="cb267-3476"><a href="#cb267-3476" aria-hidden="true" tabindex="-1"></a>                <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>), <span class="at">term_evals =</span> <span class="dv">10</span>)</span>
<span id="cb267-3477"><a href="#cb267-3477" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3478"><a href="#cb267-3478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3479"><a href="#cb267-3479" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3480"><a href="#cb267-3480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3481"><a href="#cb267-3481" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3482"><a href="#cb267-3482" aria-hidden="true" tabindex="-1"></a>instance<span class="sc">$</span>result</span>
<span id="cb267-3483"><a href="#cb267-3483" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3484"><a href="#cb267-3484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3485"><a href="#cb267-3485" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3486"><a href="#cb267-3486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3487"><a href="#cb267-3487" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3488"><a href="#cb267-3488" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(instance)</span>
<span id="cb267-3489"><a href="#cb267-3489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3490"><a href="#cb267-3490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3491"><a href="#cb267-3491" aria-hidden="true" tabindex="-1"></a>In this example, <span class="in">`6`</span> is the optimal number of features. It can be especially useful in feature selection to visualize the tuning results as there may be cases where the optimal result is only marginally better than a result with less features (which would lead to a model that is quicker to train and possibly easier to interpret).</span>
<span id="cb267-3492"><a href="#cb267-3492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3493"><a href="#cb267-3493" aria-hidden="true" tabindex="-1"></a>Now we can see that four variables may be equally as good in this case so we could consider going forward by selecting four features and not six as suggested by <span class="in">`instance$result`</span>.</span>
<span id="cb267-3494"><a href="#cb267-3494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3495"><a href="#cb267-3495" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在这个示例中，</span><span class="in">`6`</span><span class="at">是最佳的特征数量。在特征选择中，将调整结果可视化呈现可能特别有用，因为有些情况下，最佳结果可能仅略优于具有较少特征的结果（这将导致模型训练更快，可能更容易解释）。</span></span>
<span id="cb267-3496"><a href="#cb267-3496" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3497"><a href="#cb267-3497" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 现在我们可以看到，在这种情况下，四个变量可能同样有效，因此我们可以考虑选择四个特征，而不是像</span><span class="in">`instance$result`</span><span class="at">建议的六个。</span></span>
<span id="cb267-3498"><a href="#cb267-3498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3499"><a href="#cb267-3499" aria-hidden="true" tabindex="-1"></a><span class="fu"># Preprocessing {#sec-preprocessing}</span></span>
<span id="cb267-3500"><a href="#cb267-3500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3501"><a href="#cb267-3501" aria-hidden="true" tabindex="-1"></a>In this book, preprocessing refers to everything that happens with data before it is used to fit a model, while postprocessing encompasses everything that occurs with predictions after the model is fitted.</span>
<span id="cb267-3502"><a href="#cb267-3502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3503"><a href="#cb267-3503" aria-hidden="true" tabindex="-1"></a>Data cleaning is an important part of preprocessing that involves the removal of errors, noise, and redundancy in the data; we only consider data cleaning very briefly as it is usually performed outside of <span class="in">`mlr3`</span> on the raw dataset.</span>
<span id="cb267-3504"><a href="#cb267-3504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3505"><a href="#cb267-3505" aria-hidden="true" tabindex="-1"></a>Another aspect of preprocessing is feature engineering, which covers all other transformations of data before it is fed to the machine learning model, including the creation of features from possibly unstructured data, such as written text, sequences or images. The goal of feature engineering is to enable the data to be handled by a given learner, and/or to further improve predictive performance. It is important to note that feature engineering helps mostly for simpler algorithms, while highly complex models usually gain less from it and require little data preparation to be trained. Common difficulties in data that can be solved with feature engineering include features with skewed distributions, high cardinality categorical features, missing observations, high dimensionality and imbalanced classes in classification tasks. Deep learning has shown promising results in automating feature engineering, however, its effectiveness depends on the complexity and nature of the data being processed, as well as the specific problem being addressed. Typically it can work well with natural language processing and computer vision problems, while for standard tabular data, tree-based ensembles such as a random forest or gradient boosting are often still superior (and easier to handle). However, tabular deep learning approaches are currently catching up quickly. Hence, manual feature engineering is still often required but with <span class="in">`mlr3pipelines`</span>, which can simplify the process as much as possible.</span>
<span id="cb267-3506"><a href="#cb267-3506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3507"><a href="#cb267-3507" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在本书中，预处理指的是在数据用于拟合模型之前发生的一切，而后处理则包括在模型拟合后对预测进行的一切操作。</span></span>
<span id="cb267-3508"><a href="#cb267-3508" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3509"><a href="#cb267-3509" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 数据清理是预处理的重要部分，涉及到消除数据中的错误、噪音和冗余；我们只会简要地考虑数据清理，因为它通常是在原始数据集上进行的，而不是在</span><span class="in">`mlr3`</span><span class="at">上执行。</span></span>
<span id="cb267-3510"><a href="#cb267-3510" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3511"><a href="#cb267-3511" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 预处理的另一个方面是特征工程，它涵盖了在将数据提供给机器学习模型之前对数据进行的所有其他转换，包括从可能是非结构化数据（如书面文本、序列或图像）中创建特征。特征工程的目标是使数据能够被给定的学习器处理，和/或进一步提高预测性能。需要注意的是，特征工程主要有助于较简单的算法，而高度复杂的模型通常受益较少，并且需要较少的数据准备来进行训练。可以通过特征工程解决的数据常见问题包括具有倾斜分布的特征、高基数分类特征、缺失观测、高维度以及分类任务中的不平衡类。深度学习在自动化特征工程方面表现出有希望的结果，然而，其有效性取决于正在处理的数据的复杂性和性质，以及所解决的具体问题。通常情况下，它在自然语言处理和计算机视觉问题上表现良好，而对于标准表格数据，如随机森林或梯度提升等基于树的集成方法通常仍然更占优势（并且更易处理）。但是，表格型深度学习方法目前正在迅速赶超。因此，手动特征工程仍然经常需要，但使用</span><span class="in">`mlr3pipelines`</span><span class="at">可以尽可能简化这个过程。</span></span>
<span id="cb267-3512"><a href="#cb267-3512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3513"><a href="#cb267-3513" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3514"><a href="#cb267-3514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3515"><a href="#cb267-3515" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3516"><a href="#cb267-3516" aria-hidden="true" tabindex="-1"></a>ames <span class="ot">=</span> mlr3data<span class="sc">::</span>ames_housing</span>
<span id="cb267-3517"><a href="#cb267-3517" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3518"><a href="#cb267-3518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3519"><a href="#cb267-3519" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data Cleaning</span></span>
<span id="cb267-3520"><a href="#cb267-3520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3521"><a href="#cb267-3521" aria-hidden="true" tabindex="-1"></a>As a first step, we explore the data and look for simple problems such as constant or duplicated features. This can be done quite efficiently with a package like <span class="in">`DataExplorer`</span> or <span class="in">`skimr`</span> which can be used to create a large number of informative plots.</span>
<span id="cb267-3522"><a href="#cb267-3522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3523"><a href="#cb267-3523" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--</span></span>
<span id="cb267-3524"><a href="#cb267-3524" aria-hidden="true" tabindex="-1"></a><span class="co">quarto-executable-code-5450563D</span></span>
<span id="cb267-3525"><a href="#cb267-3525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3526"><a href="#cb267-3526" aria-hidden="true" tabindex="-1"></a><span class="co">```r</span></span>
<span id="cb267-3527"><a href="#cb267-3527" aria-hidden="true" tabindex="-1"></a><span class="co">skimr::skim(ames)</span></span>
<span id="cb267-3528"><a href="#cb267-3528" aria-hidden="true" tabindex="-1"></a><span class="co">```</span></span>
<span id="cb267-3529"><a href="#cb267-3529" aria-hidden="true" tabindex="-1"></a><span class="co">--&gt;</span></span>
<span id="cb267-3530"><a href="#cb267-3530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3531"><a href="#cb267-3531" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3532"><a href="#cb267-3532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3533"><a href="#cb267-3533" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3534"><a href="#cb267-3534" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. `Misc_Feature_2` is a factor with only a single level `Othr`.</span></span>
<span id="cb267-3535"><a href="#cb267-3535" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ames<span class="sc">$</span>Misc_Feature_2)</span>
<span id="cb267-3536"><a href="#cb267-3536" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3537"><a href="#cb267-3537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3538"><a href="#cb267-3538" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3539"><a href="#cb267-3539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3540"><a href="#cb267-3540" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3541"><a href="#cb267-3541" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. `Condition_2` and `Condition_3` are identical.</span></span>
<span id="cb267-3542"><a href="#cb267-3542" aria-hidden="true" tabindex="-1"></a><span class="fu">identical</span>(ames<span class="sc">$</span>Condition_2, ames<span class="sc">$</span>Condition_3)</span>
<span id="cb267-3543"><a href="#cb267-3543" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3544"><a href="#cb267-3544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3545"><a href="#cb267-3545" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3546"><a href="#cb267-3546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3547"><a href="#cb267-3547" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3548"><a href="#cb267-3548" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. `Lot_Area` and `Lot_Area_m2` are same data on different scales</span></span>
<span id="cb267-3549"><a href="#cb267-3549" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(ames<span class="sc">$</span>Lot_Area, ames<span class="sc">$</span>Lot_Area_m2)</span>
<span id="cb267-3550"><a href="#cb267-3550" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3551"><a href="#cb267-3551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3552"><a href="#cb267-3552" aria-hidden="true" tabindex="-1"></a>For all three problems, simply removing the problematic features (or feature in a pair) might be the best course of action.</span>
<span id="cb267-3553"><a href="#cb267-3553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3554"><a href="#cb267-3554" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3555"><a href="#cb267-3555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3556"><a href="#cb267-3556" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3557"><a href="#cb267-3557" aria-hidden="true" tabindex="-1"></a>to_remove <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"Lot_Area_m2"</span>, <span class="st">"Condition_3"</span>, <span class="st">"Misc_Feature_2"</span>)</span>
<span id="cb267-3558"><a href="#cb267-3558" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3559"><a href="#cb267-3559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3560"><a href="#cb267-3560" aria-hidden="true" tabindex="-1"></a>Other typical problems that should be checked are:</span>
<span id="cb267-3561"><a href="#cb267-3561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3562"><a href="#cb267-3562" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>ID columns, i.e., columns that are unique for every observation should be removed or tagged.</span>
<span id="cb267-3563"><a href="#cb267-3563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3564"><a href="#cb267-3564" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`NA`</span>s not correctly encoded, e.g. as <span class="in">`"NA"`</span> or <span class="in">`""`</span></span>
<span id="cb267-3565"><a href="#cb267-3565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3566"><a href="#cb267-3566" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Semantic errors in the data, e.g., negative <span class="in">`Lot_Area`</span></span>
<span id="cb267-3567"><a href="#cb267-3567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3568"><a href="#cb267-3568" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Numeric features encoded as categorical for learners that can not handle such features.</span>
<span id="cb267-3569"><a href="#cb267-3569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3570"><a href="#cb267-3570" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3571"><a href="#cb267-3571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3572"><a href="#cb267-3572" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3573"><a href="#cb267-3573" aria-hidden="true" tabindex="-1"></a>tsk_ames <span class="ot">=</span> <span class="fu">as_task_regr</span>(ames, <span class="at">target =</span> <span class="st">"Sale_Price"</span>, <span class="at">id =</span> <span class="st">"ames"</span>)</span>
<span id="cb267-3574"><a href="#cb267-3574" aria-hidden="true" tabindex="-1"></a><span class="co"># remove problematic features</span></span>
<span id="cb267-3575"><a href="#cb267-3575" aria-hidden="true" tabindex="-1"></a>tsk_ames<span class="sc">$</span><span class="fu">select</span>(<span class="fu">setdiff</span>(tsk_ames<span class="sc">$</span>feature_names, to_remove))</span>
<span id="cb267-3576"><a href="#cb267-3576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3577"><a href="#cb267-3577" aria-hidden="true" tabindex="-1"></a>msr_mae <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"regr.mae"</span>)</span>
<span id="cb267-3578"><a href="#cb267-3578" aria-hidden="true" tabindex="-1"></a>rsmp_cv3 <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>)</span>
<span id="cb267-3579"><a href="#cb267-3579" aria-hidden="true" tabindex="-1"></a>rsmp_cv3<span class="sc">$</span><span class="fu">instantiate</span>(tsk_ames)</span>
<span id="cb267-3580"><a href="#cb267-3580" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3581"><a href="#cb267-3581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3582"><a href="#cb267-3582" aria-hidden="true" tabindex="-1"></a>Lastly, we run a very simple experiment to verify our setup works as expected with a simple featureless baseline, note below we set <span class="in">`robust = TRUE`</span> to always predict the *median* sale price as opposed to the *mean*.</span>
<span id="cb267-3583"><a href="#cb267-3583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3584"><a href="#cb267-3584" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3585"><a href="#cb267-3585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3586"><a href="#cb267-3586" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3587"><a href="#cb267-3587" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3588"><a href="#cb267-3588" aria-hidden="true" tabindex="-1"></a>lrn_baseline <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.featureless"</span>, <span class="at">robust =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-3589"><a href="#cb267-3589" aria-hidden="true" tabindex="-1"></a>lrn_baseline<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"Baseline"</span></span>
<span id="cb267-3590"><a href="#cb267-3590" aria-hidden="true" tabindex="-1"></a>rr_baseline <span class="ot">=</span> <span class="fu">resample</span>(tsk_ames, lrn_baseline, rsmp_cv3)</span>
<span id="cb267-3591"><a href="#cb267-3591" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3592"><a href="#cb267-3592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3593"><a href="#cb267-3593" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3594"><a href="#cb267-3594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3595"><a href="#cb267-3595" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3596"><a href="#cb267-3596" aria-hidden="true" tabindex="-1"></a>rr_baseline<span class="sc">$</span><span class="fu">aggregate</span>(msr_mae)</span>
<span id="cb267-3597"><a href="#cb267-3597" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3598"><a href="#cb267-3598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3599"><a href="#cb267-3599" aria-hidden="true" tabindex="-1"></a><span class="fu">## Factor Encoding</span></span>
<span id="cb267-3600"><a href="#cb267-3600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3601"><a href="#cb267-3601" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3602"><a href="#cb267-3602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3603"><a href="#cb267-3603" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3604"><a href="#cb267-3604" aria-hidden="true" tabindex="-1"></a><span class="co">#| error: true</span></span>
<span id="cb267-3605"><a href="#cb267-3605" aria-hidden="true" tabindex="-1"></a>lrn_xgb <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.xgboost"</span>, <span class="at">nrounds =</span> <span class="dv">100</span>)</span>
<span id="cb267-3606"><a href="#cb267-3606" aria-hidden="true" tabindex="-1"></a>lrn_xgb<span class="sc">$</span><span class="fu">train</span>(tsk_ames)</span>
<span id="cb267-3607"><a href="#cb267-3607" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3608"><a href="#cb267-3608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3609"><a href="#cb267-3609" aria-hidden="true" tabindex="-1"></a>Categorical features can be grouped by their cardinality, which refers to the number of levels they contain: binary features (two levels), low-cardinality features, and high-cardinality features; there is no universal threshold for when a feature should be considered high-cardinality and this threshold can even be tuned. For now, we will consider high-cardinality to be features with more than 10 levels:</span>
<span id="cb267-3610"><a href="#cb267-3610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3611"><a href="#cb267-3611" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 分类特征可以按其基数进行分组，基数指的是它们包含的级别数量：二元特征（两个级别）、低基数特征和高基数特征；对于何时将特征视为高基数特征，没有通用的阈值，这个阈值甚至可以进行调整。目前，我们将认为高基数特征是具有超过10个级别的特征：</span></span>
<span id="cb267-3612"><a href="#cb267-3612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3613"><a href="#cb267-3613" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3614"><a href="#cb267-3614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3615"><a href="#cb267-3615" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3616"><a href="#cb267-3616" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(<span class="fu">which</span>(<span class="fu">lengths</span>(tsk_ames<span class="sc">$</span><span class="fu">levels</span>()) <span class="sc">&gt;</span> <span class="dv">10</span>))</span>
<span id="cb267-3617"><a href="#cb267-3617" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3618"><a href="#cb267-3618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3619"><a href="#cb267-3619" aria-hidden="true" tabindex="-1"></a>Low-cardinality features can be handled by one-hot encoding. One-hot encoding is a process of converting categorical features into a binary representation, where each possible category is represented as a separate binary feature. Theoretically, it is sufficient to create one less binary feature than levels, as setting all binary features to zero is also a valid representation. This is typically called dummy or treatment encoding and is required if the learner is a generalized linear model (GLM) or additive model (GAM).</span>
<span id="cb267-3620"><a href="#cb267-3620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3621"><a href="#cb267-3621" aria-hidden="true" tabindex="-1"></a>Some learners support handling categorical features but may still crash for high-cardinality features if they internally apply encodings that are only suitable for low-cardinality features, such as one-hot encoding. Impact encoding (Micci-Barreca 2001) is a good approach for handling high-cardinality features. Impact encoding converts categorical features into numeric values. The idea behind impact encoding is to use the target feature to create a mapping between the categorical feature and a numerical value that reflects its importance in predicting the target feature. Impact encoding involves the following steps:</span>
<span id="cb267-3622"><a href="#cb267-3622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3623"><a href="#cb267-3623" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Group the target variable by the categorical feature.</span>
<span id="cb267-3624"><a href="#cb267-3624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3625"><a href="#cb267-3625" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Compute the mean of the target variable for each group.</span>
<span id="cb267-3626"><a href="#cb267-3626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3627"><a href="#cb267-3627" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Compute the global mean of the target variable.</span>
<span id="cb267-3628"><a href="#cb267-3628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3629"><a href="#cb267-3629" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Compute the impact score for each group as the difference between the mean of the target variable for the group and the global mean of the target variable.</span>
<span id="cb267-3630"><a href="#cb267-3630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3631"><a href="#cb267-3631" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Replace the categorical feature with the impact scores.</span>
<span id="cb267-3632"><a href="#cb267-3632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3633"><a href="#cb267-3633" aria-hidden="true" tabindex="-1"></a>Impact encoding preserves the information of the categorical feature while also creating a numerical representation that reflects its importance in predicting the target. Compared to one-hot encoding, the main advantage is that only a single numeric feature is created regardless of the number of levels of the categorical features, hence it is especially useful for high-cardinality features. As information from the target is used to compute the impact scores, the encoding process must be embedded in cross-validation to avoid leakage between training and testing data.</span>
<span id="cb267-3634"><a href="#cb267-3634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3635"><a href="#cb267-3635" aria-hidden="true" tabindex="-1"></a>As well as encoding features, other basic preprocessing steps for categorical features include removing constant features (which only have one level and may have been removed as part of data cleaning), and collapsing levels that occur very rarely. These types of problems can occur as artifacts of resampling as the dataset size is further reduced. Stratification on such features would be an alternative way to mitigate this.</span>
<span id="cb267-3636"><a href="#cb267-3636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3637"><a href="#cb267-3637" aria-hidden="true" tabindex="-1"></a>In the code below we use <span class="in">`po("removeconstants")`</span> to remove features with only one level, <span class="in">`po("collapsefactors")`</span> to collapse levels that occur less than 1% of the time in the data, <span class="in">`po("encodeimpact")`</span> to impact-encode high-cardinality features, <span class="in">`po("encode", method = "one-hot")`</span> to one-hot encode low-cardinality features, and finally <span class="in">`po("encode", method = "treatment")`</span> to treatment encode binary features.</span>
<span id="cb267-3638"><a href="#cb267-3638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3639"><a href="#cb267-3639" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 低基数特征可以通过独热编码进行处理。独热编码是一种将分类特征转换为二进制表示的过程，其中每个可能的类别都被表示为一个单独的二进制特征。从理论上讲，只需创建比级别少一个二进制特征就足够了，因为将所有二进制特征都设置为零也是有效的表示。这通常被称为虚拟编码或处理编码，如果学习器是广义线性模型（GLM）或加性模型（GAM），则需要这样的编码。</span></span>
<span id="cb267-3640"><a href="#cb267-3640" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3641"><a href="#cb267-3641" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 有些学习器支持处理分类特征，但如果它们在内部应用的编码仅适用于低基数特征（例如独热编码），则对于高基数特征仍可能出现问题。影响编码（Micci-Barreca 2001）是处理高基数特征的良好方法。影响编码将分类特征转换为数值值。影响编码的背后思想是使用目标特征来创建分类特征与预测目标特征中的重要性之间的映射。影响编码包括以下步骤：</span></span>
<span id="cb267-3642"><a href="#cb267-3642" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3643"><a href="#cb267-3643" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 1. 通过分类特征对目标变量进行分组。</span></span>
<span id="cb267-3644"><a href="#cb267-3644" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3645"><a href="#cb267-3645" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2. 计算每个组的目标变量的平均值。</span></span>
<span id="cb267-3646"><a href="#cb267-3646" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3647"><a href="#cb267-3647" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3. 计算目标变量的全局平均值。</span></span>
<span id="cb267-3648"><a href="#cb267-3648" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3649"><a href="#cb267-3649" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 4. 计算每个组的影响分数，作为该组目标变量平均值与目标变量的全局平均值之间的差异。</span></span>
<span id="cb267-3650"><a href="#cb267-3650" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3651"><a href="#cb267-3651" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5. 用影响分数替换分类特征。</span></span>
<span id="cb267-3652"><a href="#cb267-3652" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3653"><a href="#cb267-3653" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 影响编码在保留分类特征信息的同时，还创建了一个反映其在预测目标中的重要性的数值表示。与独热编码相比，主要优点是无论分类特征的级别数如何多，都只创建一个数值特征，因此特别适用于高基数特征。由于使用了目标变量的信息来计算影响分数，编码过程必须嵌入交叉验证中，以避免训练数据和测试数据之间的信息泄漏。</span></span>
<span id="cb267-3654"><a href="#cb267-3654" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3655"><a href="#cb267-3655" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 除了编码特征，对于分类特征的其他基本预处理步骤包括删除常量特征（只有一个级别的特征，可能已被作为数据清理的一部分删除）和合并很少出现的级别。这些问题可能会出现在通过重采样减小数据集大小时。在这种情况下，对这些特征进行分层抽样可能是缓解的替代方法。</span></span>
<span id="cb267-3656"><a href="#cb267-3656" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3657"><a href="#cb267-3657" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在下面的代码中，我们使用</span><span class="in">`po("removeconstants")`</span><span class="at">来删除只有一个级别的特征，</span><span class="in">`po("collapsefactors")`</span><span class="at">来合并数据中出现不到1%的级别，</span><span class="in">`po("encodeimpact")`</span><span class="at">来对高基数特征进行影响编码，</span><span class="in">`po("encode", method = "one-hot")`</span><span class="at">来独热编码低基数特征，最后使用</span><span class="in">`po("encode", method = "treatment")`</span><span class="at">来处理二元特征。</span></span>
<span id="cb267-3658"><a href="#cb267-3658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3659"><a href="#cb267-3659" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3660"><a href="#cb267-3660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3661"><a href="#cb267-3661" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3662"><a href="#cb267-3662" aria-hidden="true" tabindex="-1"></a>factor_pipeline <span class="ot">=</span> </span>
<span id="cb267-3663"><a href="#cb267-3663" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"removeconstants"</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3664"><a href="#cb267-3664" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"collapsefactors"</span>, <span class="at">no_collapse_above_prevalence =</span> <span class="fl">0.01</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3665"><a href="#cb267-3665" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"encodeimpact"</span>,</span>
<span id="cb267-3666"><a href="#cb267-3666" aria-hidden="true" tabindex="-1"></a>     <span class="at">affect_columns =</span> <span class="fu">selector_cardinality_greater_than</span>(<span class="dv">10</span>),</span>
<span id="cb267-3667"><a href="#cb267-3667" aria-hidden="true" tabindex="-1"></a>     <span class="at">id =</span> <span class="st">"high_card_enc"</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3668"><a href="#cb267-3668" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"encode"</span>, <span class="at">method =</span> <span class="st">"one-hot"</span>,</span>
<span id="cb267-3669"><a href="#cb267-3669" aria-hidden="true" tabindex="-1"></a>     <span class="at">affect_columns =</span> <span class="fu">selector_cardinality_greater_than</span>(<span class="dv">2</span>),</span>
<span id="cb267-3670"><a href="#cb267-3670" aria-hidden="true" tabindex="-1"></a>     <span class="at">id =</span> <span class="st">"low_card_enc"</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3671"><a href="#cb267-3671" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"encode"</span>, <span class="at">method =</span> <span class="st">"treatment"</span>,</span>
<span id="cb267-3672"><a href="#cb267-3672" aria-hidden="true" tabindex="-1"></a>     <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"factor"</span>), <span class="at">id =</span> <span class="st">"binary_enc"</span>)</span>
<span id="cb267-3673"><a href="#cb267-3673" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3674"><a href="#cb267-3674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3675"><a href="#cb267-3675" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3676"><a href="#cb267-3676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3677"><a href="#cb267-3677" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3678"><a href="#cb267-3678" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3679"><a href="#cb267-3679" aria-hidden="true" tabindex="-1"></a>glrn_xgb_impact <span class="ot">=</span> <span class="fu">as_learner</span>(factor_pipeline <span class="sc">%&gt;&gt;%</span> lrn_xgb)</span>
<span id="cb267-3680"><a href="#cb267-3680" aria-hidden="true" tabindex="-1"></a>glrn_xgb_impact<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"XGB_enc_impact"</span></span>
<span id="cb267-3681"><a href="#cb267-3681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3682"><a href="#cb267-3682" aria-hidden="true" tabindex="-1"></a>glrn_xgb_one_hot <span class="ot">=</span> <span class="fu">as_learner</span>(<span class="fu">po</span>(<span class="st">"encode"</span>) <span class="sc">%&gt;&gt;%</span> lrn_xgb)</span>
<span id="cb267-3683"><a href="#cb267-3683" aria-hidden="true" tabindex="-1"></a>glrn_xgb_one_hot<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"XGB_enc_onehot"</span></span>
<span id="cb267-3684"><a href="#cb267-3684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3685"><a href="#cb267-3685" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(</span>
<span id="cb267-3686"><a href="#cb267-3686" aria-hidden="true" tabindex="-1"></a>  <span class="fu">benchmark_grid</span>(tsk_ames,</span>
<span id="cb267-3687"><a href="#cb267-3687" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">list</span>(lrn_baseline, glrn_xgb_impact, glrn_xgb_one_hot),</span>
<span id="cb267-3688"><a href="#cb267-3688" aria-hidden="true" tabindex="-1"></a>                 rsmp_cv3)</span>
<span id="cb267-3689"><a href="#cb267-3689" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-3690"><a href="#cb267-3690" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3691"><a href="#cb267-3691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3692"><a href="#cb267-3692" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3693"><a href="#cb267-3693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3694"><a href="#cb267-3694" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3695"><a href="#cb267-3695" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(msr_mae)[, .(learner_id, regr.mae)]</span>
<span id="cb267-3696"><a href="#cb267-3696" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3697"><a href="#cb267-3697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3698"><a href="#cb267-3698" aria-hidden="true" tabindex="-1"></a><span class="fu">## Missing Values {#sec-preprocessing-missing}</span></span>
<span id="cb267-3699"><a href="#cb267-3699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3700"><a href="#cb267-3700" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3701"><a href="#cb267-3701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3702"><a href="#cb267-3702" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3703"><a href="#cb267-3703" aria-hidden="true" tabindex="-1"></a><span class="co"># print first five with missing data</span></span>
<span id="cb267-3704"><a href="#cb267-3704" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(<span class="fu">which</span>(tsk_ames<span class="sc">$</span><span class="fu">missings</span>() <span class="sc">&gt;</span> <span class="dv">0</span>))[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb267-3705"><a href="#cb267-3705" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3706"><a href="#cb267-3706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3707"><a href="#cb267-3707" aria-hidden="true" tabindex="-1"></a>The simplest data imputation method is to replace missing values by the feature’s mean <span class="in">`(po("imputemean")`</span>), median (<span class="in">`po("imputemedian")`</span>), or mode (<span class="in">`po("imputemode")`</span>). Alternatively, one can impute by sampling from the empirical distribution of the feature, for example a histogram (<span class="in">`po("imputehist")`</span>). Instead of guessing at what a missing feature might be, missing values could instead be replaced by a new level, for example, called <span class="in">`.MISSING`</span> (<span class="in">`po("imputeoor")`</span>). For numeric features, Ding and Simonoff (2010) show that for binary classification and tree-based models, encoding missing values out-of-range (OOR), e.g. a constant value above the largest observed value, is a reasonable approach.</span>
<span id="cb267-3708"><a href="#cb267-3708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3709"><a href="#cb267-3709" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 最简单的数据插补方法是用特征的均值（</span><span class="in">`po("imputemean")`</span><span class="at">），中位数（</span><span class="in">`po("imputemedian")`</span><span class="at">）或众数（</span><span class="in">`po("imputemode")`</span><span class="at">）来替代缺失值。另外，也可以通过从特征的经验分布中进行采样，例如使用直方图（</span><span class="in">`po("imputehist")`</span><span class="at">）。与猜测缺失特征可能是什么不同，缺失值可以被替换为一个新级别，例如称为</span><span class="in">`.MISSING`</span><span class="at">~（</span><span class="in">`po("imputeoor")`</span><span class="at">）。对于数值特征，Ding和Simonoff（2010）表明，对于二元分类和基于树的模型，编码超出范围（OOR）的缺失值，例如，一个大于观察到的最大值的常数值，是一个合理的方法。</span></span>
<span id="cb267-3710"><a href="#cb267-3710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3711"><a href="#cb267-3711" aria-hidden="true" tabindex="-1"></a>It is often important for predictive tasks that you keep track of missing data as it is common for missing data to be informative in itself. To preserve the information about which data was missing, imputation should be tracked by adding binary indicator features (one for each imputed feature) that are <span class="in">`1`</span> if the feature was missing for an observation and <span class="in">`0`</span> if it was present (<span class="in">`po("missind")`</span>). It is important to note that recording this information will not prevent problems in model interpretation on its own. As a real-world example, medical data are typically collected more extensively for White communities than for racially minoritized communities. Imputing data from minoritized communities would at best mask this data bias, and at worst would make the data bias even worse by making vastly inaccurate assumptions (see Chapter 14 for data bias and algorithmic fairness).</span>
<span id="cb267-3712"><a href="#cb267-3712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3713"><a href="#cb267-3713" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 对于预测任务来说，跟踪缺失数据通常很重要，因为缺失数据本身常常包含有信息。为了保留有关哪些数据缺失的信息，插补应该通过添加二进制指示特征来进行跟踪（每个插补特征都有一个），如果观察中的特征缺失，则该特征为</span><span class="in">`1`</span><span class="at">，如果存在则为</span><span class="in">`0`</span><span class="at">（</span><span class="in">`po("missind")`</span><span class="at">）。需要注意的是，仅记录这些信息本身不会防止模型解释方面的问题。以现实世界的例子来说，医疗数据通常对白人社区进行的收集要比对少数民族社区进行的收集要详尽。从少数民族社区插补数据最多会掩盖数据偏差，最坏的情况下会通过进行极其不准确的假设而使数据偏差变得更严重（请参见第14章关于数据偏差和算法公平性的内容）。</span></span>
<span id="cb267-3714"><a href="#cb267-3714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3715"><a href="#cb267-3715" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3716"><a href="#cb267-3716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3717"><a href="#cb267-3717" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3718"><a href="#cb267-3718" aria-hidden="true" tabindex="-1"></a>impute_hist <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb267-3719"><a href="#cb267-3719" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"missind"</span>, <span class="at">type =</span> <span class="st">"integer"</span>,</span>
<span id="cb267-3720"><a href="#cb267-3720" aria-hidden="true" tabindex="-1"></a>     <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"integer"</span>)),</span>
<span id="cb267-3721"><a href="#cb267-3721" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"imputehist"</span>, <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"integer"</span>))</span>
<span id="cb267-3722"><a href="#cb267-3722" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3723"><a href="#cb267-3723" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"featureunion"</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb267-3724"><a href="#cb267-3724" aria-hidden="true" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">"imputeoor"</span>, <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"factor"</span>))</span>
<span id="cb267-3725"><a href="#cb267-3725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3726"><a href="#cb267-3726" aria-hidden="true" tabindex="-1"></a>impute_hist<span class="sc">$</span><span class="fu">plot</span>(<span class="at">horizontal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb267-3727"><a href="#cb267-3727" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3728"><a href="#cb267-3728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3729"><a href="#cb267-3729" aria-hidden="true" tabindex="-1"></a>Using this pipeline we can now run experiments with <span class="in">`lrn("regr.ranger")`</span>, which cannot handle missing data; we also compare a simpler pipeline that only uses OOR imputation to demonstrate performance differences resulting from different strategies.</span>
<span id="cb267-3730"><a href="#cb267-3730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3731"><a href="#cb267-3731" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3732"><a href="#cb267-3732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3733"><a href="#cb267-3733" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3734"><a href="#cb267-3734" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3735"><a href="#cb267-3735" aria-hidden="true" tabindex="-1"></a>glrn_rf_impute_hist <span class="ot">=</span> <span class="fu">as_learner</span>(impute_hist <span class="sc">%&gt;&gt;%</span> <span class="fu">lrn</span>(<span class="st">"regr.ranger"</span>))</span>
<span id="cb267-3736"><a href="#cb267-3736" aria-hidden="true" tabindex="-1"></a>glrn_rf_impute_hist<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"RF_imp_Hist"</span></span>
<span id="cb267-3737"><a href="#cb267-3737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3738"><a href="#cb267-3738" aria-hidden="true" tabindex="-1"></a>glrn_rf_impute_oor <span class="ot">=</span> <span class="fu">as_learner</span>(<span class="fu">po</span>(<span class="st">"imputeoor"</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">lrn</span>(<span class="st">"regr.ranger"</span>))</span>
<span id="cb267-3739"><a href="#cb267-3739" aria-hidden="true" tabindex="-1"></a>glrn_rf_impute_oor<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"RF_imp_OOR"</span></span>
<span id="cb267-3740"><a href="#cb267-3740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3741"><a href="#cb267-3741" aria-hidden="true" tabindex="-1"></a>design <span class="ot">=</span> <span class="fu">benchmark_grid</span>(tsk_ames,</span>
<span id="cb267-3742"><a href="#cb267-3742" aria-hidden="true" tabindex="-1"></a>                        <span class="fu">list</span>(glrn_rf_impute_hist, glrn_rf_impute_oor),</span>
<span id="cb267-3743"><a href="#cb267-3743" aria-hidden="true" tabindex="-1"></a>                             rsmp_cv3)</span>
<span id="cb267-3744"><a href="#cb267-3744" aria-hidden="true" tabindex="-1"></a>bmr_new <span class="ot">=</span> <span class="fu">benchmark</span>(design)</span>
<span id="cb267-3745"><a href="#cb267-3745" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3746"><a href="#cb267-3746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3747"><a href="#cb267-3747" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3748"><a href="#cb267-3748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3749"><a href="#cb267-3749" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3750"><a href="#cb267-3750" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">combine</span>(bmr_new)</span>
<span id="cb267-3751"><a href="#cb267-3751" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(msr_mae)[, .(learner_id, regr.mae)]</span>
<span id="cb267-3752"><a href="#cb267-3752" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3753"><a href="#cb267-3753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3754"><a href="#cb267-3754" aria-hidden="true" tabindex="-1"></a>Similarly to encoding, we see limited differences in performance between the different imputation strategies. This is expected here and confirms the findings of Ding and Simonoff (2010) – out-of-range imputation is a simple yet effective imputation for tree-based methods.</span>
<span id="cb267-3755"><a href="#cb267-3755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3756"><a href="#cb267-3756" aria-hidden="true" tabindex="-1"></a>Many more advanced imputation strategies exist, including model-based imputation where machine learning models are used to predict missing values, and multiple imputation where data is repeatedly resampled and imputed in each sample (e.g., by mean imputation) to attain more robust estimates. However, these more advanced techniques rarely improve the models predictive performance substantially and the simple imputation techniques introduced above are usually sufficient (Poulos and Valle 2018). Nevertheless, these methods are still important, as finding imputations that fit well to the distribution of the observed values allows a model to be fitted that can be interpreted and analyzed in a second step.</span>
<span id="cb267-3757"><a href="#cb267-3757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3758"><a href="#cb267-3758" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 与编码类似，我们在不同的插补策略之间看到了有限的性能差异。这在这里是预期的，并证实了Ding和Simonoff（2010）的研究结果 - 超出范围插补是树模型方法的一种简单而有效的插补方法。</span></span>
<span id="cb267-3759"><a href="#cb267-3759" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3760"><a href="#cb267-3760" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 还存在许多更高级的插补策略，包括基于模型的插补，其中使用机器学习模型来预测缺失值，以及多重插补，其中数据被重复重采样并在每个样本中进行插补（例如，通过均值插补），以获得更稳健的估计。然而，这些更高级的技术很少会显着改善模型的预测性能，上面介绍的简单插补技术通常已经足够了（Poulos和Valle 2018）。尽管如此，这些方法仍然很重要，因为找到与观测值的分布很好匹配的插补允许拟合一个可以在第二步中进行解释和分析的模型。</span></span>
<span id="cb267-3761"><a href="#cb267-3761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3762"><a href="#cb267-3762" aria-hidden="true" tabindex="-1"></a><span class="fu">## Pipeline Robustify</span></span>
<span id="cb267-3763"><a href="#cb267-3763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3764"><a href="#cb267-3764" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3pipelines`</span> offers a simple and reusable pipeline for (among other things) imputation and factor encoding called <span class="in">`ppl("robustify")`</span>, which includes sensible defaults that can be used most of the time when encoding or imputing data. The pipeline includes the following <span class="in">`PipeOp`</span>s (some are applied multiple times and most use selectors):</span>
<span id="cb267-3765"><a href="#cb267-3765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3766"><a href="#cb267-3766" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("removeconstants")`</span> – Constant features are removed.</span>
<span id="cb267-3767"><a href="#cb267-3767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3768"><a href="#cb267-3768" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("colapply")`</span> – Character and ordinal features are encoded as categorical, and date/time features are encoded as numeric.</span>
<span id="cb267-3769"><a href="#cb267-3769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3770"><a href="#cb267-3770" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("imputehist")`</span> – Numeric features are imputed by histogram sampling.</span>
<span id="cb267-3771"><a href="#cb267-3771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3772"><a href="#cb267-3772" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("imputesample")`</span> – Logical features are imputed by sampling from the empirical distribution – this only affects the <span class="in">`$predict()`</span>-step.</span>
<span id="cb267-3773"><a href="#cb267-3773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3774"><a href="#cb267-3774" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("missind")`</span> – Missing data indicators are added for imputed numeric and logical variables.</span>
<span id="cb267-3775"><a href="#cb267-3775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3776"><a href="#cb267-3776" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("imputeoor")`</span> – Missing values of categorical features are encoded with a new level.</span>
<span id="cb267-3777"><a href="#cb267-3777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3778"><a href="#cb267-3778" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("fixfactors")`</span> – Fixes levels of categorical features such that the same levels are present during prediction and training (which may involve dropping empty factor levels).</span>
<span id="cb267-3779"><a href="#cb267-3779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3780"><a href="#cb267-3780" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("imputesample")`</span> – Missing values in categorical features introduced from dropping levels in the previous step are imputed by sampling from the empirical distributions.</span>
<span id="cb267-3781"><a href="#cb267-3781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3782"><a href="#cb267-3782" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("collapsefactors")`</span> – Categorical features levels are collapsed (starting from the rarest factors in the training data) until there are less than a certan number of levels, controlled by the <span class="in">`max_cardinality`</span> argument (with a conservative default of <span class="in">`1000`</span>).</span>
<span id="cb267-3783"><a href="#cb267-3783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3784"><a href="#cb267-3784" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("encode")`</span> – Categorical features are one-hot encoded.</span>
<span id="cb267-3785"><a href="#cb267-3785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3786"><a href="#cb267-3786" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`po("removeconstants")`</span> – Constant features that might have been created in the previous steps are removed.</span>
<span id="cb267-3787"><a href="#cb267-3787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3788"><a href="#cb267-3788" aria-hidden="true" tabindex="-1"></a><span class="in">`ppl("robustify")`</span> has optional arguments <span class="in">`task`</span> and <span class="in">`learner`</span>. If these are provided, then the resulting pipeline will be set up to handle the given task and learner specifically, for example, it will not impute missing values if the learner has the <span class="in">`"missings"`</span> property, or if there are no missing values in the task to begin with. By default, when <span class="in">`task`</span> and <span class="in">`learner`</span> are not provided, the graph is set up to be defensive: it imputes all missing values and converts all feature types to numerics.</span>
<span id="cb267-3789"><a href="#cb267-3789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3790"><a href="#cb267-3790" aria-hidden="true" tabindex="-1"></a>Linear regression is a simple model that cannot handle most problems that we may face when processing data, but with the <span class="in">`ppl("robustify")`</span> we can now include it in our experiment:</span>
<span id="cb267-3791"><a href="#cb267-3791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3792"><a href="#cb267-3792" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`mlr3pipelines`</span><span class="at">提供了一个用于插补和因子编码（以及其他任务）的简单且可重复使用的管道，称为</span><span class="in">`ppl("robustify")`</span><span class="at">，其中包括了通常在对数据进行编码或插补时可使用的明智默认设置。该管道包括以下</span><span class="in">`PipeOp`</span><span class="at">（一些被多次应用，大多数使用选择器）：</span></span>
<span id="cb267-3793"><a href="#cb267-3793" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3794"><a href="#cb267-3794" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 1. </span><span class="in">`po("removeconstants")`</span><span class="at"> - 删除常量特征。</span></span>
<span id="cb267-3795"><a href="#cb267-3795" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3796"><a href="#cb267-3796" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2. </span><span class="in">`po("colapply")`</span><span class="at"> - 字符和序数特征被编码为分类特征，日期/时间特征被编码为数值特征。</span></span>
<span id="cb267-3797"><a href="#cb267-3797" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3798"><a href="#cb267-3798" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3. </span><span class="in">`po("imputehist")`</span><span class="at"> - 通过直方图采样对数值特征进行插补。</span></span>
<span id="cb267-3799"><a href="#cb267-3799" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3800"><a href="#cb267-3800" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 4. </span><span class="in">`po("imputesample")`</span><span class="at"> - 通过从经验分布中进行采样对逻辑特征进行插补 - 这仅影响</span><span class="in">`$predict()`</span><span class="at">步骤。</span></span>
<span id="cb267-3801"><a href="#cb267-3801" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3802"><a href="#cb267-3802" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5. </span><span class="in">`po("missind")`</span><span class="at"> - 为被插补的数值和逻辑变量添加缺失数据指示。</span></span>
<span id="cb267-3803"><a href="#cb267-3803" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3804"><a href="#cb267-3804" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 6. </span><span class="in">`po("imputeoor")`</span><span class="at"> - 使用新级别编码分类特征的缺失值。</span></span>
<span id="cb267-3805"><a href="#cb267-3805" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3806"><a href="#cb267-3806" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 7. </span><span class="in">`po("fixfactors")`</span><span class="at"> - 修复分类特征的级别，以便在预测和训练期间存在相同的级别（这可能涉及删除空的因子级别）。</span></span>
<span id="cb267-3807"><a href="#cb267-3807" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3808"><a href="#cb267-3808" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 8. </span><span class="in">`po("imputesample")`</span><span class="at"> - 通过从经验分布中进行采样来插补在前一步中删除级别引入的分类特征的缺失值。</span></span>
<span id="cb267-3809"><a href="#cb267-3809" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3810"><a href="#cb267-3810" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 9. </span><span class="in">`po("collapsefactors")`</span><span class="at"> - 折叠分类特征级别（从训练数据中最稀有的因子开始），直到级别少于由</span><span class="in">`max_cardinality`</span><span class="at">参数控制的某个数量（默认值为</span><span class="in">`1000`</span><span class="at">，具有保守性）。</span></span>
<span id="cb267-3811"><a href="#cb267-3811" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3812"><a href="#cb267-3812" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 10. </span><span class="in">`po("encode")`</span><span class="at"> - 对分类特征进行独热编码。</span></span>
<span id="cb267-3813"><a href="#cb267-3813" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3814"><a href="#cb267-3814" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 11. </span><span class="in">`po("removeconstants")`</span><span class="at"> - 删除可能在前一步中创建的常量特征。</span></span>
<span id="cb267-3815"><a href="#cb267-3815" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3816"><a href="#cb267-3816" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="in">`ppl("robustify")`</span><span class="at">具有可选参数</span><span class="in">`task`</span><span class="at">和</span><span class="in">`learner`</span><span class="at">。如果提供了这些参数，那么生成的管道将被设置为专门处理给定的任务和学习器，例如，如果学习器具有</span><span class="in">`"missings"`</span><span class="at">属性，或者任务一开始就没有缺失值，那么它将不会插补缺失值。默认情况下，当未提供</span><span class="in">`task`</span><span class="at">和</span><span class="in">`learner`</span><span class="at">时，图形被设置为具有防御性：它会对所有缺失值进行插补并将所有特征类型转换为数值型。</span></span>
<span id="cb267-3817"><a href="#cb267-3817" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3818"><a href="#cb267-3818" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 线性回归是一个简单的模型，无法处理我们在处理数据时可能面临的大多数问题，但使用</span><span class="in">`ppl("robustify")`</span><span class="at">，我们现在可以将它包括在我们的实验中。</span></span>
<span id="cb267-3819"><a href="#cb267-3819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3820"><a href="#cb267-3820" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3821"><a href="#cb267-3821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3822"><a href="#cb267-3822" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3823"><a href="#cb267-3823" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3824"><a href="#cb267-3824" aria-hidden="true" tabindex="-1"></a>glrn_lm_robust <span class="ot">=</span> <span class="fu">as_learner</span>(<span class="fu">ppl</span>(<span class="st">"robustify"</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">lrn</span>(<span class="st">"regr.lm"</span>))</span>
<span id="cb267-3825"><a href="#cb267-3825" aria-hidden="true" tabindex="-1"></a>glrn_lm_robust<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"lm_roubst"</span></span>
<span id="cb267-3826"><a href="#cb267-3826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3827"><a href="#cb267-3827" aria-hidden="true" tabindex="-1"></a>bmr_new <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_ames, glrn_lm_robust, rsmp_cv3))</span>
<span id="cb267-3828"><a href="#cb267-3828" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3829"><a href="#cb267-3829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3830"><a href="#cb267-3830" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3831"><a href="#cb267-3831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3832"><a href="#cb267-3832" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3833"><a href="#cb267-3833" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">combine</span>(bmr_new)</span>
<span id="cb267-3834"><a href="#cb267-3834" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(msr_mae)[, .(learner_id, regr.mae)]</span>
<span id="cb267-3835"><a href="#cb267-3835" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3836"><a href="#cb267-3836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3837"><a href="#cb267-3837" aria-hidden="true" tabindex="-1"></a><span class="fu">## Transforming Features and Targets</span></span>
<span id="cb267-3838"><a href="#cb267-3838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3839"><a href="#cb267-3839" aria-hidden="true" tabindex="-1"></a>Simple transformations of features and the target can be beneficial (and sometimes essential) for certain learners. In particular, log transformation of the target can help in making the distribution more symmetrical and can help reduce the impact of outliers. Similarly, log transformation of skewed features can help to reduce the influence of outliers. </span>
<span id="cb267-3840"><a href="#cb267-3840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3841"><a href="#cb267-3841" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 对于某些学习算法，对特征和目标进行简单的转换可能是有益的（有时甚至是必不可少的）。特别是，对目标进行对数转换有助于使分布更对称，可以帮助减小异常值的影响。同样，对偏斜特征进行对数转换可以帮助减少异常值的影响。</span></span>
<span id="cb267-3842"><a href="#cb267-3842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3843"><a href="#cb267-3843" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3844"><a href="#cb267-3844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3845"><a href="#cb267-3845" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3846"><a href="#cb267-3846" aria-hidden="true" tabindex="-1"></a><span class="co"># copy ames data</span></span>
<span id="cb267-3847"><a href="#cb267-3847" aria-hidden="true" tabindex="-1"></a>log_ames <span class="ot">=</span> <span class="fu">copy</span>(ames)</span>
<span id="cb267-3848"><a href="#cb267-3848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3849"><a href="#cb267-3849" aria-hidden="true" tabindex="-1"></a><span class="co"># log transform target</span></span>
<span id="cb267-3850"><a href="#cb267-3850" aria-hidden="true" tabindex="-1"></a>log_ames[, logSalePrice <span class="sc">:</span><span class="er">=</span> <span class="fu">log</span>(Sale_Price)]</span>
<span id="cb267-3851"><a href="#cb267-3851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3852"><a href="#cb267-3852" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(<span class="fu">as_task_regr</span>(log_ames, <span class="at">target =</span> <span class="st">"Sale_Price"</span>)) <span class="sc">+</span></span>
<span id="cb267-3853"><a href="#cb267-3853" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(<span class="fu">as_task_regr</span>(log_ames, <span class="at">target =</span> <span class="st">"logSalePrice"</span>))</span>
<span id="cb267-3854"><a href="#cb267-3854" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3855"><a href="#cb267-3855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3856"><a href="#cb267-3856" aria-hidden="true" tabindex="-1"></a>Normalization of features may also be necessary to ensure features with a larger scale do not have a higher impact, which is especially important for distance-based methods such as k-nearest neighbors models or regularized parametric models such as Lasso or Elastic net. Many models internally scale the data if required by the algorithm so most of the time we do not need to manually do this in preprocessing, though if this is required then <span class="in">`po("scale")`</span> can be used to center and scale numeric features.</span>
<span id="cb267-3857"><a href="#cb267-3857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3858"><a href="#cb267-3858" aria-hidden="true" tabindex="-1"></a>Any transformations applied to the target during training must be inverted during model prediction to ensure predictions are made on the correct scale.</span>
<span id="cb267-3859"><a href="#cb267-3859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3860"><a href="#cb267-3860" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 对特征进行归一化可能也是必要的，以确保具有较大尺度的特征不会产生较大影响，这对于基于距离的方法（例如k最近邻模型）或正则化参数模型（例如Lasso或弹性网络）尤为重要。许多模型在算法需要时会自动对数据进行内部缩放，因此在预处理过程中通常不需要手动进行此操作，但如果需要的话，可以使用</span><span class="in">`po("scale")`</span><span class="at">来对数值特征进行居中和缩放。</span></span>
<span id="cb267-3861"><a href="#cb267-3861" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3862"><a href="#cb267-3862" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在训练期间应用于目标的任何转换在模型预测期间必须被反转，以确保在正确的尺度上进行预测。</span></span>
<span id="cb267-3863"><a href="#cb267-3863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3864"><a href="#cb267-3864" aria-hidden="true" tabindex="-1"></a>We could manually transform and invert the target, however, this is much more complex when dealing with resampling and benchmarking experiments and so the pipeline <span class="in">`ppl("targettrafo")`</span> will do this heavy lifting for you. The pipeline includes a parameter <span class="in">`targetmutate.trafo`</span> for the transformation to be applied during training to the target, as well as <span class="in">`targetmutate.inverter`</span> for the transformation to be applied to invert the original transformation during prediction. So now let us consider the log transformation by adding this pipeline to our robust linear regression model:</span>
<span id="cb267-3865"><a href="#cb267-3865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3866"><a href="#cb267-3866" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ]我们可以手动转换和反转目标变量，但是在处理重新采样和基准实验时，这会变得更加复杂。因此，管道</span><span class="in">`ppl("targettrafo")`</span><span class="at">将为您完成这项繁重的工作。该管道包括一个名为</span><span class="in">`targetmutate.trafo`</span><span class="at">的参数，用于在训练期间对目标变量应用的转换，以及一个名为</span><span class="in">`targetmutate.inverter`</span><span class="at">的参数，用于在预测时反转原始转换。现在让我们考虑通过将这个管道添加到我们的鲁棒线性回归模型中来进行对数变换：</span></span>
<span id="cb267-3867"><a href="#cb267-3867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3868"><a href="#cb267-3868" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3869"><a href="#cb267-3869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3870"><a href="#cb267-3870" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3871"><a href="#cb267-3871" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3872"><a href="#cb267-3872" aria-hidden="true" tabindex="-1"></a>glrn_log_lm_robust <span class="ot">=</span> <span class="fu">as_learner</span>(</span>
<span id="cb267-3873"><a href="#cb267-3873" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ppl</span>(<span class="st">"targettrafo"</span>,</span>
<span id="cb267-3874"><a href="#cb267-3874" aria-hidden="true" tabindex="-1"></a>  <span class="at">graph =</span> glrn_lm_robust,</span>
<span id="cb267-3875"><a href="#cb267-3875" aria-hidden="true" tabindex="-1"></a>  <span class="at">targetmutate.trafo =</span> \(x) <span class="fu">log</span>(x),</span>
<span id="cb267-3876"><a href="#cb267-3876" aria-hidden="true" tabindex="-1"></a>  <span class="at">targetmutate.inverter =</span> \(x) <span class="fu">list</span>(<span class="at">response =</span> <span class="fu">exp</span>(x<span class="sc">$</span>response))</span>
<span id="cb267-3877"><a href="#cb267-3877" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb267-3878"><a href="#cb267-3878" aria-hidden="true" tabindex="-1"></a>glrn_log_lm_robust<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"lm_robust_logtrafo"</span></span>
<span id="cb267-3879"><a href="#cb267-3879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3880"><a href="#cb267-3880" aria-hidden="true" tabindex="-1"></a>bmr_new <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_ames, glrn_log_lm_robust, rsmp_cv3))</span>
<span id="cb267-3881"><a href="#cb267-3881" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3882"><a href="#cb267-3882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3883"><a href="#cb267-3883" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3884"><a href="#cb267-3884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3885"><a href="#cb267-3885" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3886"><a href="#cb267-3886" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">combine</span>(bmr_new)</span>
<span id="cb267-3887"><a href="#cb267-3887" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(msr_mae)[, .(learner_id, regr.mae)]</span>
<span id="cb267-3888"><a href="#cb267-3888" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3889"><a href="#cb267-3889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3890"><a href="#cb267-3890" aria-hidden="true" tabindex="-1"></a>With the target transformation and the <span class="in">`ppl("robustify")`</span>, the simple linear regression now appears to be the best-performing model.</span>
<span id="cb267-3891"><a href="#cb267-3891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3892"><a href="#cb267-3892" aria-hidden="true" tabindex="-1"></a><span class="fu">## Functional Feature Extraction</span></span>
<span id="cb267-3893"><a href="#cb267-3893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3894"><a href="#cb267-3894" aria-hidden="true" tabindex="-1"></a>As a final step of data preprocessing, we will look at feature extraction from functional features. In Chapter 6 we look at automated feature selection and how automated approaches with filters and wrappers can be used to reduce a dataset to an optimized set of features. Functional feature extraction differs from this process as we are now interested in features that are dependent on one another and together may provide useful information but not individually. Figure 9.4 visualizes the difference between regular and functional features.</span>
<span id="cb267-3895"><a href="#cb267-3895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3896"><a href="#cb267-3896" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 作为数据预处理的最后一步，我们将看一下从功能性特征中提取特征。我们探讨了自动特征选择以及如何使用过滤器和包装器的自动方法来将数据集减少到一组优化的特征。功能性特征提取与此过程不同，因为我们现在关注的是彼此依赖的特征，它们共同可能提供有用的信息，但单独来看则不具备这种信息。</span></span>
<span id="cb267-3897"><a href="#cb267-3897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3898"><a href="#cb267-3898" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3899"><a href="#cb267-3899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3900"><a href="#cb267-3900" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3901"><a href="#cb267-3901" aria-hidden="true" tabindex="-1"></a>energy_data <span class="ot">=</span> mlr3data<span class="sc">::</span>energy_usage</span>
<span id="cb267-3902"><a href="#cb267-3902" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3903"><a href="#cb267-3903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3904"><a href="#cb267-3904" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3905"><a href="#cb267-3905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3906"><a href="#cb267-3906" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3907"><a href="#cb267-3907" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">y =</span> <span class="fu">as.numeric</span>(energy_data[<span class="dv">1</span>, ])),</span>
<span id="cb267-3908"><a href="#cb267-3908" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">720</span>)) <span class="sc">+</span></span>
<span id="cb267-3909"><a href="#cb267-3909" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb267-3910"><a href="#cb267-3910" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"2-Minute Interval"</span>, <span class="at">y =</span> <span class="st">"Power Consumption"</span>)</span>
<span id="cb267-3911"><a href="#cb267-3911" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3912"><a href="#cb267-3912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3913"><a href="#cb267-3913" aria-hidden="true" tabindex="-1"></a>Adding these 720 features to our full dataset is a bad idea as each individual feature does not provide meaningful information, similarly, we cannot automate selection of the best feature subset for the same reason. Instead, we can extract information about the curves to gain insights into the kitchen’s overall energy usage. For example, we could extract the maximum used wattage, overall used wattage, number of peaks, and other similar features.</span>
<span id="cb267-3914"><a href="#cb267-3914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3915"><a href="#cb267-3915" aria-hidden="true" tabindex="-1"></a>To extract features we will write our own <span class="in">`PipeOp`</span> that inherits from <span class="in">`PipeOpTaskPreprocSimple`</span>. To do this we add a private method called <span class="in">`.transform_dt`</span> that hardcodes the operations in our task. In this example, we select the functional features (which all start with “att”), extract the mean, minimum, maximum, and variance of the power consumption, and then remove the functional features. To read more about building custom PipeOps, open the corresponding vignette by running vignette("extending", package = "mlr3pipelines") in R.</span>
<span id="cb267-3916"><a href="#cb267-3916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3917"><a href="#cb267-3917" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 将这720个特征添加到我们的完整数据集中是一个不好的主意，因为每个单独的特征并不提供有意义的信息，同样，由于同样的原因，我们也不能自动选择最佳的特征子集。相反，我们可以提取有关曲线的信息，以了解厨房整体能源使用情况。例如，我们可以提取最大功率使用量、总体功率使用量、峰值数量等类似的特征。</span></span>
<span id="cb267-3918"><a href="#cb267-3918" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3919"><a href="#cb267-3919" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 为了提取特征，我们将编写一个继承自</span><span class="in">`PipeOpTaskPreprocSimple`</span><span class="at">的自定义</span><span class="in">`PipeOp`</span><span class="at">。为此，我们添加一个名为</span><span class="in">`.transform_dt`</span><span class="at">的私有方法，其中包含我们任务中硬编码的操作。在这个例子中，我们选择功能性特征（它们都以“att”开头），提取功耗的均值、最小值、最大值和方差，然后删除功能性特征。要了解更多关于构建自定义</span><span class="in">`PipeOps`</span><span class="at">的信息，请在R中运行</span><span class="in">`vignette("extending", package = "mlr3pipelines")`</span><span class="at">以打开相应的文档。</span></span>
<span id="cb267-3920"><a href="#cb267-3920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3921"><a href="#cb267-3921" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3922"><a href="#cb267-3922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3923"><a href="#cb267-3923" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3924"><a href="#cb267-3924" aria-hidden="true" tabindex="-1"></a>PipeOpFuncExtract <span class="ot">=</span> R6<span class="sc">::</span><span class="fu">R6Class</span>(</span>
<span id="cb267-3925"><a href="#cb267-3925" aria-hidden="true" tabindex="-1"></a>  <span class="st">"PipeOpFuncExtract"</span>,</span>
<span id="cb267-3926"><a href="#cb267-3926" aria-hidden="true" tabindex="-1"></a>  <span class="at">inherit =</span> mlr3pipelines<span class="sc">::</span>PipeOpTaskPreprocSimple,</span>
<span id="cb267-3927"><a href="#cb267-3927" aria-hidden="true" tabindex="-1"></a>  <span class="at">private =</span> <span class="fu">list</span>(</span>
<span id="cb267-3928"><a href="#cb267-3928" aria-hidden="true" tabindex="-1"></a>    <span class="at">.transform_dt =</span> <span class="cf">function</span>(dt, levels) {</span>
<span id="cb267-3929"><a href="#cb267-3929" aria-hidden="true" tabindex="-1"></a>      ffeat_names <span class="ot">=</span> <span class="fu">paste0</span>(<span class="st">"att"</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">720</span>)</span>
<span id="cb267-3930"><a href="#cb267-3930" aria-hidden="true" tabindex="-1"></a>      ffeats <span class="ot">=</span> dt[, ..ffeat_names]</span>
<span id="cb267-3931"><a href="#cb267-3931" aria-hidden="true" tabindex="-1"></a>      dt[, energy_means <span class="sc">:</span><span class="er">=</span> <span class="fu">apply</span>(ffeats, <span class="dv">1</span>, mean)]</span>
<span id="cb267-3932"><a href="#cb267-3932" aria-hidden="true" tabindex="-1"></a>      dt[, energy_mins <span class="sc">:</span><span class="er">=</span> <span class="fu">apply</span>(ffeats, <span class="dv">1</span>, min)]</span>
<span id="cb267-3933"><a href="#cb267-3933" aria-hidden="true" tabindex="-1"></a>      dt[, energy_maxs <span class="sc">:</span><span class="er">=</span> <span class="fu">apply</span>(ffeats, <span class="dv">1</span>, max)]</span>
<span id="cb267-3934"><a href="#cb267-3934" aria-hidden="true" tabindex="-1"></a>      dt[, energy_vars <span class="sc">:</span><span class="er">=</span> <span class="fu">apply</span>(ffeats, <span class="dv">1</span>, var)]</span>
<span id="cb267-3935"><a href="#cb267-3935" aria-hidden="true" tabindex="-1"></a>      dt[, (ffeat_names) <span class="sc">:</span><span class="er">=</span> <span class="cn">NULL</span>]</span>
<span id="cb267-3936"><a href="#cb267-3936" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb267-3937"><a href="#cb267-3937" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb267-3938"><a href="#cb267-3938" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb267-3939"><a href="#cb267-3939" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3940"><a href="#cb267-3940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3941"><a href="#cb267-3941" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3942"><a href="#cb267-3942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3943"><a href="#cb267-3943" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3944"><a href="#cb267-3944" aria-hidden="true" tabindex="-1"></a><span class="co"># test PipeOp</span></span>
<span id="cb267-3945"><a href="#cb267-3945" aria-hidden="true" tabindex="-1"></a>tsk_ames_ext <span class="ot">=</span> <span class="fu">cbind</span>(ames, energy_data)</span>
<span id="cb267-3946"><a href="#cb267-3946" aria-hidden="true" tabindex="-1"></a>tsk_ames_ext <span class="ot">=</span> <span class="fu">as_task_regr</span>(tsk_ames_ext, <span class="st">"Sale_Price"</span>, <span class="st">"ames_ext"</span>)</span>
<span id="cb267-3947"><a href="#cb267-3947" aria-hidden="true" tabindex="-1"></a><span class="co"># remove the redundant variables identified at the start of this chapter</span></span>
<span id="cb267-3948"><a href="#cb267-3948" aria-hidden="true" tabindex="-1"></a>tsk_ames_ext<span class="sc">$</span><span class="fu">select</span>(<span class="fu">setdiff</span>(tsk_ames_ext<span class="sc">$</span>feature_names, to_remove))</span>
<span id="cb267-3949"><a href="#cb267-3949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3950"><a href="#cb267-3950" aria-hidden="true" tabindex="-1"></a>func_extractor <span class="ot">=</span> PipeOpFuncExtract<span class="sc">$</span><span class="fu">new</span>(<span class="st">"energy_extract"</span>)</span>
<span id="cb267-3951"><a href="#cb267-3951" aria-hidden="true" tabindex="-1"></a>tsk_ames_ext <span class="ot">=</span> func_extractor<span class="sc">$</span><span class="fu">train</span>(<span class="fu">list</span>(tsk_ames_ext))[[<span class="dv">1</span>]]</span>
<span id="cb267-3952"><a href="#cb267-3952" aria-hidden="true" tabindex="-1"></a>tsk_ames_ext<span class="sc">$</span><span class="fu">data</span>(<span class="dv">1</span>,</span>
<span id="cb267-3953"><a href="#cb267-3953" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">c</span>(<span class="st">"energy_means"</span>, <span class="st">"energy_mins"</span>, <span class="st">"energy_maxs"</span>, <span class="st">"energy_vars"</span>))</span>
<span id="cb267-3954"><a href="#cb267-3954" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3955"><a href="#cb267-3955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3956"><a href="#cb267-3956" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3957"><a href="#cb267-3957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3958"><a href="#cb267-3958" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3959"><a href="#cb267-3959" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb267-3960"><a href="#cb267-3960" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">list</span>(lrn_baseline, <span class="fu">lrn</span>(<span class="st">"regr.rpart"</span>), glrn_xgb_impact,</span>
<span id="cb267-3961"><a href="#cb267-3961" aria-hidden="true" tabindex="-1"></a>                glrn_rf_impute_oor, glrn_lm_robust, glrn_log_lm_robust)</span>
<span id="cb267-3962"><a href="#cb267-3962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3963"><a href="#cb267-3963" aria-hidden="true" tabindex="-1"></a>bmr_final <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(<span class="fu">c</span>(tsk_ames_ext, tsk_ames), learners, rsmp_cv3))</span>
<span id="cb267-3964"><a href="#cb267-3964" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3965"><a href="#cb267-3965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3966"><a href="#cb267-3966" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb267-3967"><a href="#cb267-3967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3968"><a href="#cb267-3968" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb267-3969"><a href="#cb267-3969" aria-hidden="true" tabindex="-1"></a>perf <span class="ot">=</span> bmr_final<span class="sc">$</span><span class="fu">aggregate</span>(msr_mae)</span>
<span id="cb267-3970"><a href="#cb267-3970" aria-hidden="true" tabindex="-1"></a>perf[<span class="fu">order</span>(learner_id, task_id), .(task_id, learner_id, regr.mae)]</span>
<span id="cb267-3971"><a href="#cb267-3971" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb267-3972"><a href="#cb267-3972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3973"><a href="#cb267-3973" aria-hidden="true" tabindex="-1"></a>The final results indicate that adding these extracted features improved the performance of all models (except the featureless baseline).</span>
<span id="cb267-3974"><a href="#cb267-3974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3975"><a href="#cb267-3975" aria-hidden="true" tabindex="-1"></a>In this example, we could have just applied the transformations to the dataset directly and not used a <span class="in">`PipeOp`</span>. However, the advantage of using the <span class="in">`PipeOp`</span> is that we could have chained it to a subset of learners to prevent a blow-up of experiments in the benchmark experiment.</span>
<span id="cb267-3976"><a href="#cb267-3976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3977"><a href="#cb267-3977" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 最终结果显示，添加这些提取的特征提高了所有模型的性能（除了没有特征的基线模型）。</span></span>
<span id="cb267-3978"><a href="#cb267-3978" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb267-3979"><a href="#cb267-3979" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 在这个例子中，我们本可以直接将这些变换应用于数据集，而不使用</span><span class="in">`PipeOp`</span><span class="at">。然而，使用</span><span class="in">`PipeOp`</span><span class="at">的优势在于我们可以将它链接到一部分学习器上，以防止在基准实验中引发大规模的实验。</span></span>
<span id="cb267-3980"><a href="#cb267-3980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3981"><a href="#cb267-3981" aria-hidden="true" tabindex="-1"></a><span class="fu"># Advanced Topics {-}</span></span>
<span id="cb267-3982"><a href="#cb267-3982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3983"><a href="#cb267-3983" aria-hidden="true" tabindex="-1"></a><span class="fu"># Advanced Technical Aspects of mlr3</span></span>
<span id="cb267-3984"><a href="#cb267-3984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3985"><a href="#cb267-3985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3986"><a href="#cb267-3986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3987"><a href="#cb267-3987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3988"><a href="#cb267-3988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3989"><a href="#cb267-3989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3990"><a href="#cb267-3990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3991"><a href="#cb267-3991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3992"><a href="#cb267-3992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3993"><a href="#cb267-3993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3994"><a href="#cb267-3994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3995"><a href="#cb267-3995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3996"><a href="#cb267-3996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3997"><a href="#cb267-3997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3998"><a href="#cb267-3998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-3999"><a href="#cb267-3999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4000"><a href="#cb267-4000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4001"><a href="#cb267-4001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4002"><a href="#cb267-4002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4003"><a href="#cb267-4003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4004"><a href="#cb267-4004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4005"><a href="#cb267-4005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4006"><a href="#cb267-4006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4007"><a href="#cb267-4007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4008"><a href="#cb267-4008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4009"><a href="#cb267-4009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4010"><a href="#cb267-4010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4011"><a href="#cb267-4011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4012"><a href="#cb267-4012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4013"><a href="#cb267-4013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4014"><a href="#cb267-4014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4015"><a href="#cb267-4015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4016"><a href="#cb267-4016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4017"><a href="#cb267-4017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4018"><a href="#cb267-4018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4019"><a href="#cb267-4019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4020"><a href="#cb267-4020" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="To be continued"}</span>
<span id="cb267-4021"><a href="#cb267-4021" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="ot">&lt;https://mlr3book.mlr-org.com/chapters/chapter10/advanced_technical_aspects_of_mlr3.html&gt;</span></span>
<span id="cb267-4022"><a href="#cb267-4022" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb267-4023"><a href="#cb267-4023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4024"><a href="#cb267-4024" aria-hidden="true" tabindex="-1"></a>等待交叉引用：</span>
<span id="cb267-4025"><a href="#cb267-4025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4026"><a href="#cb267-4026" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Section 10.1</span>
<span id="cb267-4027"><a href="#cb267-4027" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>10.1.3</span>
<span id="cb267-4028"><a href="#cb267-4028" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>10.2.1</span>
<span id="cb267-4029"><a href="#cb267-4029" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>11.3</span>
<span id="cb267-4030"><a href="#cb267-4030" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>13.1</span>
<span id="cb267-4031"><a href="#cb267-4031" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Chapter 14</span></code></pre></div>
</div>
</section></main><!-- /main --><div class="giscus">
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("https:\/\/learn\.shitao5\.org\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
      <div class="footer-contents">Copyright 2023, [Shitao5](https://shitao5.org/)</div>  
    </div>   
    <div class="nav-footer-center">
       
    </div>
    <div class="nav-footer-right">
      <div class="footer-contents">This blog is built with [Quarto](https://quarto.org/)❤️.</div>  
    </div>
  </div>
</footer>
</div>
</body>
</html>
